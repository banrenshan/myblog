[{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"exemplars exemplar表示在给定时间间隔内的metrics对应的trace。虽然metrics擅长为您提供系统的聚合视图，但trace可以为您提供单个请求的细粒度视图；exemplar是将两者联系起来的一种方式。\n假设您的公司网站正在经历流量激增。虽然超过80%的用户能够在两秒内访问网站，但一些用户的响应时间比正常时间长，导致用户体验不佳。要确定导致延迟的因素，必须将快速响应的trace与慢速响应的trace进行比较。考虑到典型生产环境中的大量数据，这将是一项极其费力和耗时的工作。\n使用exemplars，查询在一段时间间隔内表现出高延迟的trace，帮助诊断数据分布中的问题。一旦将延迟问题定位为几个exemplars trace，就可以将其与其他基于系统的信息或位置属性相结合，以更快地执行根本原因分析，从而快速解决性能问题。\n对exemplars的支持仅适用于Prometheus数据源。启用该功能后，默认情况下exemplars数据可用。具体配置参考 configuring exemplars in Prometheus data source\nGrafana在Explore视图和仪表板中显示了exemplars以及metrics。每个exemplars为突出显示的星形。您可以将光标悬停在exemplars上查看更多，它是键值对的组合。要进一步调查，请单击traceID属性旁边的蓝色按钮。\n配置 Grafana具有默认和自定义配置文件。您可以通过修改自定义配置文件或使用环境变量来自定义Grafana实例。Grafana实例的默认设置存储在$WORKING_DIR/conf/defaults.ini 文件。不要更改此文件。你可以使用 \u0026ndash;config 参数指定自定义文件。\nGrafana使用分号（；）注释.ini文件中的行。\n变量替换 不要使用环境变量添加新的配置。相反，使用环境变量替代现有选项。\nGF_\u0026lt;SectionName\u0026gt;_\u0026lt;KeyName\u0026gt; SectionName 和 KeyName要全大写 . 和 - 要替换成 _ # default section instance_name = ${HOSTNAME} [security] admin_user = admin [auth.google] client_secret = 0ldS3cretKey [plugin.grafana-image-renderer] rendering_ignore_https_errors = true [feature_toggles] enable = newNavigation export GF_DEFAULT_INSTANCE_NAME=my-instance export GF_SECURITY_ADMIN_USER=owner export GF_AUTH_GOOGLE_CLIENT_SECRET=newS3cretKey export GF_PLUGIN_GRAFANA_IMAGE_RENDERER_RENDERING_IGNORE_HTTPS_ERRORS=true export GF_FEATURE_TOGGLES_ENABLE=newNavigation 变量扩展 如果配置包含表达式$__\u0026lt;provider\u0026gt;{\u0026lt;argument\u0026gt;}或${\u0026lt;environmentvariable\u0026gt;}，则它们将由Grafana的变量扩展器处理。有三个提供程序：env、file和vault。\nEnv provider env提供程序可用于扩展环境变量。如果将选项设置为$__env｛PORT｝，则将在其位置使用PORT环境变量。对于环境变量，您还可以使用速记语法${PORT}。\n[paths] logs = $__env{LOGDIR}/grafana File provider file从文件系统读取文件。它删除文件开头和结尾的空白。以下示例中的数据库密码将替换为/etc/secrets/gf_sql_password文件的内容：\n[database] password = $__file{/etc/secrets/gf_sql_password} Vault provider vault提供程序允许您使用Hashicorp vault管理机密。\n主要配置项 app_mode：可选值是production（默认） 和 development. 除非您正在开发Grafana，否则不要更改此选项。\ninstance_name：设置grafana服务器实例的名称。用于日志记录、内部度量和群集信息。默认值为：${HOSTNAME｝，如果环境变量HOSTNAME为空或不存在，则该变量将被替换为HOSTNAME,Grafana将尝试使用系统调用获取机器名称。\nforce_migration: 强制迁移可能导致数据丢失。默认值为false。\npaths\ndata: Grafana存储sqlite3数据库（如果使用）、基于文件的会话（如果使用的话）和其他数据的路径。此路径通常通过init.d脚本或systemd服务文件指定。\ntemp_data_lifetime: 数据目录中的临时图片应保留多长时间。默认值为：24小时。支持的修饰符：h（小时）、m（分钟），例如：168h、30m、10h30m。使用0从不清理临时文件。\nlogs: Grafana存储日志的路径。此路径通常通过init.d脚本或systemd服务文件指定。您可以在配置文件或默认环境变量文件中覆盖它。但是，请注意，在Grafana完全初始化/启动之前，将临时使用默认日志路径。\n./grafana-server --config /custom/config.ini --homepath /custom/homepath cfg:default.paths.logs=/custom/path plugins:Grafana自动扫描和查找插件的目录。\nprovisioning: 包含Grafana将在启动时应用的配置文件的文件夹。当json文件更改时，仪表板将重新加载。\ndatabase: Grafana需要一个数据库来存储用户和仪表盘（以及其他东西）。默认情况下，它被配置为使用sqlite3，这是一个嵌入式数据库。\ntype: 可选值 mysql, postgres ，sqlite3 remote_cache：在配置的数据库Redis或Memcached中缓存身份验证详细信息和会话信息。此设置不配置Grafana Enterprise中的查询缓存。\nlog：\nmode： 可选值 “console”, “file”, “syslog”， 默认是 console file. level： “debug”, “info”, “warn”, “error”, “critical”. filters：为特定记录器设置不同级别的可选设置，例如 filters = sqlstore:debug grafana对外暴漏的指标信息：\nActive Grafana instances Number of dashboards, users, and playlists HTTP status codes Requests by routing group Grafana active alerts Grafana performance Provision 可以在配置文件中使用环境变量插值。允许的语法是$ENV_VAR_NAME或${ENV_VAR_NAME}，并且只能用于值，而不能用于键。它在仪表板的定义文件中不可用，只能仪表板provisioning配置中使用。例子：\ndatasources: - name: Graphite url: http://localhost:$PORT user: $USER secureJsonData: password: $PASSWORD 如果您的值中有一个文字$，并且希望避免插值，则可以使用$$。\n目前，我们没有提供任何用于配置Grafana的脚本。但是有几个社区支持：\nPuppet https://forge.puppet.com/puppet/grafana Ansible https://github.com/cloudalchemy/ansible-grafana Chef https://github.com/JonathanTron/chef-grafana Saltstack https://github.com/salt-formulas/salt-formula-grafana Jsonnet https://github.com/grafana/grafonnet-lib/ 配置数据源 您可以通过在provision/datasources目录中添加YAML配置文件来管理Grafana中的数据源。每个配置文件都可以包含启动期间要添加或更新的数据源列表。如果数据源已经存在，Grafana会重新配置它以匹配配置的配置文件。\n配置文件还可以列出要自动删除的数据源，称为deleteDatasources。Grafana删除deleteDatasources中列出的数据源，然后再添加或更新数据源列表中的数据源。\n如果运行多个Grafana实例，请在配置中为每个数据源添加版本号，并在更新配置时增加版本号。Grafana仅更新版本号与配置中指定的版本号相同或更低的数据源。\n由于并非所有数据源都具有相同的配置设置，因此我们只将最常见的作为字段。要提供数据源的其余设置，请将它们作为JSON blob包含在jsonData字段中。\n可以在Grafana UI中更改已配置的仪表板。但是，无法将更改自动保存回调配源。如果allowUiUpdates设置为true，并且您对配置的仪表板进行了更改，则可以保存仪表板，然后将更改保存到Grafana数据库中。\n如果allowUiUpdates配置为false，则无法对配置的仪表板进行更改。单击“保存”时，Grafana将显示“无法保存已配置的仪表板”对话框。下面的截图说明了这种行为。\n如果JSON文件中的仪表板包含UID，Grafana会强制插入/更新该UID。这允许您在Grafana实例之间迁移仪表板，并从配置中配置Grafana，而不破坏给定的URL，因为新的仪表板URL使用UID作为标识符。Grafana启动时，会更新/插入配置文件夹中的所有可用仪表板。如果修改文件，则仪表板也会更新。默认情况下，如果文件被删除，Grafana会删除数据库中的仪表板。可以使用disableDelete设置禁用此行为。\n如果您已经使用git repo或文件系统中的文件夹存储仪表板，并且希望在Grafana菜单中具有相同的文件夹名称，则可以使用foldersFromFilesStructure选项。例如，为了将这些仪表板结构从文件系统复制到Grafana：\n/etc/dashboards ├── /server │ ├── /common_dashboard.json │ └── /network_dashboard.json └── /application ├── /requests_dashboard.json └── /resources_dashboard.json 您只需要指定这个简短的配置文件:\napiVersion: 1 providers: - name: dashboards type: file updateIntervalSeconds: 30 options: path: /etc/dashboards foldersFromFilesStructure: true folder和folderUid选项应为空或缺失，以使foldersFromFilesStructure正常工作。\n要将仪表板设置到“General”文件夹，请将它们存储在路径的根目录中。\nAlerting 警报基础设施通常是复杂的，其中许多管道通常位于不同的地方。在多个团队和组织中扩展这一点是一项特别具有挑战性的任务。Grafana Alerting provisioning使您能够以最适合您的组织的方式创建、管理和维护警报数据，从而使此过程更加简单。\n有三个选项可供选择：\n使用文件provisioning 通过磁盘上的文件配置Grafana Alerting资源，如警报规则和联系人。 使用警报配置HTTP API provisioning 警报资源。通常，您无法从Grafana UI编辑API provisioning 的警报规则。为了启用编辑，在API中创建或编辑警报规则时，将x-disable-provenance标头添加到以下请求中： POST /api/v1/provisioning/alert-rules PUT /api/v1/provisioning/alert-rules/{UID} 使用Terraform配置您的警报资源。 目前，Grafana Alerting的provisioning 支持警报规则、联系人、静音计时和模板。使用文件配置或Terraform配置的警报资源只能在创建它们的源中编辑，而不能在Grafana或任何其他源中编辑。例如，如果您使用磁盘上的文件配置警报资源，则无法在Terraform或Grafana中编辑数据。\nfile provisioning 使用磁盘中的文件配置警报资源。启动Grafana时，这些文件中的数据将在Grafana系统中创建。Grafana添加您创建的任何新资源，更新您更改的任何资源，并删除旧资源。\n以最适合您的用例的方式在目录中排列文件。例如，您可以选择基于团队的布局，其中每个团队都有自己的文件，您可以为所有团队创建一个大文件；或者每个资源类型可以有一个文件。\n下面列出了有关如何设置文件以及每个对象需要哪些字段的详细信息，具体取决于您正在配置的资源。\n具体操作步骤：\n在Grafana中创建警报规则。 使用警报设置API提取警报规则。 将内容复制到YAML或JSON配置文件中。 确保您的文件位于运行Grafana服务器的节点上的正确目录中，以便它们与Grafana实例一起部署。 删除Grafana中的警报规则。如果不删除警报规则，则上载后将与设置的警报规则冲突。 下面是用于创建警报规则的配置文件的示例。\n# config file version apiVersion: 1 # List of rule groups to import or update groups: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgId: 1 # \u0026lt;string, required\u0026gt; name of the rule group name: my_rule_group # \u0026lt;string, required\u0026gt; name of the folder the rule group will be stored in folder: my_first_folder # \u0026lt;duration, required\u0026gt; interval that the rule group should evaluated at interval: 60s # \u0026lt;list, required\u0026gt; list of rules that are part of the rule group rules: # \u0026lt;string, required\u0026gt; unique identifier for the rule - uid: my_id_1 # \u0026lt;string, required\u0026gt; title of the rule that will be displayed in the UI title: my_first_rule # \u0026lt;string, required\u0026gt; which query should be used for the condition condition: A # \u0026lt;list, required\u0026gt; list of query objects that should be executed on each # evaluation - should be obtained trough the API data: - refId: A datasourceUid: \u0026#39;-100\u0026#39; model: conditions: - evaluator: params: - 3 type: gt operator: type: and query: params: - A reducer: type: last type: query datasource: type: __expr__ uid: \u0026#39;-100\u0026#39; expression: 1==0 intervalMs: 1000 maxDataPoints: 43200 refId: A type: math # \u0026lt;string\u0026gt; UID of a dashboard that the alert rule should be linked to dashboardUid: my_dashboard # \u0026lt;int\u0026gt; ID of the panel that the alert rule should be linked to panelId: 123 # \u0026lt;string\u0026gt; the state the alert rule will have when no data is returned # possible values: \u0026#34;NoData\u0026#34;, \u0026#34;Alerting\u0026#34;, \u0026#34;OK\u0026#34;, default = NoData noDataState: Alerting # \u0026lt;string\u0026gt; the state the alert rule will have when the query execution # failed - possible values: \u0026#34;Error\u0026#34;, \u0026#34;Alerting\u0026#34;, \u0026#34;OK\u0026#34; # default = Alerting # \u0026lt;duration, required\u0026gt; for how long should the alert fire before alerting for: 60s # \u0026lt;map\u0026lt;string, string\u0026gt;\u0026gt; a map of strings to pass around any data annotations: some_key: some_value # \u0026lt;map\u0026lt;string, string\u0026gt; a map of strings that can be used to filter and # route alerts labels: team: sre_team_1 下面是用于删除警报规则的配置文件的示例。\n# config file version apiVersion: 1 # List of alert rule UIDs that should be deleted deleteRules: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgId: 1 # \u0026lt;string, required\u0026gt; unique identifier for the rule uid: my_id_1 Provision 联系人 在Grafana实例中创建或删除联系人。\n创建YAML或JSON配置文件。 将文件添加到GitOps工作流中，以便它们与Grafana实例一起部署。 # config file version apiVersion: 1 # List of contact points to import or update contactPoints: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgId: 1 # \u0026lt;string, required\u0026gt; name of the contact point name: cp_1 receivers: # \u0026lt;string, required\u0026gt; unique identifier for the receiver - uid: first_uid # \u0026lt;string, required\u0026gt; type of the receiver type: prometheus-alertmanager # \u0026lt;object, required\u0026gt; settings for the specific receiver type settings: url: http://test:9000 以下是用于删除联系人的配置文件的示例。\n# config file version apiVersion: 1 # List of receivers that should be deleted deleteContactPoints: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgId: 1 # \u0026lt;string, required\u0026gt; unique identifier for the receiver uid: first_uid Provision 通知策略 创建YAML或JSON配置文件。 将文件添加到GitOps工作流中，以便它们与Grafana实例一起部署。 # config file version apiVersion: 1 # List of notification policies policies: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgId: 1 # \u0026lt;string\u0026gt; name of the contact point that should be used for this route receiver: grafana-default-email # \u0026lt;list\u0026gt; The labels by which incoming alerts are grouped together. For example, # multiple alerts coming in for cluster=A and alertname=LatencyHigh would # be batched into a single group. # # To aggregate by all possible labels use the special value \u0026#39;...\u0026#39; as # the sole label name, for example: # group_by: [\u0026#39;...\u0026#39;] # This effectively disables aggregation entirely, passing through all # alerts as-is. This is unlikely to be what you want, unless you have # a very low alert volume or your upstream notification system performs # its own grouping. group_by: [\u0026#39;...\u0026#39;] # \u0026lt;list\u0026gt; a list of matchers that an alert has to fulfill to match the node matchers: - alertname = Watchdog - severity =~ \u0026#34;warning|critical\u0026#34; # \u0026lt;list\u0026gt; Times when the route should be muted. These must match the name of a # mute time interval. # Additionally, the root node cannot have any mute times. # When a route is muted it will not send any notifications, but # otherwise acts normally (including ending the route-matching process # if the `continue` option is not set) mute_time_intervals: - abc # \u0026lt;duration\u0026gt; How long to initially wait to send a notification for a group # of alerts. Allows to collect more initial alerts for the same group. # (Usually ~0s to few minutes), default = 30s group_wait: 30s # \u0026lt;duration\u0026gt; How long to wait before sending a notification about new alerts that # are added to a group of alerts for which an initial notification has # already been sent. (Usually ~5m or more), default = 5m group_interval: 5m # \u0026lt;duration\u0026gt; How long to wait before sending a notification again if it has already # been sent successfully for an alert. (Usually ~3h or more), default = 4h repeat_interval: 4h # \u0026lt;list\u0026gt; Zero or more child routes # routes: # ... 下面是用于重置通知策略的配置文件的示例:\n# config file version apiVersion: 1 # List of orgIds that should be reset to the default policy resetPolicies: - 1 Provision 通知模板 # config file version apiVersion: 1 # List of templates to import or update templates: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgID: 1 # \u0026lt;string, required\u0026gt; name of the template, must be unique name: my_first_template # \u0026lt;string, required\u0026gt; content of the the template template: Alerting with a custom text template 删除模板：\n# config file version apiVersion: 1 # List of alert rule UIDs that should be deleted deleteTemplates: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgId: 1 # \u0026lt;string, required\u0026gt; name of the template, must be unique name: my_first_template Provision 静默 # config file version apiVersion: 1 # List of mute time intervals to import or update muteTimes: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgId: 1 # \u0026lt;string, required\u0026gt; name of the mute time interval, must be unique name: mti_1 # \u0026lt;list\u0026gt; time intervals that should trigger the muting # refer to https://prometheus.io/docs/alerting/latest/configuration/#time_interval-0 time_intervals: - times: - start_time: \u0026#39;06:00\u0026#39; end_time: \u0026#39;23:59\u0026#39; weekdays: [\u0026#39;monday:wednesday\u0026#39;, \u0026#39;saturday\u0026#39;, \u0026#39;sunday\u0026#39;] months: [\u0026#39;1:3\u0026#39;, \u0026#39;may:august\u0026#39;, \u0026#39;december\u0026#39;] years: [\u0026#39;2020:2022\u0026#39;, \u0026#39;2030\u0026#39;] days_of_month: [\u0026#39;1:5\u0026#39;, \u0026#39;-3:-1\u0026#39;] 删除静默：\n# config file version apiVersion: 1 # List of mute time intervals that should be deleted deleteMuteTimes: # \u0026lt;int\u0026gt; organization ID, default = 1 - orgId: 1 # \u0026lt;string, required\u0026gt; name of the mute time interval, must be unique name: mti_1 Alert Notification Channels ","date":"2022年12月10日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/grafana/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1670680572,"title":"Grafana"},{"authors":[],"categories":[{"title":"中间件","url":"/myblog/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"content":"核心概念 1. Gradle 是一个通用的构建工具 Gradle 可以用于构建（build）任何软件，因为它对你要构建的东西或构建方式几乎不做任何假设。不过当前它最大的限制是，只支持兼容 Maven 和 lvy 的仓库和文件系统。\n这并不意味着你需要为构建做许多工作。Gradle 可以通过插件（plugins）添加一层约定（convention）以及预构建功能（prebuild functionality）来让常见的项目类型，例如 Java 库，更容易被构建。你甚至能将自己的约定和构建功能封装成插件来发布。\n2. 核心模型基于 task task 是 Gradle 的工作单元。Gradle 的构建模型就是一个 task 的定向无环图（Directed Acyclic Graphs, DAGs）。也就是说，构建本质上是在配置一个由 task 组成的定向无环图。task 之间根据它们的依赖关系相连。一旦 task 图被创建，Gradle 就能确定该以何种顺序执行 task。\n这张图显示了两个 task 图的例子，一个是抽象的，一个是具体的，task 之间的依赖关系用箭头表示：\n几乎所有的构建过程都可以通过这种方式建模为一个 task 图，这也是 Gradle 灵活的原因之一。而且这个 task 图可以由插件和你的构建脚本来定义，并通过 task 依赖机制将 task 连接起来。\n一个 task 包括：\n动作（Actions）——执行某些工作。例如复制文件或者编译源码。 输入（Inputs）——给动作使用或操作的值、文件和目录 输出（Outputs）——由动作修改或生成的文件和目录 以上内容都是可选的，使用与否取决于实际需要。一些 task，比如标准生命周期 task（standard lifecycle tasks），甚至没有任何动作。它们只是将多个任务聚合在一起，以方便使用。\n你可以选择你需要的 task 来运行。为了节约时间，请选择刚好能满足需要的 task。如果想运行单元测试，就选择执行单元测试的 task——通常是 test。如果想打包一个应用，大多数构建都提供一个 assemble task 以供使用。\n最后，Gradle 的增量构建支持强大而又可靠，所以为了保持构建的运行速度，请避免运行 clean task，除非你确实想执行清理。\n3. Gradle 的多个固定构建阶段 Gradle 会在三个阶段（phases）评估（evaluates）并执行（execute）构建脚本。理解这三个阶段非常重要。\n初始化（Initialization） 设置构建的环境，并明确哪些项目将参与其中。 配置（Configuration） 构造并配置构建的 task 图。然后根据用户想要运行的 task，确定需要运行哪些任务，以及运行的顺序。 执行（Execution） 运行配置阶段结束时选择的 task。 这些阶段组成了 Gradle 的构建生命周期（Build Lifecycle）。\n与 Apache Maven 术语的比较\nGradle 的“构建阶段”与 Maven 的“阶段”不同。Maven 的“阶段”将构建执行划分成了多个部分。它们的作用类似于 Gradle 的 task 图，尽管没有那么灵活。\nMaven 的构建生命周期概念与 Gradle 的生命周期 task 大致相似。\n设计良好的构建脚本主要由声明式配置组成，而非命令式逻辑。容易理解的是，这些配置在配置阶段就会被评估。但许多构建也有 task 动作（例如通过 doLast {} 和 doFirst {} 添加的），它们在执行阶段被评估。理解这一点非常重要，因为配置阶段评估的代码无法感知到执行阶段发生的变化。\n配置阶段的另一个重要方面是，每当构建运行时，都会对其中涉及的一切进行评估。因此要避免在配置阶段做复杂的工作。除此之外，构建扫描（build scan）可以帮助你识别这样的热点。\n4. Gradle 可以使用多种方式进行扩展 如果你能用 Gradle 内建的构建逻辑来构建你的项目，那再好不过了。然而事实往往没有这么顺利。大多数构建都有一些特殊的要求，这就要求你能添加自定义构建逻辑。\nGradle 提供了多种机制来进行扩展，比如：\n自定义 task 类型 当你想让构建做一些现有 task 不能做的工作时，你可以简单地编写自己的 task 类型。通常最好把自定义 task 类型的源文件放在 buildSrc 目录或打包的插件中。然后你就可以像使用任何 Gradle 内建的 task 类型一样，使用这个自定义 task 类型。 自定义 task 动作 你可以通过 Task.doFirst() 和 Task.doLast() 方法将自定义构建逻辑附加在 task 之前或之后执行。 项目和 task 的额外属性 你可以将自定义属性添加到项目或 task 中，并在自定义动作或任何其他构建逻辑中使用。额外的属性甚至能被应用到那些不是由你明确创建的 task 上，比如由 Gradle 核心插件创建的 task。 自定义约定 约定是简化构建的有力方法，它可以让用户更容易理解和使用。这可以从标准项目结构和命名约定中看出，比如 Java 构建。你可以编写你自己的插件来提供约定，它们只需要为构建的相关方面配置默认值。 自定义模型 Gradle 允许你在构建中引入除了 task、文件、依赖配置之外的新概念。你可以在大多数语言插件中看到这一点，它们将源集（source sets）的概念添加到了构建之中。对构建过程进行适当的建模可以大大提高构建的易用性和效率。 5. 用构建脚本操作 API Gradle 的构建脚本看起来像可执行代码，实际上它的确是。这里有一个实现细节：设计良好的构建脚本描述了构建软件需要哪些（what）步骤，而不是这些步骤应该如何（how）完成工作。那是自定义任务类型和插件的工作。\n有一个普遍的误解，认为 Gradle 的强大和灵活来自于它的构建脚本是代码这一事实。这个观点完全错误。实际上那是底层模型和 API 提供的力量。正如我们在最佳实践中所建议的那样，你应该避免在你的构建脚本中放入过多的命令式逻辑。\n然而，有一个领域，“将构建脚本视为可执行代码”在此领域是很有用的，即：理解构建脚本的语法如何映射到 Gradle 的 API。API 文档（由 Groovy DSL 参考和 Javadocs 组成）中列出了方法、属性并题及了闭包和动作。它们在构建脚本的上下文中有什么含义？请阅读 Groovy 构建脚本入门来获得这个问题的答案。这能帮助你有效地使用 API 文档。\n由于 Gradle 运行在 JVM 上，构建脚本也可以使用标准的 Java API。Groovy 构建脚本可以额外使用 Groovy API，而 Kotlin 构建脚本可以使用 Kotlin 的。\nGradle生命周期 build.gradle文件 build脚本构建有三个阶段：\n初始化: Gradle 支持单项目和多项目构建。在初始化阶段，Gradle 确定哪些项目将参与构建，并为每个项目创建Project实例。 配置: 配置Project对象。 all 脚本里面的内容被执行用来配置所有项目。 执行：Gradle 确定要执行的任务子集，这些任务在配置阶段创建和配置。子集由传递给gradle命令的任务名称参数和当前目录确定。然后，Gradle 执行每个选定的任务。 settings.gradle文件 设置文件在初始化阶段执行。multi-project项目必须在根目录创建settings文件，因为该文件定义了哪些项目参与构建。对于单项目，设置文件是可选的。除了定义包含的项目之外，您可能还需要它来将库添加到构建脚本类路径。\n示例：单项目的构建配置\nsettings.gradle\nrootProject.name = \u0026#39;basic\u0026#39; println \u0026#39;This is executed during the initialization phase.\u0026#39; build.gradle\nprintln \u0026#39;This is executed during the configuration phase.\u0026#39; tasks.register(\u0026#39;configured\u0026#39;) { println \u0026#39;This is also executed during the configuration phase, because :configured is used in the build.\u0026#39; } tasks.register(\u0026#39;test\u0026#39;) { doLast { println \u0026#39;This is executed during the execution phase.\u0026#39; } } tasks.register(\u0026#39;testBoth\u0026#39;) { doFirst { println \u0026#39;This is executed first during the execution phase.\u0026#39; } doLast { println \u0026#39;This is executed last during the execution phase.\u0026#39; } println \u0026#39;This is executed during the configuration phase as well, because :testBoth is used in the build.\u0026#39; } 输出结果：\n\u0026gt; gradle test testBoth This is executed during the initialization phase. \u0026gt; Configure project : This is executed during the configuration phase. This is executed during the configuration phase as well, because :testBoth is used in the build. \u0026gt; Task :test This is executed during the execution phase. \u0026gt; Task :testBoth This is executed first during the execution phase. This is executed last during the execution phase. BUILD SUCCESSFUL in 0s 2 actionable tasks: 2 executed 对于Build脚本，属性访问和方法调用的目标对象都是project。而settings脚本的目标对象是settings。\n初始化 Gradle 如何知道是进行单项目构建还是多项目构建？如果你触发构建的目录存在settings.gradle文件，gradle会使用该文件进行build。gradle也允许你在任何子项目目录下进行构建。当gradle运行的时候当前目录不存在settings.gradle文件，将会按照下面的方式查找：\n在父目录中查找 如果没有发现，按照单项目执行 如果发现，Gradle 会检查当前项目是否是多项目层次结构的一部分。如果不是，则作为单个项目执行。否则，将执行多项目build。 此行为的目的是什么？Gradle 需要确定您所处的项目是否为多项目构建的子项目。当然，如果是子项目，则仅构建子项目及其依赖项目，但是gradle需要为整个多项目创建build配置。\n生命周期监听 监听构建过程有两种方式：实现监听器接口或触发执行闭包。\n你可以在项目evaluated之前或之后收到通知。这在可以在所有build脚本被定义后加入一些自己的逻辑，例如日志和监控。\n下面是一个示例，该示例向hasTests属性值为 true 的每个项目添加一个任务。\nbuild.gradle\nallprojects { afterEvaluate { project -\u0026gt; if (project.hasTests) { println \u0026#34;Adding test task to $project\u0026#34; project.task(\u0026#39;test\u0026#39;) { doLast { println \u0026#34;Running tests for $project\u0026#34; } } } } } project-a.gradle\nhasTests = true 输出：\n\u0026gt; gradle -q test Adding test task to project \u0026#39;:project-a\u0026#39; Running tests for project \u0026#39;:project-a\u0026#39; 评估任何项目时，也可以接收通知。此示例执行项目评估的一些自定义日志记录。请注意，无论项目评估成功还是失败并出现异常，都会收到通知。\nbuild.gradle\ngradle.afterProject { project -\u0026gt; if (project.state.failure) { println \u0026#34;Evaluation of $project FAILED\u0026#34; } else { println \u0026#34;Evaluation of $project succeeded\u0026#34; } } 输出：\n\u0026gt; gradle -q test Evaluation of root project \u0026#39;build-project-evaluate-events\u0026#39; succeeded Evaluation of project \u0026#39;:project-a\u0026#39; succeeded Evaluation of project \u0026#39;:project-b\u0026#39; FAILED FAILURE: Build failed with an exception. * Where: Build file \u0026#39;/home/user/gradle/samples/project-b.gradle\u0026#39; line: 1 * What went wrong: A problem occurred evaluating project \u0026#39;:project-b\u0026#39;. \u0026gt; broken * Try: \u0026gt; Run with --stacktrace option to get the stack trace. \u0026gt; Run with --info or --debug option to get more log output. \u0026gt; Run with --scan to get full insights. * Get more help at https://help.gradle.org BUILD FAILED in 0s 将任务添加到项目后，您可以立即收到通知。这可用于在构建文件中提供任务之前设置一些默认值或添加行为。\n下面的示例在创建每个任务时设置srcDir属性\nbuild.gradle\ntasks.whenTaskAdded { task -\u0026gt; task.ext.srcDir = \u0026#39;src/main/java\u0026#39; } tasks.register(\u0026#39;a\u0026#39;) println \u0026#34;source dir is $a.srcDir\u0026#34; 输出：\n\u0026gt; gradle -q a source dir is src/main/java 您可以在执行任何任务之前和之后立即收到通知。\n下面的示例记录每个任务执行的开始和结束。请注意，无论任务是成功完成还是失败并出现异常，都会收到通知。\nbuild.gradle\ntasks.register(\u0026#39;ok\u0026#39;) tasks.register(\u0026#39;broken\u0026#39;) { dependsOn ok doLast { throw new RuntimeException(\u0026#39;broken\u0026#39;) } } gradle.taskGraph.beforeTask { Task task -\u0026gt; println \u0026#34;executing $task ...\u0026#34; } gradle.taskGraph.afterTask { Task task, TaskState state -\u0026gt; if (state.failure) { println \u0026#34;FAILED\u0026#34; } else { println \u0026#34;done\u0026#34; } } gradle使用的目录和文件 Gradle 使用两个主要目录来执行和管理其工作：Gradle 用户主目录和项目根目录。以下两节介绍每个部分中存储的内容以及如何清理瞬态文件和目录。\nGradle 用户主目录 Gradle 用户主目录（默认情况下）用于存储全局配置属性和初始化脚本以及缓存和日志文件。其结构大致如下：$USER_HOME/.gradle\n全局缓存目录（用于非项目特定的所有内容） 特定于版本的缓存（例如，支持增量构建） 共享缓存（例如，用于依赖项的工件） Gradle 守护进程的注册表和日志 全局初始化脚本 工具链支持下载的 JDK 由 Gradle Wrapper 下载的发行版 全局 Gradle 配置属性 清理缓存和分发 从版本 4.10 开始，Gradle 会自动清理其用户主目录。当 Gradle 守护程序停止或关闭时，清理将在后台运行。如果使用 --no-daemon，它将在build后的以前台方式运行，并带有可视进度指示器\n定期应用以下清理策略（最多每 24 小时一次）：\n将检查caches/\u0026lt;gradle-version\u0026gt;/ 中特定于版本的缓存，以确定它们是否仍在使用中。否则，发布版本的目录将在 30 天处于非活动状态后删除，快照版本的目录将在不活动 7 天后删除。 检查。caches 中的共享缓存（例如 jars-*）是否仍在使用。如果没有仍在使用它们的 Gradle 版本，则会将其删除 当前 Gradle 版本使用的共享缓存caches/中的文件（例如 jars-3h或modules-2 ） 将检查上次访问它们的时间。根据文件是可以在本地重新创建还是必须再次从远程存储库下载，该文件将分别在 7 天或 30 天未被访问后被删除。 将检查wrapper/dists/ 中的 Gradle 发行版是否仍在使用，即是否存在相应的特定于版本的缓存目录。未使用的分配将被删除。 项目根目录 项目根目录包含属于项目的所有源文件。此外，它还包含由 Gradle 生成的文件和目录，例如 .gradle和build 。虽然前者通常签入源代码管理，但后者是Gradle用于支持增量构建等功能的瞬态文件。总体而言，典型项目根目录的剖析大致如下：\n由 Gradle 生成的特定于项目的缓存目录 特定于版本的缓存（例如，支持增量构建） 此项目的构建目录，Gradle 在其中生成所有构建工件。 包含 Gradle Wrapper 的 JAR 文件和配置 特定于项目的 Gradle 配置属性 用于使用 Gradle 包装器执行构建的脚本 项目的设置文件，其中定义了子项目列表 通常，一个项目被组织成一个或多个子项目 每个子项目都有自己的 Gradle 构建脚本 项目缓存清理 从版本 4.10 开始，Gradle 会自动清理特定于项目的缓存目录。生成项目后，将定期（最多每 24 小时）检查.gradle/\u0026lt;gradle-version\u0026gt;/ 中特定于版本的缓存目录，以确定它们是否仍在使用中。如果 7 天未使用，则会将其删除。\ngradle属性配置 Gradle 提供了多种机制来配置 Gradle 本身和特定项目的行为。 以下是使用这些机制的参考。\n配置 Gradle 行为时，您可以使用这些方法，按优先级从高到低的顺序列出：\n命令行：例如 --build-cache 系统属性：gradle.properties 文件中以 systemProp 开头的属性 ，例如 systemProp.http.proxyHost=somehost.org gradle属性：项目根目录或用户gradle目录 gradle.properties 文件 中的属性，例如 org.gradle.caching=true 环境变量：GRADLE_OPTS 环境变量中指定的属性 除了配置构建环境之外，您还可以使用项目属性（例如 -PreleaseType=final）配置给定的项目构建。\ngradle属性 Gradle 考虑的最终配置是命令行上设置的所有 Gradle 属性和您的 gradle.properties 文件的组合。 如果在多个位置配置了一个选项，则在这些位置中的任何一个中找到的第一个将获胜：\n命令行，例如 -P 或 \u0026ndash;project-prop 指定的属性 GRADLE_USER_HOME 目录下的 gradle.properties 项目根目录下gradle.properties gradle安装目录下的 gradle.properties -Dgradle.user.home 命令行更改用户目录\n下面的这些属性来配置gradle的构建环境：\norg.gradle.caching=(true,false)：当设置为 true 时，Gradle 将尽可能重用任何先前构建的任务输出，从而加快构建速度。 默认情况下，构建缓存未启用。 org.gradle.daemon=(true,false)：当设置为 true 时，Gradle 守护进程用于运行构建。 默认为 true，构建将使用守护程序运行。 org.gradle.jvmargs=(JVM arguments)：指定用于 Gradle 守护程序的 JVM 参数。 该设置对于配置 JVM 内存设置以提高构建性能特别有用。 这不会影响 Gradle 客户端 VM 的 JVM 设置。默认：-Xmx512m \u0026ldquo;-XX:MaxMetaspaceSize=256m\u0026rdquo; org.gradle.logging.level=(quiet,warn,lifecycle,info,debug)：指定gradle的日志级别。默认是lifecycle org.gradle.parallel=(true,false):配置后，Gradle 将 fork org.gradle.workers.max JVM 以并行执行项目。 默认为false。 org.gradle.workers.max=(max # of worker processes):配置并行工作线程数，默认和CPU个数相同 系统属性 使用 -D 命令行选项，您可以将系统属性传递给运行 Gradle 的 JVM。 gradle 命令的 -D 选项与 java 命令的 -D 选项作用相同。\n您还可以在 gradle.properties 文件中使用前缀 systemProp 设置系统属性。\n下面是常用的系统属性：\ngradle.wrapperUser=(myuser)： 下载gradle发行包时使用的basic身份验证-用户名 gradle.wrapperPassword=(mypassword)：下载gradle发行包时使用的basic身份验证-密码 gradle.user.home=(path to directory)： 指定gradle的用户目录 https.protocols：以逗号分隔格式指定支持的 TLS 版本。 例如：TLSv1.2、TLSv1.3。 在多项目构建中，除根以外的任何项目中设置的systemProp属性都将被忽略。 也就是说，只会检查根项目的 gradle.properties 文件中以“systemProp”开头的属性。\n配置gradle wapper的http代理\nsystemProp.http.proxyHost=www.somehost.org systemProp.http.proxyPort=8080 systemProp.http.proxyUser=userid systemProp.http.proxyPassword=password systemProp.http.nonProxyHosts=*.nonproxyrepos.com|localhost systemProp.https.proxyHost=www.somehost.org systemProp.https.proxyPort=8080 systemProp.https.proxyUser=userid systemProp.https.proxyPassword=password systemProp.http.nonProxyHosts=*.nonproxyrepos.com|localhost 环境变量 以下环境变量可用于 gradle 命令。 请注意，命令行选项和系统属性优先于环境变量。\nGRADLE_OPTS： 指定启动 Gradle 客户端 VM 时要使用的 JVM 参数。 客户端 VM 仅处理命令行输入/输出，因此很少需要更改其 VM 选项。 实际构建由 Gradle 守护程序运行，不受此环境变量的影响。 GRADLE_USER_HOME JAVA_HOME：指定用于客户端 VM 的 JDK 安装目录。 此 VM 也用于守护进程，除非在带有 org.gradle.java.home 的 Gradle 属性文件中指定了不同的 VM。 项目属性 您可以通过 -P 命令行选项将属性直接添加到您的项目对象。\nGradle 还可以在看到特殊命名的系统属性或环境变量时设置项目属性。 如果环境变量名称看起来像 ORG_GRADLE_PROJECT_prop=somevalue，那么 Gradle 将在您的项目对象上设置一个 prop 属性，其值为 somevalue。 Gradle 也支持系统属性，但命名模式不同，类似于 org.gradle.project.prop。 以下两项都将您的 Project 对象上的 foo 属性设置为“bar”。\n如果引用了项目属性但不存在，则会引发异常并且构建将失败。使用 Project.hasProperty(java.lang.String) 方法检查是否存在。\ntasks.register(\u0026#39;performRelease\u0026#39;) { doLast { if (project.hasProperty(\u0026#34;isCI\u0026#34;)) { println(\u0026#34;Performing release actions\u0026#34;) } else { throw new InvalidUserDataException(\u0026#34;Cannot perform release outside of CI\u0026#34;) } } } 初始化脚本 初始化脚本（又名 init 脚本）类似于 Gradle 中的其他脚本。 但是，这些脚本在构建开始之前运行。 以下是几种可能的用途：\n设置企业范围的配置，例如在哪里可以找到自定义插件。 根据当前环境设置属性，例如开发人员的机器与持续集成服务器。 提供构建所需的有关用户的个人信息，例如存储库或数据库身份验证凭据。 定义特定于机器的详细信息，例如 JDK 的安装位置。 注册构建监听器。 希望收听 Gradle 事件的外部工具可能会发现这很有用。 注册构建记录器。 您可能希望自定义 Gradle 如何记录它生成的事件。 初始化脚本的一个主要限制是它们无法访问 buildSrc 项目中的类\n依赖管理 就拿java项目来举例。可能需要导入Guava类库，这是一个提供丰富实用函数的开源库。除了Guava，该项目还需要JUnit库来编译和执行测试代码。\nGuava和JUnit代表了这个项目的依赖关系。开发人员可以在构建脚本中声明不同范围的依赖关系，例如仅用于编译源代码或执行测试。在Gradle中，依赖项的范围称为配置（configuration）。\n依赖关系通常以模块（modules）的形式出现。您需要告诉Gradle在哪里可以找到这些模块，以便在构建过程中使用它们。存储模块的位置称为存储库。通过为构建声明存储库，Gradle将知道如何查找和检索模块。存储库可以有不同的形式：本地目录或远程存储库。\n在运行时，Gradle将根据指定的任务查找声明的依赖项。依赖项可能需要从远程存储库下载、从本地目录检索或需要在多项目设置中构建另一个项目。此过程称为依赖关系解析。\n解析后，解析机制将依赖项的底层文件存储在本地缓存（也称为依赖缓存）中。未来的构建重用缓存中存储的文件，以避免不必要的网络调用。\n模块可以提供额外的元数据。元数据是更详细地描述模块的数据，例如在存储库中查找模块的坐标、项目信息或其作者。作为元数据的一部分，模块可以定义需要其他模块才能正常工作。例如，JUnit5平台模块还需要平台公共模块。Gradle自动解析这些附加模块，称为传递依赖关系。如果需要，您可以根据项目的需求定制行为和传递依赖关系的处理。\n具有数十个或数百个已声明依赖项的项目很容易受到依赖地狱的困扰。Gradle提供了足够的工具，可以通过构建扫描或内置任务来可视化、导航和分析项目的依赖关系图。\n存储库管理 支持的存储库 Maven Central是一个流行的存储库，托管开源库供Java项目使用。 Google 存储库托管了特定于 Android 的工件，包括 Android SDK。 maven自定义url 某些项目可能更喜欢将依赖项存储在共享驱动器上，或作为项目源代码的一部分存储，而不是二进制存储库产品。如果要使用（flatDir）文件系统目录作为存储库。这种类型的存储库不支持任何元数据格式，如 Ivy XML 或 Maven POM 文件。相反，Gradle 将根据工件的存在动态生成一个模块描述符 Gradle 可以使用本地 Maven 存储库中提供的依赖项。声明此存储库对于使用一个项目发布到本地 Maven 存储库并在另一个项目中使用 Gradle 工件的团队是有益的 repositories { mavenCentral() google() maven { url \u0026#34;https://repo.spring.io/release\u0026#34; } flatDir { dirs \u0026#39;lib\u0026#39; } flatDir { dirs \u0026#39;lib1\u0026#39;, \u0026#39;lib2\u0026#39; } mavenLocal() } 声明的顺序决定了 Gradle 在运行时如何检查依赖项。如果 Gradle 在特定存储库中找到模块描述符，它将尝试从同一存储库下载该模块的所有工件。\nMaven POM 元数据可以引用其他存储库。这些将被Gradle忽略，Gradle将仅使用构建本身中声明的存储库。\n作为建议，应避免添加mavenLocal()为存储库。\nMaven 将其用作缓存，而不是存储库，这意味着它可以包含部分模块。 例如，如果 Maven 从未下载过给定模块的源代码或 javadoc 文件，则 Gradle 也不会找到它们，因为一旦找到模块，它就会在单个存储库中搜索文件。 作为本地存储库，Gradle 不信任其内容，因为： 无法跟踪工件的来源，这是一个正确性和安全问题 工件很容易被覆盖，这是一个安全性、正确性和可重复性问题 为了减轻元数据和/或工件可以更改的事实，Gradle 不会对本地存储库执行任何缓存 因此，您的构建速度较慢 鉴于存储库的顺序很重要，首先添加mavenLocal()意味着所有构建速度都会变慢。 筛选器 Gradle公开了一个API来声明存储库可能包含或不包含的内容。它有不同的用例：\n性能，当您知道在特定存储库中永远找不到依赖项时 安全性，通过避免泄露私有项目中使用的依赖项 可靠性，当某些存储库包含损坏的元数据或工件时 当考虑到存储库的声明顺序很重要时，这一点更为重要。\n示例一： 按照group过滤\nrepositories { maven { url \u0026#34;https://repo.mycompany.com/maven2\u0026#34; content { // this repository *only* contains artifacts with group \u0026#34;my.company\u0026#34; includeGroup \u0026#34;my.company\u0026#34; } } mavenCentral { content { // this repository contains everything BUT artifacts with group starting with \u0026#34;my.company\u0026#34; excludeGroupByRegex \u0026#34;my\\\\.company.*\u0026#34; } } } 默认情况下，存储库包含所有内容，不排除任何内容：\n如果您声明include，那么它将排除除包含的内容之外的所有内容。 如果您声明了一个exclude，那么它包括除被排除的内容之外的所有内容。 如果同时声明include和exclude，那么它只包含显式包含而不排除的内容。 可以严格地或使用正则表达式按组、模块或版本进行过滤。使用严格版本时，可以使用Gradle支持的格式使用版本范围。此外，还有按解析上下文筛选选项：配置名称甚至配置属性。有关详细信息，请参阅RepositoryContentDescriptor。\n示例二： 按照版本类型过滤\nrepositories { maven { url \u0026#34;https://repo.mycompany.com/releases\u0026#34; mavenContent { releasesOnly() } } maven { url \u0026#34;https://repo.mycompany.com/snapshots\u0026#34; mavenContent { snapshotsOnly() } } } 插件存储库 Gradle将在构建期间的两个不同阶段使用存储库。\n第一个阶段是配置构建并加载它应用的插件。为此，Gradle将使用一组特殊的存储库。 第二阶段是在依赖关系解析期间。此时Gradle将使用项目中声明的存储库。 默认情况下，Gradle将使用Gradle插件门户来查找插件。然而，出于不同的原因，其他公共或非公共存储库中都有可用的插件。当构建需要其中一个插件时，需要指定额外的存储库，以便Gradle知道在哪里搜索。\nsettings.gradle\npluginManagement { repositories { maven(url = \u0026#34;./maven-repo\u0026#34;) gradlePluginPortal() ivy(url = \u0026#34;./ivy-repo\u0026#34;) } } 集中声明存储库 Gradle提供了一种在所有项目的中心位置声明存储库的方法，而不是在构建的每个子项目中或通过allprojects块声明存储库：\nsettings.gradle\ndependencyResolutionManagement { repositories { mavenCentral() } } 默认情况下，项目声明的存储库将覆盖settings中声明的任何内容。您可以更改此行为以确保始终使用settings中的存储库：\nsettings.gradle\ndependencyResolutionManagement { repositoriesMode.set(RepositoriesMode.PREFER_SETTINGS) } 如果出于某种原因，项目或插件在项目中声明了存储库，Gradle会警告您。但是，如果您希望强制只使用设置存储库，则可以使其在生成过程中失败：\nsettings.gradle\ndependencyResolutionManagement { repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS) } 处理凭据 有些仓库访问，需要通过身份认证。\nrepositories { maven { url \u0026#34;http://repo.mycompany.com/maven2\u0026#34; credentials { username \u0026#34;user\u0026#34; password \u0026#34;password\u0026#34; } } } 摘要式身份验证\nrepositories { maven { url \u0026#39;https://repo.mycompany.com/maven2\u0026#39; credentials { username \u0026#34;user\u0026#34; password \u0026#34;password\u0026#34; } authentication { digest(DigestAuthentication) } } } basic身份验证\nrepositories { maven { url \u0026#39;https://repo.mycompany.com/maven2\u0026#39; credentials { username \u0026#34;user\u0026#34; password \u0026#34;password\u0026#34; } authentication { basic(BasicAuthentication) } } } 使用 HTTP 标头身份验证\nrepositories { maven { url \u0026#34;http://repo.mycompany.com/maven2\u0026#34; credentials(HttpHeaderCredentials) { name = \u0026#34;Private-Token\u0026#34; value = \u0026#34;TOKEN\u0026#34; } authentication { header(HttpHeaderAuthentication) } } } 外部化存储库凭据\nrepositories { maven { name = \u0026#39;mySecureRepository\u0026#39; credentials(PasswordCredentials) // url = uri(\u0026lt;\u0026lt;some repository url\u0026gt;\u0026gt;) } } 用户名和密码将从 mySecureRepositoryUsername和 mySecureRepositoryPassword属性中查找。\n共享依赖管理 示例一： 基本使用\n在setting文件中声明依赖 dependencyResolutionManagement { versionCatalogs { libs { version(\u0026#39;groovy\u0026#39;, \u0026#39;3.0.5\u0026#39;) version(\u0026#39;checkstyle\u0026#39;, \u0026#39;8.37\u0026#39;) library(\u0026#39;groovy-core\u0026#39;, \u0026#39;org.codehaus.groovy\u0026#39;, \u0026#39;groovy\u0026#39;).versionRef(\u0026#39;groovy\u0026#39;) library(\u0026#39;groovy-json\u0026#39;, \u0026#39;org.codehaus.groovy\u0026#39;, \u0026#39;groovy-json\u0026#39;).versionRef(\u0026#39;groovy\u0026#39;) library(\u0026#39;groovy-nio\u0026#39;, \u0026#39;org.codehaus.groovy\u0026#39;, \u0026#39;groovy-nio\u0026#39;).versionRef(\u0026#39;groovy\u0026#39;) library(\u0026#39;commons-lang3\u0026#39;, \u0026#39;org.apache.commons\u0026#39;, \u0026#39;commons-lang3\u0026#39;).version { strictly \u0026#39;[3.8, 4.0[\u0026#39; prefer \u0026#39;3.9\u0026#39; } } } } 在build文件中引入依赖： dependencies { implementation libs.commons.lang3 } 声明依赖名称中指定的 - ，在引入时需要转化成 .\n示例二： 依赖分组管理\n我们可以将几个相关的依赖组合在一起，然后引入的时候一起引入。\ndependencyResolutionManagement { versionCatalogs { libs { version(\u0026#39;groovy\u0026#39;, \u0026#39;3.0.5\u0026#39;) version(\u0026#39;checkstyle\u0026#39;, \u0026#39;8.37\u0026#39;) library(\u0026#39;groovy-core\u0026#39;, \u0026#39;org.codehaus.groovy\u0026#39;, \u0026#39;groovy\u0026#39;).versionRef(\u0026#39;groovy\u0026#39;) library(\u0026#39;groovy-json\u0026#39;, \u0026#39;org.codehaus.groovy\u0026#39;, \u0026#39;groovy-json\u0026#39;).versionRef(\u0026#39;groovy\u0026#39;) library(\u0026#39;groovy-nio\u0026#39;, \u0026#39;org.codehaus.groovy\u0026#39;, \u0026#39;groovy-nio\u0026#39;).versionRef(\u0026#39;groovy\u0026#39;) library(\u0026#39;commons-lang3\u0026#39;, \u0026#39;org.apache.commons\u0026#39;, \u0026#39;commons-lang3\u0026#39;).version { strictly \u0026#39;[3.8, 4.0[\u0026#39; prefer \u0026#39;3.9\u0026#39; } bundle(\u0026#39;groovy\u0026#39;, [\u0026#39;groovy-core\u0026#39;, \u0026#39;groovy-json\u0026#39;, \u0026#39;groovy-nio\u0026#39;]) } } } 只需要引入分组名称，就可以引入多个依赖：\ndependencies { implementation libs.bundles.groovy } 示例三： 插件版本\n除了可以集中管理依赖，还可以集中管理插件\ndependencyResolutionManagement { versionCatalogs { libs { plugin(\u0026#39;jmh\u0026#39;, \u0026#39;me.champeau.jmh\u0026#39;).version(\u0026#39;0.6.5\u0026#39;) } } } 在build文件中引入声明的插件：\nplugins { id \u0026#39;java-library\u0026#39; id \u0026#39;checkstyle\u0026#39; alias(libs.plugins.jmh) } 示例四：toml文件集中声明依赖\nGradle 还提供了一个常规文件来声明依赖，避免在settings文件中管理。这个文件名称默认是 libs.versions.toml ，可以在settings文件使用下列配置更改名称：\ndependencyResolutionManagement { defaultLibrariesExtensionName.set(\u0026#39;projectLibs\u0026#39;) } libs.versions.toml文件的示例内容如下：\n[versions] groovy = \u0026#34;3.0.5\u0026#34; checkstyle = \u0026#34;8.37\u0026#34; my-lib = { strictly = \u0026#34;[1.0, 2.0[\u0026#34;, prefer = \u0026#34;1.2\u0026#34; } [libraries] groovy-core = { module = \u0026#34;org.codehaus.groovy:groovy\u0026#34;, version.ref = \u0026#34;groovy\u0026#34; } groovy-json = { module = \u0026#34;org.codehaus.groovy:groovy-json\u0026#34;, version.ref = \u0026#34;groovy\u0026#34; } groovy-nio = { module = \u0026#34;org.codehaus.groovy:groovy-nio\u0026#34;, version.ref = \u0026#34;groovy\u0026#34; } commons-lang3 = { group = \u0026#34;org.apache.commons\u0026#34;, name = \u0026#34;commons-lang3\u0026#34;, version = { strictly = \u0026#34;[3.8, 4.0[\u0026#34;, prefer=\u0026#34;3.9\u0026#34; } } [bundles] groovy = [\u0026#34;groovy-core\u0026#34;, \u0026#34;groovy-json\u0026#34;, \u0026#34;groovy-nio\u0026#34;] [plugins] jmh = { id = \u0026#34;me.champeau.jmh\u0026#34;, version = \u0026#34;0.6.5\u0026#34; } 示例五： 导入bom文件\n另一种集中管理项目依赖的方式是platform，maven的BOM文件就是platform的一个示例：\ndependencies { // import a BOM implementation platform(\u0026#39;org.springframework.boot:spring-boot-dependencies:1.5.8.RELEASE\u0026#39;) // define dependencies without versions implementation \u0026#39;com.google.code.gson:gson\u0026#39; implementation \u0026#39;dom4j:dom4j\u0026#39; } 插件 常用插件 java Java插件将Java编译以及测试和打包功能添加到项目中。它是许多其他JVM语言Gradle插件的基础。\njava-library 功能如下：\ncompileJava：编译 _src/main/_java 下所有 Java 源文件 compileTestJava：编译 src/test/java 下的源文件 test： 从 src/test/java 运行测试的任务 jar：将已编译的类和src/main/resources 的资源打包 project-version.jar javadoc: 为类生成 Javadoc Java 库插件还将上述任务集成到标准的基本插件生命周期任务中：\njar附加到 ssemble test附加到check 自定义源文件目录\nsourceSets { main { java { srcDirs = [\u0026#39;src\u0026#39;] } } test { java { srcDirs = [\u0026#39;test\u0026#39;] } } } 这会覆盖默认的配置，下面的方式是在默认的方式上进行追加：\nsourceSets { main { java { srcDir \u0026#39;thirdParty/src/main/java\u0026#39; } } } 指定jdk的版本：\njava { toolchain { languageVersion = JavaLanguageVersion.of(8) } } application插件 创建可执行的JVM应用程序，它使在开发过程中轻松地在本地启动应用程序，并将应用程序打包为TAR或ZIP，包括特定于操作系统的启动脚本。\n该插件会隐式的引用java插件，用来指定source set.\n该插件隐式引用 Distribution plugin ， 该插件用来打包应用，包括启动脚本。\n使用：\nplugins { id \u0026#39;application\u0026#39; } application { // 启动类 mainClass = \u0026#39;org.gradle.sample.Main\u0026#39; // 启动脚本的目录 executableDir = \u0026#39;custom_bin_dir\u0026#39; } java-platform 子项目间共享依赖版本,例如constraints 引入异构项目的BOM清单，用于统一版本，例如spring boot ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/gradle-basic/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"},{"title":"gradle","url":"/myblog/tags/gradle/"}],"timestamp":1669999439,"title":"Gradle-Basic"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"零拷贝 概述 零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。实现零拷贝用到的最主要技术是 DMA 数据传输技术和内存区域映射技术。\n零拷贝机制可以减少数据在内核缓冲区和用户进程缓冲区之间反复的 I/O 拷贝操作。\n零拷贝机制可以减少用户进程地址空间和内核地址空间之间因为上下文切换而带来的 CPU 开销。\n物理内存和虚拟内存 进程之间是共享 CPU 和内存资源的，因此需要一套内存管理机制防止进程之间内存泄漏的问题。为了更加有效地管理内存并减少出错，现代操作系统提供了一种对主存的抽象概念，即是虚拟内存（Virtual Memory）。虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。\n物理内存：物理内存（Physical memory）是相对于虚拟内存（Virtual Memory）而言的。物理内存指通过物理内存条而获得的内存空间，而虚拟内存则是指将硬盘的一块区域划分来作为内存。内存主要作用是在计算机运行时为操作系统和各种程序提供临时储存。\n虚拟内存：是计算机系统内存管理的一种技术。 它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间）。而实际上，虚拟内存通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换，加载到物理内存中来。 目前，大多数操作系统都使用了虚拟内存，如 Windows 系统的虚拟内存、Linux 系统的交换空间等等。\n虚拟内存地址和用户进程紧密相关，一般来说不同进程里的同一个虚拟地址指向的物理地址是不一样的，所以离开进程谈虚拟内存没有任何意义。每个进程所能使用的虚拟地址大小和 CPU 位数有关。在 32 位的系统上，虚拟地址空间大小是 2 ^ 32 = 4G，在 64位系统上，虚拟地址空间大小是 2 ^ 64 = 2 ^ 34G，而实际的物理内存可能远远小于虚拟内存的大小。每个用户进程维护了一个单独的页表（Page Table），虚拟内存和物理内存就是通过这个页表实现地址空间的映射的。下面给出两个进程 A、B 各自的虚拟内存空间以及对应的物理内存之间的地址映射示意图：\n当进程执行一个程序时，需要先从内存中读取该进程的指令然后执行，获取指令时用到的就是虚拟地址。这个虚拟地址是程序链接时确定的（内核加载并初始化进程时会调整动态库的地址范围）。为了获取到实际的数据，CPU 需要将虚拟地址转换成物理地址，CPU 转换地址时需要用到进程的页表（Page Table），而页表（Page Table）里面的数据由操作系统维护。\n其中页表（Page Table）可以简单的理解为单个内存映射（Memory Mapping）的链表（当然实际结构很复杂），里面的每个内存映射（Memory Mapping）都将一块虚拟地址映射到一个特定的地址空间（物理内存或者磁盘存储空间）。每个进程拥有自己的页表（Page Table），和其它进程的页表（Page Table）没有关系。\n通过上面的介绍，我们可以简单的将用户进程申请并访问物理内存（或磁盘存储空间）的过程总结如下：\n用户进程向操作系统发出内存申请请求\n系统会检查进程的虚拟地址空间是否被用完，如果有剩余，给进程分配虚拟地址\n系统为这块虚拟地址创建的内存映射（Memory Mapping），并将它放进该进程的页表（Page Table）\n系统返回虚拟地址给用户进程，用户进程开始访问该虚拟地址\nCPU 根据虚拟地址在此进程的页表（Page Table）中找到了相应的内存映射（Memory Mapping），但是这个内存映射（Memory Mapping）没有和物理内存关联，于是产生缺页中断\n操作系统收到缺页中断后，分配真正的物理内存并将它关联到页表相应的内存映射（Memory Mapping）。中断处理完成后 CPU 就可以访问内存了\n当然缺页中断不是每次都会发生，只有系统觉得有必要延迟分配内存的时候才用的着，也即很多时候在上面的第 3 步系统会分配真正的物理内存并和内存映射（Memory Mapping）进行关联。\n在用户进程和物理内存（磁盘存储器）之间引入虚拟内存主要有以下的优点：\n地址空间：提供更大的地址空间，并且地址空间是连续的，使得程序编写、链接更加简单\n进程隔离：不同进程的虚拟地址之间没有关系，所以一个进程的操作不会对其它进程造成影响\n数据保护：每块虚拟内存都有相应的读写属性，这样就能保护程序的代码段不被修改，数据块不能被执行等，增加了系统的安全性\n内存映射：有了虚拟内存之后，可以直接映射磁盘上的文件（可执行文件或动态库）到虚拟地址空间。这样可以做到物理内存延时分配，只有在需要读相应的文件的时候，才将它真正的从磁盘上加载到内存中来，而在内存吃紧的时候又可以将这部分内存清空掉，提高物理内存利用效率，并且所有这些对应用程序是都透明的\n共享内存：比如动态库只需要在内存中存储一份，然后将它映射到不同进程的虚拟地址空间中，让进程觉得自己独占了这个文件。进程间的内存共享也可以通过映射同一块物理内存到进程的不同虚拟地址空间来实现共享\n物理内存管理：物理地址空间全部由操作系统管理，进程无法直接分配和回收，从而系统可以更好的利用内存，平衡进程间对内存的需求\n内核空间和用户空间 操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的权限。为了避免用户进程直接操作内核，保证内核安全，操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space），一部分是用户空间（User-space）。 在 Linux 系统中，内核模块运行在内核空间，对应的进程处于内核态；而用户程序运行在用户空间，对应的进程处于用户态。\n内核进程和用户进程所占的虚拟内存比例是 1:3，而 Linux x86_32 系统的寻址空间（虚拟存储空间）为 4G（2的32次方），将最高的 1G 的字节（从虚拟地址 0xC0000000 到 0xFFFFFFFF）供内核进程使用，称为内核空间；而较低的 3G 的字节（从虚拟地址 0x00000000 到 0xBFFFFFFF），供各个用户进程使用，称为用户空间。下图是一个进程的用户空间和内核空间的内存布局：\n内核空间 内核空间总是驻留在内存中，它是为操作系统的内核保留的。应用程序是不允许直接在该区域进行读写或直接调用内核代码定义的函数的。上图左侧区域为内核进程对应的虚拟内存，按访问权限可以分为进程私有和进程共享两块区域。\n进程私有的虚拟内存：每个进程都有单独的内核栈、页表、task 结构以及 mem_map 结构等。\n进程共享的虚拟内存：属于所有进程共享的内存区域，包括物理存储器、内核数据和内核代码区域。\n用户空间 每个普通的用户进程都有一个单独的用户空间，处于用户态的进程不能访问内核空间中的数据，也不能直接调用内核函数的 ，因此要进行系统调用的时候，就要将进程切换到内核态才行。用户空间包括以下几个内存区域：\n运行时栈：由编译器自动释放，存放函数的参数值，局部变量和方法返回值等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存储到栈顶，调用结束后调用信息会被弹出弹出并释放掉内存。栈区是从高地址位向低地址位增长的，是一块连续的内在区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。\n运行时堆：用于存放进程运行中被动态分配的内存段，位于 BSS 和栈中间的地址位。由卡发人员申请分配（malloc）和释放（free）。堆是从低地址位向高地址位增长，采用链式存储结构。频繁地 malloc/free 造成内存空间的不连续，产生大量碎片。当申请堆空间时，库函数按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。\n代码段：存放 CPU 可以执行的机器指令，该部分内存只能读不能写。通常代码区是共享的，即其它执行程序可调用它。假如机器中有数个进程运行相同的一个程序，那么它们就可以使用同一个代码段。\n未初始化的数据段：存放未初始化的全局变量，BSS 的数据在程序开始执行之前被初始化为 0 或 NULL。\n已初始化的数据段：存放已初始化的全局变量，包括静态全局变量、静态局部变量以及常量。\n内存映射区域：例如将动态库，共享内存等虚拟空间的内存映射到物理空间的内存，一般是 mmap 函数所分配的虚拟内存空间。\n内核态可以执行任意命令，调用系统的一切资源，而用户态只能执行简单的运算，不能直接调用系统资源。用户态必须通过系统接口（System Call），才能向内核发出指令。比如，当用户进程启动一个 bash 时，它会通过 getpid() 对内核的 pid 服务发起系统调用，获取当前用户进程的 ID；当用户进程通过 cat 命令查看主机配置时，它会对内核的文件子系统发起系统调用。\n内核空间可以访问所有的 CPU 指令和所有的内存空间、I/O 空间和硬件设备。\n用户空间只能访问受限的资源，如果需要特殊权限，可以通过系统调用获取相应的资源。\n用户空间允许页面中断，而内核空间则不允许。\n内核空间和用户空间是针对线性地址空间的。\nx86 CPU中用户空间是 0 - 3G 的地址范围，内核空间是 3G - 4G 的地址范围。x86_64 CPU 用户空间地址范围为0x0000000000000000 – 0x00007fffffffffff，内核地址空间为 0xffff880000000000 - 最大地址。\n所有内核进程（线程）共用一个地址空间，而用户进程都有各自的地址空间。\n有了用户空间和内核空间的划分后，Linux 内部层级结构可以分为三部分，从最底层到最上层依次是硬件、内核空间和用户空间，如下图所示:\nDMA技术由来 read读取磁盘数据的过程：\n当应用程序需要读取磁盘数据时，调用 read() 从用户态陷入内核态，read() 这个系统调用最终由 CPU 来完成。\nCPU 向磁盘发起 I/O 请求，磁盘收到之后开始准备数据。\n磁盘将数据放到磁盘缓冲区之后，向 CPU 发起 I/O 中断，报告 CPU 数据已经 Ready 了。\nCPU 收到磁盘控制器的 I/O 中断之后，开始拷贝数据，完成之后 read() 返回，再从内核态切换回用户态。\n上面的过程中，CPU大量参与了数据拷贝工作， DMA可以帮助CPU干这些杂活。\n最主要的变化是，CPU 不再和磁盘直接交互，而是 DMA 和磁盘交互并且将数据从磁盘缓冲区拷贝到内核缓冲区，之后还是需要CPU将数据从内核态搬运到用户态。\n来看下完整的数据拷贝过程简图：\n读数据过程：\n应用程序要读取磁盘数据，调用 read() 函数从而实现用户态切换内核态，这是第 1 次状态切换。\nDMA 控制器将数据从磁盘拷贝到内核缓冲区，这是第 1 次 DMA 拷贝。\nCPU 将数据从内核缓冲区复制到用户缓冲区，这是第 1 次 CPU 拷贝。\nCPU 完成拷贝之后，read() 函数返回实现用户态切换用户态，这是第 2 次状态切换。\n写数据过程：\n应用程序要向网卡写数据，调用 write() 函数实现用户态切换内核态，这是第 1 次切换。\nCPU 将用户缓冲区数据拷贝到内核缓冲区，这是第 1 次 CPU 拷贝。\nDMA 控制器将数据从内核缓冲区复制到 socket 缓冲区，这是第 1 次 DMA 拷贝。\n完成拷贝之后，write() 函数返回实现内核态切换用户态，这是第 2 次切换。\n可以看到，如果我们不对数据进行修改，是没必要将数据从内核态复制到用户态的。\n零拷贝技术的几个实现手段包括：mmap+write、sendfile、sendfile+DMA 收集、splice 等。\nmmap 方式 mmap 是 Linux 提供的一种内存映射文件的机制，它实现了将内核中读缓冲区地址与用户空间缓冲区地址进行映射，从而实现内核缓冲区与用户缓冲区的共享。 这样就减少了一次用户态和内核态的 CPU 拷贝，但是在内核空间内仍然有一次 CPU 拷贝。\nmmap 对大文件传输有一定优势，但是小文件可能出现碎片，并且在多个进程同时操作文件时可能产生引发 coredump 的 signal。\n用户态和内核态共享数据缓冲区，避免了两者之间的复制。适用于大文件读取并处理的场景\nsendfile 方式 sendfile 相比于 mmap+write 有一定改进，但是由系统调用引起的状态切换并没有减少。\nsendfile 方式只使用一个函数就可以完成之前的 read+write 和 mmap+write 的功能，这样就少了 2 次状态切换，由于数据不经过用户缓冲区，因此该数据无法被修改。\n应用程序只需要调用 sendfile 函数即可完成，只有 2 次状态切换、1 次 CPU 拷贝、2 次 DMA 拷贝。但是 sendfile 在内核缓冲区和 socket 缓冲区仍然存在一次 CPU 拷贝。Linux 2.4 内核对此进行了优化，但是需要硬件 DMA 控制器的配合。升级后的 sendfile 将内核缓冲区中对应的数据描述信息（文件描述符、地址偏移量等信息）记录到 socket 缓冲区中。DMA 控制器根据 socket 缓冲区中的地址和偏移量将数据从内核缓冲区拷贝到网卡中，从而省去了内核空间中仅剩 1 次的 CPU 拷贝。\n这种方式有 2 次状态切换、0 次 CPU 拷贝、2 次 DMA 拷贝，但是无法对数据进行修改，并且需要硬件层面 DMA 的支持，并且 sendfile 只能将文件数据拷贝到 socket 描述符上，有一定的局限性。\nsendfile 直接发起系统调用，将数据直接发送到了网卡。避免了数据来回的复制。\nsplice 方式 splice 系统调用是 Linux 在 2.6 版本引入的，其不需要硬件支持，并且不再限定于 socket 上，实现两个普通文件之间的数据零拷贝。\nsplice 系统调用可以在内核缓冲区和 socket 缓冲区之间建立管道来传输数据，避免了两者之间的 CPU 拷贝操作。\nsplice 也有一些局限，它的两个文件描述符参数中有一个必须是管道设备。\nJava NIO零拷贝实现 在 Java NIO 中的通道（Channel）就相当于操作系统的内核空间（kernel space）的缓冲区，而缓冲区（Buffer）对应的相当于操作系统的用户空间（user space）中的用户缓冲区（user buffer）。\n通道（Channel）是全双工的（双向传输），它既可能是读缓冲区（read buffer），也可能是网络缓冲区（socket buffer）。\n缓冲区（Buffer）分为堆内存（HeapBuffer）和堆外内存（DirectBuffer），这是通过 malloc() 分配出来的用户态内存。\n堆外内存（DirectBuffer）在使用后需要应用程序手动回收，而堆内存（HeapBuffer）的数据在 GC 时可能会被自动回收。因此，在使用 HeapBuffer 读写数据时，为了避免缓冲区数据因为 GC 而丢失，NIO 会先把 HeapBuffer 内部的数据拷贝到一个临时的 DirectBuffer 中的本地内存（native memory），这个拷贝涉及到 sun.misc.Unsafe.copyMemory() 的调用，背后的实现原理与 memcpy() 类似。 最后，将临时生成的 DirectBuffer 内部的数据的内存地址传给 I/O 调用函数，这样就避免了再去访问 Java 对象处理 I/O 读写。\nMappedByteBuffer MappedByteBuffer 是 NIO 基于内存映射（mmap）这种零拷贝方式的提供的一种实现，它继承自 ByteBuffer。FileChannel 定义了一个 map() 方法，它可以把一个文件从 position 位置开始的 size 大小的区域映射为内存映像文件。抽象方法 map() 方法在 FileChannel 中的定义如下：\npublic abstract MappedByteBuffer map(MapMode mode, long position, long size)\n​ throws IOException;\nmode：限定内存映射区域（MappedByteBuffer）对内存映像文件的访问模式，包括只可读（READ_ONLY）、可读可写（READ_WRITE）和写时拷贝（PRIVATE）三种模式。\nposition：文件映射的起始地址，对应内存映射区域（MappedByteBuffer）的首地址。\nsize：文件映射的字节长度，从 position 往后的字节数，对应内存映射区域（MappedByteBuffer）的大小。\nMappedByteBuffer 相比 ByteBuffer 新增了 fore()、load() 和 isLoad() 三个重要的方法：\nfore()：对于处于 READ_WRITE 模式下的缓冲区，把对缓冲区内容的修改强制刷新到本地文件。\nload()：将缓冲区的内容载入物理内存中，并返回这个缓冲区的引用。\nisLoaded()：如果缓冲区的内容在物理内存中，则返回 true，否则返回 false。\n下面给出一个利用 MappedByteBuffer 对文件进行读写的使用示例：\nprivate final static String CONTENT = \u0026ldquo;Zero copy implemented by MappedByteBuffer\u0026rdquo;;\nprivate final static String FILE_NAME = \u0026ldquo;/mmap.txt\u0026rdquo;;\nprivate final static String CHARSET = \u0026ldquo;UTF-8\u0026rdquo;;\n写文件数据：打开文件通道 fileChannel 并提供读权限、写权限和数据清空权限，通过 fileChannel 映射到一个可写的内存缓冲区 mappedByteBuffer，将目标数据写入 mappedByteBuffer，通过 force() 方法把缓冲区更改的内容强制写入本地文件。\n@Test\npublic void writeToFileByMappedByteBuffer() {\nPath path = Paths.get(getClass().getResource(FILE_NAME).getPath());\nbyte[] bytes = CONTENT.getBytes(Charset.forName(CHARSET));\ntry (FileChannel fileChannel = FileChannel.open(path, StandardOpenOption.READ,\n​ StandardOpenOption.WRITE, StandardOpenOption.TRUNCATE_EXISTING)) {\n​ MappedByteBuffer mappedByteBuffer = fileChannel.map(READ_WRITE, 0, bytes.length);\n​ if (mappedByteBuffer != null) {\n​ mappedByteBuffer.put(bytes);\n​ mappedByteBuffer.force();\n​ }\n} catch (IOException e) {\n​ e.printStackTrace();\n}\n}\n读文件数据：打开文件通道 fileChannel 并提供只读权限，通过 fileChannel 映射到一个只可读的内存缓冲区 mappedByteBuffer，读取 mappedByteBuffer 中的字节数组即可得到文件数据。\n@Test\npublic void readFromFileByMappedByteBuffer() {\nPath path = Paths.get(getClass().getResource(FILE_NAME).getPath());\nint length = CONTENT.getBytes(Charset.forName(CHARSET)).length;\ntry (FileChannel fileChannel = FileChannel.open(path, StandardOpenOption.READ)) {\n​ MappedByteBuffer mappedByteBuffer = fileChannel.map(READ_ONLY, 0, length);\n​ if (mappedByteBuffer != null) {\n​ byte[] bytes = new byte[length];\n​ mappedByteBuffer.get(bytes);\n​ String content = new String(bytes, StandardCharsets.UTF_8);\n​ assertEquals(content, \u0026ldquo;Zero copy implemented by MappedByteBuffer\u0026rdquo;);\n​ }\n} catch (IOException e) {\n​ e.printStackTrace();\n}\n}\n应用 RocketMQ 选择了 mmap + write 这种零拷贝方式，适用于业务级消息这种小块文件的数据持久化和传输；\n而 Kafka 采用的是 sendfile 这种零拷贝方式，适用于系统日志消息这种高吞吐量的大块文件的数据持久化和传输。\n但是值得注意的一点是，Kafka 的索引文件使用的是 mmap + write 方式，数据文件使用的是 sendfile 方式。\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/zero-copy/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669986378,"title":"Zero-Copy"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"Java锁 对象头 Java对象保存在内存中时，由以下三部分组成：对象头、实例数据、对齐填充字节。\njava的对象头由以下三部分组成：Mark Word、指向类的指针、数组长度（只有数组对象才有）\nMark Word在不同的锁状态下存储的内容不同，在32位JVM中是这么存的：\nSyschronized底层的原理 Monitor Monitor被翻译为监视器或管程\n每个Java对象都可以关联一个Monitor对象,如果使用synchronized给对象上锁(重量级)之后【之前可能要先经过轻量级锁或者偏向锁】，该对象头的Mark Word中就被设置指向Monitor对象的指针。\nMonitor的结果如下：\n刚开始Monitor中Owner为null\n当Thread-2执行synchronized(obj)就会将Monitor的所有者Owner置为Thread-2, Monitor中只能有一一个Owner\n在Thread-2持有锁的过程中，如果Thread-3, Thread-4， Thread-5 也来执行synchronized(obj)， 就会进入EntryList BLOCKED\nThread-2执行完同步代码块的内容，然后唤醒EntryL ist中等待的线程来竞争锁，竞争的时是非公平的\n图中WaitSet中的Thread-0，Thread-1 是之前获得过锁，但条件不满足进入WAITING状态的线程，后面讲wait-notify时会分析\n注意:\nsynchronized必须是进入同一个对象的monitor才有上述的效果\n不加synchronized的对象不会关联监视器， 不遵从以上规则\n字节码层面的上理解 static final Object lock = new Object();\nstatic int counter = 0;\npublic static void main(String[] args) {\nsynchronized (lock) {\n​ counter++;\n}\n}\nCode:\n​\tstack=2, locals=3, args_size=1\n​\t0: getstatic #2 // 获取静态变量\n​\t3: dup // 压入操作数栈顶\n​\t4: astore_1 // lock引用 存入 slot 1\n​\t5: monitorenter // 将 lock对象 MarkWord 置为 Monitor 指针\n​\t6: getstatic #3 // 获取counter的值\n​\t9: iconst_1 // 准备常数 1\n​\t10: iadd // +1\n​\t11: putstatic #3 // -\u0026gt; i\n​\t14: aload_1 // \u0026lt;- lock引用\n​\t15: monitorexit // 将 lock对象 MarkWord 重置, 唤醒 EntryList\n​\t16: goto 24\n​\t19: astore_2 // e -\u0026gt; slot 2\n​\t20: aload_1 // \u0026lt;- lock引用\n​\t21: monitorexit // 将 lock对象 MarkWord 重置, 唤醒 EntryList\n​\t22: aload_2 // \u0026lt;- slot 2 (e)\n​\t23: athrow // throw e\n​\t24: return\nException table:\n​\tfrom to target type\n​\t6 16 19 any\n​\t19 22 19 any\nLineNumberTable:\n​\tline 8: 0\n​\tline 9: 6\n​\tline 10: 14\n​\tline 11: 24\nLocalVariableTable:\n​\tStart Length Slot Name Signature\n​\t0 25 0 args [Ljava/lang/String;\nStackMapTable: number_of_entries = 2\n​\tframe_type = 255 /* full_frame */\n​\toffset_delta = 19\n​\tlocals = [ class \u0026ldquo;[Ljava/lang/String;\u0026rdquo;, class java/lang/Object ]\n​\tstack = [ class java/lang/Throwable ]\n​\tframe_type = 250 /* chop */\n​\toffset_delta = 4\n上面讲述的都是重量级锁的状态，其实，一开始的时候并不是重量级锁的状态，而是在竞争后升级成的，下面我们来看这个升级的过程。\n锁升级 轻量级锁 轻量级锁的使用场景：如果一个对象虽然有多线程要加锁，但加锁的时间是错开的（也就是没有竞争），那么可以使用轻量级锁来优化。\n上锁过程\n当线程Thread0执行到monitorenter时，会在线程的栈帧中创建一个名为锁记录的结构： 让锁记录中 Object reference 指向锁对象，并尝试用 cas 替换 Object【锁对象】 的 Mark Word，并将Mark Word 的值存入锁记录【解锁的时候需要替换回来】。 如果 cas 替换成功，对象头中存储了 锁记录地址和状态 00 ，表示由该线程给对象加锁，这时图示如下： 如果 cas 失败，有两种情况\n如果是其它线程已经持有了该 Object 的轻量级锁，这时表明有竞争，进入锁膨胀过程 【参考下面的章节】\n如果是自己执行了 synchronized 锁重入，那么再添加一条 Lock Record 作为重入的计数：\n解锁过程：\n当退出 synchronized 代码块（解锁时）如果有取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重入计数减一。结束\n当退出 synchronized 代码块（解锁时）锁记录的值不为 null，这时使用 cas 将 Mark Word 的值恢复给对象头\n成功，则解锁成功\n失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程【参考monitor】\n锁膨胀过程：\n当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁，这时 Thread-1 加轻量级锁失败，进入锁膨胀流程。\n为 Object 对象申请 Monitor 锁，让 Object markword 指向重量级锁地址,然后自己进入 Monitor 的 EntryList BLOCKED\n当 Thread-0 退出同步块解锁时，使用 cas 将 Mark Word 的值恢复给对象头，失败。这时会进入重量级解锁 流程，即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中 BLOCKED 线程 自旋锁 重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步 块，释放了锁），这时当前线程就可以避免阻塞。\n这是一种侥幸心里，在进入阻塞队里之前，碰碰运气一样 的重新获取锁几次，如果成功了就不必进行上下问的切换了。\n自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势。\n在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。\nJava 7 之后不能控制是否开启自旋功能。\n偏向锁 轻量级锁在没有竞争时（就自己这个线程），每次重入仍然需要执行 CAS 操作。 Java 6 中引入了偏向锁来做进一步优化：只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现 这个线程 ID 是自己的，就表示没有竞争，不用重新 CAS。以后只要不发生竞争，这个对象就归该线程所有。\n加锁过程：\n一个对象刚开始实例化的时候，没有任何线程来访问它的时候。它是可偏向的，意味着，它现在认为只可能有一个线程来访问它，所以当第一个线程来访问它的时候，它会偏向这个线程。\n此时，对象持有偏向锁。偏向第一个线程，这个线程在修改对象头成为偏向锁的时候使用CAS操作，并将对象头中的ThreadID改成自己的ID，之后再次访问这个对象时，只需要对比ID，不需要再使用CAS在进行操作。\n一旦有第二个线程访问这个对象，因为偏向锁不会主动释放，所以第二个线程可以看到对象的偏向状态，这时表明在这个对象上已经存在竞争了。等待偏向线程到达安全点，进行暂停，检查原来持有该对象锁的线程是否依然存活，如果挂了，则可以将对象变为无锁状态，然后重新偏向新的线程\n如果原来的线程依然存活，那么就会将偏向锁升级为轻量级锁，然后唤醒线程 A 执行完后续操作，线程 B 自旋获取轻量级锁。\n锁撤销过程：\n调用了对象的 hashCode，但偏向锁的对象 MarkWord 中存储的是线程 id，如果调用 hashCode 会导致偏向锁被 撤销 。\n轻量级锁会在锁记录中记录 hashCode\n重量级锁会在 Monitor 中记录 hashCode\n小知识：\n如果开启了偏向锁（默认开启），那么对象创建后，markword 值为 0x05 即最后 3 位为 101，这时它的 thread、epoch、age 都为 0\n偏向锁是默认是延迟的，不会在程序启动时立即生效，如果想避免延迟，可以加 VM 参数 - XX:BiasedLockingStartupDelay=0 来禁用延迟\n如果没有开启偏向锁，那么对象创建后，markword 值为 0x01 即最后 3 位为 001，这时它的 hashcode、 age 都为 0，第一次用到 hashcode 时才会赋值\n锁消除 锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持（第11章已经讲解过逃逸分析技术），如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。\n每个StringBuffer.append()方法中都有一个同步块，锁就是sb对象。虚拟机观察变量sb，很快就会发现它的动态作用域被限制在concatString()方法内部。也就是说，sb的所有引用永远不会“逃逸”到concatString()方法之外，其他线程无法访问到它，因此，虽然这里有锁，但是可以被安全地消除掉，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了。\n锁粗化 原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。上面的append()方法就属于这类情况。如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部\nAQS 提供了一个基于FIFO队列，可以用于构建锁或者其他相关同步装置的基础框架。\n在将AQS之前，我们先讲一下锁的套路：\n当多个线程过来竞争锁的时候，只有一个【可以有多个】能成功。\n获取到锁的线程会设置state为加锁状态，并设置当前线程为锁的持有者【可以支持锁重入】。【想想这是为什么】\n没有获取到锁的线程，就会被协调到队列中进行排队\n当锁线程释放锁之后，就会调度队列中的线程去枪锁【根据调度方式的不同，分为公平锁和非公平锁】\n在上面的流程中有几个核心点：\nstate:表示锁是否被持有。每个线程枪锁时，都会判断这个锁是否被持有，没有持有则占锁\n锁的持有线程信息： 当锁被持有后，还有一种情况就是持有线程又来加锁了，此时可以比对这个信息来支持重入【还需要state计数重入次数】\n排队队列【阻塞队列】：这个用来用来存储等待的线程，锁释放之后，会叫醒其中的线程抢锁。\n明白这些以后，我们先看看怎么使用AQS，稍后再说源码。\n下面的代码是一个不可重入的互斥锁，它使用值 0 表示解锁状态，使用值 1 表示锁定状态。 虽然不可重入锁并不严格要求记录当前所有者线程，建议这样做，因为更容易监控。 它还支持condition：\nclass Mutex implements Lock, java.io.Serializable {\n// Our internal helper class\nprivate static class Sync extends AbstractQueuedSynchronizer {\n// 获取锁\npublic boolean tryAcquire(int acquires) {\n​ assert acquires == 1; // Otherwise unused\n​ if (compareAndSetState(0, 1)) {\n​ setExclusiveOwnerThread(Thread.currentThread());\n​ return true;\n​ }\n​ return false;\n}\n// 释放锁\nprotected boolean tryRelease(int releases) {\n​ assert releases == 1; // Otherwise unused\n​ if (!isHeldExclusively()) //判断线程是否是锁的持有者\n​ throw new IllegalMonitorStateException();\n​ setExclusiveOwnerThread(null);\n​ setState(0);\n​ return true;\n}\n// 检测锁是否已经被占用\npublic boolean isLocked() {\n​ return getState() != 0;\n}\n// 检测当前线程是否是锁的持有者\npublic boolean isHeldExclusively() {\n​ // a data race, but safe due to out-of-thin-air guarantees\n​ return getExclusiveOwnerThread() == Thread.currentThread();\n}\n//创建 Condition\npublic Condition newCondition() {\n​ return new ConditionObject();\n}\n// 反序列化\nprivate void readObject(ObjectInputStream s)\n​ throws IOException, ClassNotFoundException {\n​ s.defaultReadObject();\n​ setState(0); // reset to unlocked state\n}\n}\n// The sync object does all the hard work. We just forward to it.\nprivate final Sync sync = new Sync();\npublic void lock() { sync.acquire(1); }\npublic boolean tryLock() { return sync.tryAcquire(1); }\npublic void unlock() { sync.release(1); }\npublic Condition newCondition() { return sync.newCondition(); }\npublic boolean isLocked() { return sync.isLocked(); }\npublic boolean isHeldByCurrentThread() {\nreturn sync.isHeldExclusively();\n}\npublic boolean hasQueuedThreads() {\nreturn sync.hasQueuedThreads();\n}\npublic void lockInterruptibly() throws InterruptedException {\nsync.acquireInterruptibly(1);\n}\npublic boolean tryLock(long timeout, TimeUnit unit)\n​ throws InterruptedException {\nreturn sync.tryAcquireNanos(1, unit.toNanos(timeout));\n}\n}\n看完这些代码，你可能比较晕，里面提供了一些名字几乎相同的方法，比如release和tryRelease，我们先来解析一下这个。\n我们先来看几个受保护的方法，需要子类去实现的：\ntryAcquire(int arg)：获取独占锁，成功返回true，失败返回false。该方法内会根据state值来决定返回结果\ntryRelease(int arg)：释放独占锁，成功返回true,失败返回false.\ntryAcquireShared(int arg)：获取共享锁，成功返回true，失败返回false。\ntryReleaseShared(int arg)：释放共享锁，成功返回true,失败返回false.\nisHeldExclusively：是否是独占锁。\n这些方法需要子类继承并实现，才能提供服务。\n下面我们来看AQS提供的对外公开方法：\nacquire(int arg)：获取独占锁，成功则返回，失败可能会阻塞\nacquireInterruptibly(int arg)：acquire的升级版，获取锁的过程支持可打断\nacquireShared(int arg)：获取共享锁，负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源\nacquireSharedInterruptibly(int arg)：获取共享锁，过程支持可打断。\nrelease(int arg)：释放独占锁\nreleaseShared(int arg)：释放共享锁，如果释放后允许唤醒后续等待结点返回true，否则返回false。\ntryAcquireNanos(int arg, long nanosTimeout)：获取独占锁，支持超时\ntryAcquireSharedNanos(int arg, long nanosTimeout)：获取共享锁，支持超时\n这些方法提供了加锁的入口，我们应该先从这些方法的源码看起。\n等待队列\n​\n​ // CANCELLED，值为1，表示当前的线程被取消；\n​ // SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark；\n​ // CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中；\n​ // PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行；\n​ // 值为0，表示当前节点在sync队列中，等待着获取锁。\n​ volatile int waitStatus; //等待的状态\n​ volatile Node prev; //前一个节点\n​ volatile Node next; //后一个节点\n​ volatile Thread thread; //持有该节点的线程\n​ Node nextWaiter; //存储condition队列中的后继节点。\n​ Node() { // Used to establish initial head or SHARED marker\n​ }\n​ Node(Thread thread, Node mode) { // Used by addWaiter\n​ this.nextWaiter = mode;\n​ this.thread = thread;\n​ }\n​ Node(Thread thread, int waitStatus) { // Used by Condition\n​ this.waitStatus = waitStatus;\n​ this.thread = thread;\n​ }\n独占加锁流程【ReentrantLock】 代码顺序：lock\u0026raquo; acquire(1)\u0026raquo;tryAcquire(1)【ReentrantLock.Sync.nonfairTryAcquire(1)】\u0026raquo;addWaiter(Node.EXCLUSIVE), 1)\u0026raquo;acquireQueued\n对应的流程：开始\u0026raquo;获取锁，成功则终止\u0026raquo;添加到等待队列\u0026raquo;再次尝试获取锁，失败则等待\n【入口，尝试直接加锁，简化版】\n​ final void lock() {\n​ if (compareAndSetState(0, 1))\n​ setExclusiveOwnerThread(Thread.currentThread());\n​ else\n​ acquire(1);\n​ }\n【流程概览】\npublic final void acquire(int arg) { //arg=1\n​ if (!tryAcquire(arg) \u0026amp;\u0026amp; // 尝试获取锁，成功则返回\n​ acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //添加到等待队列 ，Node.EXCLUSIVE是null,表示独占模式\n​ selfInterrupt(); //该模式下不支持打断，这个是被打断线程获取到锁之后，根据之前的打断状态，然后自我打断\n}\n【获取锁的过程，详细版】tryAcquire底层执行的是下面的代码：\n​ final boolean nonfairTryAcquire(int acquires) { //acquires=1\n​ final Thread current = Thread.currentThread();\n​ int c = getState();\n​ if (c == 0) { // 0:未加锁\n​ if (compareAndSetState(0, acquires)) { //加锁\n​ setExclusiveOwnerThread(current);\n​ return true;\n​ }\n​ }\n​ else if (current == getExclusiveOwnerThread()) { //是否是锁重入\n​ int nextc = c + acquires;\n​ if (nextc \u0026lt; 0) // overflow //超过整数的范围了，重入的次数太多了\n​ throw new Error(\u0026ldquo;Maximum lock count exceeded\u0026rdquo;);\n​ setState(nextc); //锁重入计数\n​ return true;\n​ }\n​ return false;\n​ }\n枪锁失败，【添加节点到阻塞队列】\nprivate Node addWaiter(Node mode) { //mode 是null\n​ Node node = new Node(Thread.currentThread(), mode); //mode传入null，代表该节点不是用于await队列\n​ // Try the fast path of enq; backup to full enq on failure\n​ Node pred = tail;\n​ if (pred != null) { //队列中有节点\n​ node.prev = pred; //设置添加节点的前驱\n​ if (compareAndSetTail(pred, node)) { //设置当前节点为尾节点\n​ pred.next = node; //原先尾节点的next指向新的尾节点\n​ return node;\n​ }\n​ }\n​ // 初始化队列，并添加节点\n​ enq(node);\n​ return node;\n}\n【初始化等待对立，并添加节点】\nprivate Node enq(final Node node) {\n​ for (;;) {\n​ Node t = tail;\n​ if (t == null) { // 这是第一次进来，初始化队列，头尾相等，\n​ if (compareAndSetHead(new Node())) //设置头节点\n​ tail = head; //设置尾节点\n​ } else { //第二次进来，将新节点添加到队列\n​ node.prev = t;\n​ if (compareAndSetTail(t, node)) {\n​ t.next = node;\n​ return t;\n​ }\n​ }\n​ }\n}\n【队列节点进入阻塞状态】\nfinal boolean acquireQueued(final Node node, int arg) { //node表示被添加的节点 arg=1\n​ boolean failed = true;\n​ try {\n​ boolean interrupted = false; //线程阻塞的过程中，是否被打断过\n​ for (;;) { //线程被唤醒也会走这里\n​ final Node p = node.predecessor(); //前驱节点\n​ //如果是队列中的第一个节点，阻塞前，再尝试获取一把锁\n​ if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) {\n​ setHead(node); //将节点设置为头节点，原先头节点移除\n​ p.next = null; // help GC\n​ failed = false;\n​ return interrupted;\n​ }\n​ // 检查受否应该让线程阻塞，通过设置节点的waitStatus\n​ if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp;\n​ parkAndCheckInterrupt()) //阻塞线程\n​ interrupted = true; //线程被打断过则设置打断标记为true\n​ }\n​ } finally {\n​ if (failed)\n​ cancelAcquire(node);\n​ }\n}\nprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // node.pre == pred\n​ int ws = pred.waitStatus;\n​ if (ws == Node.SIGNAL) //-1 ， 节点状态已经是Signal了，可以被阻塞\n​ return true;\n​ if (ws \u0026gt; 0) { //前驱节点被取消了\n​ do { //删除前驱节点\n​ node.prev = pred = pred.prev;\n​ } while (pred.waitStatus \u0026gt; 0);\n​ pred.next = node;\n​ } else { //0或-3(PROPAGATE)的情况\n​ // 设置节点为signal\n​ compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n​ }\n​ return false;\n}\n// 阻塞线程了\nprivate final boolean parkAndCheckInterrupt() {\n​ LockSupport.park(this);\n​ // 判断线程是否被打断过，并清除打断标记\n​ return Thread.interrupted();\n}\n下面是线程A持有锁，线程B抢锁过程的示意图：\nThead-0获取到了锁 Thread-1 执行了CAS 尝试将 state 由 0 改为 1，结果失败。进入 tryAcquire 逻辑，这时 state 已经是1，结果仍然失败 接下来进入 addWaiter 逻辑，构造 Node 队列。图中黄色三角表示该 Node 的 waitStatus 状态，其中 0 为默认正常状态 。Node 的创建是懒惰的 。其中第一个 Node 称为 Dummy（哑元）或哨兵，用来占位，并不关联线程 当前线程进入 acquireQueued 逻辑 【acquireQueued 会在一个死循环中尝试几次获得锁，失败后进入 park 阻塞 】。如果自己是紧邻着 head（排第二位），那么再次 tryAcquire 尝试获取锁，当然这时 state 仍为 1，失败 。 进入 shouldParkAfterFailedAcquire 逻辑，将前驱 node，即 head 的 waitStatus 改为 -1，这次返回 false； shouldParkAfterFailedAcquire 执行完毕回到 acquireQueued ，再次 tryAcquire 尝试获取锁，当然这时state 仍为 1，失败。当再次进入 shouldParkAfterFailedAcquire 时，这时因为其前驱 node 的 waitStatus 已经是 -1，这次返回true。进入 parkAndCheckInterrupt， Thread-1 park（灰色表示） 再次有多个线程经历上述过程竞争失败，变成这个样子： 独占锁解锁流程 【释放锁的总流程】\npublic final boolean release(int arg) {\n​ if (tryRelease(arg)) { //解锁成功\n​ Node h = head;\n​ if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) //有排队等待的线程, -1 -2 -3\n​ unparkSuccessor(h); //唤醒线程\n​ return true;\n​ }\n​ return false;\n}\n【释放锁的操作】\n​ protected final boolean tryRelease(int releases) { //releases=1\n​ int c = getState() - releases;\n​ if (Thread.currentThread() != getExclusiveOwnerThread()) //必须是持有锁的线程才能释放锁\n​ throw new IllegalMonitorStateException();\n​ boolean free = false;\n​ if (c == 0) { // c=0 ；表示锁都释放成功了，其他大于0的值，表示还有重入的锁\n​ free = true;\n​ setExclusiveOwnerThread(null);\n​ }\n​ setState(c);\n​ return free;\n​ }\n【唤醒其他线程来枪锁】\nprivate void unparkSuccessor(Node node) { //node是头节点\n​ // 如果节点是负值，代表是需要唤醒后续节点\n​ int ws = node.waitStatus;\n​ if (ws \u0026lt; 0)\n​ // 节点修改成0，该节点如果是线程节点，在唤醒后可能被删除了\n​ compareAndSetWaitStatus(node, ws, 0);\n​ // unpark后继节点，通常是下一个节点。 但如果下个节点的状态是取消或明显为空，\n​ // 从尾部向后遍历以找到实际未取消的节点。\n​ Node s = node.next;\n​ if (s == null || s.waitStatus \u0026gt; 0) { // 1代表取消\n​ s = null;\n​ for (Node t = tail; t != null \u0026amp;\u0026amp; t != node; t = t.prev)\n​ if (t.waitStatus \u0026lt;= 0)\n​ s = t; // 找到待唤醒的节点\n​ }\n​ if (s != null) //唤醒后续节点\n​ LockSupport.unpark(s.thread);\n}\n此时需要我们继续回到原先抢锁暂停的地方。\n我们来总结一下这个过程：\nThread-0 释放锁，进入 tryRelease 流程，如果成功，设置 exclusiveOwnerThread 为 null，state = 0 当前队列不为 null，并且 head 的 waitStatus = -1，进入 unparkSuccessor 流程，找到队列中离 head 最近的一个 Node（没取消的），unpark 恢复其运行，本例中即为 Thread-1回到 Thread-1 的 acquireQueued 流程： 如果加锁成功（没有竞争），会设置exclusiveOwnerThread 为 Thread-1，state = 1。如果这时候有其它线程来竞争（非公平的体现），例如这时有 Thread-4 来了： 如果不巧又被 Thread-4 占了先，Thread-4 被设置为 exclusiveOwnerThread，state = 1。Thread-1 再次进入 acquireQueued 流程，获取锁失败，重新进入 park 阻塞 打断锁的原理 上面的代码中所讲的锁，是不可打断的。即使线程被打断，他仍然在队列节点中等待。当抢到锁之后，会根据线程的打断记录来进行一次自我打断的调用。\nacquireInterruptibly(int arg)方法支持打断，我们来看一下原理：\npublic final void acquireInterruptibly(int arg)\n​ throws InterruptedException {\n​ if (Thread.interrupted())\n​ throw new InterruptedException();\n​ if (!tryAcquire(arg)) // 尝试获取锁，成功则终止\n​ doAcquireInterruptibly(arg);\n}\n下面就是加入阻塞队列的流程了，跟上面的几乎一样：\nprivate void doAcquireInterruptibly(int arg)\n​ throws InterruptedException {\n​ final Node node = addWaiter(Node.EXCLUSIVE);\n​ boolean failed = true;\n​ try {\n​ for (;;) {\n​ final Node p = node.predecessor();\n​ if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) {\n​ setHead(node);\n​ p.next = null; // help GC\n​ failed = false;\n​ return;\n​ }\n​ if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp;\n​ parkAndCheckInterrupt()) // 被打断了\n​ throw new InterruptedException(); //直接抛出异常\n​ }\n​ } finally {\n​ if (failed)\n​ cancelAcquire(node);\n​ }\n}\n公平锁的实现 新线程每次在抢锁的时候，会检查队列中是否有等待的线程，有就去排队\n​ protected final boolean tryAcquire(int acquires) {\n​ final Thread current = Thread.currentThread();\n​ int c = getState();\n​ if (c == 0) {\n​ // 检查是否有排队的线程\n​ if (!hasQueuedPredecessors() \u0026amp;\u0026amp;\n​ compareAndSetState(0, acquires)) {\n​ setExclusiveOwnerThread(current);\n​ return true;\n​ }\n​ }\n​ else if (current == getExclusiveOwnerThread()) {\n​ int nextc = c + acquires;\n​ if (nextc \u0026lt; 0)\n​ throw new Error(\u0026ldquo;Maximum lock count exceeded\u0026rdquo;);\n​ setState(nextc);\n​ return true;\n​ }\n​ return false;\n​ }\npublic final boolean hasQueuedPredecessors() {\n​ // The correctness of this depends on head being initialized\n​ // before tail and on head.next being accurate if the current\n​ // thread is first in queue.\n​ Node t = tail; // Read fields in reverse initialization order\n​ Node h = head;\n​ Node s;\n​ return h != t \u0026amp;\u0026amp;\n​ ((s = h.next) == null || s.thread != Thread.currentThread());\n}\n锁超时 流程基本跟可打算锁一样，在实现的park的时候，增加了超时时间，这样线程可以在超时之后醒来，并终止获取锁流程。\npublic final boolean tryAcquireNanos(int arg, long nanosTimeout)\n​ throws InterruptedException {\n​ if (Thread.interrupted())\n​ throw new InterruptedException();\n​ return tryAcquire(arg) ||\n​ doAcquireNanos(arg, nanosTimeout);\n}\nprivate boolean doAcquireNanos(int arg, long nanosTimeout)\n​ throws InterruptedException {\n​ if (nanosTimeout \u0026lt;= 0L)\n​ return false;\n​ final long deadline = System.nanoTime() + nanosTimeout;\n​ final Node node = addWaiter(Node.EXCLUSIVE);\n​ boolean failed = true;\n​ try {\n​ for (;;) {\n​ final Node p = node.predecessor();\n​ if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) {\n​ setHead(node);\n​ p.next = null; // help GC\n​ failed = false;\n​ return true;\n​ }\n​ nanosTimeout = deadline - System.nanoTime();\n​ if (nanosTimeout \u0026lt;= 0L)\n​ return false;\n​ if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp;\n​ nanosTimeout \u0026gt; spinForTimeoutThreshold)\n​ LockSupport.parkNanos(this, nanosTimeout);\n​ if (Thread.interrupted())\n​ throw new InterruptedException();\n​ }\n​ } finally {\n​ if (failed) // 超时之后要执行一些清理工作\n​ cancelAcquire(node);\n​ }\n}\n条件变量的实现原理 如果当前线程被中断，则抛出 InterruptedException。\n保存由 getState 返回的锁状态。\n以保存的状态作为参数调用 release，如果失败则抛出 IllegalMonitorStateException。\n阻塞直到发出信号或被中断。\n通过以保存的状态作为参数调用特定版本的获取来重新获取。\n如果在步骤 4 中被阻塞时被中断，则抛出 InterruptedException。\n​ public final void await() throws InterruptedException {\n​ if (Thread.interrupted())\n​ throw new InterruptedException();\n​ // 添加到等待队列\n​ Node node = addConditionWaiter();\n​ // 释放锁\n​ int savedState = fullyRelease(node);\n​ int interruptMode = 0;\n​ // 判断节点是否已经被移动到阻塞队列，有可能刚调用await,另外一个线程调用了signal\n​ while (!isOnSyncQueue(node)) {\n​ LockSupport.park(this); //进入阻塞模式\n​ if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) //检测节点在等待过程是否被打断\n​ break;\n​ }\n​ // 被唤醒之后，添加到阻塞队列\n​ if (acquireQueued(node, savedState) \u0026amp;\u0026amp; interruptMode != THROW_IE)\n​ interruptMode = REINTERRUPT;\n​ if (node.nextWaiter != null)\n​ unlinkCancelledWaiters(); // 清除失效的节点\n​ if (interruptMode != 0)\n​ reportInterruptAfterWait(interruptMode);\n​ }\n​ // 检测线程是否被打断\n​ private int checkInterruptWhileWaiting(Node node) {\n​ return Thread.interrupted() ?\n​ (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :\n​ 0;\n​ }\n​ // 根据打断模式进行相应的处理\n​ private void reportInterruptAfterWait(int interruptMode)\n​ throws InterruptedException {\n​ if (interruptMode == THROW_IE)\n​ throw new InterruptedException();\n​ else if (interruptMode == REINTERRUPT)\n​ selfInterrupt();\n​ }\nfinal int fullyRelease(Node node) {\n​ boolean failed = true;\n​ try {\n​ int savedState = getState();\n​ if (release(savedState)) {\n​ failed = false;\n​ return savedState;\n​ } else {\n​ throw new IllegalMonitorStateException();\n​ }\n​ } finally {\n​ if (failed)\n​ node.waitStatus = Node.CANCELLED;\n​ }\n}\nfinal boolean isOnSyncQueue(Node node) {\n​ if (node.waitStatus == Node.CONDITION || node.prev == null)\n​ return false;\n​ if (node.next != null) //如果有后继节点，肯定在同步队列\n​ return true;\n​ return findNodeFromTail(node);\n}\n// 从阻塞队列中查找该节点，true表示在阻塞队列\nprivate boolean findNodeFromTail(Node node) {\n​ Node t = tail;\n​ for (;;) {\n​ if (t == node)\n​ return true;\n​ if (t == null)\n​ return false;\n​ t = t.prev;\n​ }\n}\n【添加等待节点】\n​ private Node addConditionWaiter() {\n​ Node t = lastWaiter;\n​ // 取消失效的等待节点\n​ if (t != null \u0026amp;\u0026amp; t.waitStatus != Node.CONDITION) {\n​ unlinkCancelledWaiters();\n​ t = lastWaiter;\n​ }\n​ //下面的流程就是创建节点并添加到队列中\n​ Node node = new Node(Thread.currentThread(), Node.CONDITION);\n​ if (t == null)\n​ firstWaiter = node;\n​ else\n​ t.nextWaiter = node;\n​ lastWaiter = node;\n​ return node;\n​ }\n唤醒机制 ​ public final void signal() {\n​ if (!isHeldExclusively())\n​ throw new IllegalMonitorStateException();\n​ Node first = firstWaiter;\n​ if (first != null)\n​ doSignal(first);\n​ }\n​ private void doSignal(Node first) {\n​ do {\n​ if ( (firstWaiter = first.nextWaiter) == null)\n​ lastWaiter = null;\n​ first.nextWaiter = null;\n​ } while (!transferForSignal(first) \u0026amp;\u0026amp;\n​ (first = firstWaiter) != null);\n​ }\nfinal boolean transferForSignal(Node node) {\n​ // 如果设置不成功，说明切点已经被取消\n​ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))\n​ return false;\n​ // 节点入队，p是当前节点的前驱\n​ Node p = enq(node);\n​ int ws = p.waitStatus;\n​ // 前驱节点需要设置waitstatus=-1,表示他的后继节点需要被唤醒\n​ if (ws \u0026gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))\n​ LockSupport.unpark(node.thread);\n​ return true;\n}\n下面我们来对这个代码流程进行总结：\n开始 Thread-0 持有锁，调用 await，进入 ConditionObject 的 addConditionWaiter 流程。创建新的 Node 状态为 -2（Node.CONDITION），关联 Thread-0，加入等待队列尾部。 接下来进入 AQS 的 fullyRelease 流程，释放同步器上的锁 unpark AQS 队列中的下一个节点，竞争锁，假设没有其他竞争线程，那么 Thread-1 竞争成功 park 阻塞 Thread-0： 下面进入唤醒流程，假设 Thread-1 要来唤醒 Thread-0，进入 ConditionObject 的 doSignal 流程，取得等待队列中第一个 Node，即 Thread-0 所在 Node 执行 transferForSignal 流程，将该 Node 加入 AQS 队列尾部，将 Thread-0 的 waitStatus 改为 0，Thread-3 的waitStatus 改为 -1 Thread-1 释放锁，进入 unlock 流程，略。 读写锁 读写锁的应用场景：【更新缓存】\nclass CachedData {\nObject data;\nvolatile boolean cacheValid;\nfinal ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();\nvoid processCachedData() {\nrwl.readLock().lock();\nif (!cacheValid) {\n​ // 获取写锁之前必须释放读锁\n​ rwl.readLock().unlock();\n​ rwl.writeLock().lock();\n​ try {\n​ // 重新检查，可能会有别的写线程已经修改了数据\n​ if (!cacheValid) {\n​ data = \u0026hellip;\n​ cacheValid = true;\n​ }\n​ // 在释放写锁前，先降级为读锁\n​ rwl.readLock().lock();\n​ } finally {\n​ rwl.writeLock().unlock(); // 释放了写锁，但是仍然持有读锁\n​ }\n}\ntry {\n​ use(data);\n} finally {\n​ rwl.readLock().unlock();\n}\n}\n}\n在看源代码之前，我们先来明确几点：\n读写锁用的是同一个 Sycn 同步器，因此等待队列、state 等也是同一个\n流程与 ReentrantLock 加锁相比没有特殊之处，不同是写锁状态占了 state 的低 16 位，而读锁使用的是 state 的高 16 位\n上写锁成功之后，后序的节点也会依次加入到阻塞队列中。不过，在写锁释放的时候，会唤醒所有的读锁【假如后面紧跟者着多个读锁】\n先看一下锁的构建函数,底层使用的是同一个同步器：\npublic ReentrantReadWriteLock(boolean fair) {\n​ sync = fair ? new FairSync() : new NonfairSync();\n​ readerLock = new ReadLock(this);\n​ writerLock = new WriteLock(this);\n}\n​ protected ReadLock(ReentrantReadWriteLock lock) {\n​ sync = lock.sync;\n​ }\n​ protected WriteLock(ReentrantReadWriteLock lock) {\n​ sync = lock.sync;\n​ }\n写锁加锁 // 下面这些代码是不是很熟悉，关键看子类实现的tryAcquire方法\npublic void lock() {\n​ sync.acquire(1);\n}\npublic final void acquire(int arg) {\n​ if (!tryAcquire(arg) \u0026amp;\u0026amp;\n​ acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n​ selfInterrupt();\n}\n【写锁加锁】:\n（如果读锁计数非零）||（写锁计数非零且不是当前线程），写锁获取失败\n如果锁计数超过限定的范围，则抛出异常\n否则，此线程有资格锁定， 并更新状态并设置所有者。\n​ protected final boolean tryAcquire(int acquires) {\n​ Thread current = Thread.currentThread();\n​ int c = getState();\n​ int w = exclusiveCount(c); //获取写锁上的计数\n​ if (c != 0) {\n​ //写锁计数不为零，并且非当前线程，则获取锁失败\n​ if (w == 0 || current != getExclusiveOwnerThread())\n​ return false;\n​ if (w + exclusiveCount(acquires) \u0026gt; MAX_COUNT)\n​ throw new Error(\u0026ldquo;Maximum lock count exceeded\u0026rdquo;);\n​ // Reentrant acquire\n​ setState(c + acquires);\n​ return true;\n​ }\n​ // writerShouldBlock：用来判断是否是公平锁，非公平默认返回true\n​ if (writerShouldBlock() ||\n​ //cas 更新锁计数，成功则返回true,表示加锁成功\n​ !compareAndSetState(c, c + acquires))\n​ return false;\n​ setExclusiveOwnerThread(current);\n​ return true;\n​ }\n假如现在写锁加锁成功了，还没有释放锁，我们来看读锁的工作流程。\npublic void lock() {\n​ sync.acquireShared(1);\n​ }\npublic final void acquireShared(int arg) { // arg=1\n​ // -1 表示失败\n​ // 0 表示成功，但后继节点不会继续唤醒\n​ // 正数表示成功，而且数值是还有几个后继节点需要唤醒，读写锁返回 1\n​ if (tryAcquireShared(arg) \u0026lt; 0) // 尝试获取锁，成功则返回1，失败则返回-1\n​ doAcquireShared(arg); //进入阻塞队列\n}\n共享锁获取流程 如果其他线程持有写锁，则失败，返回-1\ncas更新读锁计数\n如果失败，进入完整版本的获取锁流程，该流程可能会让线程进入等待队列\n​ protected final int tryAcquireShared(int unused) {\n​ Thread current = Thread.currentThread();\n​ int c = getState();\n​ // 判断是否有写线程上锁，并且写线程不是当前线程\n​ if (exclusiveCount(c) != 0 \u0026amp;\u0026amp;\n​ getExclusiveOwnerThread() != current)\n​ return -1;\n​ int r = sharedCount(c);\n​ if (!readerShouldBlock() \u0026amp;\u0026amp;\n​ r \u0026lt; MAX_COUNT \u0026amp;\u0026amp;\n​ compareAndSetState(c, c + SHARED_UNIT)) { // cas抢锁\n​ if (r == 0) {\n​ firstReader = current;\n​ firstReaderHoldCount = 1;\n​ } else if (firstReader == current) {\n​ firstReaderHoldCount++;\n​ } else {\n​ HoldCounter rh = cachedHoldCounter;\n​ if (rh == null || rh.tid != getThreadId(current))\n​ cachedHoldCounter = rh = readHolds.get();\n​ else if (rh.count == 0)\n​ readHolds.set(rh);\n​ rh.count++;\n​ }\n​ return 1; // 获得了读锁\n​ }\n​ return fullTryAcquireShared(current); // 完成版的抢锁流程\n​ }\n【完整版的读锁获取流程】，比较难懂，掠过\n​ final int fullTryAcquireShared(Thread current) {\n​ HoldCounter rh = null;\n​ for (;;) {\n​ int c = getState();\n​ if (exclusiveCount(c) != 0) { //判断写锁计数\n​ if (getExclusiveOwnerThread() != current) //判断写锁线程是否是当前线程\n​ return -1;\n​ // else we hold the exclusive lock; blocking here\n​ // would cause deadlock.\n​ } else if (readerShouldBlock()) {\n​ // Make sure we\u0026rsquo;re not acquiring read lock reentrantly\n​ if (firstReader == current) {\n​ // assert firstReaderHoldCount \u0026gt; 0;\n​ } else {\n​ if (rh == null) {\n​ rh = cachedHoldCounter;\n​ if (rh == null || rh.tid != getThreadId(current)) {\n​ rh = readHolds.get();\n​ if (rh.count == 0)\n​ readHolds.remove();\n​ }\n​ }\n​ if (rh.count == 0)\n​ return -1;\n​ }\n​ }\n​ if (sharedCount(c) == MAX_COUNT)\n​ throw new Error(\u0026ldquo;Maximum lock count exceeded\u0026rdquo;);\n​ if (compareAndSetState(c, c + SHARED_UNIT)) {\n​ if (sharedCount(c) == 0) {\n​ firstReader = current;\n​ firstReaderHoldCount = 1;\n​ } else if (firstReader == current) {\n​ firstReaderHoldCount++;\n​ } else {\n​ if (rh == null)\n​ rh = cachedHoldCounter;\n​ if (rh == null || rh.tid != getThreadId(current))\n​ rh = readHolds.get();\n​ else if (rh.count == 0)\n​ readHolds.set(rh);\n​ rh.count++;\n​ cachedHoldCounter = rh; // cache for release\n​ }\n​ return 1;\n​ }\n​ }\n​ }\n【读锁等待流程】\nprivate void doAcquireShared(int arg) {\n​ // 添加等待节点到队尾，注意这里是共享节点，不是独占了\n​ final Node node = addWaiter(Node.SHARED);\n​ boolean failed = true;\n​ try {\n​ boolean interrupted = false;\n​ for (;;) {\n​ final Node p = node.predecessor();\n​ if (p == head) { //如果当前节点的前驱是头节点，再次尝试获取锁\n​ int r = tryAcquireShared(arg);\n​ if (r \u0026gt;= 0) { //获取锁成功\n​ setHeadAndPropagate(node, r); //继续唤醒后面的读锁\n​ p.next = null; // help GC\n​ if (interrupted)\n​ selfInterrupt();\n​ failed = false;\n​ return;\n​ }\n​ }\n​ // 检查线程是否需要阻塞\n​ if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp;\n​ parkAndCheckInterrupt()) //阻塞线程\n​ interrupted = true;\n​ }\n​ } finally {\n​ if (failed)\n​ cancelAcquire(node);\n​ }\n}\n我们接着来看，读锁唤醒的流程setHeadAndPropagate：\n// node是已经唤醒的节点，propagate待唤醒的读锁个数\nprivate void setHeadAndPropagate(Node node, int propagate) {\n​ Node h = head; // Record old head for check below\n​ setHead(node);\n​ if (propagate \u0026gt; 0 || h == null || h.waitStatus \u0026lt; 0 ||\n​ (h = head) == null || h.waitStatus \u0026lt; 0) {\n​ Node s = node.next;\n​ if (s == null || s.isShared()) //后续节点还是共享节点，继续唤醒\n​ doReleaseShared();\n​ }\n}\nprivate void doReleaseShared() {\n​ for (;;) {\n​ Node h = head;\n​ if (h != null \u0026amp;\u0026amp; h != tail) {\n​ int ws = h.waitStatus;\n​ if (ws == Node.SIGNAL) { // 节点需要唤醒\n​ if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) //设置头节点状态为0，防止乱序唤醒\n​ continue; // loop to recheck cases\n​ unparkSuccessor(h);\n​ }\n​ else if (ws == 0 \u0026amp;\u0026amp;\n​ !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n​ continue; // loop on failed CAS\n​ }\n​ if (h == head) // loop if head changed\n​ break;\n​ }\n}\n写锁的释放流程 public final boolean release(int arg) {\n​ if (tryRelease(arg)) {\n​ Node h = head;\n​ if (h != null \u0026amp;\u0026amp; h.waitStatus != 0)\n​ unparkSuccessor(h);\n​ return true;\n​ }\n​ return false;\n}\nprotected final boolean tryRelease(int releases) {\n​ if (!isHeldExclusively())\n​ throw new IllegalMonitorStateException();\n​ int nextc = getState() - releases;\n​ boolean free = exclusiveCount(nextc) == 0;\n​ if (free)\n​ setExclusiveOwnerThread(null);\n​ setState(nextc);\n​ return free;\n}\n读锁的释放流程 public final boolean releaseShared(int arg) {\n​ if (tryReleaseShared(arg)) {\n​ doReleaseShared();\n​ return true;\n​ }\n​ return false;\n}\n​ protected final boolean tryReleaseShared(int unused) {\n​ Thread current = Thread.currentThread();\n​ if (firstReader == current) {\n​ // assert firstReaderHoldCount \u0026gt; 0;\n​ if (firstReaderHoldCount == 1)\n​ firstReader = null;\n​ else\n​ firstReaderHoldCount\u0026ndash;;\n​ } else {\n​ HoldCounter rh = cachedHoldCounter;\n​ if (rh == null || rh.tid != getThreadId(current))\n​ rh = readHolds.get();\n​ int count = rh.count;\n​ if (count \u0026lt;= 1) {\n​ readHolds.remove();\n​ if (count \u0026lt;= 0)\n​ throw unmatchedUnlockException();\n​ }\n​ \u0026ndash;rh.count;\n​ }\n​ for (;;) {\n​ int c = getState();\n​ int nextc = c - SHARED_UNIT;\n​ if (compareAndSetState(c, nextc))\n​ // Releasing the read lock has no effect on readers,\n​ // but it may allow waiting writers to proceed if\n​ // both read and write locks are now free.\n​ return nextc == 0;\n​ }\n​ }\n我们来对上面的代码进行一下总结：假设 t1 w.lock，t2 r.lock\nt1 成功上锁，流程与 ReentrantLock 加锁相比没有特殊之处，不同是写锁状态占了 state 的低 16 位，而读锁使用的是 state 的高 16 位 t2 执行 r.lock，这时进入读锁的 sync.acquireShared(1) 流程，首先会进入 tryAcquireShared 流程。如果有写锁占据，那么 tryAcquireShared 返回 -1 表示失败 这时会进入 sync.doAcquireShared(1) 流程，首先也是调用 addWaiter 添加节点，不同之处在于节点被设置为Node.SHARED 模式而非 Node.EXCLUSIVE 模式，注意此时 t2 仍处于活跃状态 t2 会看看自己的节点是不是老二，如果是，还会再次调用 tryAcquireShared(1) 来尝试获取锁\n如果没有成功，在 doAcquireShared 内 for (;;) 循环一次，把前驱节点的 waitStatus 改为 -1，再 for (;;) 循环一次尝试 tryAcquireShared(1) 如果还不成功，那么在 parkAndCheckInterrupt() 处 park\n这种状态下，假设又有 t3 加读锁和 t4 加写锁，这期间 t1 仍然持有锁，就变成了下面的样子 t1 w.unlock这时会走到写锁的 sync.release(1) 流程，调用 sync.tryRelease(1) 成功，变成下面的样子 接下来执行唤醒流程 sync.unparkSuccessor，即让老二恢复运行，这时 t2 在 doAcquireShared 内parkAndCheckInterrupt() 处恢复运行这回再来一次 for (;;) 执行 tryAcquireShared 成功则让读锁计数加一 这时 t2 已经恢复运行，接下来 t2 调用 setHeadAndPropagate(node, 1)，它原本所在节点被置为头节点 事情还没完，在 setHeadAndPropagate 方法内还会检查下一个节点是否是 shared，如果是则调用doReleaseShared() 将 head 的状态从 -1 改为 0 并唤醒老二，这时 t3 在 doAcquireShared 内parkAndCheckInterrupt() 处恢复运行\n这回再来一次 for (;;) 执行 tryAcquireShared 成功则让读锁计数加一 这时 t3 已经恢复运行，接下来 t3 调用 setHeadAndPropagate(node, 1)，它原本所在节点被置为头节点 下一个节点不是 shared 了，因此不会继续唤醒 t4 所在节点。\nt2 r.unlock，t3 r.unlock。t2 进入 sync.releaseShared(1) 中，调用 tryReleaseShared(1) 让计数减一，但由于计数还不为零\nt3 进入 sync.releaseShared(1) 中，调用 tryReleaseShared(1) 让计数减一，这回计数为零了，进入doReleaseShared() 将头节点从 -1 改为 0 并唤醒老二，即 之后 t4 在 acquireQueued 中 parkAndCheckInterrupt 处恢复运行，再次 for (;;) 这次自己是老二，并且没有其他竞争，tryAcquire(1) 成功，修改头结点，流程结束 Semaphore原理 信号量，用来限制能同时访问共享资源的线程上限。\nSemaphore 有点像一个停车场，permits 就好像停车位数量，当线程获得了 permits 就像是获得了停车位，然后停车场显示空余车位减一\n模拟：刚开始，permits（state）为 3，这时 5 个线程来获取资源\n假设其中 Thread-1，Thread-2，Thread-4 cas 竞争成功，而 Thread-0 和 Thread-3 竞争失败，进入 AQS 队列park 阻塞\n这时 Thread-4 释放了 permits，状态如下：\n接下来 Thread-0 竞争成功，permits 再次设置为 0，设置自己为 head 节点，断开原来的 head 节点，unpark 接下来的 Thread-3 节点，但由于 permits 是 0，因此 Thread-3 在尝试不成功后再次进入 park 状态\n我们先来看怎么使用\n​ Semaphore semaphore = new Semaphore(3);\n​ for (int i = 0; i \u0026lt; 5; i++) {\n​ new Thread(() -\u0026gt; {\n​ try {\n​ semaphore.acquire();\n​ System.err.println(Thread.currentThread().getName() + \u0026ldquo;执行了\u0026rdquo;);\n​ } catch (InterruptedException e) {\n​ e.printStackTrace();\n​ } finally {\n​ semaphore.release();\n​ }\n​ }).start();\n​ }\n看源码的顺序： new \u0026raquo; acquire \u0026raquo; release\n先看如何构造：利用state创建许可数。\npublic Semaphore(int permits) {\n​ sync = new NonfairSync(permits);\n}\nNonfairSync(int permits) {\n​ super(permits);\n}\nSync(int permits) {\n​ setState(permits);\n}\n再看如何获取许可：\npublic void acquire() throws InterruptedException {\n​ sync.acquireSharedInterruptibly(1);\n}\npublic final void acquireSharedInterruptibly(int arg)\n​ throws InterruptedException {\n​ if (Thread.interrupted())\n​ throw new InterruptedException();\n​ if (tryAcquireShared(arg) \u0026lt; 0) //代表获取许可失败\n​ doAcquireSharedInterruptibly(arg);\n}\nprotected int tryAcquireShared(int acquires) {\n​ return nonfairTryAcquireShared(acquires);\n}\nfinal int nonfairTryAcquireShared(int acquires) {\n​ for (;;) {\n​ int available = getState();\n​ int remaining = available - acquires;\n​ if (remaining \u0026lt; 0 ||\n​ compareAndSetState(available, remaining)) //设置成功则获取许可成功\n​ return remaining;\n​ }\n​ }\n我们再看如何释放许可：\npublic void release() {\n​ sync.releaseShared(1);\n}\npublic final boolean releaseShared(int arg) {\n​ if (tryReleaseShared(arg)) { //释放许可成功，则走释放成功流程，唤醒其他等待线程\n​ doReleaseShared();\n​ return true;\n​ }\n​ return false;\n}\n释放的许可直接加回state就行了\n​ protected final boolean tryReleaseShared(int releases) {\n​ for (;;) {\n​ int current = getState();\n​ int next = current + releases;\n​ if (next \u0026lt; current) // overflow\n​ throw new Error(\u0026ldquo;Maximum permit count exceeded\u0026rdquo;);\n​ if (compareAndSetState(current, next))\n​ return true;\n​ }\n​ }\nCountDownLatch原理 用来进行线程同步协作，等待所有线程完成倒计时。其中构造参数用来初始化等待计数值，await() 用来等待计数归零，countDown() 用来让计数减一：\npublic static void main(String[] args) throws InterruptedException {\n​ CountDownLatch latch = new CountDownLatch(3);\n​ new Thread(() -\u0026gt; {\n​ log.debug(\u0026ldquo;begin\u0026hellip;\u0026rdquo;);\n​ sleep(1);\n​ latch.countDown();\n​ log.debug(\u0026ldquo;end\u0026hellip;{}\u0026rdquo;, latch.getCount());\n​ }).start();\n​ new Thread(() -\u0026gt; {\n​ log.debug(\u0026ldquo;begin\u0026hellip;\u0026rdquo;);\n​ sleep(2);\n​ latch.countDown();\n​ log.debug(\u0026ldquo;end\u0026hellip;{}\u0026rdquo;, latch.getCount());\n​ }).start();\n​ new Thread(() -\u0026gt; {\n​ log.debug(\u0026ldquo;begin\u0026hellip;\u0026rdquo;);\n​ sleep(1.5);\n​ latch.countDown();\n​ log.debug(\u0026ldquo;end\u0026hellip;{}\u0026rdquo;, latch.getCount());\n​ }).start();\n​ log.debug(\u0026ldquo;waiting\u0026hellip;\u0026rdquo;);\n​ latch.await();\n​ log.debug(\u0026ldquo;wait end\u0026hellip;\u0026rdquo;);\n}\n先从构造看起：\npublic CountDownLatch(int count) {\n​ if (count \u0026lt; 0) throw new IllegalArgumentException(\u0026ldquo;count \u0026lt; 0\u0026rdquo;);\n​ this.sync = new Sync(count);\n}\nSync(int count) {\n​ setState(count);\n}\n再看await：\npublic void await() throws InterruptedException {\n​ sync.acquireSharedInterruptibly(1);\n}\npublic final void acquireSharedInterruptibly(int arg)\n​ throws InterruptedException {\n​ if (Thread.interrupted())\n​ throw new InterruptedException();\n​ if (tryAcquireShared(arg) \u0026lt; 0)\n​ doAcquireSharedInterruptibly(arg);\n}\nprotected int tryAcquireShared(int acquires) {\n​ return (getState() == 0) ? 1 : -1; // 计数不为0，就进入等待队列\n}\n再看countDown\npublic void countDown() {\n​ sync.releaseShared(1);\n}\npublic final boolean releaseShared(int arg) {\n​ if (tryReleaseShared(arg)) {\n​ doReleaseShared(); //唤醒等待\n​ return true;\n​ }\n​ return false;\n}\nprotected boolean tryReleaseShared(int releases) {\n​ // 递减计数； 过渡到零时就开始唤醒等待\n​ for (;;) {\n​ int c = getState();\n​ if (c == 0)\n​ return false;\n​ int nextc = c-1;\n​ if (compareAndSetState(c, nextc))\n​ return nextc == 0;\n​ }\n}\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/java-lock/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669986228,"title":"Java-Lock"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"JAVA日志体系 日志门面 SLF4J(Simple Logging Facade for Java)是一套日志门面，或者说规范。其他的日志组件都是基于这个门面进行实际实现，比如 java.util.logging, logback 和 reload4j.\n用户只需要在代码中使用SLF4J的API，而不需要关系具体的实现，是不是与JDBC很像。\n快速入门 在类路径添加依赖：slf4j-api-xx.jar 编写下面示例代码： import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class HelloWorld { public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(\u0026#34;Hello World\u0026#34;); } } 运行此代码，控制台会打印以下警告信息：\nSLF4J: Failed to load class \u0026#34;org.slf4j.impl.StaticLoggerBinder\u0026#34;. SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. 打印此警告是因为在类路径上找不到 slf4j 绑定实现。此时我们将 slf4j-simple-xxx.jar 添加到类路径，就会打印出下面的正常日志信息：\n0 [main] INFO HelloWorld - Hello World 典型的使用方式 占位符\nlogger.debug(\u0026#34;your name {}.\u0026#34;,name ); logger.trace(\u0026#34;hello world\u0026#34;); logger.info(\u0026#34;hello world\u0026#34;); logger.warn(\u0026#34;hello world\u0026#34;); logger.error(\u0026#34;hello world\u0026#34;); SELF4J2.0之后引入了fluent API，并且向后兼容，这意味着你不需要修改旧版本的API。\nfluent API 想法是使用 LoggingEventBuilder 逐个构建日志事件，并在事件完全构建后进行日志记录。 atTrace()、atDebug()、atInfo()、atWarn() 和 atError() 方法都是 org.slf4j.Logger 接口中的新方法，它们返回 LoggingEventBuilder 的实例。 对于禁用的日志级别，返回的 LoggingEventBuilder 实例什么都不做，从而保留了传统日志接口的纳秒级性能。下面是示例：\nlogger.atInfo().log(\u0026#34;Hello world.\u0026#34;); // 等同于 logger.info(\u0026#34;Hello world.\u0026#34;); 以下日志语句在其输出中是等效的（对于默认实现）：\nint newT = 15; int oldT = 16; logger.debug(\u0026#34;set to {}. Old was {}.\u0026#34;, newT, oldT); logger.atDebug().addArgument(newT).addArgument(oldT).log(\u0026#34;set to {}. Old was {}.\u0026#34;); logger.atDebug().log(\u0026#34;set to {}. Old was {}.\u0026#34;, newT, oldT); logger.atDebug().addArgument(newT).log(\u0026#34;set to {}. Old was {}.\u0026#34;, oldT); logger.atDebug().addArgument(() -\u0026gt; t16()).log(msg, \u0026#34;set to {}. Old was {}.\u0026#34;, oldT); API还支持k-v形式：\nint newT = 15; int oldT = 16; logger.debug(\u0026#34;oldT={} newT={} Temperature changed.\u0026#34;, newT, oldT); logger.atDebug().addKeyValue(\u0026#34;oldT\u0026#34;, oldT).addKeyValue(\u0026#34;newT\u0026#34;, newT).log(\u0026#34;Temperature changed.\u0026#34;); 日志绑定 如前所述，SLF4J 支持各种日志框架。 SLF4J 发行版附带了几个称为“SLF4J 绑定”的 jar 文件，每个绑定对应一个受支持的框架。\n*slf4j-log4j12-1.7.36.jar：log4j 1.2 版的绑定。 鉴于 log4j 1.x 已在 2015 年和 2022 年宣布 EOL，从 SLF4J 1.7.35 开始，slf4j-log4j 模块在构建时自动重定向到 slf4j-reload4j 模块。 假设您希望继续使用 log4j 1.x 框架，我们强烈建议您改用 slf4j-reload4j。 * *slf4j-reload4j-1.7.36.jar：*Reload4j 是 log4j 版本 1.2.7 的直接替代品。 您还需要将 reload4j.jar 放在您的类路径上。 *slf4j-jdk14-1.7.36.jar：*java.util.logging slf4j-nop-1.7.36.jar： NOP 的绑定，默默地丢弃所有日志记录。 *slf4j-simple-1.7.36.jar： *简单实现，它将所有事件输出到 System.err。 只打印级别 INFO 和更高级别的消息。 此绑定在小型应用程序的上下文中可能很有用。 *slf4j-jcl-1.7.36.jar：*Jakarta Commons Logging 的绑定/提供者。 此绑定会将所有 SLF4J 日志记录委托给 JCL。 logback-classic-1.2.10.jar (requires logback-core-1.2.10.jar)： SLF4J 的原生实现： logback。 Logback 的 ch.qos.logback.classic.Logger 类是 SLF4J 的 org.slf4j.Logger 接口的直接实现。 要切换日志框架，只需替换类路径上的 slf4j 绑定。 例如，要从 java.util.logging 切换到 log4j，只需将 slf4j-jdk14-1.7.36.jar 替换为 slf4j-log4j12-1.7.36.jar。\nSLF4J 不依赖任何特殊的类加载器机制。 事实上，每个 SLF4J 绑定在编译时都是硬连线的，以使用一个且只有一个特定的日志框架。 例如，slf4j-log4j12-1.7.36.jar 绑定在编译时绑定为使用 log4j。 在您的代码中，除了 slf4j-api-1.7.36.jar 之外，您只需将一个且只有一个您选择的绑定拖放到适当的类路径位置。 不要在类路径上放置多个绑定。\n从 2.0.0 版开始，SLF4J 绑定被称为提供者。 尽管如此，总体思路还是一样的。 SLF4J API 版本 2.0.0 依赖 ServiceLoader 机制来查找其日志记录后端。\n日志桥接 通常，您依赖的某些组件可能依赖于 SLF4J 以外的日志记录 API。为了处理这种情况，SLF4J 附带了几个桥接模块，这些模块将调用重定向到 log4j、JCL 和 java.util.logging API，使其表现得像是对 SLF4J API 进行的调用一样。下图说明了这个想法。\n请注意，对于您控制的源代码，您应该使用slf4j-migrator。\njul-to-slf4j.jar 和 slf4j-jdk14.jar 不能同时存在\nslf4j-jdk14.jar 的存在，即 SLF4J 的 jul 绑定，将强制 SLF4J 调用委托给 jul。 另一方面，jul-to-slf4j.jar 的存在，加上 SLF4JBridgeHandler 的安装，通过调用“SLF4JBridgeHandler.install()”将 jul 日志路由到 SLF4J。 因此，如果两个 jar 同时存在（并且安装了 SLF4JBridgeHandler），slf4j 调用将被委托给 jul，而 jul 记录将被路由到 SLF4J，从而导致无限循环。\nSLF4J 迁移器 SLF4J 迁移器是一个小型 Java 工具，用于将 Java 源文件从 Jakarta Commons Logging (JCL) API 迁移到 SLF4J。 它还可以从 log4j API 迁移到 SLF4J，或从 java.util.logging API 迁移到 SLF4J。\nSLF4J 迁移器由一个 jar 文件组成，可以作为独立的 java 应用程序启动。 这是命令：\njava -jar slf4j-migrator-2.0.0-alpha7.jar 启动应用程序后，应出现类似于以下内容的窗口:\nSLF4J 迁移器旨在作为一个简单的工具来帮助您将使用 JCL、log4j 或 JUL 的项目源迁移到 SLF4J。 它只能执行基本的转换步骤。 本质上，它将替换适当的导入行和记录器声明。\n迁移之前：\npackage some.package; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; public MyClass { Log logger = LogFactory.getLog(MyClass.class); public void someMethod() { logger.info(\u0026#34;Hello world\u0026#34;); } } 迁移之后：\npackage some.package; import org.slf4j.Logger; import org.slf4j.LoggerFactory; public MyClass { Logger logger = LoggerFactory.getLogger(MyClass.class); public void someMethod() { logger.info(\u0026#34;Hello world\u0026#34;); } } logback logback分为三个模块:\nlogback-core: 为其他两个模块奠定了基础 logback-classic: 原生实现了SLF4J API logback-access: 与 Servlet 容器集成以提供HTTP 访问日志功能 Logback 建立在三个主要类之上:\nLogger: logback-classic 模块的一部分 Appender: logback-core模块的一部分 Layout / Encoder: logback-core模块的一部分 ,Encoder 负责将事件转换为字节数组，并将该字节数组写入 OutputStream。 在以前的版本中，大多数Appender依赖于Layout 将事件转换为字符串并使用 java.io.Writer 将其写出。现在，只需要在 FileAppender 使用 Encoder 即可。 这三种类型的组件协同工作，使开发人员能够根据消息类型和级别记录消息，并在运行时控制这些消息的格式和存储位置。\nLogger 每个logger都会绑定到一个LoggerContext 。LoggerContext 制造logger并将他们按照树状排列。\n记录器是命名实体。它们的名称区分大小写，并遵循分层命名规则。例如名为com.foo logger 是 名为 com.foo.Bar logger的父级。\nroot logger位于层次结构的顶部，它的特殊之处在于它从一开始就是每个层次结构的一部分。像每个logger一样，它可以通过名称被检索：\nLogger rootLogger = LoggerFactory.getLogger(org.slf4j.Logger.ROOT_LOGGER_NAME); 为了确保所有logger最终都可以继承一个级别，根logger始终具有分配的级别。默认情况下，此级别为 DEBUG。\n下面是几个级别继承的示例\nLogger name Assigned level Effective level root DEBUG DEBUG X none DEBUG X.Y none DEBUG X.Y.Z none DEBUG Logger name Assigned level Effective level root ERROR ERROR X INFO INFO X.Y DEBUG DEBUG X.Y.Z WARN WARN Logger name Assigned level Effective level root DEBUG DEBUG X INFO INFO X.Y none INFO X.Y.Z ERROR ERROR Logger name Assigned level Effective level root DEBUG DEBUG X INFO INFO X.Y none INFO X.Y.Z none INFO 根据定义，打印方法决定了日志请求的级别。 例如，如果 L 是记录器实例，则语句 L.info(\u0026quot;..\u0026quot;) 是级别 INFO 的记录语句。\n如果日志请求的级别高于或等于其记录器的有效级别，则称该日志请求已启用。 否则，该请求被称为被禁用。级别排序如下：\nTRACE \u0026lt; DEBUG \u0026lt; INFO \u0026lt; WARN \u0026lt; ERROR\nAppender Logback 允许将日志记录请求打印到多个目的地。在 logback 中，输出目的地称为 appender。目前，存在控制台、文件、远程套接字服务器、MySQL、PostgreSQL、Oracle 和其他数据库、JMS 和远程 UNIX Syslog 守护程序的附加程序。\n控制台 \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg %n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; FileAppender FileAppender 是 OutputStreamAppender 的子类，将日志事件附加到文件中。 目标文件由 File 选项指定。 如果文件已经存在，则根据 append 属性的值将其追加或截断。\n\u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;testFile.log\u0026lt;/file\u0026gt; \u0026lt;append\u0026gt;true\u0026lt;/append\u0026gt; \u0026lt;immediateFlush\u0026gt;true\u0026lt;/immediateFlush\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; append: 如果为 true，则将事件附加到现有文件的末尾。否则任何现有文件都将被截断。append选项默认设置为 true 。 immediateFlush: 默认情况下，每个日志事件都会立即刷新到底层输出流。 这种默认方法更安全，因为如果您的应用程序在没有正确关闭appender 的情况下退出，日志事件不会丢失。 但是，为了显着提高日志记录吞吐量，您可能需要将 immediateFlush 属性设置为 false。 在应用程序开发阶段或Job应用程序的情况下，例如 批处理应用程序，最好在每次新应用程序启动时创建一个新日志文件。 在 元素的帮助下，这很容易做到：\n\u0026lt;timestamp key=\u0026#34;bySecond\u0026#34; datePattern=\u0026#34;yyyyMMdd\u0026#39;T\u0026#39;HHmmss\u0026#34;/\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;log-${bySecond}.txt\u0026lt;/file\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; RollingFileAppender RollingFileAppender 扩展了 FileAppender 具有翻转日志文件的能力。 例如，RollingFileAppender 可以记录到一个名为 log.txt 的文件，一旦满足某个条件，就可以将其记录目标更改为另一个文件。\n有两个重要的子组件与 RollingFileAppender 交互\nRollingPolicy：负责执行翻转所需的操作。 TriggeringPolicy：确定是否以及何时发生翻转。 RollingFileAppender 必须同时设置 RollingPolicy 和 TriggeringPolicy。 但是，如果它的 RollingPolicy 也实现了 TriggeringPolicy 接口，那么只需要显式指定前者即可。\nTimeBasedRollingPolicy TimeBasedRollingPolicy 可能是最流行的滚动策略。 它定义了基于时间的翻转策略，例如按天或按月。 TimeBasedRollingPolicy 承担翻转以及触发所述翻转的责任。 实际上，TimeBasedTriggeringPolicy 实现了 RollingPolicy 和 TriggeringPolicy 接口。\n\u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;logFile.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;logFile.%d{yyyy-MM-dd}.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;totalSizeCap\u0026gt;3GB\u0026lt;/totalSizeCap\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; fileNamePattern: 必需的，定义滚动（归档）日志文件的名称。 它的值应该由文件名加上一个适当放置的 %d 转换说明符组成。 %d 转换说明符可以包含由 java.text.SimpleDateFormat 类指定的日期和时间模式。 如果省略日期和时间模式，则假定默认模式 yyyy-MM-dd。 翻转周期是从 fileNamePattern 的值推断出来的。 **maxHistory: **可选, 控制要保留的存档文件的最大数量，异步删除旧文件。 例如，如果您指定每月翻转，并将 maxHistory 设置为 6，则将保留 6 个月的存档文件，而 6 个月之前的文件将被删除。 请注意，由于旧的归档日志文件已被删除，因此为归档日志文件而创建的任何文件夹都将被适当地删除。 totalSizeCap: 可选的 , 控制所有存档文件的总大小。 当超过总大小上限时，最旧的档案将被异步删除。 totalSizeCap 属性也需要设置 maxHistory 属性。 此外，始终首先应用“最大历史记录”限制，然后应用“总大小上限”限制。 SizeAndTimeBasedRollingPolicy 有时您可能希望基本上按日期归档文件，但同时限制每个日志文件的大小。为了满足这个要求，logback 附带了 SizeAndTimeBasedRollingPolicy。\n这是一个示例配置文件，展示了基于时间和大小的日志文件归档。\n\u0026lt;appender name=\u0026#34;ROLLING\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;mylog.txt\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;mylog-%d{yyyy-MM-dd}.%i.txt\u0026lt;/fileNamePattern\u0026gt; \u0026lt;maxFileSize\u0026gt;100MB\u0026lt;/maxFileSize\u0026gt; \u0026lt;maxHistory\u0026gt;60\u0026lt;/maxHistory\u0026gt; \u0026lt;totalSizeCap\u0026gt;20GB\u0026lt;/totalSizeCap\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; FixedWindowRollingPolicy 翻转时，FixedWindowRollingPolicy 根据固定窗口算法重命名文件，如下所述。\nfileNamePattern 选项表示归档（翻转）日志文件的文件名模式。 此选项是必需的，并且必须在模式中的某处包含整数标记 %i。\n\u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;test.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.FixedWindowRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;tests.%i.log.zip\u0026lt;/fileNamePattern\u0026gt; \u0026lt;minIndex\u0026gt;1\u0026lt;/minIndex\u0026gt; \u0026lt;maxIndex\u0026gt;3\u0026lt;/maxIndex\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;triggeringPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\u0026#34;\u0026gt; \u0026lt;maxFileSize\u0026gt;5MB\u0026lt;/maxFileSize\u0026gt; \u0026lt;/triggeringPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%-4relative [%thread] %-5level %logger{35} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; additivity addAppender 方法将 appender 添加到给定的记录器。给定记录器的每个启用的记录请求都将转发到该记录器中的所有appender。换句话说，appender 是从 logger 层次结构中继承的。例如，如果将控制台appender添加到根记录器，则所有启用的日志记录请求至少将打印在控制台上。如果另外一个文件appender被添加到一个记录器中，比如L ，那么为L和L的孩子启用的记录请求将打印在一个文件上 和 控制台上。可以通过将记录器的 additivity 标志设置为 false 来覆盖此默认行为，以便不再累加appender。\n下表是additivity 示例\nLogger Name Attached Appenders Additivity Flag Output Targets root A1 not applicable A1 x A-x1, A-x2 true A1, A-x1, A-x2 x.y none true A1, A-x1, A-x2 x.y.z A-xyz1 true A1, A-x1, A-x2, A-xyz1 security A-sec false A-sec security.access none true A-sec 通常，用户不仅希望自定义输出目标，还希望自定义输出格式。 这是通过将Layout与Appenders相关联来实现的。 Layout负责根据用户的意愿格式化日志记录请求，而Appenders负责将格式化的输出发送到其目的地。 PatternLayout 是标准 logback 分发的一部分，允许用户根据类似于 C 语言 printf 函数的转换模式指定输出格式。例如，具有转换模式 \u0026ldquo;%-4relative [%thread] %-5level %logger{32} - %msg%n\u0026rdquo; 的 PatternLayout 将输出类似于：\n176 [main] DEBUG manual.architecture.HelloWorld2 - Hello world. 运行过程 现在让我们分析当用户调用名为com.wombat的记录器的 info()方法时 logback 所采取的步骤：\n1.获取过滤器链决策 如果存在，则调用 TurboFilter 链。 Turbo 过滤器可以设置上下文范围的阈值，或者根据与每个日志记录请求相关联的标记、级别、记录器、消息或 Throwable 等信息过滤掉某些事件。 如果过滤器链的回复是 FilterReply.DENY，则记录请求被丢弃。 如果是FilterReply.NEUTRAL，那么我们继续下一步，即步骤2。如果回复是FilterReply.ACCEPT，我们跳过下一步，直接跳到步骤3。\n2.应用基本选择规则 这一步，logback会比较logger的有效级别和请求的级别。如果根据此测试禁用了日志记录请求，则 logback 将丢弃该请求而无需进一步处理。否则，它进入下一步。\n3.创建一个LoggingEvent对象 如果请求通过了之前的过滤器，logback 将创建一个ch.qos.logback.classic.LoggingEvent对象，其中包含请求的所有相关参数，例如请求的记录器、请求级别、消息本身、可能与请求一起传递的异常、当前时间、当前线程、有关发出日志记录请求的类的各种数据以及MDC. 请注意，其中一些字段是延迟初始化的，即仅在实际需要时才初始化。MDC用于用额外的上下文信息装饰日志记录请求。MDC 将在后续章节中讨论。\n4.调用appender 创建LoggingEvent对象后，logback 会调用doAppend()所有适用的 appender 的方法，即继承自 logger 上下文的 appender。\nlogback 发行版附带的所有 appender 都扩展了 在同步块AppenderBase中实现方法的抽象类， doAppend以确保线程安全。如果存在任何此类过滤器，该doAppend()方法 还调用附加到appender的自定义过滤器。AppenderBase可以动态附加到任何 appender 的自定义过滤器在单独的章节中介绍。\n5\\. 格式化输出 被调用的appender负责格式化日志事件。但是，一些（但不是全部）appender将格式化日志事件的任务委托给Layout。Layout格式化LoggingEvent实例并将结果作为字符串返回。请注意，某些附加程序（例如 ） SocketAppender不会将日志记录事件转换为字符串，而是将其序列化。因此，它们没有也不需要布局。\n6\\. 发出LoggingEvent 在日志事件完全格式化后，每个appender将其发送到其目的地。\n配置 Logback 可以通过编程方式进行配置，也可以使用以 XML 或 Groovy 格式表示的配置脚本进行配置。\nhttps://logback.qos.ch/translator/ ：这个网址可以将log4j的配置文件转成logback。\nlogback初始化的流程：\nLogback 尝试在 classpath中找到一个名为 logback-test.xml 的文件。 如果没有找到这样的文件，它会检查 类路径中的logback.xml 文件. 如果没有找到这样的文件，则 使用服务提供者加载工具（在 JDK 1.6 中引入） 通过查找文件 META-INF\\services\\ch.qos.logback.classic.spi.Configurator来解析接口 。其内容应指定所需 实现的完全限定类名： com.qos.logback.classic.spi.Configurator 如果以上都没有成功，logback 会自动配置自己：BasicConfigurator 将日志输出到控制台。 配置文件主要有下面几个元素组成：\n调试 \u0026lt;configuration debug=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;!‐- encoders are by default assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder ‐‐\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 定义变量 \u0026lt;configuration\u0026gt; \u0026lt;property name=\u0026#34;USER_HOME\u0026#34; value=\u0026#34;/home/sebastien\u0026#34; /\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${USER_HOME}/myApp.log\u0026lt;/file\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 变量也可以通过命令行传入，例如：\njava -DUSER_HOME=\u0026#34;/home/sebastien\u0026#34; MyApp2 变量也可以存在配置文件中\n\u0026lt;configuration\u0026gt; \u0026lt;property resource=\u0026#34;resource1.properties\u0026#34; /\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${USER_HOME}/myApp.log\u0026lt;/file\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 条件处理 \u0026lt;configuration debug=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;if condition=\u0026#39;property(\u0026#34;HOSTNAME\u0026#34;).contains(\u0026#34;torino\u0026#34;)\u0026#39;\u0026gt; \u0026lt;then\u0026gt; \u0026lt;appender name=\u0026#34;CON\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d %-5level %logger{35} - %msg %n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CON\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/then\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;${randomOutputDir}/conditional.log\u0026lt;/file\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d %-5level %logger{35} - %msg %n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root level=\u0026#34;ERROR\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/java-log/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669986152,"title":"Java-Log"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"Flyway 工作原理 项目启动，应用程序完成数据库连接池的建立后，Flyway自动运行。 初次使用时，Flyway会创建一个flyway_schema_history表，用于记录sql执行记录。 Flyway会扫描项目指定路径下(默认是classpath:db/migration)的所有sql脚本，与flyway_schema_history表脚本记录进行比对。根据脚本的名称提取版本号来比对 如果脚本没有执行过，则执行脚本。如果脚本执行过，则比对文件是否发生变更，如果发生了变更，则抛出异常，终止迁移 在spring boot中使用 初始化一个SpringBoot项目，引入MySQL数据库驱动依赖等，并且需要引入Flyway依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.flywaydb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flyway-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;6.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 添加Flyway配置： spring: # 数据库连接配置 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm-demo?characterEncoding=utf-8\u0026amp;useSSL=false\u0026amp;serverTimezone=GMT%2B8 username: xxx password: xxx flyway: # 是否启用flyway enabled: true # 编码格式，默认UTF-8 encoding: UTF-8 # 迁移sql脚本文件存放路径，默认db/migration locations: classpath:db/migration # 迁移sql脚本文件名称的前缀，默认V sql-migration-prefix: V # 迁移sql脚本文件名称的分隔符，默认2个下划线__.前面的用作版本号，后面的用作描述信息 sql-migration-separator: __ # 迁移sql脚本文件名称的后缀 sql-migration-suffixes: .sql # 迁移时是否进行校验，默认true validate-on-migrate: true # 当迁移发现数据库非空且存在没有元数据的表时，自动执行基准迁移，新建schema_version表 baseline-on-migrate: 根据在配置文件的脚本存放路径的配置，在resource目录下建立文件夹db/migration。 添加需要运行的sql脚本。sql脚本的命名规范为：V+版本号(版本号的数字间以”.“或”_“分隔开)+双下划线(用来分隔版本号和描述)+文件描述+后缀名，例如：V20201100__create_user.sql。如图所示： 启动项目。启动成功后，在数据库中可以看到已按照定义好的脚本，完成数据库变更，并在flyway_schema_history表插入了sql执行记录： 主要配置项 flyway.baseline-on-migrate： 当迁移时发现目标schema非空，而且带有没有元数据的表时，是否自动执行基准迁移（创建元数据表，然后执行sql脚本），默认false.\nflyway.baseline-version开始执行基准迁移时对现有的schema的版本打标签，默认值为1.\nflyway.validate-on-migrate迁移时是否校验，默认为true. 校验机制检查本地迁移是否仍与数据库中已执行的迁移具有相同的校验和。主要防止已迁移的本地文件发生了变动，数据库却没有更新这种变化。这是一种预警机制。\nflyway.clean-on-validation-error当发现校验错误时是否自动调用clean，这是开发环境中的方便机制。默认false. 警告！ 不要在生产中启用！\nflyway.ignore-failed-future-migration当读取元数据表时是否忽略错误的迁移，默认false.\nflyway.out-of-order是否允许无序的迁移，默认false.\nflyway.enabled是否开启flywary，默认true.\nflyway.password：目标数据库的密码.\nflyway.url：迁移时使用的JDBC URL，如果没有指定的话，将使用配置的主数据源\nflyway.user：迁移数据库的用户名\nflyway.schemas设定需要flywary迁移的schema，大小写敏感，默认为连接默认的schema.\nflyway.tableflyway使用的元数据表名，默认为schema_version\nflyway.placeholder-prefix设置每个placeholder的前缀，默认${.\nflyway.placeholder-suffix设置每个placeholder的后缀，默认}.\nflyway.placeholder-replacementplaceholders是否要被替换，默认true.\nflyway.placeholders.[placeholder name]设置placeholder的value\nflyway.sql-migration-prefix迁移文件的前缀，默认为V.\nflyway.sql-migration-separator迁移脚本的文件名分隔符，默认__\nflyway.sql-migration-suffix迁移脚本的后缀，默认为.sql\nflyway.init-sqls当初始化好连接时要执行的SQL.\nflyway.locations迁移脚本的位置，默认db/migration.\nflyway.encoding设置迁移时的编码，默认UTF-8.\n版本迁移的问题 当对flyway升级的时候，会出现兼容性问题，例如checksum不一致：\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026#39;flywayInitializer\u0026#39; defined in class path resource [org/springframework/boot/autoconfigure/flyway/FlywayAutoConfiguration$FlywayConfiguration.class]: Invocation of init method failed; nested exception is org.flywaydb.core.api.FlywayException: Validate failed: Migration checksum mismatch for migration version 1.0.0.01 -\u0026gt; Applied to database : 1062144176 -\u0026gt; Resolved locally : 1432425380 可以通过执行修复方法来解决。将已应用迁移的校验和、描述和类型与可用迁移的校验和、描述和类型重新对齐\nflyway.repair(); ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/flyway/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669986115,"title":"Flyway"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"Spring Boot应用部署 传统服务器部署 除了使用 java -jar 命令运行程序之外，你还可以将jar包制作成可执行的，这样你只需要使用 ./xx.jar 的方式就可以启动程序。\n完全可执行的 jar 文件通过在文件前面嵌入一个额外的脚本来工作。 包含 jar 的目录用作应用程序的工作目录。\n可以通过构建工具制作完全可执行jar：\nmaven方式：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;executable\u0026gt;true\u0026lt;/executable\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; gradle方式：\ntasks.named(\u0026#39;bootJar\u0026#39;) { launchScript() } 安装成Systemd服务 我们可以将可执行jar与系统服务结合使用，例如systemd。\n假设您在/var/myapp中安装了 Spring Boot 应用程序，要将 Spring Boot 应用程序安装为systemd服务，请创建一个名为myapp.service的脚本并将其放置在/etc/systemd/system目录中：\n[Unit] Description=myapp After=syslog.target [Service] User=myapp ExecStart=/var/myapp/myapp.jar SuccessExitStatus=143 [Install] WantedBy=multi-user.target 请注意，与作为init.d服务运行时不同，运行应用程序的用户、PID 文件和控制台日志文件由systemd自身管理，因此必须使用“service”脚本中的适当字段进行配置。\n自定启动脚本 有两种方式可以更改启动脚本，一种是在写入之前，另一种是在启动之前。\n写入之前 所谓写入之前，即在脚本写入到jar包的时候。你可以使用maven插件的embeddedLaunchScriptProperties或 gradle的launchScript更改脚本的内容。\n默认脚本支持以下属性替换：\n参数 描述 Gradle default Maven default mode 脚本的模式 auto auto initInfoProvides 服务的名称 ${task.baseName} ${project.artifactId} initInfoRequiredStart 服务启动前依赖的其他服务 $remote_fs $syslog $network $remote_fs $syslog $network initInfoRequiredStop 服务关闭前的，需要关闭的其他的服务 $remote_fs $syslog $network $remote_fs $syslog $network initInfoDefaultStart 服务的启动级别 2 3 4 5 2 3 4 5 initInfoDefaultStop 服务的关闭级别 0 1 6 0 1 6 initInfoShortDescription 服务的简短描述 Single-line version of ${project.description} (falling back to ${task.baseName}) ${project.name} initInfoDescription 服务的详细描述 ${project.description} (falling back to ${task.baseName}) ${project.description} (falling back to ${project.name}) initInfoChkconfig 检查启动状态 2345 99 01 2345 99 01 confFolder 配置文件的目录 包含jar包的目录 包含jar包的目录 inlinedConfScript 对应在默认启动脚本中内联的文件脚本的引用。 这可用于在加载任何外部配置文件之前设置环境变量，例如 JAVA_OPTS logFolder LOG_FOLDER 的默认值。 仅对 init.d 服务有效 logFilename LOG_FILENAME 的默认值。 仅对 init.d 服务有效 pidFolder PID_FOLDER 的默认值。 仅对 init.d 服务有效 pidFilename PID_FOLDER 中 PID 文件名称的默认值。 仅对 init.d 服务有效 useStartStopDaemon 是否应该使用 start-stop-daemon 命令（当它可用时）来控制进程 true true stopWaitTime STOP_WAIT_TIME 的默认值（以秒为单位）。 仅对 init.d 服务有效 60 60 启动之前 在脚本启动之前，可以通过修改环境变量的方式或配置文件的方式，影响启动脚本的运行。\n默认脚本支持以下环境属性：\n环境变量 描述 MODE 操作的“模式”。默认值取决于 jar 的构建方式，但通常是auto（这意味着它会尝试通过检查它是否是名为init.d 的目录中的符号链接来猜测它是否是一个 init 脚本）。如果您想在前台运行脚本，您可以将其显式设置为service以便`run stop RUN_AS_USER 将用于运行应用程序的用户。未设置时，将使用拥有 jar 文件的用户。 USE_START_STOP_DAEMON start-stop-daemon当命令可用时，是否应该使用该命令来控制进程。默认为true. PID_FOLDER pid 文件夹名称（/var/run默认情况下）。 LOG_FOLDER 放置日志文件的文件夹的名称（默认/var/log）。 CONF_FOLDER 从中读取 .conf 文件的文件夹的名称（默认情况下与 jar 文件相同的文件夹）。 LOG_FILENAME LOG_FOLDER（\u0026lt;appname\u0026gt;.log默认情况下）中的日志文件的名称。 APP_NAME 应用程序的名称。如果 jar 是从符号链接运行的，则脚本会猜测应用程序名称。如果它不是符号链接或者您想显式设置应用程序名称，这可能很有用。 RUN_ARGS 要传递给程序（Spring Boot 应用程序）的参数。 JAVA_HOME java默认情况下使用 发现可执行文件的位置PATH，但如果在$JAVA_HOME/bin/java. JAVA_OPTS 启动时传递给 JVM 的选项。 JARFILE jar 文件的显式位置，以防脚本用于启动实际上未嵌入的 jar。 DEBUG 如果不为空，则-x在 shell 进程上设置标志，允许您查看脚本中的逻辑。 STOP_WAIT_TIME 在强制关闭之前停止应用程序时等待的时间（60默认情况下）。 除了JARFILE和之外APP_NAME，上一节中列出的设置都可以通过.conf文件进行配置。该文件应位于 jar 文件旁边，并具有相同的名称但后缀为.conf. 例如，一个名为的 jar/var/myapp/myapp.jar使用名为 /var/myapp/myapp.conf的配置文件，如下例所示：\nJAVA_OPTS=-Xmx1024M LOG_FOLDER=/custom/log/folder Docker 部署 很容易将 Spring Boot fat jar 打包为 docker 镜像。 然而，在 docker 镜像中复制和运行 fat jar 有很多缺点。 在不解压的情况下运行 fat jar 总是有一定的开销，在容器化环境中这可能很明显。 另一个问题是，将应用程序的代码及其所有依赖项放在 Docker 映像中的同一层是次优的。 由于您可能更频繁地重新编译您的代码，而spring boot依赖却不变化，因此最好分开一些东西。 如果你把jar文件放在你的应用程序类之前的层，Docker通常只需要改变最底层，就可以从它的缓存中提取其他的。\n如果您从容器运行应用程序，则可以使用可执行 jar，但分解它并以不同的方式运行它通常有很多好处。 某些 PaaS 实现也可能会选择在运行前解压缩。 例如，Cloud Foundry 就是这样运作的。 运行解压的一种方法是启动适当的启动器，如下所示：\n$ jar -xf myapp.jar $ java org.springframework.boot.loader.JarLauncher 这实际上在启动时（取决于 jar 的大小）比从未分解的存档中运行要快一些。 在运行时，您不应期望有任何差异。\n解压缩 jar 文件后，您还可以通过使用其main方法，（ 比JarLauncher稍微慢点）。 例如：\n$ jar -xf myapp.jar $ java -cp BOOT-INF/classes:BOOT-INF/lib/* com.example.MyApplication main方式需要扫描类路径下的文件， JarLauncher直接读取classpath.idx 文件，所以耗时更少。\n为了更容易创建优化的 Docker 镜像，Spring Boot 支持向 jar 中添加层索引文件。 它提供了层列表和应包含在其中的 jar 的部分。 索引中的层列表是根据应将层添加到 Docker/OCI 映像的顺序进行排序的。 开箱即用，支持以下层：\ndependencies (for regular released dependencies) spring-boot-loader (for everything under org/springframework/boot/loader) snapshot-dependencies (for snapshot dependencies) application (for application classes and resources) layers.idx 文件示例如下：\n- \u0026#34;dependencies\u0026#34;: - BOOT-INF/lib/library1.jar - BOOT-INF/lib/library2.jar - \u0026#34;spring-boot-loader\u0026#34;: - org/springframework/boot/loader/JarLauncher.class - org/springframework/boot/loader/jar/JarEntry.class - \u0026#34;snapshot-dependencies\u0026#34;: - BOOT-INF/lib/library3-SNAPSHOT.jar - \u0026#34;application\u0026#34;: - META-INF/MANIFEST.MF - BOOT-INF/classes/a/b/C.class 此分层旨在根据应用程序构建之间更改的可能性来分离代码。 库代码在构建之间不太可能发生变化，因此它被放置在自己的层中，以允许工具重新使用缓存中的层。 应用程序代码更有可能在构建之间发生变化，因此它被隔离在一个单独的层中。\nSpring Boot 还支持在 layers.idx 的帮助下对 war 文件进行分层。\n虽然只需 Dockerfile 中的几行代码就可以将 Spring Boot fat jar 转换为 docker 镜像，但我们将使用分层功能来创建优化的 docker 镜像。 当您创建一个包含层索引文件的 jar 时，spring-boot-jarmode-layertools jar 将作为依赖项添加到您的 jar 中。 使用类路径中的这个 jar，您可以在特殊模式下启动应用程序，该模式允许引导代码运行与您的应用程序完全不同的东西，例如，提取层的东西。\nlayertools 模式不能与包含启动脚本的完全可执行的 Spring Boot 存档一起使用。 在构建旨在与 layertools 一起使用的 jar 文件时禁用启动脚本配置。\n以下是使用 layertools jar 模式启动 jar 的方法：\n$ java -Djarmode=layertools -jar my-app.jar 这将提供以下输出：\nUsage: java -Djarmode=layertools -jar my-app.jar Available commands: list List layers from the jar that can be extracted extract Extracts layers from the jar for image creation help Help about any command extract 命令可用于轻松地将应用程序拆分为要添加到 dockerfile 的层。 这是使用 jarmode 的 Dockerfile 示例:\nFROM adoptopenjdk:11-jre-hotspot as builder WORKDIR application ARG JAR_FILE=target/*.jar COPY ${JAR_FILE} application.jar RUN java -Djarmode=layertools -jar application.jar extract FROM adoptopenjdk:11-jre-hotspot WORKDIR application COPY --from=builder application/dependencies/ ./ COPY --from=builder application/spring-boot-loader/ ./ COPY --from=builder application/snapshot-dependencies/ ./ COPY --from=builder application/application/ ./ ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;org.springframework.boot.loader.JarLauncher\u0026#34;] 假设上面的 Dockerfile 在当前目录下，你的 docker 镜像可以用 docker build . 构建，或者可选地指定你的应用程序 jar 的路径，如下例所示：\n$ docker build --build-arg JAR_FILE=path/to/myapp.jar . 这是一个多阶段的 dockerfile。 构建器阶段提取稍后需要的目录。 每个 COPY 命令都与 jarmode 提取的层相关。\n当然，不使用 jarmode 也可以编写 Dockerfile。 您可以使用 unzip 和 mv 的某种组合将内容移动到正确的层，但 jarmode 简化了这一点。\nDockerfiles 只是构建 docker 镜像的一种方式。 构建 docker 镜像的另一种方法是直接从您的 Maven 或 Gradle 插件中使用 buildpacks。 如果您曾经使用过 Cloud Foundry 或 Heroku 等应用程序平台，那么您可能使用过 buildpack。 Buildpacks 是平台的一部分，它将您的应用程序转换为平台可以实际运行的东西。 例如，Cloud Foundry 的 Java buildpack 会注意到您正在推送 .jar 文件并自动添加相关的 JRE。\n使用 Cloud Native Buildpacks，您可以创建可以在任何地方运行的 Docker 兼容镜像。 Spring Boot 直接包含对 Maven 和 Gradle 的 buildpack 支持。 这意味着您只需键入一个命令，就可以快速将合理的映像放入本地运行的 Docker 守护程序中。\n请参阅单独的插件文档，了解如何将 buildpacks 与Maven和Gradle一起使用。\nk8s部署 Spring Boot 通过检测 *_SERVICE_HOST 和 *_SERVICE_PORT 环境变量，来确定当前环境是否是k8s。你可以设置 spring.main.cloud-platform 来覆盖此行为\n当 Kubernetes 删除一个应用程序实例时，关闭过程会同时涉及多个子系统：关闭钩子、注销服务、从负载均衡器中删除实例……因为这个关闭过程是并行发生的（并且由于分布式系统的性质）， 存在请求被路由到正在关闭的pod上。\n您可以在 preStop 处理程序中配置睡眠执行，以避免将请求路由到已经开始关闭的 pod。 这种休眠应该足够长，以使新请求停止路由到 pod，并且其持续时间因部署而异。 preStop 处理程序可以使用 Pod 配置文件中的 PodSpec 进行配置，如下所示：\nspec: containers: - name: \u0026#34;example-container\u0026#34; image: \u0026#34;example-image\u0026#34; lifecycle: preStop: exec: command: [\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sleep 10\u0026#34;] 一旦 pre-stop 钩子完成，SIGTERM 将被发送到容器并开始正常关闭，允许任何剩余的正在进行的请求完成。\n当 Kubernetes 向 pod 发送 SIGTERM 信号时，它会等待一个称为终止宽限期的指定时间（默认为 30 秒）。 如果容器在宽限期后仍在运行，则会向它们发送 SIGKILL 信号并强制删除。 如果 pod 的关闭时间超过 30 秒，这可能是因为您增加了 spring.lifecycle.timeout-per-shutdown-phase，请确保通过在 Pod YAML 中设置 terminateGracePeriodSeconds 选项来增加终止宽限期。\nOpenShift部署 TBD\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-boot-deploy/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669986020,"title":"Spring-Boot-Deploy"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"Spring Boot性能监控 Spring Boot 包含许多附加功能，可帮助您在将应用程序推送到生产环境时对其进行监控和管理。 您可以选择使用 HTTP 端点或 JMX 来管理和监视您的应用程序。 审计、健康和指标收集也可以自动应用于您的应用程序。\n这些功能是通过 spring-boot-actuator 模块实现的，你只需要在类路径添加spring-boot-starter-actuator 依赖即可。\ndependencies { implementation \u0026#39;org.springframework.boot:spring-boot-starter-actuator\u0026#39; } 端点 执行器端点使您可以监视应用程序并与之交互。Spring Boot 包含许多内置端点，并允许您添加自己的端点。例如，health端点提供基本的应用程序健康信息。\n您可以启用或禁用每个单独的端点并通过 HTTP 或 JMX 公开它们（使它们可以远程访问）。当端点被启用和公开时，它被认为是可用的。内置端点仅在可用时才会自动配置。大多数应用程序选择通过 HTTP 公开，其中端点的 ID 和前缀/actuator映射到 URL。例如，默认情况下，health端点映射到/actuator/health.\n以下与技术无关的端点：\nID 描述 auditevents 公开当前应用程序的审计事件信息。需要一个AuditEventRepository bean。 beans 显示应用程序中所有 Spring bean 的完整列表。 caches 公开可用的缓存。 conditions 显示在配置和自动配置类上评估的条件以及它们匹配或不匹配的原因。 configprops 显示所有@ConfigurationProperties. env 公开 Spring 的ConfigurableEnvironment. flyway 显示已应用的任何 Flyway 数据库迁移。需要一个或多个Flyway bean。 health 显示应用程序运行状况信息。 httptrace 显示 HTTP 跟踪信息（默认情况下，最近 100 个 HTTP 请求-响应交换）。需要一个HttpTraceRepository bean。 info 显示任意应用程序信息。 integrationgraph 显示 Spring 集成图。需要依赖spring-integration-core. loggers 显示和修改应用程序中记录器的配置。 liquibase 显示已应用的任何 Liquibase 数据库迁移。需要一个或多个Liquibase bean。 metrics 显示当前应用程序的“指标”信息。 mappings 显示所有@RequestMapping路径的整理列表。 quartz 显示有关 Quartz 调度程序作业的信息。 scheduledtasks 显示应用程序中的计划任务。 sessions 允许从 Spring Session 支持的会话存储中检索和删除用户会话。需要使用 Spring Session 的基于 servlet 的 Web 应用程序。 shutdown 让应用程序正常关闭。默认禁用。 startup 显示由ApplicationStartup 收集的启动过程数据需要SpringApplication配置BufferingApplicationStartup. threaddump 执行线程转储。 如果您的应用程序是 Web 应用程序（Spring MVC、Spring WebFlux 或 Jersey），您可以使用以下附加端点：\nID 描述 heapdump 返回一个堆转储文件。在 HotSpot JVM 上，返回一个HPROF-format 文件。在 OpenJ9 JVM 上，返回一个 PHD-format 文件。 jolokia 当 Jolokia 在类路径上时，通过 HTTP 公开 JMX bean（不适用于 WebFlux）。需要依赖jolokia-core. logfile 返回日志文件的内容（如果已设置logging.file.name）。logging.file.path支持使用 HTTPRange标头检索部分日志文件内容。 prometheus 以 Prometheus 服务器可以抓取的格式公开指标。需要依赖micrometer-registry-prometheus. 启动端点 默认，除了 shutdown 端点，其他端点都是启用状态。开启端点的配置： management.endpoint.\u0026lt;id\u0026gt;.enabled ，例如：\nmanagement: endpoint: shutdown: enabled: true 如果您希望端点启用是选择加入而不是选择退出，请将 management.endpoints.enabled-by-default 属性设置为 false 并使用单个启用端点的属性来选择重新加入。以下示例启用 info 端点并禁用 所有其他端点：\nmanagement: endpoints: enabled-by-default: false endpoint: info: enabled: true 禁用的端点完全从应用程序上下文中删除。 如果您只想更改暴露端点的技术，请改用 include 和 exclude 属性。\n公开端点 由于端点可能包含敏感信息，您应该仔细考虑何时公开它们。下标列出了默认公开的端点：\nID JMX Web auditevents Yes No beans Yes No caches Yes No conditions Yes No configprops Yes No env Yes No flyway Yes No health Yes Yes heapdump N/A No httptrace Yes No info Yes No integrationgraph Yes No jolokia N/A No logfile N/A No loggers Yes No liquibase Yes No metrics Yes No mappings Yes No prometheus N/A No quartz Yes No scheduledtasks Yes No sessions Yes No shutdown Yes No startup Yes No threaddump Yes No 要更改公开的端点，请使用以下特定于技术的include和exclude属性：\nProperty Default management.endpoints.jmx.exposure.exclude management.endpoints.jmx.exposure.include * management.endpoints.web.exposure.exclude management.endpoints.web.exposure.include health include属性列出了公开的端点的 ID。exclude属性列出不应公开的端点的 ID。exclude优先于include。您可以使用端点 ID 列表来配置include和exclude属性。\nmanagement: endpoints: jmx: exposure: include: \u0026#34;health,info\u0026#34; *可用于选择所有端点。例如，要通过 HTTP 公开除env和beans端点之外的所有内容，请使用以下属性：\nmanagement: endpoints: web: exposure: include: \u0026#34;*\u0026#34; exclude: \u0026#34;env,beans\u0026#34; *在 YAML 中具有特殊含义，因此如果要包含（或排除）所有端点，请务必添加引号。\n安全 出于安全目的，默认情况下只有/health端点通过 HTTP 公开。\n如果 Spring Security 在类路径上并且不存在其他WebSecurityConfigurerAdapter或SecurityFilterChainbean，则除/health之外的所有端点都受保护。\n如果您希望为 HTTP 端点配置自定义安全性（例如，只允许具有特定角色的用户访问它们），Spring Boot 提供了一些方便RequestMatcher的对象，您可以将它们与 Spring Security 结合使用：\nimport org.springframework.boot.actuate.autoconfigure.security.servlet.EndpointRequest; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.web.SecurityFilterChain; @Configuration(proxyBeanMethods = false) public class MySecurityConfiguration { @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http.requestMatcher(EndpointRequest.toAnyEndpoint()) .authorizeRequests((requests) -\u0026gt; requests.anyRequest().hasRole(\u0026#34;ENDPOINT_ADMIN\u0026#34;)); http.httpBasic(); return http.build(); } } 跨站点请求伪造保护 由于 Spring Boot 依赖于 Spring Security 的默认设置，因此默认开启 CSRF 保护。这意味着在使用默认安全配置时，所有的POST（shutdown端点）和PUT、DELETE请求会收到403失败。\n我们建议仅在创建非浏览器客户端使用的服务时完全禁用 CSRF 保护。\n不带任何参数的读取操作,端点会自动缓存响应。要配置端点缓存的时间，请使用cache.time-to-live属性。以下示例将beans端点缓存的生存时间设置为 10 秒：\nmanagement: endpoint: beans: cache: time-to-live: \u0026#34;10s\u0026#34; CORS 支持默认禁用，只有在您设置了management.endpoints.web.cors.allowed-origins属性后才会启用\nmanagement: endpoints: web: cors: allowed-origins: \u0026#34;https://example.com\u0026#34; allowed-methods: \u0026#34;GET,POST\u0026#34; 自定义端点 如果您添加一个带有@Endpoint 注释的@Bean，那么任何带有@ReadOperation、@WriteOperation 或@DeleteOperation 的方法都会自动通过JMX 公开，并且在Web 应用程序中，也可以通过HTTP 公开。 可以使用 Jersey、Spring MVC 或 Spring WebFlux 通过 HTTP 公开端点。 如果 Jersey 和 Spring MVC 都可用，则使用 Spring MVC。\nTDB\n健康信息 您可以使用健康信息来检查正在运行的应用程序的状态。当生产系统出现故障时，监控软件经常使用它来提醒某人。端点公开的health信息取决于management.endpoint.health.show-details和management.endpoint.health.show-components属性，可以使用以下值之一进行配置：\nName 描述 never 从不显示细节。默认 when-authorized 详细信息仅向授权用户显示。可以使用 management.endpoint.health.roles配置授权角色。 always 向所有用户显示详细信息。 指标监控 Spring Boot 自动配置一个复合 MeterRegistry， 并自动添加类路径上的所有registry实现。 在运行时类路径中依赖 micrometer-registry-{system} 就足以让 Spring Boot 配置注册表。\n即使 Micrometer registry 实现在类路径上，您也可以禁用特定registry。 以下示例禁用 Datadog：\nmanagement: metrics: export: datadog: enabled: false Prometheus Spring Boot 提供了一个执行器端点/actuator/prometheus 暴漏指标数据。该端点默认不公开，你需要暴漏。\nprometheus.yml配置如下：\nscrape_configs: - job_name: \u0026#34;spring\u0026#34; metrics_path: \u0026#34;/actuator/prometheus\u0026#34; static_configs: - targets: [\u0026#34;HOST:PORT\u0026#34;] prometheus间隔访问/actuator/prometheus 来获取指标数据。\n对于可能存在时间不够长而无法被抓取的临时或批处理作业，您可以使用Prometheus Pushgateway支持，将指标推送给 Prometheus。要启用 Prometheus Pushgateway 支持，请将以下依赖项添加到您的项目中：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;simpleclient_pushgateway\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 当类路径上存在 Prometheus Pushgateway 依赖项并且management.metrics.export.prometheus.pushgateway.enabled属性设置为 true时，PrometheusPushGatewayManager会自动配置 bean。PrometheusPushGatewayManager管理将指标推送到 Prometheus Pushgateway。\n对于高级配置，您还可以提供自己的PrometheusPushGatewayManagerbean。\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-boot-starter-actuator/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985976,"title":"Spring-Boot-Starter-Actuator"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"spring mvc官方文档 DispatcherServlet 与其他许多Web框架一样，Spring MVC围绕前端控制器模式进行设计，在该模式下，中央Servlet DispatcherServlet提供了用于请求处理的共享算法，而实际工作是由可配置的委托组件执行的。 该模型非常灵活，并支持多种工作流程。\n与任何Servlet一样，都需要使用Java配置或在web.xml中根据Servlet规范声明和映射DispatcherServlet。 反过来，DispatcherServlet使用Spring配置发现请求映射，视图解析，异常处理等所需的委托组件。\n以下Java配置示例注册并初始化DispatcherServlet，该容器由Servlet容器自动检测到（请参阅Servlet Config）：\npublic class MyWebApplicationInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext servletContext) { // 加载 Spring web application configuration AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); context.register(AppConfig.class); // 创建并注册DispatcherServlet DispatcherServlet servlet = new DispatcherServlet(context); ServletRegistration.Dynamic registration = servletContext.addServlet(\u0026#34;app\u0026#34;, servlet); registration.setLoadOnStartup(1); registration.addMapping(\u0026#34;/app/*\u0026#34;); } } 除了使用 ServletContext API，你也可以继承AbstractAnnotationConfigDispatcherServletInitializer，覆盖指定的方法来配置DispatcherServlet,参考Conetxt层级关系中的例子\nContext的层级关系 DispatcherServlet需要配置WebApplicationContext（纯ApplicationContext的扩展）为自身属性。 WebApplicationContext具有指向ServletContext和与其关联的Servlet的链接。它还绑定到ServletContext，以便应用程序可以在RequestContextUtils上使用静态方法来查找WebApplicationContext（如果需要访问它们）。\n对于许多应用程序来说，拥有一个WebApplicationContext很简单并且足够。也可能具有上下文层次结构，其中一个根WebApplicationContext在多个DispatcherServlet（或其他Servlet）实例之间共享，每个实例都有其自己的子WebApplicationContext配置。有关上下文层次结构功能的更多信息，请参见ApplicationContext的其他功能。\n根WebApplicationContext通常包含基础结构bean，例如需要在多个Servlet实例之间共享的数据存储库和业务服务。这些Bean是有效继承的，并且可以在Servlet特定的子WebApplicationContext中重写（即重新声明），该子WebApplicationContext通常包含给定Servlet本地的Bean。下图显示了这种关系：\n下面的例子配置WebApplicationContext\npublic class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class\u0026lt;?\u0026gt;[] getRootConfigClasses() { return new Class\u0026lt;?\u0026gt;[] { RootConfig.class }; } @Override protected Class\u0026lt;?\u0026gt;[] getServletConfigClasses() { return new Class\u0026lt;?\u0026gt;[] { App1Config.class }; } @Override protected String[] getServletMappings() { return new String[] { \u0026#34;/app1/*\u0026#34; }; } } 当不需要层级上下文时，只需要getRootConfigClasses返回配置类，getServletConfigClasses返回null。\n特殊的spring bean DispatcherServlet委托给特殊的bean处理请求并响应。 所谓“特殊bean”，是指实现框架协定的Spring管理对象实例。 这些通常带有内置合同，但是您可以自定义它们的属性并扩展或替换它们。\n下表列出了DispatcherServlet检测到的特殊bean：\nBean 类型 描述 HandlerMapping 将请求映射到带拦截器列表的处理程序，以进行预处理和后期处理。 映射基于一些标准，具体细节因HandlerMapping实现而异。两个主要的HandlerMapping实现是RequestMappingHandlerMapping（支持@RequestMapping注释方法）和SimpleUrlHandlerMapping（维护显式注册） 处理程序的URI路径模式）。 HandlerAdapter 帮助“ DispatcherServlet”调用请求的具体handler，而不管该处理程序的实际调用方式如何。 例如，调用带注释的控制器需要解析注释。 HandlerAdapter的主要目的是保护DispatcherServlet免受此类细节的影响。 HandlerExceptionResolver 解决异常的策略，可能将它们映射Handler，HTML错误视图或其他目标。 ViewResolver 解析从handler返回的基于逻辑的字符串视图名称，以实际的视图呈现给响应。 LocaleResolver, LocaleContextResolver 解决客户正在使用的“语言环境”以及可能的时区问题，以便能够提供国际化的视图。 ThemeResolver 解决Web应用程序可以使用的主题，例如提供个性化的布局。 MultipartResolver 借助一些多部分解析库来解析多部分请求的抽象（例如，浏览器表单文件上传）。 FlashMapManager 存储和检索“输入”和“输出”“ FlashMap”，可用于将属性从一个请求传递到另一个请求，通常跨重定向。 Web MVC配置 应用程序可以声明处理请求所需的特殊Bean类型中列出的基础结构Bean。 DispatcherServlet检查每个特殊bean的WebApplicationContext。 如果没有匹配的bean类型，它将使用DispatcherServlet.properties（参考附录）中列出的默认类型。\n在大多数情况下，MVC Config是最佳起点。 它使用Java或XML声明所需的bean，并提供更高级别的配置回调API对其进行自定义。\nServlet配置 在Servlet 3.0+环境中，您可以选择以编程方式配置Servlet容器，以替代web.xml文件的方式。 下面的示例注册一个DispatcherServlet：\nimport org.springframework.web.WebApplicationInitializer; public class MyWebApplicationInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext container) { XmlWebApplicationContext appContext = new XmlWebApplicationContext(); appContext.setConfigLocation(\u0026#34;/WEB-INF/spring/dispatcher-config.xml\u0026#34;); ServletRegistration.Dynamic registration = container.addServlet(\u0026#34;dispatcher\u0026#34;, new DispatcherServlet(appContext)); registration.setLoadOnStartup(1); registration.addMapping(\u0026#34;/\u0026#34;); } } WebApplicationInitializer是Spring MVC提供的接口，可确保检测到您的实现并将其自动用于初始化任何Servlet 3容器。 WebApplicationInitializer的抽象基类实现名为AbstractDispatcherServletInitializer，它通过覆盖指定Servlet映射和DispatcherServlet配置location 的方法，使注册DispatcherServlet更容易。\n对于使用基于Java的Spring配置的应用程序，建议这样做，如以下示例所示：\npublic class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class\u0026lt;?\u0026gt;[] getRootConfigClasses() { return null; } @Override protected Class\u0026lt;?\u0026gt;[] getServletConfigClasses() { return new Class\u0026lt;?\u0026gt;[] { MyWebConfig.class }; } @Override protected String[] getServletMappings() { return new String[] { \u0026#34;/\u0026#34; }; } } 如果使用基于XML的Spring配置，则应直接从AbstractDispatcherServletInitializer进行扩展，如以下示例所示：\npublic class MyWebAppInitializer extends AbstractDispatcherServletInitializer { @Override protected WebApplicationContext createRootApplicationContext() { return null; } @Override protected WebApplicationContext createServletApplicationContext() { XmlWebApplicationContext cxt = new XmlWebApplicationContext(); cxt.setConfigLocation(\u0026#34;/WEB-INF/spring/dispatcher-config.xml\u0026#34;); return cxt; } @Override protected String[] getServletMappings() { return new String[] { \u0026#34;/\u0026#34; }; } } AbstractDispatcherServletInitializer还提供了一种方便的方法来添加Filter实例，并将其自动映射到DispatcherServlet，如以下示例所示：\npublic class MyWebAppInitializer extends AbstractDispatcherServletInitializer { // ... @Override protected Filter[] getServletFilters() { return new Filter[] { new HiddenHttpMethodFilter(), new CharacterEncodingFilter() }; } } 每个过滤器都会根据其具体类型添加一个默认名称，并自动映射到DispatcherServlet。\nAbstractDispatcherServletInitializer的isAsyncSupported受保护方法提供了一个位置，以在DispatcherServlet及其映射的所有过滤器上启用异步支持。 默认情况下，此标志设置为true。\n最后，如果您需要进一步自定义DispatcherServlet本身，则可以覆盖createDispatcherServlet方法。\nDispatcherServlet的处理流程 DispatcherServlet处理请求的流程如下：\n搜索WebApplicationContext并将其绑定在请求中，作为控制器和流程中其他元素可以使用的属性。 默认情况下，它绑定在DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE键下。 语言环境解析器绑定到请求，以使流程中的元素在处理请求（渲染视图，准备数据等）时要解析使用的语言环境。 如果不需要语言环境解析，则不需要语言环境解析器。 主题解析器绑定到请求，以使诸如视图之类的元素确定要使用的主题。 如果不使用主题，则可以将其忽略。 如果指定多部分文件解析器，则将检查请求中是否有多部分。 如果找到多部分，则将该请求包装在MultipartHttpServletRequest中，以供流程中的其他元素进一步处理。 有关多部分处理的更多信息，请参见Multipart Resolver。 搜索适当的Handler。 如果找到Handler，则将运行与该Handler（预处理器，后处理器和Handler）关联的执行链，以准备要渲染的模型。 另外，对于带注释的控制器，可以渲染响应（在HandlerAdapter中），而不是返回视图。 如果返回模型，则渲染视图。 如果没有返回任何模型（可能是由于预处理器或后处理器拦截了该请求，可能出于安全原因），则不会渲染任何视图，因为该请求可能已经被满足。 WebApplicationContext中声明的HandlerExceptionResolver Bean用于解决在请求处理期间引发的异常。 这些异常解析器允许定制逻辑以解决异常。 有关更多详细信息，请参见异常模块。\nSpring DispatcherServlet还支持Servlet API所指定的last-modification-date的返回。 确定特定请求的最后修改日期的过程很简单：DispatcherServlet查找适当的handler ，并测试找到的handler 是否实现了LastModified接口。 如果是这样，则将LastModified接口的long getLastModified（request）方法的值返回给客户端。\n您可以通过将Servlet初始化参数（init-param元素）添加到web.xml文件中的Servlet声明中，来定制各个DispatcherServlet实例。 下表列出了受支持的参数：\nParameter Explanation contextClass 实现“ ConfigurableWebApplicationContext”的类，将由该Servlet实例化并在本地配置。 默认情况下，使用XmlWebApplicationContext。 contextConfigLocation 传递给上下文实例的字符串（由contextClass指定），指示可以在哪里找到上下文。 该字符串可能包含多个字符串（使用逗号作为分隔符）以支持多个上下文。 对于具有两次定义的bean的多个上下文位置，以最新位置为准。 namespace WebApplicationContext的命名空间。 默认为[servlet-name] -servlet。 throwExceptionIfNoHandlerFound 在找不到请求的处理程序时是否引发NoHandlerFoundException。 然后可以使用HandlerExceptionResolver捕获异常（例如通过使用@ExceptionHandler控制器方法）并以其他方式进行处理。默认情况下，将其设置为false，在这种情况下DispatcherServlet会设置 响应状态为404（NOT_FOUND），而不会引发异常。请注意，如果[默认servlet处理](https://docs.spring.io/spring-framework/docs/current/reference/html/web.html#mvc -default-servlet-handler)，未解决的请求始终转发到默认servlet，并且永远不会引发404。 拦截器 所有HandlerMapping实现都支持处理拦截器，当您要将特定功能应用于某些请求时（例如，检查主体），该拦截器很有用。 HandlerInterceptor提供了三个方法来做拦截处理逻辑，提供了足够的灵活性来执行各种预处理和后处理：\npreHandle：在handler之前执行 postHandle：在handler之后执行 afterCompletion：完成请求处理后（即渲染视图之后）的回调。 无论handler执行是否有异常，都会被调用，从而允许适当的资源清理。 preHandle返回bool,你可以通过这个值来决定执行链是否继续。当返回false时，DispatcherServlet假定拦截器本身已经处理了请求（例如，渲染了适当的视图），并且不会继续执行其他拦截器和执行链中的实际handler。\n请注意，对于@ResponseBody和ResponseEntity方法中，postHandle的用处不大，在postHandle执行之前，HandlerAdapter已经编写和提交响应。 这意味着对响应进行任何更改为时已晚，例如添加额外的标头。 对于这种情况，您可以实现ResponseBodyAdvice并将其声明为Controller Advice Bean或直接在RequestMappingHandlerAdapter上对其进行配置。\n异常 如果异常在请求映射期间发生或从handler（例如@Controller）抛出，则DispatcherServlet委托给HandlerExceptionResolver Bean链来解决该异常并提供替代处理，通常是错误响应。\n下表列出了可用的HandlerExceptionResolver实现：\nHandlerExceptionResolver Description SimpleMappingExceptionResolver 异常类名称和错误视图名称之间的映射。 对于在浏览器应用程序中呈现错误页面很有用。 DefaultHandlerExceptionResolver 解决Spring MVC引发的异常，并将其映射到HTTP状态代码。 另请参见替代的ResponseEntityExceptionHandler和REST API异常。 ResponseStatusExceptionResolver 使用@ResponseStatus批注解决异常，并根据批注中的值将其映射到HTTP状态代码。 ExceptionHandlerExceptionResolver 通过调用@Controller或@ControllerAdvice类中的@ExceptionHandler方法来解决异常。 参见@ExceptionHandler方法。 解析器链 您可以通过在Spring配置中声明多个HandlerExceptionResolver bean并根据需要设置其order属性来形成异常解析器链。 order属性越高，异常解析器的定位就越晚。\nHandlerExceptionResolver的约定可以返回：\nModelAndView指向错误页面 如果在resolver中处理了异常，则为空的ModelAndView。 如果该异常仍未解决，则为null，以供后续解析器尝试；如果该异常仍在末尾，则允许将其冒泡到Servlet容器。 MVC Config使用支持@ResponseStatus注释的异常解析器和对@ExceptionHandler方法的支持声明内置解析器作为默认的Spring MVC异常配置。 您可以自定义该列表或替换它。\n容器错误页 如果任何HandlerExceptionResolver都无法解决异常，因此该异常可以传播，或者如果响应状态设置为错误状态（即4xx，5xx），则Servlet容器可以在HTML中呈现默认错误页面。 要自定义容器的默认错误页面，可以在web.xml中声明错误页面映射。 以下示例显示了如何执行此操作：\n\u0026lt;error-page\u0026gt; \u0026lt;location\u0026gt;/error\u0026lt;/location\u0026gt; \u0026lt;/error-page\u0026gt; 给定前面的示例，当异常冒出或响应具有错误状态时，Servlet容器在容器内向配置的URL（例如/ error）进行ERROR调度。 然后由DispatcherServlet处理它，可能将其映射到@Controller，可以实现该错误以使用模型返回错误视图名称或呈现JSON响应，如以下示例所示：\n@RestController public class ErrorController { @RequestMapping(path = \u0026#34;/error\u0026#34;) public Map\u0026lt;String, Object\u0026gt; handle(HttpServletRequest request) { Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;String, Object\u0026gt;(); map.put(\u0026#34;status\u0026#34;, request.getAttribute(\u0026#34;javax.servlet.error.status_code\u0026#34;)); map.put(\u0026#34;reason\u0026#34;, request.getAttribute(\u0026#34;javax.servlet.error.message\u0026#34;)); return map; } } 视图解析 Spring MVC定义了ViewResolver和View接口，这些接口使您可以在浏览器中呈现模型，而无需将您与特定的视图技术联系在一起。 ViewResolver提供了视图名称和实际视图之间的映射。 视图在移交给特定的视图技术之前着手准备数据。\n下表提供了有关ViewResolver层次结构的更多详细信息：\nViewResolver Description AbstractCachingViewResolver AbstractCachingViewResolver的子类缓存它们解析的视图实例。 缓存可以提高某些视图技术的性能。 您可以通过将cache属性设置为false来关闭缓存。 此外，如果必须在运行时刷新某个视图（例如，当修改FreeMarker模板时），则可以使用removeFromCache（String viewName，Locale loc）方法。 UrlBasedViewResolver ViewResolver接口的简单实现会影响逻辑视图名称到URL的直接解析，而无需显式映射定义。 如果您的逻辑名称以直接的方式与视图资源的名称匹配，而不需要任意映射，则这是适当的。 InternalResourceViewResolver UrlBasedViewResolver的方便子类，它支持InternalResourceView（实际上是Servlet和JSP）以及诸如JstlView和TilesView之类的子类。 您可以使用setViewClass（..）为该解析器生成的所有视图指定视图类。 有关详细信息，请参见UrlBasedViewResolver Javadoc。 FreeMarkerViewResolver UrlBasedViewResolver的便捷子类，支持FreeMarkerView及其自定义子类。 ContentNegotiatingViewResolver ViewResolver接口的实现，该接口根据请求文件名或Accept标头解析视图。 请参阅内容协商。 BeanNameViewResolver ViewResolver接口的实现，该接口将视图名称解释为当前应用程序上下文中的Bean名称。 这是一个非常灵活的变体，它允许根据不同的视图名称来混合和匹配不同的视图类型。 每个这样的View可以定义为一个bean，例如 在XML或配置类中。 处理 您可以通过声明多个解析器bean以及必要时通过设置order属性以指定排序来链接视图解析器。 请记住，order属性越高，视图解析器在链中的定位就越晚。\nViewResolver的协议指定它可以返回null，以指示找不到该视图。 但是，对于JSP和InternalResourceViewResolver，确定JSP是否存在的唯一方法是通过RequestDispatcher进行调度。 因此，您必须始终将InternalResourceViewResolver配置为在视图解析器的总体顺序中排在最后。\n配置视图解析器就像将ViewResolver bean添加到Spring配置中一样简单。 MVC Config为View解析器和添加无逻辑的View Controller提供了专用的配置API，这对于无需控制器逻辑的HTML模板呈现非常有用。\n重定向 视图名称中的特殊redirect：前缀使您可以执行重定向。 UrlBasedViewResolver（及其子类）将其识别为需要重定向的指令。 视图名称的其余部分是重定向URL。\n最终效果与控制器返回RedirectView的效果相同，但是现在控制器本身可以根据逻辑视图名称进行操作。 逻辑视图名称（如redirect：/ myapp / some / resource）相对于当前Servlet上下文进行重定向，而名称如redirect：https：//myhost.com/some/arbitrary/path则重定向至绝对URL。\n请注意，如果使用@ResponseStatus注释控制器方法，则注释值优先于RedirectView设置的响应状态。\n转发 您还可以对视图名称使用特殊的forward：前缀，这些视图名称最终由UrlBasedViewResolver和子类解析。 这将创建一个InternalResourceView，它执行RequestDispatcher.forward（）。 因此，此前缀在InternalResourceViewResolver和InternalResourceView（对于JSP）中没有用，但是如果您使用另一种视图技术但仍希望强制转发由Servlet / JSP引擎处理的资源，则该前缀很有用。 请注意，您也可以改为链接多个视图解析器。\n内容协商 ContentNegotiatingViewResolver不会解析视图本身，而是委派给其他视图解析器，并选择类似于客户端请求的表示形式的视图。可以从Accept标头或查询参数（例如，“ / path？format = pdf”）中确定表示形式。\nContentNegotiatingViewResolver通过将请求媒体类型与与其每个ViewResolver关联的View支持的媒体类型（也称为Content-Type）进行比较，从而选择合适的View处理该请求。列表中具有兼容Content-Type的第一个View将表示形式返回给客户端。如果ViewResolver链无法提供兼容的视图，请查阅通过DefaultViews属性指定的视图列表。后一个选项适用于可以呈现当前资源的适当表示形式的单例视图，而与逻辑视图名称无关。 Accept标头可以包含通配符（例如text / *），在这种情况下，其Content-Type为text / xml的View是兼容的匹配。\n语言环境 正如Spring Web MVC框架所做的那样，Spring体系结构的大多数部分都支持国际化。通过DispatcherServlet，您可以使用客户端的语言环境自动解析消息。这是通过LocaleResolver对象完成的。\n收到请求时，DispatcherServlet会查找语言环境解析器，如果找到了它，则尝试使用它来设置语言环境。通过使用RequestContext.getLocale（）方法，您始终可以检索由语言环境解析器解析的语言环境。\n除了自动的语言环境解析之外，您还可以在处理程序映射上附加一个拦截器（有关处理程序映射拦截器的更多信息，请参见拦截），以在特定情况下（例如，基于请求中的参数）更改语言环境。\n语言环境解析器和拦截器在org.springframework.web.servlet.i18n包中定义，并以常规方式在应用程序上下文中进行配置。 Spring包含以下选择的语言环境解析器。\nTime Zone Header Resolver Cookie Resolver Session Resolver Locale Interceptor Time Zone 除了获取客户的语言环境外，了解其时区通常也很有用。 LocaleContextResolver接口提供了LocaleResolver的扩展，该扩展使解析程序可以提供更丰富的LocaleContext，其中可能包含时区信息。\n如果可用，则可以使用RequestContext.getTimeZone（）方法获取用户的TimeZone。 通过Spring的ConversionService注册的任何日期/时间转换器和格式器对象都会自动使用时区信息。\nHeader Resolver 该语言环境解析器检查客户端（例如，Web浏览器）发送的请求中的accept-language标头。 通常，此标头字段包含客户端操作系统的语言环境。 请注意，此解析器不支持时区信息。\nCookie Resolver 此语言环境解析器检查客户端上可能存在的Cookie，以查看是否指定了语言环境或TimeZone。 如果是这样，它将使用指定的详细信息。 通过使用此语言环境解析器的属性，可以指定Cookie的名称以及最长期限。 以下示例定义了CookieLocaleResolver：\n\u0026lt;bean id=\u0026#34;localeResolver\u0026#34; class=\u0026#34;org.springframework.web.servlet.i18n.CookieLocaleResolver\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;cookieName\u0026#34; value=\u0026#34;clientlanguage\u0026#34;/\u0026gt; \u0026lt;!-- in seconds. If set to -1, the cookie is not persisted (deleted when browser shuts down) --\u0026gt; \u0026lt;property name=\u0026#34;cookieMaxAge\u0026#34; value=\u0026#34;100000\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; CookieLocaleResolver的几个属性\nProperty Default Description cookieName classname + LOCALE 名称 cookieMaxAge Servlet container default Cookie在客户端上保留的最长时间。 如果指定了-1，则cookie将不会保留。 它仅在客户端关闭浏览器之前可用。 cookiePath / 将Cookie的可见性限制在您网站的特定部分。 当指定cookiePath时，该cookie仅对该路径及其下方的路径可见。 Session Resolver 通过SessionLocaleResolver，您可以从可能与用户请求关联的会话中检索Locale和TimeZone。 与CookieLocaleResolver相比，此策略将本地选择的语言环境设置存储在Servlet容器的HttpSession中。 这些设置对于每个会话都是临时的，因此在每个会话结束时会丢失。\n请注意，与外部会话管理机制（例如Spring Session项目）没有直接关系。 该SessionLocaleResolver针对当前HttpServletRequest评估并修改相应的HttpSession属性。\nLocale Interceptor 您可以通过将LocaleChangeInterceptor添加到HandlerMapping定义之一来启用语言环境更改。 它检测请求中的参数并相应地更改语言环境，在调度程序的应用程序上下文中在LocaleResolver上调用setLocale方法。 下一个示例显示，对所有包含名为siteLanguage的参数的* .view资源的调用现在都会更改语言环境。 因此，例如，对URL的请求https://www.sf.net/home.view?siteLanguage=nl会将站点语言更改为荷兰语。 以下示例显示如何拦截语言环境：\n\u0026lt;bean id=\u0026#34;localeChangeInterceptor\u0026#34; class=\u0026#34;org.springframework.web.servlet.i18n.LocaleChangeInterceptor\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;paramName\u0026#34; value=\u0026#34;siteLanguage\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;localeResolver\u0026#34; class=\u0026#34;org.springframework.web.servlet.i18n.CookieLocaleResolver\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;urlMapping\u0026#34; class=\u0026#34;org.springframework.web.servlet.handler.SimpleUrlHandlerMapping\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;interceptors\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;ref bean=\u0026#34;localeChangeInterceptor\u0026#34;/\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;mappings\u0026#34;\u0026gt; \u0026lt;value\u0026gt;/**/*.view=someController\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 主题 您可以应用Spring Web MVC框架主题来设置应用程序的整体外观，从而增强用户体验。 主题是静态资源（通常是样式表和图像）的集合，这些资源会影响应用程序的视觉样式。\n定义主题 要在Web应用程序中使用主题，您必须设置org.springframework.ui.context.ThemeSource接口的实现。 WebApplicationContext接口扩展了ThemeSource，但将其职责委托给专用的实现。 默认情况下，委托是org.springframework.ui.context.support.ResourceBundleThemeSource实现，该实现从类路径的根加载属性文件。 要使用自定义ThemeSource实现或配置ResourceBundleThemeSource的基本名称前缀，可以在应用程序上下文中注册使名称themeSource的bean。 Web应用程序上下文会自动检测到具有该名称的bean并使用它。\n当您使用ResourceBundleThemeSource时，将在一个简单的属性文件中定义一个主题。 属性文件列出了组成主题的资源，如以下示例所示：\nstyleSheet=/themes/cool/style.css background=/themes/cool/img/coolBg.jpg 属性的键是引用视图代码中主题元素的名称。 对于JSP，通常使用spring：theme定制标记来执行此操作，该标记与spring：message标记非常相似。 以下JSP片段使用上一示例中定义的主题来自定义外观：\n\u0026lt;%@ taglib prefix=\u0026#34;spring\u0026#34; uri=\u0026#34;http://www.springframework.org/tags\u0026#34;%\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;\u0026lt;spring:theme code=\u0026#39;styleSheet\u0026#39;/\u0026gt;\u0026#34; type=\u0026#34;text/css\u0026#34;/\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body style=\u0026#34;background=\u0026lt;spring:theme code=\u0026#39;background\u0026#39;/\u0026gt;\u0026#34;\u0026gt; ... \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 默认情况下，ResourceBundleThemeSource使用一个空的基本名称前缀。 结果，从类路径的根加载属性文件。 因此，您可以将cool.properties主题定义放在类路径的根目录中（例如，在/ WEB-INF / classes中）。 ResourceBundleThemeSource使用标准的Java资源束加载机制，允许主题的完全国际化。 例如，我们可以有一个/WEB-INF/classes/cool_nl.properties，它引用带有荷兰文字的特殊背景图像。\n解析主题 在定义主题之后，如上一节所述，您可以确定要使用的主题。 DispatcherServlet查找一个名为themeResolver的bean，以找出要使用的ThemeResolver实现。 主题解析器的工作方式与LocaleResolver大致相同。 它可以检测用于特定请求的主题，还可以更改请求的主题。 下表描述了Spring提供的主题解析器：\nClass Description FixedThemeResolver 选择一个固定的主题，通过使用defaultThemeName属性设置。 SessionThemeResolver 该主题在用户的HTTP会话中维护。 每个会话只需设置一次，但在会话之间不会保留。 CookieThemeResolver 所选主题存储在客户端的cookie中。 Spring还提供了ThemeChangeInterceptor，可以使用简单的请求参数对每个请求进行主题更改。\nMultipart Resolver org.springframework.web.multipart包中的MultipartResolver是一种用于解析包括文件上传在内的多部分请求的策略。 有一种基于Commons FileUpload的实现，另一种基于Servlet 3.0多部分请求解析。\n要启用多部分处理，您需要在DispatcherServlet Spring配置中声明一个名为multipartResolver的MultipartResolver bean。 DispatcherServlet检测到它并将其应用于传入的请求。 当收到内容类型为multipart / form-data的POST时，解析程序将解析内容并将当前的HttpServletRequest包装为MultipartHttpServletRequest，以提供对已解析部分的访问权，此外还可以将其公开为请求参数。\nApache Commons FileUpload 要使用Apache Commons FileUpload，可以配置名称为multipartResolver的CommonsMultipartResolver类型的Bean。 您还需要commons-fileupload作为对类路径的依赖。\nServlet 3.0 需要通过Servlet容器配置启用Servlet 3.0多部分解析。 为此：\n在Java中，在Servlet注册上设置MultipartConfigElement。\n在web.xml中，将“ ”部分添加到Servlet声明中。\n以下示例显示了如何在Servlet注册上设置MultipartConfigElement：\npublic class AppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { // ... @Override protected void customizeRegistration(ServletRegistration.Dynamic registration) { // Optionally also set maxFileSize, maxRequestSize, fileSizeThreshold registration.setMultipartConfig(new MultipartConfigElement(\u0026#34;/tmp\u0026#34;)); } } Servlet 3.0配置到位后，您可以添加名称为multipartResolver的StandardServletMultipartResolver类型的Bean。\n日志 Spring MVC中的DEBUG级别的日志被设计为紧凑，最少且人性化的。 它侧重于一遍又一遍有用的高价值信息，而其他信息仅在调试特定问题时才有用。\nTRACE级别的日志记录通常遵循与DEBUG相同的原则，但可用于调试任何问题。 此外，某些日志消息在TRACE和DEBUG上可能显示不同级别的详细信息。\n良好的日志记录来自使用日志的经验。 如果发现任何不符合既定目标的东西，请告诉我们。\n敏感数据 调试和跟踪日志记录可能会记录敏感信息。 这就是默认情况下屏蔽请求参数和标头，并且必须通过DispatcherServlet上的enableLoggingRequestDetails属性显式启用它们的原因。打印日志效果参考附录\n以下示例显示了如何通过使用Java配置来执行此操作：\npublic class MyInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class\u0026lt;?\u0026gt;[] getRootConfigClasses() { return ... ; } @Override protected Class\u0026lt;?\u0026gt;[] getServletConfigClasses() { return ... ; } @Override protected String[] getServletMappings() { return ... ; } @Override protected void customizeRegistration(ServletRegistration.Dynamic registration) { registration.setInitParameter(\u0026#34;enableLoggingRequestDetails\u0026#34;, \u0026#34;true\u0026#34;); } } 过滤器 Form Data 浏览器只能通过HTTP GET或HTTP POST提交表单数据，但非浏览器客户端也可以使用HTTP PUT，PATCH和DELETE。 Servlet API的ServletRequest.getParameter 之类的方法来仅支持HTTP POST的表单字段访问。\nspring-web模块提供FormContentFilter来拦截内容类型为application / x-www-form-urlencoded的HTTP PUT，PATCH和DELETE请求，从请求主体中读取表单数据，并包装ServletRequest以使表单数据可通过ServletRequest.getParameter 方法族获得。\nForwarded Headers 当请求通过代理（例如负载平衡器）进行处理时，主机，端口和协议可能会更改，这会映射获取客户端的实际IP和端口等信息。\nRFC 7239定义了用来提供有关原始请求的信息的HTTP转发头。还有其他非标准标头，包括X-Forwarded-Host，X-Forwarded-Port，X-Forwarded-Proto，X-Forwarded-Ssl和X-Forwarded-Prefix。\nForwardedHeaderFilter是一个Servlet过滤器，用于修改请求，以便\na）基于Forwarded标头更改主机，端口和协议\nb）删除这些Forwarded标头以消除影响\n该过滤器依赖于包装请求，因此必须在其他过滤器（例如RequestContextFilter）之前，其他过滤器应与修改后的请求而不是原始请求一起使用。\n对于转发的标头，存在安全方面的考虑，因为应用程序无法知道标头是由代理添加的，还是由恶意客户端添加的。这就是为什么应配置信任边界处的代理以删除来自外部的不受信任的转发标头的原因。您还可以使用removeOnly = true配置ForwardedHeaderFilter，在这种情况下，它将删除但不使用标头。\n为了支持异步请求和错误调度，此过滤器应与DispatcherType.ASYNC以及DispatcherType.ERROR映射。如果使用Spring Framework的AbstractAnnotationConfigDispatcherServletInitializer（请参阅Servlet Config），则会为所有调度类型自动注册所有过滤器。但是，如果通过web.xml或在Spring Boot中通过FilterRegistrationBean注册过滤器，请确保除了DispatcherType.REQUEST之外，还包括DispatcherType.ASYNC和DispatcherType.ERROR。\nShallow ETag ShallowEtagHeaderFilter过滤器通过缓存写入响应的内容并从中计算MD5哈希值来创建“shallow” ETag。客户端下一次发送时，它会执行相同的操作，但是还会将计算值与If-None-Match请求标头进行比较，如果两者相等，则返回304（NOT_MODIFIED）。\n此策略可节省网络带宽，但不能节省CPU，因为必须为每个请求计算完整响应。如前所述，控制器级别的其他策略可以避免计算。请参阅HTTP缓存。\n该过滤器具有writeWeakETag参数，该参数将过滤器配置为写入弱ETag，类似于以下内容：W /“ 02a2d595e6ed9a0b24f027f2b63b134d6”（在RFC 7232第2.3节中定义）。\n为了支持异步请求，此过滤器必须与DispatcherType.ASYNC映射，以便过滤器可以延迟并成功生成ETag到最后一个异步调度的末尾。如果使用Spring Framework的AbstractAnnotationConfigDispatcherServletInitializer（请参阅Servlet Config），则会为所有调度类型自动注册所有过滤器。但是，如果通过web.xml或在Spring Boot中通过FilterRegistrationBean注册过滤器，请确保包括DispatcherType.ASYNC。\nCORS Spring MVC通过控制器上的注释为CORS配置提供了细粒度的支持。 但是，当与Spring Security一起使用时，我们建议您依赖内置的CorsFilter，该CorsFilter必须在Spring Security的过滤器链之前。\n有关更多详细信息，请参见有关CORS和CORS过滤器的部分。\n注解式控制器 Spring MVC提供了一个基于注释的编程模型，其中@Controller和@RestController组件使用注释来表达请求映射，请求输入，异常处理等。 带注释的控制器具有灵活的方法签名，无需扩展基类或实现特定的接口。 以下示例显示了由注释定义的控制器：\n@Controller public class HelloController { @GetMapping(\u0026#34;/hello\u0026#34;) public String handle(Model model) { model.addAttribute(\u0026#34;message\u0026#34;, \u0026#34;Hello World!\u0026#34;); return \u0026#34;index\u0026#34;; } } 在前面的示例中，该方法接受Model并以String的形式返回视图名称，但是还存在许多其他选项，本章稍后将对其进行说明。\n声明 您可以使用Servlet的WebApplicationContext中的标准Spring bean定义来定义控制器bean。 @Controller构造型允许自动检测，与Spring对在类路径中检测@Component类并为其自动注册Bean定义的常规支持保持一致。 它还充当带注释的类的原型，来表明其作为Web组件的作用。\n要启用对此类@Controller bean的自动检测，可以将组件扫描添加到Java配置中，如以下示例所示：\n@Configuration @ComponentScan(\u0026#34;org.example.web\u0026#34;) public class WebConfig { // ... } @RestController是一个组合的批注，其本身使用@Controller和@ResponseBody进行了元注释，以指示其每个方法都继承类型级别@ResponseBody批注的控制器，因此，将其直接写入响应主体（相对于视图解析器）并渲染HTML模板。\nAOP代理 在某些情况下，您可能需要在运行时用AOP代理装饰控制器。 一个示例是，如果您选择直接在控制器上使用@Transactional批注。 在这种情况下，特别是对于控制器，我们建议使用基于类的代理。 这通常是控制器的默认选择。 但是，如果控制器必须实现不是Spring Context回调的接口（例如InitializingBean，* Aware等），则可能需要显式配置基于类的代理。 例如，使用\u0026lt;tx：annotation-driven /\u0026gt;，您可以更改为\u0026lt;tx:annotation-driven proxy-target-class=\u0026ldquo;true\u0026rdquo;/\u0026gt;；使用@EnableTransactionManagement，您可以更改为@EnableTransactionManagement（proxyTargetClass = true）。\n请求映射 您可以使用@RequestMapping批注将请求映射到控制器方法。 它具有多个属性，可以通过URL，HTTP方法，请求参数，标头和媒体类型进行匹配。 您可以在类级别使用它来表示共享的映射，也可以在方法级别使用它来缩小到特定的端点映射。\n@RequestMapping还有HTTP方法特定的快捷方式：\n@GetMapping @PostMapping @PutMapping @DeleteMapping @PatchMapping 快捷方式是提供的“自定义注释”，因为，大多数控制器方法应该映射到特定的HTTP方法，而不是使用@RequestMapping，后者默认情况下与所有HTTP方法匹配。 同时，在类级别仍需要@RequestMapping来表示共享映射。\n以下示例具有类型和方法级别的映射：\n@RestController @RequestMapping(\u0026#34;/persons\u0026#34;) class PersonController { @GetMapping(\u0026#34;/{id}\u0026#34;) public Person getPerson(@PathVariable Long id) { // ... } @PostMapping @ResponseStatus(HttpStatus.CREATED) public void add(@RequestBody Person person) { // ... } } URI匹配模式 可以使用URL模式映射@RequestMapping方法。 有两种选择：\nPathPattern-与URL路径匹配的预解析模式，该URL路径也预解析为PathContainer。 该解决方案专为Web使用而设计，可有效处理编码和路径参数，并有效匹配。 AntPathMatcher-匹配字符串模式和字符串路径。 这是在Spring配置中还用于选择类路径，文件系统和其他位置上的资源的原始解决方案。 它效率较低，并且字符串路径输入对于有效处理URL的编码和其他问题是一个挑战。 PathPattern是Web应用程序的推荐解决方案，它是Spring WebFlux中的唯一选择。 在5.3版之前，AntPathMatcher是Spring MVC中的唯一选择，并且继续是默认设置。 但是，可以在MVC配置中启用PathPattern。\nPathPattern支持与AntPathMatcher相同的模式语法。 此外，它还支持捕获模式，例如 {* spring}，用于匹配路径末尾的0个或更多路径段。 PathPattern还限制了使用**来匹配多个路径段，以便仅在模式末尾才允许使用。 当为给定请求选择最佳匹配模式时，这消除了很多歧义。 有关完整模式的语法，请参阅PathPattern (Spring Framework 5.3.1 API)和AntPathMatcher (Spring Framework 5.3.1 API)。\n一些例子：\n\u0026ldquo;/resources/ima?e.png\u0026rdquo;：匹配路径段中的一个字符 \u0026ldquo;/resources/*.png\u0026rdquo;：匹配路径段中的零个或多个字符 \u0026ldquo;/resources/**\u0026quot;：匹配多个路径段 \u0026ldquo;/projects/{project}/versions\u0026rdquo;：匹配路径段并将其捕获为变量 \u0026ldquo;/projects/{project:[a-z]+}/versions\u0026rdquo;：用正则表达式匹配并捕获变量 捕获的URI变量可以使用@PathVariable访问。 例如：\n@GetMapping(\u0026#34;/owners/{ownerId}/pets/{petId}\u0026#34;) public Pet findPet(@PathVariable Long ownerId, @PathVariable Long petId) { // ... } 您可以在类和方法级别声明URI变量，如以下示例所示：\n@Controller @RequestMapping(\u0026#34;/owners/{ownerId}\u0026#34;) public class OwnerController { @GetMapping(\u0026#34;/pets/{petId}\u0026#34;) public Pet findPet(@PathVariable Long ownerId, @PathVariable Long petId) { // ... } } URI变量将自动转换为适当的类型，或者引发TypeMismatchException。 默认情况下，支持简单类型（int，long，Date等），您可以注册对任何其他数据类型的支持。 请参阅类型转换和DataBinder。\n您可以显式地命名URI变量（例如，@PathVariable（“ customId”）），但是如果名称相同并且您的代码是使用调试信息或Java 8上的-parameters编译器标志编译的，则可以省略该详细信息。 。\n语法{varName：regex}声明带有正则表达式的URI变量，语法为{varName：regex}。 例如，给定URL“ /spring-web-3.0.5 .jar”，以下方法将提取名称，版本和文件扩展名：\n@GetMapping(\u0026#34;/{name:[a-z-]+}-{version:\\\\d\\\\.\\\\d\\\\.\\\\d}{ext:\\\\.[a-z]+}\u0026#34;) public void handle(@PathVariable String name, @PathVariable String version, @PathVariable String ext) { // ... } URI路径模式还可以嵌入$ {…}占位符，这些占位符在启动时通过针对本地，系统，环境和其他属性源使用PropertyPlaceHolderConfigurer进行解析。 例如，您可以使用它来基于一些外部配置参数化基本URL。\n模式比较 当多个模式与URL匹配时，必须选择最佳匹配。 根据是否启用了已解析的“ PathPattern”，使用以下一种方法来完成此操作：\nPathPattern.SPECIFICITY_COMPARATOR AntPathMatcher 两者都有助于对模式进行排序。 如果模式的URI变量（计数为1），单通配符（计数为1）和双通配符（计数为2）的数量较少，则模式的含义不太明确。 给定相等的分数，则选择更长的模式。 给定相同的分数和长度，将选择URI变量多于通配符的模式。\n默认映射模式（/ **）从评分中排除，并且始终排在最后。 同样，前缀模式（例如/ public / **）被认为比其他没有双通配符的模式更不具体。\n有关完整的详细信息，请单击上面的链接到模式比较器。\n后缀匹配 从5.3开始，默认情况下，Spring MVC不再执行.*后缀模式匹配，其中映射到/ person的控制器也隐式映射到/person.*。 因此，路径扩展不再用于解释响应所请求的内容类型，例如/person.pdf、/person.xml等。\n当浏览器用于发送难以一致解释的Accept标头时，以这种方式使用文件扩展名是必要的。 目前，这已不再是必须的，使用Accept标头应该是首选。\n随着时间的流逝，文件扩展名的使用已经以各种方式证明是有问题的。 当使用URI变量，路径参数和URI编码进行覆盖时，可能会导致歧义。 关于基于URL的授权和安全性的推理（请参阅下一部分以了解更多详细信息）也变得更加困难。\n要完全禁用5.3之前版本中的路径扩展，请设置以下内容：\nuseSuffixPatternMatching(false), see PathMatchConfigurer favorPathExtension(false), see ContentNegotiationConfigurer 除了通过“ Accept”标头之外，还有一种请求内容类型的方法仍然很有用，例如 在浏览器中输入URL时。 路径扩展的一种安全替代方法是使用查询参数策略。 如果必须使用文件扩展名，请考虑通过ContentNegotiationConfigurer的mediaTypes属性将它们限制为显式注册的扩展名列表。\n后缀匹配和RDF 反射文件下载（RFD）攻击与XSS相似，因为它依赖反映在响应中的请求输入（例如，查询参数和URI变量）。 但是，RFD攻击不是将JavaScript插入HTML，而是依靠浏览器切换来执行下载，并在以后双击时将响应视为可执行脚本。\n在Spring MVC中，@ ResponseBody和ResponseEntity方法存在风险，因为它们可以呈现不同的内容类型，客户端可以通过URL路径扩展请求这些内容类型。 禁用后缀模式匹配并使用路径扩展进行内容协商可以降低风险，但不足以防止RFD攻击。\n为了防止RFD攻击，Spring MVC在呈现响应主体之前添加了Content-Disposition：inline; filename = f.txt标头，以建议提供固定且安全的下载文件。 仅当URL路径包含既不被认为安全也不被明确注册用于内容协商的文件扩展名时，才执行此操作。 但是，当直接在浏览器中键入URL时，它可能会产生副作用。\n默认情况下，许多常见路径扩展都被视为安全。 具有自定义HttpMessageConverter实现的应用程序可以显式注册文件扩展名以进行内容协商，以避免为这些扩展名添加Content-Disposition标头。 请参阅内容类型。\n有关RFD的其他建议，请参见CVE-2015-5211 RFD Attack in Spring Framework | Security | VMware Tanzu\nConsumable Media Types 您可以根据请求的Content-Type缩小请求映射，如以下示例所示：\n@PostMapping(path = \u0026#34;/pets\u0026#34;, consumes = \u0026#34;application/json\u0026#34;) public void addPet(@RequestBody Pet pet) { // ... } 消耗属性还支持否定表达式-例如，!text / plain表示除text / plain之外的任何内容类型。\n您可以在类级别上声明一个共享的消耗属性。 但是，与大多数其他请求映射属性不同，在类级别已有，方法级别consumes 属性重写而不是扩展类级别声明。\nProducible Media Types 您可以根据Accept 请求标头和控制器方法生成的内容类型列表来缩小请求映射，如以下示例所示：\n@GetMapping(path = \u0026#34;/pets/{petId}\u0026#34;, produces = \u0026#34;application/json\u0026#34;) @ResponseBody public Pet getPet(@PathVariable String petId) { // ... } 媒体类型可以指定字符集。 支持否定的表达式-例如，！text / plain表示除“ text / plain”以外的任何内容类型。\n您可以在类级别声明共享的Produces属性。 但是，与大多数其他请求映射属性不同，在类级使用时，方法级produces 属性会覆盖，而不是扩展类级声明。\n参数和请求头 您可以根据请求参数条件来缩小请求映射。 您可以测试是否存在请求参数（myParam），是否不存在一个请求参数（!myParam）或特定值（myParam = myValue）。 以下示例显示如何测试特定值：\n@GetMapping(path = \u0026#34;/pets/{petId}\u0026#34;, params = \u0026#34;myParam=myValue\u0026#34;) public void findPet(@PathVariable String petId) { // ... } 您还可以将其与请求标头条件一起使用，如以下示例所示：\n@GetMapping(path = \u0026#34;/pets\u0026#34;, headers = \u0026#34;myHeader=myValue\u0026#34;) public void findPet(@PathVariable String petId) { // ... } HTTP HEAD, OPTIONS @GetMapping（和@RequestMapping（method = HttpMethod.GET））透明地支持HTTP HEAD来进行请求映射。 控制器方法不需要更改。 应用于javax.servlet.http.HttpServlet的响应包装器确保将Content-Length标头设置为写入的字节数（实际上未写入响应）。\n@GetMapping（和@RequestMapping（method = HttpMethod.GET））被隐式映射到并支持HTTP HEAD。 像处理HTTP GET一样处理HTTP HEAD请求，不同的是，不是写入正文，而是计算字节数并设置Content-Length头。\n默认情况下，通过将“Allow ”标头设置为所有具有匹配URL模式的@RequestMapping方法中列出的HTTP方法列表来处理HTTP OPTIONS。\n对于没有HTTP方法声明的@RequestMapping，将Allow标头设置为GET，HEAD，POST，PUT，PATCH，DELETE，OPTIONS。 控制器方法应始终声明支持的HTTP方法（例如，通过使用HTTP方法特定的变体：@ GetMapping，@ PostMapping等）。\n您可以将@RequestMapping方法显式映射到HTTP HEAD和HTTP OPTIONS，但这在通常情况下不是必需的。\n自定义注解 Spring MVC支持将组合注释用于请求映射。 这些注解本身使用@RequestMapping进行元注解，并且旨在以更狭窄，更具体的用途重新声明@RequestMapping属性的子集（或全部）。\n@ GetMapping，@ PostMapping，@ PutMapping，@ DeleteMapping和@PatchMapping是组合注释的示例。 之所以提供它们，是因为大多数控制器方法应该映射到特定的HTTP方法，而不是使用@RequestMapping，后者默认情况下与所有HTTP方法都匹配。 如果需要组合注释的示例，请查看如何声明它们。\nSpring MVC还支持带有自定义请求匹配逻辑的自定义请求映射属性。 这是一个更高级的选项，它需要子类化RequestMappingHandlerMapping并覆盖getCustomMethodCondition方法，您可以在其中检查自定义属性并返回自己的RequestCondition。\n显示注册 您可以以编程方式注册handler方法，这些方法可用于动态注册或高级案例，例如同一handler注册在不同URL下。 下面的示例注册一个处理程序方法：\n@Configuration public class MyConfig { @Autowired public void setHandlerMapping(RequestMappingHandlerMapping mapping, UserHandler handler) throws NoSuchMethodException { RequestMappingInfo info = RequestMappingInfo .paths(\u0026#34;/user/{id}\u0026#34;).methods(RequestMethod.GET).build(); Method method = UserHandler.class.getMethod(\u0026#34;getUser\u0026#34;, Long.class); mapping.registerMapping(info, handler, method); } } 注入目标处理程序和控制器的处理程序映射。 准备请求映射元数据。 获取处理程序方法。 添加注册。 handler方法 @RequestMapping处理程序方法具有灵活的签名，可以从一系列受支持的控制器方法参数和返回值中进行选择。\n方法参数 下表描述了受支持的控制器方法参数。 任何参数均不支持反应性类型。\n支持JDK 8的java.util.Optional作为方法参数，并与具有required 属性（例如@ RequestParam，@ RequestHeader等）的注释结合在一起，等效于required = false。\nController method argument Description WebRequest, NativeWebRequest 对请求参数以及请求和会话属性的常规访问，而无需直接使用Servlet API。 javax.servlet.ServletRequest, javax.servlet.ServletResponse 选择任何特定的请求或响应类型-例如，ServletRequest，HttpServletRequest或Spring的MultipartRequest，MultipartHttpServletRequest。 javax.servlet.http.HttpSession 强制会话的存在。 永远不会为空。 请注意，会话访问不是线程安全的。 如果允许多个请求并发访问会话，请考虑将“ RequestMappingHandlerAdapter”实例的“ synchronizeOnSession”标志设置为“ true”。 javax.servlet.http.PushBuilder 用于程序化HTTP / 2资源推送的Servlet 4.0推送构建器API。 请注意，根据Servlet规范，如果客户端不支持HTTP / 2功能，则注入的PushBuilder实例可以为null。 java.security.Principal 当前已认证的用户-可能是特定的Principal实现类（如果已知）。 HttpMethod 请求的HTTP方法。 java.util.Locale 当前的请求区域设置，由最具体的可用LocaleResolver（实际上是配置的LocaleResolver或LocaleContextResolver）确定。 java.util.TimeZone + java.time.ZoneId 与当前请求关联的时区，由LocaleContextResolver确定。 java.io.InputStream, java.io.Reader 用于访问Servlet API公开的原始请求正文。 java.io.OutputStream, java.io.Writer 用于访问Servlet API公开的原始响应正文。 @PathVariable 用于访问URI模板变量。 参见URI模式。 @MatrixVariable 用于访问URI路径段中的名称/值对。 参见矩阵变量。 @RequestParam 用于访问Servlet请求参数，包括多部分文件。 参数值将转换为声明的方法参数类型。 参见@ RequestParam和[多部分](https：/ /docs.spring.io/spring-framework/docs/current/reference/html/web.html#mvc-multipart-forms)。请注意，对于简单的参数值，使用@RequestParam是可选的。 请参阅此表末尾的“其他任何参数”。 @RequestHeader 用于访问请求标头。 标头值将转换为声明的方法参数类型。 参见@ RequestHeader。 @CookieValue 用于访问cookie。 Cookies值将转换为声明的方法参数类型。 参见@ CookieValue。 @RequestBody 用于访问HTTP请求正文。 正文内容通过使用HttpMessageConverter实现转换为声明的方法参数类型。 参见@ RequestBody。 HttpEntity\u0026lt;B\u0026gt; 用于访问请求标头和正文。 主体是通过HttpMessageConverter转换的。 参见HttpEntity。 @RequestPart 要访问“ multipart / form-data”请求中的零件，请使用“ HttpMessageConverter”转换零件的主体。 参见Multipart。 java.util.Map, org.springframework.ui.Model, org.springframework.ui.ModelMap 用于访问HTML控制器中使用的模型，并作为视图渲染的一部分公开给模板。 RedirectAttributes 指定在重定向的情况下使用的属性（即追加到查询字符串中），并指定要临时存储的属性，直到重定向后的请求为止。 参见重定向属性和[Flash属性](https：// docs.spring.io/spring-framework/docs/current/reference/html/web.html#mvc-flash-attributes)。 @ModelAttribute 用于访问已应用数据绑定和验证的模型中现有的属性（如果不存在，则进行实例化）。 参见@ ModelAttribute 。请注意，使用@ModelAttribute是可选的（例如，设置其属性）。 请参阅此表末尾的“其他任何参数”。 Errors, BindingResult 用于访问命令对象的验证和数据绑定（即@ModelAttribute参数）中的错误，或访问@RequestBody或@RequestPart参数的验证中的错误。 您必须在经过验证的方法参数后立即声明“错误”或“ BindingResult”参数。 SessionStatus + class-level @SessionAttributes 为了标记表单处理完成，将触发清除通过类级别的@SessionAttributes批注声明的会话属性。 有关更多详细信息，请参见@ SessionAttributes。 UriComponentsBuilder 用于准备相对于当前请求的主机，端口，方案，上下文路径以及servlet映射的文字部分的URL。 参见URI链接。 @SessionAttribute 对于访问任何会话属性，与由于类级别的@SessionAttributes声明而存储在会话中的模型属性相反。 有关更多详细信息，请参见@ SessionAttribute。 @RequestAttribute 用于访问请求属性。 有关更多详细信息，请参见@ RequestAttribute。 Any other argument 如果方法参数与该表中的任何较早值都不匹配，并且是简单类型（由[BeanUtils＃isSimpleProperty](https://docs.spring.io/spring-framework/docs/5.3确定。 1 / javadoc-api / org / springframework / beans / BeanUtils.html＃isSimpleProperty-java.lang.Class-)，将其解析为“ @RequestParam”；否则，将其解析为“ @ModelAttribute”。 返回值 下表描述了受支持的控制器方法返回值。 所有返回值都支持反应性类型。\nController method return value Description @ResponseBody The return value is converted through HttpMessageConverter implementations and written to the response. See @ResponseBody. HttpEntity\u0026lt;B\u0026gt;, ResponseEntity\u0026lt;B\u0026gt; The return value that specifies the full response (including HTTP headers and body) is to be converted through HttpMessageConverter implementations and written to the response. See ResponseEntity. HttpHeaders For returning a response with headers and no body. String A view name to be resolved with ViewResolver implementations and used together with the implicit model — determined through command objects and @ModelAttribute methods. The handler method can also programmatically enrich the model by declaring a Model argument (see Explicit Registrations). View A View instance to use for rendering together with the implicit model — determined through command objects and @ModelAttribute methods. The handler method can also programmatically enrich the model by declaring a Model argument (see Explicit Registrations). java.util.Map, org.springframework.ui.Model Attributes to be added to the implicit model, with the view name implicitly determined through a RequestToViewNameTranslator. @ModelAttribute An attribute to be added to the model, with the view name implicitly determined through a RequestToViewNameTranslator.Note that @ModelAttribute is optional. See \u0026ldquo;Any other return value\u0026rdquo; at the end of this table. ModelAndView object The view and model attributes to use and, optionally, a response status. void A method with a void return type (or null return value) is considered to have fully handled the response if it also has a ServletResponse, an OutputStream argument, or an @ResponseStatus annotation. The same is also true if the controller has made a positive ETag or lastModified timestamp check (see Controllers for details).If none of the above is true, a void return type can also indicate “no response body” for REST controllers or a default view name selection for HTML controllers. DeferredResult\u0026lt;V\u0026gt; Produce any of the preceding return values asynchronously from any thread — for example, as a result of some event or callback. See Asynchronous Requests and DeferredResult. Callable\u0026lt;V\u0026gt; Produce any of the above return values asynchronously in a Spring MVC-managed thread. See Asynchronous Requests and Callable. ListenableFuture\u0026lt;V\u0026gt;, java.util.concurrent.CompletionStage\u0026lt;V\u0026gt;, java.util.concurrent.CompletableFuture\u0026lt;V\u0026gt; Alternative to DeferredResult, as a convenience (for example, when an underlying service returns one of those). ResponseBodyEmitter, SseEmitter Emit a stream of objects asynchronously to be written to the response with HttpMessageConverter implementations. Also supported as the body of a ResponseEntity. See Asynchronous Requests and HTTP Streaming. StreamingResponseBody Write to the response OutputStream asynchronously. Also supported as the body of a ResponseEntity. See Asynchronous Requests and HTTP Streaming. Reactive types — Reactor, RxJava, or others through ReactiveAdapterRegistry Alternative to DeferredResult with multi-value streams (for example, Flux, Observable) collected to a List.For streaming scenarios (for example, text/event-stream, application/json+stream), SseEmitter and ResponseBodyEmitter are used instead, where ServletOutputStream blocking I/O is performed on a Spring MVC-managed thread and back pressure is applied against the completion of each write.See Asynchronous Requests and Reactive Types. Any other return value Any return value that does not match any of the earlier values in this table and that is a String or void is treated as a view name (default view name selection through RequestToViewNameTranslator applies), provided it is not a simple type, as determined by BeanUtils#isSimpleProperty. Values that are simple types remain unresolved. 类型转化 如果参数声明为String以外的形式，则某些表示基于String的请求输入的带注释的控制器方法参数（例如@ RequestParam，@ RequestHeader，@ PathVariable，@ MatrixVariable和@CookieValue）可能需要类型转换。\n在这种情况下，将根据配置的转换器自动应用类型转换。 默认情况下，支持简单类型（int，long，Date和其他）。 您可以通过WebDataBinder（请参阅DataBinder）或通过在FormattingConversionService中注册Formatter来自定义类型转换。 参见Spring字段格式。\n矩阵变量 RFC 3986讨论路径段中的名称/值对。 在Spring MVC中，我们根据Tim Berners-Lee的“旧帖子”将其称为“矩阵变量”，但它们也可以称为URI路径参数。\n矩阵变量可以出现在任何路径段中，每个变量用分号分隔，多个值用逗号分隔（例如，/cars;color=red,green;year=2012）。 也可以通过重复的变量名称指定多个值（例如，color = red; color = green; color = blue）。\n如果期望URL包含矩阵变量，则控制器方法的请求映射必须使用URI变量来屏蔽该变量内容，并确保可以成功地匹配请求，而与矩阵变量的顺序和状态无关。 以下示例使用矩阵变量：\n// GET /pets/42;q=11;r=22 @GetMapping(\u0026#34;/pets/{petId}\u0026#34;) public void findPet(@PathVariable String petId, @MatrixVariable int q) { // petId == 42 // q == 11 } 鉴于所有路径段都可能包含矩阵变量，因此有时您可能需要消除矩阵变量应位于哪个路径变量的歧义。下面的示例演示了如何做到这一点：\n// GET /owners/42;q=11/pets/21;q=22 @GetMapping(\u0026#34;/owners/{ownerId}/pets/{petId}\u0026#34;) public void findPet( @MatrixVariable(name=\u0026#34;q\u0026#34;, pathVar=\u0026#34;ownerId\u0026#34;) int q1, @MatrixVariable(name=\u0026#34;q\u0026#34;, pathVar=\u0026#34;petId\u0026#34;) int q2) { // q1 == 11 // q2 == 22 } 可以将矩阵变量定义为可选变量，并指定默认值，如以下示例所示：\n// GET /pets/42 @GetMapping(\u0026#34;/pets/{petId}\u0026#34;) public void findPet(@MatrixVariable(required=false, defaultValue=\u0026#34;1\u0026#34;) int q) { // q == 1 } 要获取所有矩阵变量，可以使用MultiValueMap，如以下示例所示：\n// GET /owners/42;q=11;r=12/pets/21;q=22;s=23 @GetMapping(\u0026#34;/owners/{ownerId}/pets/{petId}\u0026#34;) public void findPet( @MatrixVariable MultiValueMap\u0026lt;String, String\u0026gt; matrixVars, @MatrixVariable(pathVar=\u0026#34;petId\u0026#34;) MultiValueMap\u0026lt;String, String\u0026gt; petMatrixVars) { // matrixVars: [\u0026#34;q\u0026#34; : [11,22], \u0026#34;r\u0026#34; : 12, \u0026#34;s\u0026#34; : 23] // petMatrixVars: [\u0026#34;q\u0026#34; : 22, \u0026#34;s\u0026#34; : 23] } 请注意，您需要启用矩阵变量的使用。 在MVC Java配置中，您需要通过Path Matching设置带有removeSemicolonContent = false的UrlPathHelper。 在MVC XML名称空间中，您可以设置\u0026lt;mvc：annotation-driven enable-matrix-variables =“ true” /\u0026gt;。\n@RequestParam 您可以使用@RequestParam批注将Servlet请求参数（即查询参数或表单数据）绑定到控制器中的方法参数。\n@Controller @RequestMapping(\u0026#34;/pets\u0026#34;) public class EditPetForm { // ... @GetMapping public String setupForm(@RequestParam(\u0026#34;petId\u0026#34;) int petId, Model model) { Pet pet = this.clinic.loadPet(petId); model.addAttribute(\u0026#34;pet\u0026#34;, pet); return \u0026#34;petForm\u0026#34;; } // ... } 默认情况下，使用此批注的方法参数是必需的，但是您可以通过将@RequestParam批注的required标志设置为false或使用java.util.Optional包装器声明该参数，来指定方法参数是可选的。\n如果目标方法参数类型不是字符串，则将自动应用类型转换。 请参阅类型转换。\n将参数类型声明为数组或列表，可以为同一参数名称解析多个参数值。\n如果将@RequestParam批注声明为Map \u0026lt;String，String\u0026gt;或MultiValueMap \u0026lt;String，String\u0026gt;，但未在批注中指定参数名称，则将使用每个给定参数名称的请求参数值填充映射。\n请注意，@ RequestParam的使用是可选的（例如，设置其属性）。 默认情况下，任何简单值类型的参数（由BeanUtils＃isSimpleProperty确定），并且没有被任何其他参数解析器解析，就如同使用@RequestParam进行了注释一样。\n@RequestHeader 您可以使用@RequestHeader批注将请求标头绑定到控制器中的方法参数。\n考虑以下带有标头的请求：\nHost localhost:8080 Accept text/html,application/xhtml+xml,application/xml;q=0.9 Accept-Language fr,en-gb;q=0.7,en;q=0.3 Accept-Encoding gzip,deflate Accept-Charset ISO-8859-1,utf-8;q=0.7,*;q=0.7 Keep-Alive 300 以下示例获取Accept-Encoding和Keep-Alive标头的值：\n@GetMapping(\u0026#34;/demo\u0026#34;) public void handle( @RequestHeader(\u0026#34;Accept-Encoding\u0026#34;) String encoding, @RequestHeader(\u0026#34;Keep-Alive\u0026#34;) long keepAlive) { //... } 如果目标方法的参数类型不是String，则将自动应用类型转换。 请参阅类型转换。\n在Map \u0026lt;String，String\u0026gt;，MultiValueMap \u0026lt;String，String\u0026gt;或HttpHeaders参数上使用@RequestHeader批注时，将使用所有标头值填充映射。\n内置支持可用于将逗号分隔的字符串转换为数组或字符串集合或类型转换系统已知的其他类型。 例如，用@RequestHeader（“ Accept”）注释的方法参数可以是String类型，也可以是String []或List 。\n@CookieValue 您可以使用@CookieValue批注将HTTP cookie的值绑定到控制器中的方法参数。\n考虑带有以下cookie的请求：\nJSESSIONID=415A4AC178C59DACE0B2C9CA727CDD84 @GetMapping(\u0026#34;/demo\u0026#34;) public void handle(@CookieValue(\u0026#34;JSESSIONID\u0026#34;) String cookie) { //... } 如果目标方法的参数类型不是String，则将自动应用类型转换。 请参阅类型转换。\n@ModelAttribute 您可以在方法参数上使用@ModelAttribute批注，以从模型访问属性，或将其实例化（如果不存在）。 model属性会被请求参数中的值覆盖（如果参数名称相投同）。 这称为数据绑定，它自动帮您进行解析和转化的工作。 以下示例显示了如何执行此操作：\n@PostMapping(\u0026#34;/owners/{ownerId}/pets/{petId}/edit\u0026#34;) public String processSubmit(@ModelAttribute Pet pet) { } Pet实例填充流程如下：\n从模型（如果已通过使用模型添加，该模型是通过@ModelAttribute注解在方法上实现的）。 通过使用@SessionAttributes在HTTP会话中进行。 来自通过Converter传递的URI路径变量（请参见下一个示例）。 从默认构造函数的调用开始。 从请求参数中构造 尽管通常使用模型(Model章节)来填充示例，但另一种替代方法是依赖于Converter \u0026lt;String，T\u0026gt;与URI路径变量约定结合使用。 在以下示例中，模型属性名称account与URI路径变量account匹配，并且通过将String帐号传递给已注册的Converter \u0026lt;String，Account\u0026gt;来加载Account：\n@PutMapping(\u0026#34;/accounts/{account}\u0026#34;) public String save(@ModelAttribute(\u0026#34;account\u0026#34;) Account account) { // ... } 获取模型属性实例后，将应用数据绑定。 WebDataBinder类将Servlet请求参数名称（查询参数和表单字段）与目标Object上的字段名称匹配。 应用类型转换后，如有必要，将填充匹配字段。 有关数据绑定（和验证）的更多信息，请参见验证。 有关自定义数据绑定的更多信息，请参见DataBinder。\n数据绑定可能导致错误。 默认情况下，引发BindException。 但是，要检查控制器方法中的此类错误，可以在@ModelAttribute旁边立即添加BindingResult参数，如以下示例所示：\n@PostMapping(\u0026#34;/owners/{ownerId}/pets/{petId}/edit\u0026#34;) public String processSubmit(@ModelAttribute(\u0026#34;pet\u0026#34;) Pet pet, BindingResult result) { if (result.hasErrors()) { return \u0026#34;petForm\u0026#34;; } // ... } 在某些情况下，您可能希望只访问模型属性，而不把请求参数绑定到方法参数上。 对于这种情况，可以将模型注入控制器并直接访问它，或者设置@ModelAttribute（binding = false），如以下示例所示：\n@ModelAttribute public AccountForm setUpForm() { return new AccountForm(); } @ModelAttribute public Account findAccount(@PathVariable String accountId) { return accountRepository.findOne(accountId); } @PostMapping(\u0026#34;update\u0026#34;) public String update(@Valid AccountForm form, BindingResult result, @ModelAttribute(binding=false) Account account) { // ... } 您可以在数据绑定之后通过添加javax.validation.Valid注释或Spring的@Validated注释（Bean验证和Spring验证）自动应用验证。 以下示例显示了如何执行此操作：\n@PostMapping(\u0026#34;/owners/{ownerId}/pets/{petId}/edit\u0026#34;) public String processSubmit(@Valid @ModelAttribute(\u0026#34;pet\u0026#34;) Pet pet, BindingResult result) { if (result.hasErrors()) { return \u0026#34;petForm\u0026#34;; } // ... } 请注意，使用@ModelAttribute是可选的（例如，设置其属性）。 默认情况下，任何不是简单值类型（由BeanUtils＃isSimpleProperty确定）且未被其他任何参数解析器解析的参数都将被视为使用@ModelAttribute进行了注释。\n@SessionAttributes @SessionAttributes用于在请求之间的HTTP Servlet会话中存储模型属性。 它是类型级别的注释，用于声明特定控制器使用的会话属性。 这通常列出应透明地存储在会话中以供后续访问请求的模型属性的名称或模型属性的类型。\n以下示例使用@SessionAttributes批注：\n@Controller @SessionAttributes(\u0026#34;pet\u0026#34;) public class EditPetForm { // ... } 如果有请求，将名称为pet的模型属性添加到模型时，该属性会自动提升到HTTP Servlet会话并保存在该会话中。 它会一直保留在那里，直到另一个控制器方法使用SessionStatus方法参数来清除存储，如以下示例所示：\n@Controller @SessionAttributes(\u0026#34;pet\u0026#34;) public class EditPetForm { // ... @PostMapping(\u0026#34;/pets/{id}\u0026#34;) public String handle(Pet pet, BindingResult errors, SessionStatus status) { if (errors.hasErrors) { // ... } status.setComplete(); // ... } } } @SessionAttribute 如果您需要访问全局存在的会话属性，则可以在方法参数上使用@SessionAttribute批注，例如 以下示例显示：\n@RequestMapping(\u0026#34;/\u0026#34;) public String handle(@SessionAttribute User user) { // ... } 对于需要添加或删除会话属性的用例，请考虑将org.springframework.web.context.request.WebRequest或javax.servlet.http.HttpSession注入到控制器方法中。\n要在控制器工作流中将模型属性临时存储在会话中，请考虑使用@SessionAttributes，如@SessionAttributes中所述。\n@RequestAttribute 与@SessionAttribute类似，您可以使用@RequestAttribute批注来访问之前创建的预先存在的请求属性（例如，通过Servlet Filter或HandlerInterceptor）：\n@GetMapping(\u0026#34;/\u0026#34;) public String handle(@RequestAttribute Client client) { // ... } Redirect Attributes 默认情况下，所有模型属性均被视为在重定向URL中作为URI模板变量公开。 其他属性中，那些属于原始类型或原始类型的集合或数组的属性会自动附加为查询参数。\n如果专门为重定向准备了模型实例，则将原始类型属性作为查询参数附加可能是理想的结果。 但是，在带注释的控制器中，模型可以包含为渲染目的添加的其他属性（例如，下拉字段值）。 为避免此类属性出现在URL中的可能性，@ RequestMapping方法可以声明RedirectAttributes类型的参数，并使用它指定可用于RedirectView的确切属性。 如果该方法确实重定向，则使用RedirectAttributes的内容。 否则，将使用模型的内容。\nRequestMappingHandlerAdapter提供了一个名为ignoreDefaultModelOnRedirect的标志，您可以使用该标志指示如果控制器方法重定向，则绝不要使用默认Model的内容。 相反，控制器方法应声明一个RedirectAttributes类型的属性，或者，如果没有这样做，则不应将任何属性传递给RedirectView。 MVC命名空间和MVC Java配置都将此标志设置为false，以保持向后兼容性。 但是，对于新应用程序，我们建议将其设置为true。\n请注意，展开重定向URL时，当前请求中的URI模板变量会自动变为可用，并且您无需通过Model或RedirectAttributes显式添加它们。 以下示例显示了如何定义重定向：\n@PostMapping(\u0026#34;/files/{path}\u0026#34;) public String upload(...) { // ... return \u0026#34;redirect:files/{path}\u0026#34;; } 将数据传递到重定向目标的另一种方法是使用Flash属性。 与其他重定向属性不同，Flash属性保存在HTTP会话中（因此不会出现在URL中）。 有关更多信息，请参见Flash属性。\nFlash Attributes Flash属性为一个请求提供了一种存储打算在另一个请求中使用的属性的方式。 重定向时最常需要此操作，例如Post-Redirect-Get模式。 Flash属性在重定向之前（通常在会话中）被临时保存，以便在重定向之后可供请求使用，并立即被删除。\nSpring MVC有两个主要的抽象来支持Flash属性。 FlashMap用于保存Flash属性，而FlashMapManager用于存储，检索和管理FlashMap实例。\nFlash属性支持始终处于“打开”状态，无需显式启用。 但是，如果不使用它，则永远不会导致HTTP会话创建。 在每个请求上，都有一个“input” FlashMap，其属性是从上一个请求（如果有）传递过来的，而“output” FlashMap的属性是为后续请求保存的。 可以通过RequestContextUtils中的静态方法从Spring MVC中的任何位置访问这两个FlashMap实例。\n带注释的控制器通常不需要直接使用FlashMap。 相反，@ RequestMapping方法可以接受RedirectAttributes类型的参数，并使用它为重定向方案添加Flash属性。 通过RedirectAttributes添加的Flash属性会自动传播到“output” FlashMap。 同样，重定向后，来自“input” FlashMap的属性会自动添加到服务于目标URL的控制器的模型中。\nMultipart 启用MultipartResolver后，将解析具有multipart / form-data的POST请求的内容，并将其作为常规请求参数进行访问。 以下示例访问一个常规表单字段和一个上载文件：\n@Controller public class FileUploadController { @PostMapping(\u0026#34;/form\u0026#34;) public String handleFormUpload(@RequestParam(\u0026#34;name\u0026#34;) String name, @RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) { if (!file.isEmpty()) { byte[] bytes = file.getBytes(); // store the bytes somewhere return \u0026#34;redirect:uploadSuccess\u0026#34;; } return \u0026#34;redirect:uploadFailure\u0026#34;; } } 将参数类型声明为List 允许解析相同参数名称的多个文件。\n如果将@RequestParam批注声明为Map \u0026lt;String，MultipartFile\u0026gt;或MultiValueMap \u0026lt;String，MultipartFile\u0026gt;，但未在批注中指定参数名称，则将使用每个给定参数名称的多部分文件填充该映射。\n通过Servlet 3.0多部分解析，您还可以声明javax.servlet.http.Part而不是Spring的MultipartFile作为方法参数或集合值类型。\n您还可以将多部分内容用作绑定到命令对象的数据的一部分。 例如，前面示例中的表单字段和文件可以是表单对象上的字段，如以下示例所示：\nclass MyForm { private String name; private MultipartFile file; // ... } @Controller public class FileUploadController { @PostMapping(\u0026#34;/form\u0026#34;) public String handleFormUpload(MyForm form, BindingResult errors) { if (!form.getFile().isEmpty()) { byte[] bytes = form.getFile().getBytes(); // store the bytes somewhere return \u0026#34;redirect:uploadSuccess\u0026#34;; } return \u0026#34;redirect:uploadFailure\u0026#34;; } } 在RESTful服务方案中，也可以从非浏览器客户端提交多部分请求。 以下示例显示了带有JSON的文件：\nPOST /someUrl Content-Type: multipart/mixed --edt7Tfrdusa7r3lNQc79vXuhIIMlatb7PQg7Vp Content-Disposition: form-data; name=\u0026#34;meta-data\u0026#34; Content-Type: application/json; charset=UTF-8 Content-Transfer-Encoding: 8bit { \u0026#34;name\u0026#34;: \u0026#34;value\u0026#34; } --edt7Tfrdusa7r3lNQc79vXuhIIMlatb7PQg7Vp Content-Disposition: form-data; name=\u0026#34;file-data\u0026#34;; filename=\u0026#34;file.properties\u0026#34; Content-Type: text/xml Content-Transfer-Encoding: 8bit ... File Data ... 您可以使用@RequestParam作为字符串访问“meta-data”部分，但您可能希望将其从JSON反序列化（类似于@RequestBody）。 在使用HttpMessageConverter进行转换之后，使用@RequestPart批注来访问多部分：\n@PostMapping(\u0026#34;/\u0026#34;) public String handle(@RequestPart(\u0026#34;meta-data\u0026#34;) MetaData metadata, @RequestPart(\u0026#34;file-data\u0026#34;) MultipartFile file) { // ... } 您可以将@RequestPart与javax.validation.Valid结合使用，也可以使用Spring的@Validated注释，这两种注释都会导致应用标准Bean验证。 默认情况下，验证错误会导致MethodArgumentNotValidException，该异常将转换为400（BAD_REQUEST）响应。 另外，您可以通过Errors或BindingResult参数在控制器内本地处理验证错误，如以下示例所示：\n@PostMapping(\u0026#34;/\u0026#34;) public String handle(@Valid @RequestPart(\u0026#34;meta-data\u0026#34;) MetaData metadata, BindingResult result) { // ... } @RequestBody 您可以使用@RequestBody批注使请求正文通过HttpMessageConverter读取并反序列化为Object。 以下示例使用@RequestBody参数：\n@PostMapping(\u0026#34;/accounts\u0026#34;) public void handle(@RequestBody Account account) { // ... } 您可以使用MVC Config的“消息转换器”选项来配置或自定义消息转换。\n您可以将@RequestBody与javax.validation.Valid或Spring的@Validated批注结合使用，这两种方法都会导致应用标准Bean验证。 默认情况下，验证错误会导致MethodArgumentNotValidException，该异常将转换为400（BAD_REQUEST）响应。 另外，您可以通过Errors或BindingResult参数在控制器内本地处理验证错误，如以下示例所示：\n@PostMapping(\u0026#34;/accounts\u0026#34;) public void handle(@Valid @RequestBody Account account, BindingResult result) { // ... } HttpEntity HttpEntity或多或少与使用@RequestBody相同，但它基于公开请求标头和正文的容器对象。 以下清单显示了一个示例：\n@PostMapping(\u0026#34;/accounts\u0026#34;) public void handle(HttpEntity\u0026lt;Account\u0026gt; entity) { // ... } @ResponseBody 您可以在方法上使用@ResponseBody批注，以将返回值通过HttpMessageConverter序列化为响应主体。 以下清单显示了一个示例：\n@GetMapping(\u0026#34;/accounts/{id}\u0026#34;) @ResponseBody public Account handle() { // ... } 在类级别还支持@ResponseBody，在这种情况下，所有控制器方法都将继承它。 这就是@RestController的效果，它只不过是带有@Controller和@ResponseBody标记的元注释。\n您可以将@ResponseBody与反应类型一起使用。 有关更多详细信息，请参见异步请求和响应类型。\n您可以使用MVC Config的“消息转换器”选项来配置或自定义消息转换。\n您可以将@ResponseBody方法与JSON序列化视图结合使用。 有关详细信息，请参见Jackson JSON。\nResponseEntity ResponseEntity类似于@ResponseBody，但具有状态和标头。 例如：\n@GetMapping(\u0026#34;/something\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; handle() { String body = ... ; String etag = ... ; return ResponseEntity.ok().eTag(etag).build(body); } Spring MVC支持使用单值反应类型来异步生成ResponseEntity，和/或为主体使用单值和多值反应类型。\nJSON Views Spring MVC为Jackson的序列化视图提供了内置支持，该视图仅可呈现Object中所有字段的一部分。 要将其与@ResponseBody或ResponseEntity控制器方法一起使用，可以使用Jackson的@JsonView批注来激活序列化视图类，如以下示例所示：\n@RestController public class UserController { @GetMapping(\u0026#34;/user\u0026#34;) @JsonView(User.WithoutPasswordView.class) public User getUser() { return new User(\u0026#34;eric\u0026#34;, \u0026#34;7!jd#h23\u0026#34;); } } public class User { public interface WithoutPasswordView {}; public interface WithPasswordView extends WithoutPasswordView {}; private String username; private String password; public User() { } public User(String username, String password) { this.username = username; this.password = password; } @JsonView(WithoutPasswordView.class) public String getUsername() { return this.username; } @JsonView(WithPasswordView.class) public String getPassword() { return this.password; } } @JsonView允许一组视图类，但是每个控制器方法只能指定一个。 如果需要激活多个视图，则可以使用复合接口。\n如果要以编程方式执行上述操作，而不是声明@JsonView批注，请使用MappingJacksonValue包装返回值，并使用其提供序列化视图：\n@RestController public class UserController { @GetMapping(\u0026#34;/user\u0026#34;) public MappingJacksonValue getUser() { User user = new User(\u0026#34;eric\u0026#34;, \u0026#34;7!jd#h23\u0026#34;); MappingJacksonValue value = new MappingJacksonValue(user); value.setSerializationView(User.WithoutPasswordView.class); return value; } } 对于依赖视图解析器的控制器，您可以将序列化视图类添加到模型中，如以下示例所示：\n@Controller public class UserController extends AbstractController { @GetMapping(\u0026#34;/user\u0026#34;) public String getUser(Model model) { model.addAttribute(\u0026#34;user\u0026#34;, new User(\u0026#34;eric\u0026#34;, \u0026#34;7!jd#h23\u0026#34;)); model.addAttribute(JsonView.class.getName(), User.WithoutPasswordView.class); return \u0026#34;userView\u0026#34;; } } DataBinder @Controller或@ControllerAdvice类可以具有用于初始化WebDataBinder实例的@InitBinder方法，而这些方法又可以：\n将请求参数（即表单或查询数据）绑定到模型对象。 将基于字符串的请求值（例如请求参数，路径变量，标头，Cookie等）转换为控制器方法参数的目标类型。 呈现HTML表单时，将模型对象的值格式化为String值。 @InitBinder方法可以注册特定于控制器的java.beans.PropertyEditor或Spring Converter和Formatter组件。 此外，您可以使用MVC配置在全局共享的FormattingConversionService中注册Converter和Formatter类型。\n@InitBinder方法支持与@RequestMapping方法相同的许多参数，除了@ModelAttribute（命令对象）参数。 通常，它们使用WebDataBinder参数（用于注册）和无效的返回值声明。 以下清单显示了一个示例：\n@Controller public class FormController { @InitBinder public void initBinder(WebDataBinder binder) { SimpleDateFormat dateFormat = new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;); dateFormat.setLenient(false); binder.registerCustomEditor(Date.class, new CustomDateEditor(dateFormat, false)); } // ... } 另外，当通过共享的FormattingConversionService使用基于Formatter的设置时，可以重新使用相同的方法并注册特定于控制器的Formatter实现，如以下示例所示：\n@Controller public class FormController { @InitBinder protected void initBinder(WebDataBinder binder) { binder.addCustomFormatter(new DateFormatter(\u0026#34;yyyy-MM-dd\u0026#34;)); } // ... } 异常 @Controller和@ControllerAdvice类可以具有@ExceptionHandler方法来处理控制器方法的异常，如以下示例所示：\n@Controller public class SimpleController { // ... @ExceptionHandler public ResponseEntity\u0026lt;String\u0026gt; handle(IOException ex) { // ... } } 该异常可能与正在传播的顶级异常（即，直接IOException被抛出）匹配，也可能与顶级包装程序异常（例如，包装在IllegalStateException内部的IOException）内的直接原因匹配。\n对于匹配的异常类型，如前面的示例所示，最好将目标异常声明为方法参数。 当多个异常方法匹配时，根源异常匹配通常比原因异常匹配更可取。 更具体地说，ExceptionDepthComparator用于根据从引发的异常类型开始的深度对异常进行排序。\n另外，注释声明可以缩小异常类型以使其匹配，如以下示例所示：\n@ExceptionHandler({FileSystemException.class, RemoteException.class}) public ResponseEntity\u0026lt;String\u0026gt; handle(IOException ex) { // ... } 您甚至可以使用带有非常通用的参数签名的特定异常类型的列表，如以下示例所示：\n@ExceptionHandler({FileSystemException.class, RemoteException.class}) public ResponseEntity\u0026lt;String\u0026gt; handle(Exception ex) { // ... } 我们通常建议您在参数签名中尽可能具体，以减少根类型和原因异常类型之间不匹配的可能性。 考虑将多重匹配方法分解为单独的@ExceptionHandler方法，每个方法均通过其签名匹配单个特定的异常类型。\n在多@ControllerAdvice安排中，我们建议异常的范围根据根据@ControllerAdvice顺序声明，什么意思呢？假如A,B两个顺序advice，在A中声明了FileSystemException异常，在B中声明Exception.\n最后但并非最不重要的一点是，@ExceptionHandler方法实现可以选择通过以原始形式重新抛出异常来退出处理给定异常实例。 在仅对根级别匹配或无法静态确定的特定上下文中的匹配感兴趣的情况下，这很有用。 重新抛出的异常会在其余的解决方案链中传播，就像给定的@ExceptionHandler方法最初不会匹配一样。\nSpring MVC中对@ExceptionHandler方法的支持建立在DispatcherServlet级别HandlerExceptionResolver机制上。\n方法参数 @ExceptionHandler methods support the following arguments:\nMethod argument Description Exception type For access to the raised exception. HandlerMethod For access to the controller method that raised the exception. WebRequest, NativeWebRequest Generic access to request parameters and request and session attributes without direct use of the Servlet API. javax.servlet.ServletRequest, javax.servlet.ServletResponse Choose any specific request or response type (for example, ServletRequest or HttpServletRequest or Spring’s MultipartRequest or MultipartHttpServletRequest). javax.servlet.http.HttpSession Enforces the presence of a session. As a consequence, such an argument is never null.Note that session access is not thread-safe. Consider setting the RequestMappingHandlerAdapter instance’s synchronizeOnSession flag to true if multiple requests are allowed to access a session concurrently. java.security.Principal Currently authenticated user — possibly a specific Principal implementation class if known. HttpMethod The HTTP method of the request. java.util.Locale The current request locale, determined by the most specific LocaleResolver available — in effect, the configured LocaleResolver or LocaleContextResolver. java.util.TimeZone, java.time.ZoneId The time zone associated with the current request, as determined by a LocaleContextResolver. java.io.OutputStream, java.io.Writer For access to the raw response body, as exposed by the Servlet API. java.util.Map, org.springframework.ui.Model, org.springframework.ui.ModelMap For access to the model for an error response. Always empty. RedirectAttributes Specify attributes to use in case of a redirect — (that is to be appended to the query string) and flash attributes to be stored temporarily until the request after the redirect. See Redirect Attributes and Flash Attributes. @SessionAttribute For access to any session attribute, in contrast to model attributes stored in the session as a result of a class-level @SessionAttributes declaration. See @SessionAttribute for more details. @RequestAttribute For access to request attributes. See @RequestAttribute for more details. 返回值 @ExceptionHandler methods support the following return values:\nReturn value Description @ResponseBody The return value is converted through HttpMessageConverter instances and written to the response. See @ResponseBody. HttpEntity\u0026lt;B\u0026gt;, ResponseEntity\u0026lt;B\u0026gt; The return value specifies that the full response (including the HTTP headers and the body) be converted through HttpMessageConverter instances and written to the response. See ResponseEntity. String A view name to be resolved with ViewResolver implementations and used together with the implicit model — determined through command objects and @ModelAttribute methods. The handler method can also programmatically enrich the model by declaring a Model argument (described earlier). View A View instance to use for rendering together with the implicit model — determined through command objects and @ModelAttribute methods. The handler method may also programmatically enrich the model by declaring a Model argument (descried earlier). java.util.Map, org.springframework.ui.Model Attributes to be added to the implicit model with the view name implicitly determined through a RequestToViewNameTranslator. @ModelAttribute An attribute to be added to the model with the view name implicitly determined through a RequestToViewNameTranslator.Note that @ModelAttribute is optional. See “Any other return value” at the end of this table. ModelAndView object The view and model attributes to use and, optionally, a response status. void A method with a void return type (or null return value) is considered to have fully handled the response if it also has a ServletResponse an OutputStream argument, or a @ResponseStatus annotation. The same is also true if the controller has made a positive ETag or lastModified timestamp check (see Controllers for details).If none of the above is true, a void return type can also indicate “no response body” for REST controllers or default view name selection for HTML controllers. Any other return value If a return value is not matched to any of the above and is not a simple type (as determined by BeanUtils#isSimpleProperty), by default, it is treated as a model attribute to be added to the model. If it is a simple type, it remains unresolved. REST API exceptions REST服务的常见要求是在响应正文中包含错误详细信息。 Spring框架不会自动执行此操作，因为响应主体中错误详细信息的表示是特定于应用程序的。 但是，@ RestController可以将@ExceptionHandler方法与ResponseEntity返回值一起使用，以设置响应的状态和主体。 也可以在@ControllerAdvice类中声明此类方法，以将其全局应用。\n在响应主体中使用错误详细信息实现全局异常处理的应用程序应考虑扩展ResponseEntityExceptionHandler，该处理程序可处理Spring MVC引发的异常，并提供用于自定义响应主体的钩子。 要使用此功能，请创建ResponseEntityExceptionHandler的子类，并使用@ControllerAdvice对其进行注释，重写必需的方法，并将其声明为Spring bean。\nModel @ModelAttribute注解可以用于：\n@RequestMapping标注的方法参数上，访问（没有则创建）Model里面对应的对象并使用WebDataBinder将该对象绑定到请求中。 标注在@Controller 或 @ControllerAdvice注解的方法上，初始化Model对象，该方法会在任何@RequestMapping方法之前执行。 标注在@RequestMapping方法上，表明该方法的返回值会作为Model属性。 本节讨论@ModelAttribute方法-前面列表中的第二项。 控制器可以具有任意数量的@ModelAttribute方法。 所有此类方法均在同一控制器中的@RequestMapping方法之前调用。 也可以通过@ControllerAdvice在控制器之间共享@ModelAttribute方法。 有关更多详细信息，请参见“控制器Advice”部分。\n@ModelAttribute方法具有灵活的方法签名。 它们支持许多与@RequestMapping方法相同的参数，除了@ModelAttribute本身或与请求主体相关的任何东西。\n下面的例子是@ModelAttribute注解的Controller方法\n@ModelAttribute public void populateModel(@RequestParam String number, Model model) { model.addAttribute(accountRepository.findAccount(number)); // add more ... } 以下示例仅添加一个属性：\n@ModelAttribute public Account addAccount(@RequestParam String number) { return accountRepository.findAccount(number); } 如果未明确指定名称，则根据“对象”类型选择默认名称，如javadoc中所述。 您始终可以使用重载的addAttribute方法或通过@ModelAttribute上的name属性（用于返回值）来分配显式名称。\n您也可以将@ModelAttribute用作@RequestMapping方法上的方法级注释，在这种情况下，@ RequestMapping方法的返回值将解释为模型属性。 通常不需要这样做，因为它是HTML控制器的默认行为，除非返回值是一个String，这时，返回值被解释为视图名称。 @ModelAttribute还可以自定义模型属性名称，如以下示例所示：\n@GetMapping(\u0026#34;/accounts/{id}\u0026#34;) @ModelAttribute(\u0026#34;myAccount\u0026#34;) public Account handle() { // ... return account; } @ModelAttribute @RequestMapping(\u0026#34;/model/name\u0026#34;) public String testModelName(Model model) { Map\u0026lt;String, Object\u0026gt; stringObjectMap = model.asMap(); //{myUser=MyUser{id=123, name=\u0026#39;???\u0026#39;, birth=null, password=\u0026#39;null\u0026#39;, createTime=null}} return stringObjectMap.toString(); } 这个时候，会把返回值解析成视图名称，找不到视图就会出错。\nController Advice 通常，@ ExceptionHandler，@ InitBinder和@ModelAttribute方法在声明它们的@Controller类（或类层次结构）中应用。 如果要使此类方法更全局地应用（跨控制器），则可以在带有@ControllerAdvice或@RestControllerAdvice注释的类中声明它们。\n@ControllerAdvice带有@Component注释，这意味着可以通过组件扫描将此类注册为Spring Bean。 @RestControllerAdvice是由@ControllerAdvice和@ResponseBody注释的组合注释，这实际上意味着@ExceptionHandler方法通过消息转换（与视图分辨率或模板渲染）呈现给响应主体。\n启动时，@ RequestMapping和@ExceptionHandler方法的基础结构类将检测使用@ControllerAdvice注释的Spring bean，然后在运行时应用其方法。 全局@ExceptionHandler方法（来自@ControllerAdvice）在本地方法（来自@Controller）之后应用。 相比之下，全局@ModelAttribute和@InitBinder方法在本地方法之前应用。\n默认情况下，@ ControllerAdvice方法适用于每个请求（即所有控制器），但是您可以通过使用批注上的属性将其范围缩小到控制器的子集，如以下示例所示：\n// Target all Controllers annotated with @RestController @ControllerAdvice(annotations = RestController.class) public class ExampleAdvice1 {} // Target all Controllers within specific packages @ControllerAdvice(\u0026#34;org.example.controllers\u0026#34;) public class ExampleAdvice2 {} // Target all Controllers assignable to specific classes @ControllerAdvice(assignableTypes = {ControllerInterface.class, AbstractController.class}) public class ExampleAdvice3 {} 前面示例中的选择器在运行时进行评估，如果广泛使用，可能会对性能产生负面影响。 有关更多详细信息，请参见@ControllerAdvice javadoc。\nCORS 简介 出于安全原因，浏览器禁止AJAX调用当前来源以外的资源。 例如，您可以将您的银行帐户放在一个浏览器标签中，将evil.com放在另一个标签中。 来自evil.com的脚本不应使用您的凭据向您的银行API发出AJAX请求，例如从您的帐户中取钱！\n跨域资源共享（CORS）是由大多数浏览器实现的W3C规范，可让您指定授权哪种类型的跨域请求，而不是使用基于IFRAME或JSONP的安全性较低且功能较弱的变通办法。\n处理 CORS规范区分预检（例如Options），简单和实际要求。 要了解CORS的工作原理，您可以阅读本文Cross-Origin Resource Sharing (CORS) - HTTP | MDN，或者参阅规范以获取更多详细信息。\nSpring MVC HandlerMapping实现为CORS提供内置支持。 成功将请求映射到处理程序后，HandlerMapping实现将检查给定请求和处理程序的CORS配置，并采取进一步的措施。 遇检请求直接处理，而简单和实际的CORS请求被拦截，验证并设置了必需的CORS响应标头。\n为了启用跨域请求（即存在Origin标头，并且与请求的主机不同），您需要具有一些显式声明的CORS配置。 如果找不到匹配的CORS配置，则预检请求将被拒绝。 没有将CORS标头添加到简单和实际CORS请求的响应中，因此，浏览器拒绝了它们。\n可以使用基于URL模式的CorsConfiguration映射分别配置每个HandlerMapping。 在大多数情况下，应用程序使用MVC Java配置或XML名称空间声明此类映射，这导致将单个全局映射传递给所有HandlerMappping实例。\n您可以将HandlerMapping级别的全局CORS配置与更细粒度的处理程序级别的CORS配置结合使用。 例如，带注释的控制器可以使用类或方法级别的@CrossOrigin注释（其他处理程序可以实现CorsConfigurationSource）。\n全局和本地配置组合的规则通常是相加的。 对于那些只能接受单个值的属性，例如 allowCredentials和maxAge，则局部值覆盖全局值。 有关更多详细信息，请参见CorsConfiguration＃combine（CorsConfiguration）。\n如果你想高度定制化，请参考下面几个类源码：\nCorsConfiguration CorsProcessor, DefaultCorsProcessor AbstractHandlerMapping @CrossOrigin @CrossOrigin批注启用带注释的控制器方法上的跨域请求，如以下示例所示：\n@RestController @RequestMapping(\u0026#34;/account\u0026#34;) public class AccountController { @CrossOrigin @GetMapping(\u0026#34;/{id}\u0026#34;) public Account retrieve(@PathVariable Long id) { // ... } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public void remove(@PathVariable Long id) { // ... } } @CrossOrigin默认允许所有：\nAll origins. All headers. 控制器方法映射到的所有HTTP方法。 默认情况下，allowCredentials未启用，因为它将建立一个信任级别，以公开敏感的用户特定信息（例如cookie和CSRF令牌），并且仅在适当的地方使用。 启用后，必须将allowOrigins设置为一个或多个特定域（而不是特殊值“ *”），或者可将allowOriginPatterns属性用于匹配动态的一组origins。\nmaxAge设置为30分钟。\n@CrossOrigin在类级别也受支持，并且被所有方法继承，如以下示例所示：\n@CrossOrigin(origins = \u0026#34;https://domain2.com\u0026#34;, maxAge = 3600) @RestController @RequestMapping(\u0026#34;/account\u0026#34;) public class AccountController { @GetMapping(\u0026#34;/{id}\u0026#34;) public Account retrieve(@PathVariable Long id) { // ... } @DeleteMapping(\u0026#34;/{id}\u0026#34;) public void remove(@PathVariable Long id) { // ... } } 全局配置 除了细粒度的控制器方法级别配置之外，您可能还想定义一些全局CORS配置。 您可以在任何HandlerMapping上分别设置基于URL的CorsConfiguration映射。 但是，大多数应用程序都使用MVC Java配置或MVC XML名称空间来执行此操作。\n默认情况下，全局配置启用以下功能：\nAll origins. All headers. GET, HEAD, and POST methods. 默认情况下，allowCredentials未启用，因为它将建立一个信任级别，以公开敏感的用户特定信息（例如cookie和CSRF令牌），并且仅在适当的地方使用。 启用后，必须将allowOrigins设置为一个或多个特定域（而不是特殊值“ *”），或者可将allowOriginPatterns属性用于匹配动态的一组origins。\nmaxAge设置为30分钟。\n@Configuration @EnableWebMvc public class WebConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/api/**\u0026#34;) .allowedOrigins(\u0026#34;https://domain2.com\u0026#34;) .allowedMethods(\u0026#34;PUT\u0026#34;, \u0026#34;DELETE\u0026#34;) .allowedHeaders(\u0026#34;header1\u0026#34;, \u0026#34;header2\u0026#34;, \u0026#34;header3\u0026#34;) .exposedHeaders(\u0026#34;header1\u0026#34;, \u0026#34;header2\u0026#34;) .allowCredentials(true).maxAge(3600); // Add more mappings... } } CORS过滤器 您可以通过内置的CorsFilter应用CORS支持。\n要配置过滤器，请将CorsConfigurationSource传递给其构造函数，如以下示例所示：\nCorsConfiguration config = new CorsConfiguration(); // Possibly... // config.applyPermitDefaultValues() config.setAllowCredentials(true); config.addAllowedOrigin(\u0026#34;https://domain1.com\u0026#34;); config.addAllowedHeader(\u0026#34;*\u0026#34;); config.addAllowedMethod(\u0026#34;*\u0026#34;); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); CorsFilter filter = new CorsFilter(source); HTTP缓存 HTTP缓存可以显着提高Web应用程序的性能。 HTTP缓存围绕Cache-Control响应标头以及随后的条件请求标头（例如Last-Modified和ETag）。 缓存控制为私有（例如浏览器）和公共（例如代理）缓存，提供有关如何缓存和重用响应的建议。 ETag标头用于发出条件请求，如果内容未更改，则可能导致没有主体的304（NOT_MODIFIED）。 ETag可以看作是Last-Modified头的更复杂的后继者。\nCacheControl CacheControl支持配置与Cache-Control标头相关的设置，并在许多地方作为参数被接受：\nWebContentInterceptor WebContentGenerator Controllers Static Resources 尽管RFC 7234描述了Cache-Control响应标头的所有可能的指令，但CacheControl类型采用了面向用例的方法，着重于常见方案：\n// 缓存一个小时\u0026#34;Cache-Control: max-age=3600\u0026#34; CacheControl ccCacheOneHour = CacheControl.maxAge(1, TimeUnit.HOURS); //阻止缓存\u0026#34;Cache-Control: no-store\u0026#34; CacheControl ccNoStore = CacheControl.noStore(); // 缓存10天，无论共有私有, // public缓存不应改变响应 // \u0026#34;Cache-Control: max-age=864000, public, no-transform\u0026#34; CacheControl ccCustom = CacheControl.maxAge(10, TimeUnit.DAYS).noTransform().cachePublic(); WebContentGenerator还接受一个更简单的cachePeriod属性（以秒为单位定义），该属性的工作方式如下：\n-1值不会生成Cache-Control响应标头。 值为0使用“ Cache-Control: no-store”指令进行缓存。 n\u0026gt; 0值通过使用\u0026rsquo;Cache-Control：max-age = n\u0026rsquo;指令将给定响应缓存n秒。 控制器 控制器可以添加对HTTP缓存的显式支持。 我们建议您这样做，因为需要先计算资源的lastModified或ETag值，然后才能将其与条件请求标头进行比较。 控制器可以将ETag标头和Cache-Control设置添加到ResponseEntity，如以下示例所示：\n@GetMapping(\u0026#34;/book/{id}\u0026#34;) public ResponseEntity\u0026lt;Book\u0026gt; showBook(@PathVariable Long id) { Book book = findBook(id); String version = book.getVersion(); return ResponseEntity .ok() .cacheControl(CacheControl.maxAge(30, TimeUnit.DAYS)) .eTag(version) // lastModified is also available .body(book); } 如果与条件请求标头的比较表明内容未更改，则前面的示例发送带有空正文的304（NOT_MODIFIED）响应。 否则，ETag和Cache-Control标头将添加到响应中。\n您还可以在控制器中针对条件请求标头进行检查，如以下示例所示：\n@RequestMapping public String myHandleMethod(WebRequest request, Model model) { long eTag = ... if (request.checkNotModified(eTag)) { return null; } model.addAttribute(...); return \u0026#34;myViewName\u0026#34;; } 可以使用三种变体来检查针对eTag值，lastModified值或两者的条件请求。 对于有条件的GET和HEAD请求，可以将响应设置为304（NOT_MODIFIED）。 对于条件POST，PUT和DELETE，您可以将响应设置为412（PRECONDITION_FAILED），以防止并发修改。\n静态资源 您应该为静态资源提供Cache-Control和条件响应标头，以实现最佳性能。 请参阅有关配置静态资源的部分。\nETag Filter 您可以使用ShallowEtagHeaderFilter来添加根据响应内容计算的“浅” eTag值，从而节省带宽，但不节省CPU时间。 请参阅浅ETag。\n附录 DispatcherServlet.properties spring mvc中获取Context Object attribute = request.getAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE); System.err.println(attribute.getClass().getName()); WebApplicationContext webApplicationContext = RequestContextUtils.findWebApplicationContext(request); System.err.println(webApplicationContext.equals(attribute));//true Object attribute1 = RequestContextHolder.currentRequestAttributes().getAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE, RequestAttributes.SCOPE_REQUEST); System.err.println(attribute.equals(attribute1));//true return attribute.getClass().getName(); LastModify实现 继承Controller方式\npublic class TestController implements Controller,LastModified{ private long lastModified = System.currentTimeMillis(); @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Excepti回视图的话 return new ModelAndView(\u0026#34;returnView\u0026#34;); } @Override public long getLastModified(HttpServletRequest request) { if (lastModified == 0L) { // 只用返回历史时间戳即可 return lastModified; } } Webrequest方式\n@RestController @RequestMapping(\u0026#34;/last\u0026#34;) public class LastModifyControllerTest { private long lastModify = System.currentTimeMillis(); @GetMapping(\u0026#34;/t1\u0026#34;) public String test1(WebRequest webRequest) { System.err.println(lastModify); if (webRequest.checkNotModified(lastModify)) { return null; } System.err.println(\u0026#34;test1\u0026#34;); return \u0026#34;test1\u0026#34;; } 为什么会出现这两种方式呢？我们来看一下源码：\nString method = request.getMethod(); boolean isGet = \u0026#34;GET\u0026#34;.equals(method); if (isGet || \u0026#34;HEAD\u0026#34;.equals(method)) { long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) \u0026amp;\u0026amp; isGet) { return; } } ha是HandlerAdapter，@RequestMapping对应的实现是RequestMappingHandlerAdapter，该类的getLastModified方法直接返回-1（表示已修改，不走304）.继承Controller方式的方式实现类是SimpleControllerHandlerAdapter，该类会判断handler是否实现LastModified接口，实现则调用实现接口。\nlog-request-details springboot只需要在属性文件中开启即可：\nspring.mvc.log-request-details=true debug=true DispatcherServlet : enableLoggingRequestDetails=\u0026#39;false\u0026#39;: request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data DispatcherServlet : Completed initialization in 4 ms DispatcherServlet : POST \u0026#34;/last/t1?password=122323\u0026#34;, parameters={masked} RequestMappingHandlerMapping : Mapped to com.example.dateformat.web.LastModifyControllerTest#test1(WebRequest) 1605243469961 test1 RequestResponseBodyMethodProcessor : Using \u0026#39;text/plain\u0026#39;, given [*/*] and supported [text/plain, */*, application/json, application/*+json] RequestResponseBodyMethodProcessor : Writing [\u0026#34;test1\u0026#34;] DispatcherServlet : Completed 200 OK DispatcherServlet : enableLoggingRequestDetails=\u0026#39;true\u0026#39;: request parameters and headers will be shown which may lead to unsafe logging of potentially sensitive data DispatcherServlet : Completed initialization in 6 ms DispatcherServlet : POST \u0026#34;/last/t1?password=122323\u0026#34;, parameters={password:[122323], name:[zhao]} RequestMappingHandlerMapping : Mapped to com.example.dateformat.web.LastModifyControllerTest#test1(WebRequest) 1605243584655 test1 RequestResponseBodyMethodProcessor : Using \u0026#39;text/plain\u0026#39;, given [*/*] and supported [text/plain, */*, application/json, application/*+json] RequestResponseBodyMethodProcessor : Writing [\u0026#34;test1\u0026#34;] DispatcherServlet : Completed 200 OK ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-mvc/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985769,"title":"Spring-Mvc"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"简介 Resilience4j一个轻量级（只依赖Vavr第三方库）的，易于使用的容错框架，灵感来源于Netflix Hystrix，依托于java8的函数式编程。\nResilience4j提供了断路器、限速、重试、Bulkhead等功能。你可以任意选择和搭配这些功能。\nBulkhead(隔板模式)是一种容错的应用程序设计。 在隔板架构中，应用程序的元素被隔离到池中，因此，如果其中一个失败，则其他元素将继续运行。 它是根据船体的分段隔板（凸头）来命名的。 如果船体受损，则只有损坏的部分会充满水，从而防止船下沉。\n以下示例显示了如何使用CircuitBreaker和Retry装饰lambda表达式，以便在发生异常时最多重试3次。\n// 创建默认的断路器 CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults(\u0026#34;backendService\u0026#34;); // 创建默认的重试器，重拾3次，间隔为500ms Retry retry = Retry.ofDefaults(\u0026#34;backendService\u0026#34;); // 创建默认的隔离器 Bulkhead bulkhead = Bulkhead.ofDefaults(\u0026#34;backendService\u0026#34;); //具体的业务调用 Supplier\u0026lt;String\u0026gt; supplier = () -\u0026gt; backendService.doSomething(param1, param2) // 使用装扮器装扮函数 Supplier\u0026lt;String\u0026gt; decoratedSupplier = Decorators.ofSupplier(supplier) .withCircuitBreaker(circuitBreaker) .withBulkhead(bulkhead) .withRetry(retry) .decorate(); // 执行函数，并设置后退函数 String result = Try.ofSupplier(decoratedSupplier) .recover(throwable -\u0026gt; \u0026#34;Hello from Recovery\u0026#34;).get(); // 不使用装扮器，直接使用断路器调用函数 String result = circuitBreaker .executeSupplier(backendService::doSomething); // 使用ThreadPoolBulkhead在另外的线程中异步运行 ThreadPoolBulkhead threadPoolBulkhead = ThreadPoolBulkhead.ofDefaults(\u0026#34;backendService\u0026#34;); // 设定超时机制，超时需要Scheduler来调度 ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(3); TimeLimiter timeLimiter = TimeLimiter.of(Duration.ofSeconds(1)); CompletableFuture\u0026lt;String\u0026gt; future = Decorators.ofSupplier(supplier) .withThreadPoolBulkhead(threadPoolBulkhead) .withTimeLimiter(timeLimiter, scheduledExecutorService) .withCircuitBreaker(circuitBreaker) .withFallback(asList(TimeoutException.class, CallNotPermittedException.class, BulkheadFullException.class), throwable -\u0026gt; \u0026#34;Hello from Recovery\u0026#34;) .get().toCompletableFuture(); 您可以配置重试之间的等待间隔，还可以配置回退算法。\n当所有重试均失败时，该示例使用Vavr的monad从异常中恢复并调用另一个lambda表达式作为后备。\n模块 核心模块\nresilience4j-circuitbreaker: Circuit breaking resilience4j-ratelimiter: Rate limiting resilience4j-bulkhead: Bulkheading resilience4j-retry: Automatic retrying (sync and async) resilience4j-cache: Result caching resilience4j-timelimiter: Timeout handling 扩展模块\nresilience4j-retrofit: Retrofit adapter resilience4j-feign: Feign adapter resilience4j-consumer: Circular Buffer Event consumer resilience4j-kotlin: Kotlin coroutines support 框架模块\nresilience4j-spring-boot: Spring Boot Starter resilience4j-spring-boot2: Spring Boot 2 Starter resilience4j-ratpack: Ratpack Starter resilience4j-vertx: Vertx Future decorator Reactive 模块\nresilience4j-rxjava2: Custom RxJava2 operators resilience4j-reactor: Custom Spring Reactor operators Metrics modules\nresilience4j-micrometer: Micrometer Metrics exporter resilience4j-metrics: Dropwizard Metrics exporter resilience4j-prometheus: Prometheus Metrics exporter CircuitBreaker 断路器又三个正常状态：CLOSE，OPEN和HALF_OPEN ,两个特殊状态 DISABLED和FORCED_OPEN.\n断路器使用滑动窗口来存储和汇总调用结果，这个窗口可以基于计数或时间。基于计数的滑动窗口汇总了最近N个调用的结果。 基于时间的滑动窗口汇总了最近N秒的调用结果。\n基于计数的滑动窗口由N个测量值的圆形数组实现。如果计数窗口大小为10，则圆形阵列始终具有10个测量值。滑动窗口以增量方式更新汇总结果。 当记录新的call结果时，将更新总汇总。 收回最旧的度量后，将从总聚合中减去该度量，然后重置存储桶。 （逐项扣除） 基于时间的滑动窗口是由N个部分汇总结果（存储桶）的圆形数组实现的。如果时间窗口大小为10秒，则圆形数组将始终具有10个部分汇总结果（存储桶）。 每个存储段都会汇总在某个纪元秒内发生的所有调用的结果。 圆形数组的头存储区存储当前纪元的call结果。 其他部分聚合存储前几秒的call结果。滑动窗口不会单独存储call结果（元组），而是以增量方式更新部分聚合（存储桶）和总聚合。当记录新的call结果时，总聚合将增量更新。 当最旧的存储桶被收回时，该存储桶的部分总聚合将从总聚合中减去，然后重置该存储桶（逐项扣除）。 部分聚合 由3个整数组成，以计算失败的call数，慢速call数和总call数。 一个长存储所有call的总持续时间。 故障率和慢速调用率阈值 当故障率等于或大于配置的阈值时，CircuitBreaker的状态将从“CLOSE”更改为“OPEN”。 例如，当超过50％的call失败时。默认情况下，所有异常均视为失败。 您可以定义应视为失败的异常列表。 除非忽略所有其他异常，否则所有其他异常均被视为成功。 也可以忽略异常，以使它们既不算作失败也不算成功。\n当慢速呼叫的百分比等于或大于配置的阈值时，CircuitBreaker也会从CLOSED变为OPEN。 例如，当超过50％的call时间超过5秒。 这有助于减轻被调用系统的负担。\n如果记录的call数量达到指定的要求，才会计算故障率和慢速呼叫率。 例如，如果所需call的最小数量为10，则必须至少记录10个call，然后才能计算出故障率。 如果仅评估了9个call，则即使所有9个call均失败，CircuitBreaker也不会跳闸。\n当断路器打开时，返回CallNotPermittedException 异常。 经过一段等待时间后，CircuitBreaker状态从OPEN变为HALF_OPEN，并允许可配置数量的call以查看后端是否可用， 除非所有允许的call都已完成，否则将通过CallNotPermittedException拒绝进一步的call。\n断路器支持另外两个特殊状态，即DISABLED（始终允许访问）和FORCED_OPEN（始终拒绝访问）。 在这两种状态下，不会生成任何断路器事件（状态转换除外），也不会记录任何度量。 退出这些状态的唯一方法是触发状态转换或重置断路器。\nCircuitBreaker是线程安全的，如下所示：\nCircuitBreaker的状态存储在AtomicReference中 CircuitBreaker使用原子操作来更新状态。 从“滑动窗口”记录call和读取快照是同步操作 如果有20个并发线程请求执行函数的许可，并且CircuitBreaker的状态关闭，则允许所有线程调用该功能。 即使滑动窗口的大小为15。滑动窗口也不意味着仅允许15个调用并发运行。 如果要限制并发线程的数量，请使用Bulkhead。 您可以组合使用Bulkhead和CircuitBreaker。\n单个线程的示意图\n三个线程的示意图\n如何使用 基于ConcurrentHashMap的CircuitBreakerRegistry，可提供线程安全性和原子性保证。 您可以使用CircuitBreakerRegistry来管理（创建和检索）CircuitBreaker实例。 您可以为所有CircuitBreaker实例创建一个具有全局默认CircuitBreakerConfig的CircuitBreakerRegistry，如下所示：\nCircuitBreakerRegistry circuitBreakerRegistry = CircuitBreakerRegistry.ofDefaults(); 断路器配置 您可以提供自定义的全局CircuitBreakerConfig。 为了创建定制的全局CircuitBreakerConfig，可以使用CircuitBreakerConfig构建器。 您可以使用构建器来配置以下属性。\n配置的属性 默认值 描述 failureRateThreshold 50 以百分比配置故障率阈值。当故障率等于或大于阈值时，CircuitBreaker转换为打开状态。 slowCallRateThreshold 100 当call持续时间slowCallDurationThreshold时，CircuitBreaker会将call视为慢速call 当慢速call的百分比等于或大于阈值时，CircuitBreaker转换为打开状态 slowCallDurationThreshold 60000 [ms] 当call的调用时间超过改值时，认为时慢速的 permittedNumberOfCalls InHalfOpenState 10 配置CircuitBreaker半打开时允许的call数。 maxWaitDurationInHalfOpenState 0 该时间用于控制CircuitBreaker在切换到打开之前可以保持在Half Open状态的最长时间。值0表示断路器将在HalfOpen状态下无限期等待，直到所有允许的call完成。 slidingWindowType COUNT_BASED 配置滑动窗口的类型，如果是 COUNT_BASED, 最后的 slidingWindowSize个call被记录和汇总；如果是 TIME_BASED, 最后slidingWindowSize秒数内的请求被记录和汇总 slidingWindowSize 100 配置滑动窗口的大小，该窗口用于在CircuitBreaker关闭时记录call结果。 minimumNumberOfCalls 100 配置CircuitBreaker可以计算错误率或慢速呼叫率之前所需的最小呼叫数（每个滑动窗口时段）。例如，如果minimumNumberOfCalls为10，则必须至少记录10个呼叫，然后才能计算失败率。如果仅记录了9个呼叫，则即使所有9个呼叫均失败，CircuitBreaker也不会转换为打开。 waitDurationInOpenState 60000 [ms] 从断开到半开之前CircuitBreaker应该等待的时间。 automaticTransition FromOpenToHalfOpenEnabled false 如果设置为true，则意味着CircuitBreaker将自动从打开状态转换为半打开状态，不需要调用即可触发该转换。 一旦waitDurationInOpenState通过，就会创建一个线程来监视CircuitBreakers的所有实例，以将其转换为HALF_OPEN。 而如果将其设置为false，则即使在传递了waitDurationInOpenState之后，也只有在进行调用时才发生向HALF_OPEN的转换。 这里的优点是没有线程监视所有CircuitBreakers的状态。 recordExceptions empty 记录为故障的异常列表。 除非通过ignoreExceptions表明确忽略，否则任何与列表之一匹配或继承的异常都将视为失败。 如果指定ignoreExceptions例外列表，则所有其他例外都将视为成功，除非它们被显式忽略 ignoreExceptions empty 忽略的异常列表，既不算作失败也不算成功。 从列表之一匹配或继承的任何异常都不会被视为失败或成功，即使该异常是recordExceptions其中的一部分 recordException throwable -\u0026gt; true 所有异常 一个自定义谓词，用于评估是否应将异常记录为失败。 如果异常应计为失败，则谓词必须返回true。 除非成功将ignoreExceptions异常显式忽略，否则应该算是成功 ignoreException throwable -\u0026gt; false 没有yi 一个自定义谓词，用于评估是否应忽略异常，并且该异常既不算作失败也不算成功。 如果应忽略异常，则谓词必须返回true。 如果异常应计为失败，则谓词必须返回false。 // 自定义CircuitBreaker的配置 CircuitBreakerConfig circuitBreakerConfig = CircuitBreakerConfig.custom() .failureRateThreshold(50) .slowCallRateThreshold(50) .waitDurationInOpenState(Duration.ofMillis(1000)) .slowCallDurationThreshold(Duration.ofSeconds(2)) .permittedNumberOfCallsInHalfOpenState(3) .minimumNumberOfCalls(10) .slidingWindowType(SlidingWindowType.TIME_BASED) .slidingWindowSize(5) .recordException(e -\u0026gt; INTERNAL_SERVER_ERROR .equals(getResponse().getStatus())) .recordExceptions(IOException.class, TimeoutException.class) .ignoreExceptions(BusinessException.class, OtherBusinessException.class) .build(); // 使用自定义配置创建CircuitBreakerRegistry CircuitBreakerRegistry circuitBreakerRegistry = CircuitBreakerRegistry.of(circuitBreakerConfig); // 创建默认的断路器 CircuitBreaker circuitBreakerWithDefaultConfig = circuitBreakerRegistry.circuitBreaker(\u0026#34;name1\u0026#34;); // 自定义断路器 CircuitBreaker circuitBreakerWithCustomConfig = circuitBreakerRegistry .circuitBreaker(\u0026#34;name2\u0026#34;, circuitBreakerConfig); 创建由多个实例共享的配置:\nCircuitBreakerConfig circuitBreakerConfig = CircuitBreakerConfig.custom() .failureRateThreshold(70) .build(); circuitBreakerRegistry.addConfiguration(\u0026#34;someSharedConfig\u0026#34;, config); CircuitBreaker circuitBreaker = circuitBreakerRegistry .circuitBreaker(\u0026#34;name\u0026#34;, \u0026#34;someSharedConfig\u0026#34;); 覆盖默认配置:\nCircuitBreakerConfig defaultConfig = circuitBreakerRegistry .getDefaultConfig(); CircuitBreakerConfig overwrittenConfig = CircuitBreakerConfig .from(defaultConfig) .waitDurationInOpenState(Duration.ofSeconds(20)) .build(); 如果您不想使用CircuitBreakerRegistry管理CircuitBreaker实例，也可以直接创建实例:\n// Create a custom configuration for a CircuitBreaker CircuitBreakerConfig circuitBreakerConfig = CircuitBreakerConfig.custom() .recordExceptions(IOException.class, TimeoutException.class) .ignoreExceptions(BusinessException.class, OtherBusinessException.class) .build(); CircuitBreaker customCircuitBreaker = CircuitBreaker .of(\u0026#34;testName\u0026#34;, circuitBreakerConfig); 您还可以使用其生成器方法创建CircuitBreakerRegistry：\nMap \u0026lt;String, String\u0026gt; circuitBreakerTags = Map.of(\u0026#34;key1\u0026#34;, \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;); CircuitBreakerRegistry circuitBreakerRegistry = CircuitBreakerRegistry.custom() .withCircuitBreakerConfig(CircuitBreakerConfig.ofDefaults()) .addRegistryEventConsumer(new RegistryEventConsumer() { @Override public void onEntryAddedEvent(EntryAddedEvent entryAddedEvent) { // implementation } @Override public void onEntryRemovedEvent(EntryRemovedEvent entryRemoveEvent) { // implementation } @Override public void onEntryReplacedEvent(EntryReplacedEvent entryReplacedEvent) { // implementation } }) .withTags(circuitBreakerTags) .build(); CircuitBreaker circuitBreaker = circuitBreakerRegistry.circuitBreaker(\u0026#34;testName\u0026#34;); 如果要插入自己的Registry实现，则可以提供Interface RegistryStore的自定义实现，并使用builder方法插入:\nCircuitBreakerRegistry registry = CircuitBreakerRegistry.custom() .withRegistryStore(new YourRegistryStoreImplementation()) .withCircuitBreakerConfig(CircuitBreakerConfig.ofDefaults()) .build(): 使用断路器装扮函数并调用 您可以使用CircuitBreaker装饰任何Callable，Supplier，Runnable，Consumer，CheckedRunnable，CheckedSupplier，CheckedConsumer或CompletionStage。\n您可以使用Vavr中的Try.of（\u0026hellip;）或Try.run（\u0026hellip;）来调用修饰的函数。 这允许使用map，flatMap，filter，recover或andThen链接其他功能。 仅当CircuitBreaker为CLOSED或HALF_OPEN时，才调用链接函数。\n在下面的示例中，如果函数调用成功，则Try.of（\u0026hellip;）返回Success Monad。 如果函数引发异常，则返回Failure Monad，并且不调用map。\n// Given CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults(\u0026#34;testName\u0026#34;); // When I decorate my function CheckedFunction0\u0026lt;String\u0026gt; decoratedSupplier = CircuitBreaker .decorateCheckedSupplier(circuitBreaker, () -\u0026gt; \u0026#34;This can be any method which returns: \u0026#39;Hello\u0026#34;); // and chain an other function with map Try\u0026lt;String\u0026gt; result = Try.of(decoratedSupplier) .map(value -\u0026gt; value + \u0026#34; world\u0026#39;\u0026#34;); // Then the Try Monad returns a Success\u0026lt;String\u0026gt;, if all functions ran successfully. assertThat(result.isSuccess()).isTrue(); assertThat(result.get()).isEqualTo(\u0026#34;This can be any method which returns: \u0026#39;Hello world\u0026#39;\u0026#34;); 您可以在CircuitBreakerRegistry上注册事件使用者，并在每次创建，替换或删除CircuitBreaker时采取措施。\nCircuitBreakerRegistry circuitBreakerRegistry = CircuitBreakerRegistry.ofDefaults(); circuitBreakerRegistry.getEventPublisher() .onEntryAdded(entryAddedEvent -\u0026gt; { CircuitBreaker addedCircuitBreaker = entryAddedEvent.getAddedEntry(); LOG.info(\u0026#34;CircuitBreaker {} added\u0026#34;, addedCircuitBreaker.getName()); }) .onEntryRemoved(entryRemovedEvent -\u0026gt; { CircuitBreaker removedCircuitBreaker = entryRemovedEvent.getRemovedEntry(); LOG.info(\u0026#34;CircuitBreaker {} removed\u0026#34;, removedCircuitBreaker.getName()); }); CircuitBreakerEvent可以是状态转换，断路器重置，成功调用，记录的错误或忽略的错误。 所有事件都包含其他信息，例如事件创建时间和呼叫的处理持续时间。 如果要使用事件，则必须注册事件使用者。\ncircuitBreaker.getEventPublisher() .onSuccess(event -\u0026gt; logger.info(...)) .onError(event -\u0026gt; logger.info(...)) .onIgnoredError(event -\u0026gt; logger.info(...)) .onReset(event -\u0026gt; logger.info(...)) .onStateTransition(event -\u0026gt; logger.info(...)); // Or if you want to register a consumer listening // to all events, you can do: circuitBreaker.getEventPublisher() .onEvent(event -\u0026gt; logger.info(...)); 您可以使用CircularEventConsumer将事件存储在具有固定容量的循环缓冲区中。\nCircularEventConsumer\u0026lt;CircuitBreakerEvent\u0026gt; ringBuffer = new CircularEventConsumer\u0026lt;\u0026gt;(10); circuitBreaker.getEventPublisher().onEvent(ringBuffer); List\u0026lt;CircuitBreakerEvent\u0026gt; bufferedEvents = ringBuffer.getBufferedEvents() 您可以使用RxJava或RxJava2适配器将EventPublisher转换为响应流。\n您可以通过自定义实现覆盖内存RegistryStore。 例如，如果要使用在一定时间后删除未使用实例的缓存。\nCircuitBreakerRegistry circuitBreakerRegistry = CircuitBreakerRegistry.custom() .withRegistryStore(new CacheCircuitBreakerRegistryStore()) .build(); 如果您想在CircuitBreaker将异常记录为失败之后从异常中恢复，则可以链接Try.recover（）方法。 仅当Try.of（）返回Failure Monad时，才调用恢复方法。\n// Given CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults(\u0026#34;testName\u0026#34;); // When I decorate my function and invoke the decorated function CheckedFunction0\u0026lt;String\u0026gt; checkedSupplier = CircuitBreaker.decorateCheckedSupplier(circuitBreaker, () -\u0026gt; { throw new RuntimeException(\u0026#34;BAM!\u0026#34;); }); Try\u0026lt;String\u0026gt; result = Try.of(checkedSupplier) .recover(throwable -\u0026gt; \u0026#34;Hello Recovery\u0026#34;); // Then the function should be a success, // because the exception could be recovered assertThat(result.isSuccess()).isTrue(); // and the result must match the result of the recovery function. assertThat(result.get()).isEqualTo(\u0026#34;Hello Recovery\u0026#34;); 如果要在CircuitBreaker将异常记录为失败之前从异常中恢复，可以执行以下操作：\nSupplier\u0026lt;String\u0026gt; supplier = () -\u0026gt; { throw new RuntimeException(\u0026#34;BAM!\u0026#34;); }; Supplier\u0026lt;String\u0026gt; supplierWithRecovery = SupplierUtils .recover(supplier, (exception) -\u0026gt; \u0026#34;Hello Recovery\u0026#34;); String result = circuitBreaker.executeSupplier(supplierWithRecovery); assertThat(result).isEqualTo(\u0026#34;Hello Recovery\u0026#34;); SupplierUtils和CallableUtils包含其他方法，例如andThen，可以采用这些方法来链接函数。 例如，检查HTTP响应的状态代码，以便可以引发异常。\nSupplier\u0026lt;String\u0026gt; supplierWithResultAndExceptionHandler = SupplierUtils .andThen(supplier, (result, exception) -\u0026gt; \u0026#34;Hello Recovery\u0026#34;); Supplier\u0026lt;HttpResponse\u0026gt; supplier = () -\u0026gt; httpClient.doRemoteCall(); Supplier\u0026lt;HttpResponse\u0026gt; supplierWithResultHandling = SupplierUtils.andThen(supplier, result -\u0026gt; { if (result.getStatusCode() == 400) { throw new ClientException(); } else if (result.getStatusCode() == 500) { throw new ServerException(); } return result; }); HttpResponse httpResponse = circuitBreaker .executeSupplier(supplierWithResultHandling); 断路器支持重置为原始状态，丢失所有指标并有效重置其滑动窗口。\nCircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults(\u0026#34;testName\u0026#34;); circuitBreaker.reset(); 手动转换为状态:\nCircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults(\u0026#34;testName\u0026#34;); circuitBreaker.transitionToDisabledState(); // circuitBreaker.onFailure(...) won\u0026#39;t trigger a state change circuitBreaker.transitionToClosedState(); // will transition to CLOSED state and re-enable normal behaviour, keeping metrics circuitBreaker.transitionToForcedOpenState(); // circuitBreaker.onSuccess(...) won\u0026#39;t trigger a state change circuitBreaker.reset(); // will transition to CLOSED state and re-enable normal behaviour, losing metrics Bulkhead Resilience4j 提供了两种方式实现舱壁模式来隔离线程的执行：\nSemaphoreBulkhead使用信号量 FixedThreadPoolBulkhead 使用有界队列和固定大小的线程池 SemaphoreBulkhead在各种线程和I/O模型上都能很好地工作。 它基于信号量，与Hystrix不同，它不提供“影子”线程池选项。 由客户端来确保正确的线程池大小（与配置一致）。\n跟CircuitBreaker 模块一样，Bulkhead也提供了基于内存的BulkheadRegistry 和ThreadPoolBulkheadRegistry ，你可以使用他们来管理（创建和检索）Bulkhead 实例。\nBulkheadRegistry bulkheadRegistry = BulkheadRegistry.ofDefaults(); ThreadPoolBulkheadRegistry threadPoolBulkheadRegistry = ThreadPoolBulkheadRegistry.ofDefaults(); 你可以自定义全局配置，使用BulkheadConfig 构建，相关的可配置属性如下：\n属性 默认值 描述 maxConcurrentCalls 25 最大的并行执行数 maxWaitDuration 0 尝试进入饱和舱壁时，应阻塞线程的最长时间。 // Create a custom configuration for a Bulkhead BulkheadConfig config = BulkheadConfig.custom() .maxConcurrentCalls(150) .maxWaitDuration(Duration.ofMillis(500)) .build(); // Create a BulkheadRegistry with a custom global configuration BulkheadRegistry registry = BulkheadRegistry.of(config); // Get or create a Bulkhead from the registry - // bulkhead will be backed by the default config Bulkhead bulkheadWithDefaultConfig = registry.bulkhead(\u0026#34;name1\u0026#34;); // Get or create a Bulkhead from the registry, // use a custom configuration when creating the bulkhead Bulkhead bulkheadWithCustomConfig = registry.bulkhead(\u0026#34;name2\u0026#34;, custom); ThreadPoolBulkhead配置的属性有所不同，使用ThreadPoolBulkheadConfig 构建配置项，属性列表如下：\n配置属性 默认值 描述 maxThreadPoolSize Runtime.getRuntime() .availableProcessors() 线程池的最大大小 coreThreadPoolSize Runtime.getRuntime() .availableProcessors() - 1 线程池的核心大小 queueCapacity 100 等待队列的容量 keepAliveDuration 20 [ms] 当线程数大于内核数时，这是多余的空闲线程最大空闲时间 ThreadPoolBulkheadConfig config = ThreadPoolBulkheadConfig.custom() .maxThreadPoolSize(10) .coreThreadPoolSize(2) .queueCapacity(20) .build(); // Create a BulkheadRegistry with a custom global configuration ThreadPoolBulkheadRegistry registry = ThreadPoolBulkheadRegistry.of(config); // Get or create a ThreadPoolBulkhead from the registry - // bulkhead will be backed by the default config ThreadPoolBulkhead bulkheadWithDefaultConfig = registry.bulkhead(\u0026#34;name1\u0026#34;); // Get or create a Bulkhead from the registry, // use a custom configuration when creating the bulkhead ThreadPoolBulkheadConfig custom = BulkheadConfig.custom() .maxThreadPoolSize(5) .build(); ThreadPoolBulkhead bulkheadWithCustomConfig = registry.bulkhead(\u0026#34;name2\u0026#34;, custom); 可以猜到，Bulkhead具有各种类似于CircuitBreaker的高阶装饰器功能。 您可以用隔板装饰任何Callable，Supplier，Runnable，Consumer，CheckedRunnable，CheckedSupplier，CheckedConsumer或CompletionStage。\n// Given Bulkhead bulkhead = Bulkhead.of(\u0026#34;name\u0026#34;, config); // When I decorate my function CheckedFunction0\u0026lt;String\u0026gt; decoratedSupplier = Bulkhead .decorateCheckedSupplier(bulkhead, () -\u0026gt; \u0026#34;This can be any method which returns: \u0026#39;Hello\u0026#34;); // and chain an other function with map Try\u0026lt;String\u0026gt; result = Try.of(decoratedSupplier) .map(value -\u0026gt; value + \u0026#34; world\u0026#39;\u0026#34;); // Then the Try Monad returns a Success\u0026lt;String\u0026gt;, if all functions ran successfully. assertThat(result.isSuccess()).isTrue(); assertThat(result.get()).isEqualTo(\u0026#34;This can be any method which returns: \u0026#39;Hello world\u0026#39;\u0026#34;); assertThat(bulkhead.getMetrics().getAvailableConcurrentCalls()).isEqualTo(1); ThreadPoolBulkheadConfig config = ThreadPoolBulkheadConfig.custom() .maxThreadPoolSize(10) .coreThreadPoolSize(2) .queueCapacity(20) .build(); ThreadPoolBulkhead bulkhead = ThreadPoolBulkhead.of(\u0026#34;name\u0026#34;, config); CompletionStage\u0026lt;String\u0026gt; supplier = ThreadPoolBulkhead .executeSupplier(bulkhead, backendService::doSomething); 您可以在BulkheadRegistry上注册事件使用者，并在创建，替换或删除Bulkhead时执行操作。\nBulkheadRegistry registry = BulkheadRegistry.ofDefaults(); registry.getEventPublisher() .onEntryAdded(entryAddedEvent -\u0026gt; { Bulkhead addedBulkhead = entryAddedEvent.getAddedEntry(); LOG.info(\u0026#34;Bulkhead {} added\u0026#34;, addedBulkhead.getName()); }) .onEntryRemoved(entryRemovedEvent -\u0026gt; { Bulkhead removedBulkhead = entryRemovedEvent.getRemovedEntry(); LOG.info(\u0026#34;Bulkhead {} removed\u0026#34;, removedBulkhead.getName()); }); BulkHead发出BulkHeadEvents流。 发出两种类型的事件：允许执行，拒绝执行和完成执行。 如果要使用这些事件，则必须注册一个事件使用者。\nbulkhead.getEventPublisher() .onCallPermitted(event -\u0026gt; logger.info(...)) .onCallRejected(event -\u0026gt; logger.info(...)) .onCallFinished(event -\u0026gt; logger.info(...)); TimeLimiter 超时器，跟断路器一样，提供了基于内存的TimeLimiterRegistry ，可以使用该实例管理TimeLimiter\nTimeLimiterRegistry timeLimiterRegistry = TimeLimiterRegistry.ofDefaults();\n使用TimeLimiterConfig自定义超时器的配置，可以配置的内容有两种：\n* 超时时间\n* 是否调用cancle\nTimeLimiterConfig config = TimeLimiterConfig.custom()\n.cancelRunningFuture(true)\n.timeoutDuration(Duration.ofMillis(500))\n.build();\n// Create a TimeLimiterRegistry with a custom global configuration\nTimeLimiterRegistry timeLimiterRegistry = TimeLimiterRegistry.of(config);\n// Get or create a TimeLimiter from the registry -\n// TimeLimiter will be backed by the default config\nTimeLimiter timeLimiterWithDefaultConfig = registry.timeLimiter(\u0026ldquo;name1\u0026rdquo;);\n// Get or create a TimeLimiter from the registry,\n// use a custom configuration when creating the TimeLimiter\nTimeLimiterConfig config = TimeLimiterConfig.custom()\n.cancelRunningFuture(false)\n.timeoutDuration(Duration.ofMillis(1000))\n.build();\nTimeLimiter timeLimiterWithCustomConfig = registry.timeLimiter(\u0026ldquo;name2\u0026rdquo;, config);\nTimeLimiter具有较高阶的装饰器函数来装饰CompletionStage或Future，以限制执行时间。\n// Given I have a helloWorldService.sayHelloWorld() method which takes too long\nHelloWorldService helloWorldService = mock(HelloWorldService.class);\n// Create a TimeLimiter\nTimeLimiter timeLimiter = TimeLimiter.of(Duration.ofSeconds(1));\n// The Scheduler is needed to schedule a timeout on a non-blocking CompletableFuture\nScheduledExecutorService scheduler = Executors.newScheduledThreadPool(3);\n// The non-blocking variant with a CompletableFuture\nCompletableFuture result = timeLimiter.executeCompletionStage(\nscheduler, () -\u0026gt; CompletableFuture.supplyAsync(helloWorldService::sayHelloWorld)).toCompletableFuture();\n// The blocking variant which is basically future.get(timeoutDuration, MILLISECONDS)\nString result = timeLimiter.executeFutureSupplier(\n() -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; helloWorldService::sayHelloWorld));\n缓存 以下示例显示如何使用Cache抽象装饰lambda表达式。 缓存抽象将lambda表达式的结果放入缓存实例（JCache）中，并在调用lambda表达式之前尝试从缓存中检索以前的缓存结果。 如果从分布式缓存中检索缓存失败，则会处理该异常并调用lambda表达式。\n// Create a CacheContext by wrapping a JCache instance.\njavax.cache.Cache\u0026lt;String, String\u0026gt; cacheInstance = Caching\n.getCache(\u0026ldquo;cacheName\u0026rdquo;, String.class, String.class);\nCache\u0026lt;String, String\u0026gt; cacheContext = Cache.of(cacheInstance);\n// Decorate your call to BackendService.doSomething()\nCheckedFunction1\u0026lt;String, String\u0026gt; cachedFunction = Decorators\n.ofCheckedSupplier(() -\u0026gt; backendService.doSomething())\n.withCache(cacheContext)\n.decorate();\nString value = Try.of(() -\u0026gt; cachedFunction.apply(\u0026ldquo;cacheKey\u0026rdquo;)).get();\n缓存发出CacheEvents流。 事件可以是高速缓存命中，高速缓存未命中或错误。\ncacheContext.getEventPublisher()\n.onCacheHit(event -\u0026gt; logger.info(\u0026hellip;))\n.onCacheMiss(event -\u0026gt; logger.info(\u0026hellip;))\n.onError(event -\u0026gt; logger.info(\u0026hellip;));\nEhcache 使用实例：\ncompile \u0026lsquo;org.ehcache:ehcache:3.7.1\u0026rsquo;\n// Configure a cache (once)\nthis.cacheManager = Caching.getCachingProvider().getCacheManager();\nthis.cache = Cache.of(cacheManager\n.createCache(\u0026ldquo;booksCache\u0026rdquo;, new MutableConfiguration\u0026lt;\u0026gt;()));\n// Get books using a cache\nList books = Cache.decorateSupplier(cache, library::getBooks)\n.apply(BOOKS_CACHE_KEY);\n不建议在生产环境中使用JCache参考实现，因为它会导致一些并发问题。 使用Ehcache，Caffeine，Redisson，Hazelcast，Ignite或其他JCache实现。\n重试 像断路器一样，提供了基于内存的RetryRegistry ：\nRetryRegistry retryRegistry = RetryRegistry.ofDefaults(); 属性 默认值 描述 maxAttempts 3 最大尝试次数（首次调用也被算作一次） waitDuration 500 [ms] 重试之间的固定等待时间 intervalFunction numOfAttempts -\u0026gt; waitDuration 发生故障后修改等待间隔的功能。 默认情况下，等待时间保持不变。 intervalBiFunction (numOfAttempts, Either\u0026lt;throwable, result) -\u0026gt; waitDuration 根据尝试次数和结果或异常修改失败后的等待间隔的功能。 与intervalFunction一起使用时，将抛出IllegalStateException。 retryOnResultPredicate result -\u0026gt; false 配置一个谓词，该谓词评估是否应重试结果。 如果要重试结果，则谓词必须返回true，否则必须返回false。 retryOnExceptionPredicate throwable -\u0026gt; true 配置一个谓词，该谓词评估是否应重试异常。 如果应重试异常，则谓词必须返回true，否则必须返回false。 retryExceptions empty 配置Throwable类的列表，这些类被记录为失败并因此被重试。 此参数支持子类型。 注意：如果使用的是Checked Exception，则必须使用CheckedSupplier ignoreExceptions empty 配置被忽略因而不会重试的Throwable类的列表。 此参数支持子类型。 failAfterMaxRetries false 当重试已达到配置的maxAttempts且结果仍未通过retryOnResultPredicate时，启用或禁用抛出MaxRetriesExceededException的布尔值 RetryConfig config = RetryConfig.custom() .maxAttempts(2) .waitDuration(Duration.ofMillis(1000)) .retryOnResult(response -\u0026gt; response.getStatus() == 500) .retryOnException(e -\u0026gt; e instanceof WebServiceException) .retryExceptions(IOException.class, TimeoutException.class) .ignoreExceptions(BusinessException.class, OtherBusinessException.class) .failAfterMaxAttempts(true) .build(); // Create a RetryRegistry with a custom global configuration RetryRegistry registry = RetryRegistry.of(config); // Get or create a Retry from the registry - // Retry will be backed by the default config Retry retryWithDefaultConfig = registry.retry(\u0026#34;name1\u0026#34;); // Get or create a Retry from the registry, // use a custom configuration when creating the retry RetryConfig custom = RetryConfig.custom() .waitDuration(Duration.ofMillis(100)) .build(); Retry retryWithCustomConfig = registry.retry(\u0026#34;name2\u0026#34;, custom); 可以猜到，重试具有各种高级装饰器功能，就像CircuitBreaker一样。 您可以使用重试装饰任何Callable，Supplier，Runnable，Consumer，CheckedRunnable，CheckedSupplier，CheckedConsumer或CompletionStage。\n// Given I have a HelloWorldService which throws an exception HelloWorldService helloWorldService = mock(HelloWorldService.class); given(helloWorldService.sayHelloWorld()) .willThrow(new WebServiceException(\u0026#34;BAM!\u0026#34;)); // Create a Retry with default configuration Retry retry = Retry.ofDefaults(\u0026#34;id\u0026#34;); // Decorate the invocation of the HelloWorldService CheckedFunction0\u0026lt;String\u0026gt; retryableSupplier = Retry .decorateCheckedSupplier(retry, helloWorldService::sayHelloWorld); // When I invoke the function Try\u0026lt;String\u0026gt; result = Try.of(retryableSupplier) .recover((throwable) -\u0026gt; \u0026#34;Hello world from recovery function\u0026#34;); // Then the helloWorldService should be invoked 3 times BDDMockito.then(helloWorldService).should(times(3)).sayHelloWorld(); // and the exception should be handled by the recovery function assertThat(result.get()).isEqualTo(\u0026#34;Hello world from recovery function\u0026#34;); 您可以在RetryRegistry上注册事件使用者，并在创建，替换或删除重试时执行操作。\nRetryRegistry registry = RetryRegistry.ofDefaults(); registry.getEventPublisher() .onEntryAdded(entryAddedEvent -\u0026gt; { Retry addedRetry = entryAddedEvent.getAddedEntry(); LOG.info(\u0026#34;Retry {} added\u0026#34;, addedRetry.getName()); }) .onEntryRemoved(entryRemovedEvent -\u0026gt; { Retry removedRetry = entryRemovedEvent.getRemovedEntry(); LOG.info(\u0026#34;Retry {} removed\u0026#34;, removedRetry.getName()); }); 如果不想在重试尝试之间使用固定的等待时间，则可以配置一个IntervalFunction，该函数用于计算每次尝试的等待时间。 Resilience4j提供了几种工厂方法来简化IntervalFunction的创建。\nIntervalFunction defaultWaitInterval = IntervalFunction .ofDefaults(); // This interval function is used internally // when you only configure waitDuration IntervalFunction fixedWaitInterval = IntervalFunction .of(Duration.ofSeconds(5)); IntervalFunction intervalWithExponentialBackoff = IntervalFunction .ofExponentialBackoff(); IntervalFunction intervalWithCustomExponentialBackoff = IntervalFunction .ofExponentialBackoff(IntervalFunction.DEFAULT_INITIAL_INTERVAL, 2d); IntervalFunction randomWaitInterval = IntervalFunction .ofRandomized(); // Overwrite the default intervalFunction with your custom one RetryConfig retryConfig = RetryConfig.custom() .intervalFunction(intervalWithExponentialBackoff) .build(); RateLimiter 速率限制是一项必不可少的技术，它可以为扩展您的API做好准备并建立服务的高可用性和可靠性。 而且，此技术还提供了很多不同的选择，例如如何处理检测到的限制超额，或您要限制哪种类型的请求。 您可以简单地拒绝此超限请求，或建立队列以稍后执行它们，或以某种方式组合这两种方法。\nResilience4j提供了一个RateLimiter，它将从纪元开始将所有纳秒级分为多个周期。 每个周期都有一个由RateLimiterConfig.limitRefreshPeriod配置的持续时间。 在每个周期的开始，RateLimiter会将活动许可的数量设置为RateLimiterConfig.limitForPeriod。\nRateLimiter的默认实现是AtomicRateLimiter，它通过AtomicReference管理其状态。 AtomicRateLimiter.State是完全不可变的，并且具有以下字段：\n* activeCycle : 上次调用使用的cycle号\n* activePermissions :上次call后的可用权限计数。如果保留某些权限，则可以为负\n* nanosToWait :等待上一次call的等待时间（以纳秒为单位）\n还有一个使用信号量的SemaphoreBasedRateLimiter和一个计划程序，该计划程序将在每个RateLimiterConfig＃limitRefreshPeriod之后刷新权限。\n创建默认的速率器：\nRateLimiterRegistry rateLimiterRegistry = RateLimiterRegistry.ofDefaults(); RateLimiterConfig配置速率器：\n属性 默认值 描述 timeoutDuration 5 [s] 线程等待权限的默认等待时间 limitRefreshPeriod 500 [ns] 限制刷新的时间段。 在每个时间段之后，速率限制器将其权限计数重新设置为limitForPeriod值 limitForPeriod 50 一个限制刷新期间可用的权限数 RateLimiterConfig config = RateLimiterConfig.custom() .limitRefreshPeriod(Duration.ofMillis(1)) .limitForPeriod(10) .timeoutDuration(Duration.ofMillis(25)) .build(); // Create registry RateLimiterRegistry rateLimiterRegistry = RateLimiterRegistry.of(config); // Use registry RateLimiter rateLimiterWithDefaultConfig = rateLimiterRegistry .rateLimiter(\u0026#34;name1\u0026#34;); RateLimiter rateLimiterWithCustomConfig = rateLimiterRegistry .rateLimiter(\u0026#34;name2\u0026#34;, config); 如您所料，RateLimiter具有各种类似于CircuitBreaker的高阶装饰器功能。 您可以使用RateLimiter装饰任何Callable，Supplier，Runnable，Consumer，CheckedRunnable，CheckedSupplier，CheckedConsumer或CompletionStage。\n// Decorate your call to BackendService.doSomething() CheckedRunnable restrictedCall = RateLimiter .decorateCheckedRunnable(rateLimiter, backendService::doSomething); Try.run(restrictedCall) .andThenTry(restrictedCall) .onFailure((RequestNotPermitted throwable) -\u0026gt; LOG.info(\u0026#34;Wait before call it again :)\u0026#34;)); 您可以使用changeTimeoutDuration和changeLimitForPeriod方法在运行时更改速率限制器参数。\n新的超时时间不会影响当前正在等待许可的线程。\n新的限制不会影响当前期限的权限，并且仅从下一个限制开始适用。\n// Decorate your call to BackendService.doSomething() CheckedRunnable restrictedCall = RateLimiter .decorateCheckedRunnable(rateLimiter, backendService::doSomething); // during second refresh cycle limiter will get 100 permissions rateLimiter.changeLimitForPeriod(100); 您可以在RateLimiterRegistry上注册事件使用者，并在创建，替换或删除RateLimiter时执行操作。\nRateLimiterRegistry registry = RateLimiterRegistry.ofDefaults(); registry.getEventPublisher() .onEntryAdded(entryAddedEvent -\u0026gt; { RateLimiter addedRateLimiter = entryAddedEvent.getAddedEntry(); LOG.info(\u0026#34;RateLimiter {} added\u0026#34;, addedRateLimiter.getName()); }) .onEntryRemoved(entryRemovedEvent -\u0026gt; { RateLimiter removedRateLimiter = entryRemovedEvent.getRemovedEntry(); LOG.info(\u0026#34;RateLimiter {} removed\u0026#34;, removedRateLimiter.getName()); }); RateLimiter发出RateLimiterEvents流。 事件可以是成功的许可获取或获取失败。\n所有事件都包含其他信息，例如事件创建时间和速率限制器名称。\n如果要使用事件，则必须注册事件使用者。\nrateLimiter.getEventPublisher() .onSuccess(event -\u0026gt; logger.info(...)) .onFailure(event -\u0026gt; logger.info(...)); 您可以通过自定义实现覆盖内存RegistryStore。 例如，如果要使用在一定时间后删除未使用实例的缓存。\nRateLimiterRegistry rateLimiterRegistry = RateLimiterRegistry.custom() .withRegistryStore(new CacheRateLimiterRegistryStore()) .build(); 和spring boot结合 依赖 repositories { jCenter() } dependencies { compile \u0026#34;io.github.resilience4j:resilience4j-spring-boot2:${resilience4jVersion}\u0026#34; compile(\u0026#39;org.springframework.boot:spring-boot-starter-actuator\u0026#39;) compile(\u0026#39;org.springframework.boot:spring-boot-starter-aop\u0026#39;) } 相关配置 resilience4j.circuitbreaker: instances: backendA: registerHealthIndicator: true slidingWindowSize: 100 backendB: registerHealthIndicator: true slidingWindowSize: 10 permittedNumberOfCallsInHalfOpenState: 3 slidingWindowType: TIME_BASED minimumNumberOfCalls: 20 waitDurationInOpenState: 50s failureRateThreshold: 50 eventConsumerBufferSize: 10 recordFailurePredicate: io.github.robwin.exception.RecordFailurePredicate resilience4j.retry: instances: backendA: maxAttempts: 3 waitDuration: 10s enableExponentialBackoff: true exponentialBackoffMultiplier: 2 retryExceptions: - org.springframework.web.client.HttpServerErrorException - java.io.IOException ignoreExceptions: - io.github.robwin.exception.BusinessException backendB: maxAttempts: 3 waitDuration: 10s retryExceptions: - org.springframework.web.client.HttpServerErrorException - java.io.IOException ignoreExceptions: - io.github.robwin.exception.BusinessException resilience4j.bulkhead: instances: backendA: maxConcurrentCalls: 10 backendB: maxWaitDuration: 10ms maxConcurrentCalls: 20 resilience4j.thread-pool-bulkhead: instances: backendC: maxThreadPoolSize: 1 coreThreadPoolSize: 1 queueCapacity: 1 resilience4j.ratelimiter: instances: backendA: limitForPeriod: 10 limitRefreshPeriod: 1s timeoutDuration: 0 registerHealthIndicator: true eventConsumerBufferSize: 100 backendB: limitForPeriod: 6 limitRefreshPeriod: 500ms timeoutDuration: 3s resilience4j.timelimiter: instances: backendA: timeoutDuration: 2s cancelRunningFuture: true backendB: timeoutDuration: 1s cancelRunningFuture: false 你可以覆盖默认配置、定义共享配置：\nresilience4j.circuitbreaker: configs: default: slidingWindowSize: 100 permittedNumberOfCallsInHalfOpenState: 10 waitDurationInOpenState: 10000 failureRateThreshold: 60 eventConsumerBufferSize: 10 registerHealthIndicator: true someShared: slidingWindowSize: 50 permittedNumberOfCallsInHalfOpenState: 10 instances: backendA: baseConfig: default waitDurationInOpenState: 5000 backendB: baseConfig: someShared 你还可以通过代码覆盖yaml中的配置：\n@Bean public CircuitBreakerConfigCustomizer testCustomizer() { return CircuitBreakerConfigCustomizer .of(\u0026#34;backendA\u0026#34;, builder -\u0026gt; builder.slidingWindowSize(100)); } Resilience4j 提供了自定义配置的类：\nResilienc4j Type Instance Customizer class Circuit breaker CircuitBreakerConfigCustomizer Retry RetryConfigCustomizer Rate limiter RateLimiterConfigCustomizer Bulkhead BulkheadConfigCustomizer ThreadPoolBulkhead ThreadPoolBulkheadConfigCustomizer Time Limiter TimeLimiterConfigCustomizer 注解 spring boot提供了注解支持，这些注解标注的方法的返回值可以是异步或同步的\nBulkhead注解的type属性可以指定采用何种类型的隔离器，默认是semaphore ：\n@Bulkhead(name = BACKEND, type = Bulkhead.Type.THREADPOOL) public CompletableFuture\u0026lt;String\u0026gt; doSomethingAsync() throws InterruptedException { Thread.sleep(500); return CompletableFuture.completedFuture(\u0026#34;Test\u0026#34;); } @CircuitBreaker(name = BACKEND, fallbackMethod = \u0026#34;fallback\u0026#34;) @RateLimiter(name = BACKEND) @Bulkhead(name = BACKEND) @Retry(name = BACKEND, fallbackMethod = \u0026#34;fallback\u0026#34;) @TimeLimiter(name = BACKEND) public Mono\u0026lt;String\u0026gt; method(String param1) { return Mono.error(new NumberFormatException()); } private Mono\u0026lt;String\u0026gt; fallback(String param1, IllegalArgumentException e) { return Mono.just(\u0026#34;test\u0026#34;); } private Mono\u0026lt;String\u0026gt; fallback(String param1, RuntimeException e) { return Mono.just(\u0026#34;test\u0026#34;); } 需要注意的是，fallback必须放在同个类中，并且有相同的方法签名并追加一个异常参数。\n如果有多个fallback方法，则最近的方法会执行，例如上面的方法抛出 NumberFormatException，IllegalArgumentException方法会执行。\n仅当多个方法具有相同的返回类型，并且您要一劳永逸地为它们定义相同的后备方法时，才可以使用异常参数定义一个全局后备方法。\n注解的顺序 Retry ( CircuitBreaker ( RateLimiter ( TimeLimiter ( Bulkhead ( Function ) ) ) ) ) 如果需要其他顺序，则必须使用功能链样式而不是Spring批注样式，或使用以下属性来显式设置外观顺序：\n- resilience4j.retry.retryAspectOrder - resilience4j.circuitbreaker.circuitBreakerAspectOrder - resilience4j.ratelimiter.rateLimiterAspectOrder - resilience4j.timelimiter.timeLimiterAspectOrder 例如，让短路器在重试器后执行，你必须设置retryAspectOrder 的值大于circuitBreakerAspectOrder ：\nresilience4j: circuitbreaker: circuitBreakerAspectOrder: 1 retry: retryAspectOrder: 2 指标端点 /actuator/metrics { \u0026#34;names\u0026#34;: [ \u0026#34;resilience4j.circuitbreaker.calls\u0026#34;, \u0026#34;resilience4j.circuitbreaker.buffered.calls\u0026#34;, \u0026#34;resilience4j.circuitbreaker.state\u0026#34;, \u0026#34;resilience4j.circuitbreaker.failure.rate\u0026#34; ] } 获取具体的指标信息，GET /actuator/metrics/{metric.name},例如：/actuator/metrics/resilience4j.circuitbreaker.calls：\n{ \u0026#34;name\u0026#34;: \u0026#34;resilience4j.circuitbreaker.calls\u0026#34;, \u0026#34;measurements\u0026#34;: [ { \u0026#34;statistic\u0026#34;: \u0026#34;VALUE\u0026#34;, \u0026#34;value\u0026#34;: 3 } ], \u0026#34;availableTags\u0026#34;: [ { \u0026#34;tag\u0026#34;: \u0026#34;kind\u0026#34;, \u0026#34;values\u0026#34;: [ \u0026#34;not_permitted\u0026#34;, \u0026#34;successful\u0026#34;, \u0026#34;failed\u0026#34; ] }, { \u0026#34;tag\u0026#34;: \u0026#34;name\u0026#34;, \u0026#34;values\u0026#34;: [ \u0026#34;backendB\u0026#34;, \u0026#34;backendA\u0026#34; ] } ] } 如果想要使用 prometheus，需要添加依赖 io.micrometer:micrometer-registry-prometheus，端点是/actuator/prometheus\nhealth 端点 默认，CircuitBreaker 和 RateLimiter 的health端点是禁用的。当CircuitBreaker打开时，由于应用程序状态为DOWN，因此会禁用运行状况指示器。 这可能不是您想要实现的。\nmanagement.health.circuitbreakers.enabled: true management.health.ratelimiters.enabled: true resilience4j.circuitbreaker: configs: default: registerHealthIndicator: true resilience4j.ratelimiter: configs: default: registerHealthIndicator: true 闭合的CircuitBreaker状态映射为UP，打开状态映射为DOWN，半打开状态映射为UNKNOWN。\n{ \u0026#34;status\u0026#34;: \u0026#34;UP\u0026#34;, \u0026#34;details\u0026#34;: { \u0026#34;circuitBreakers\u0026#34;: { \u0026#34;status\u0026#34;: \u0026#34;UP\u0026#34;, \u0026#34;details\u0026#34;: { \u0026#34;backendB\u0026#34;: { \u0026#34;status\u0026#34;: \u0026#34;UP\u0026#34;, \u0026#34;details\u0026#34;: { \u0026#34;failureRate\u0026#34;: \u0026#34;-1.0%\u0026#34;, \u0026#34;failureRateThreshold\u0026#34;: \u0026#34;50.0%\u0026#34;, \u0026#34;slowCallRate\u0026#34;: \u0026#34;-1.0%\u0026#34;, \u0026#34;slowCallRateThreshold\u0026#34;: \u0026#34;100.0%\u0026#34;, \u0026#34;bufferedCalls\u0026#34;: 0, \u0026#34;slowCalls\u0026#34;: 0, \u0026#34;slowFailedCalls\u0026#34;: 0, \u0026#34;failedCalls\u0026#34;: 0, \u0026#34;notPermittedCalls\u0026#34;: 0, \u0026#34;state\u0026#34;: \u0026#34;CLOSED\u0026#34; } }, \u0026#34;backendA\u0026#34;: { \u0026#34;status\u0026#34;: \u0026#34;UP\u0026#34;, \u0026#34;details\u0026#34;: { \u0026#34;failureRate\u0026#34;: \u0026#34;-1.0%\u0026#34;, \u0026#34;failureRateThreshold\u0026#34;: \u0026#34;50.0%\u0026#34;, \u0026#34;slowCallRate\u0026#34;: \u0026#34;-1.0%\u0026#34;, \u0026#34;slowCallRateThreshold\u0026#34;: \u0026#34;100.0%\u0026#34;, \u0026#34;bufferedCalls\u0026#34;: 0, \u0026#34;slowCalls\u0026#34;: 0, \u0026#34;slowFailedCalls\u0026#34;: 0, \u0026#34;failedCalls\u0026#34;: 0, \u0026#34;notPermittedCalls\u0026#34;: 0, \u0026#34;state\u0026#34;: \u0026#34;CLOSED\u0026#34; } } } } } } events端点 发出的CircuitBreaker，Retry，RateLimiter，Bulkhead和TimeLimiter事件存储在单独的循环事件消费者缓冲区中。 可以在application.yml文件（eventConsumerBufferSize）中配置事件消费者缓冲区的大小。\n端点 /ctuator/circuitbreakers 列出了所有CircuitBreaker实例的名称。 该端点也可用于Retry，RateLimiter，Bulkhead和TimeLimiter。\n{ \u0026#34;circuitBreakers\u0026#34;: [ \u0026#34;backendA\u0026#34;, \u0026#34;backendB\u0026#34; ] } 端点/ actuator / circuitbreakerevents默认情况下列出所有CircuitBreaker实例的最近100个发出的事件。 该端点也可用于Retry，RateLimiter，Bulkhead和TimeLimiter。\n{ \u0026#34;circuitBreakerEvents\u0026#34;: [ { \u0026#34;circuitBreakerName\u0026#34;: \u0026#34;backendA\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;ERROR\u0026#34;, \u0026#34;creationTime\u0026#34;: \u0026#34;2017-01-10T15:39:17.117+01:00[Europe/Berlin]\u0026#34;, \u0026#34;errorMessage\u0026#34;: \u0026#34;org.springframework.web.client.HttpServerErrorException: 500 This is a remote exception\u0026#34;, \u0026#34;durationInMs\u0026#34;: 0 }, { \u0026#34;circuitBreakerName\u0026#34;: \u0026#34;backendA\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SUCCESS\u0026#34;, \u0026#34;creationTime\u0026#34;: \u0026#34;2017-01-10T15:39:20.518+01:00[Europe/Berlin]\u0026#34;, \u0026#34;durationInMs\u0026#34;: 0 }, { \u0026#34;circuitBreakerName\u0026#34;: \u0026#34;backendB\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;ERROR\u0026#34;, \u0026#34;creationTime\u0026#34;: \u0026#34;2017-01-10T15:41:31.159+01:00[Europe/Berlin]\u0026#34;, \u0026#34;errorMessage\u0026#34;: \u0026#34;org.springframework.web.client.HttpServerErrorException: 500 This is a remote exception\u0026#34;, \u0026#34;durationInMs\u0026#34;: 0 }, { \u0026#34;circuitBreakerName\u0026#34;: \u0026#34;backendB\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SUCCESS\u0026#34;, \u0026#34;creationTime\u0026#34;: \u0026#34;2017-01-10T15:41:33.526+01:00[Europe/Berlin]\u0026#34;, \u0026#34;durationInMs\u0026#34;: 0 } ] } spring cloud 结合 将Spring Cloud 2 Starter of Resilience4j添加到您的编译依赖项中。\nSpring Cloud 2 Starter允许您将Spring Cloud Config用作在运行时管理和刷新属性。\nrepositories { jCenter() } dependencies { compile \u0026#34;io.github.resilience4j:resilience4j-spring-cloud2:${resilience4jVersion}\u0026#34; compile(\u0026#39;org.springframework.boot:spring-boot-starter-actuator\u0026#39;) compile(\u0026#39;org.springframework.boot:spring-boot-starter-aop\u0026#39;) compile(\u0026#39;org.springframework.cloud:spring-cloud-starter-config\u0026#39;) } 和feign结合 当前仅支持断路器、限流器和fallback.\n装扮接口 Resilience4jFeign.builder是用于创建feign的容错实例的主要类。\n它扩展了Feign.builder，添加自定义InvocationHandlerFactory。 Resilience4jFeign使用其自己的InvocationHandlerFactory来应用装饰器。 可以使用FeignDecorators类来构建装饰器。 可以组合多个装饰器。\n以下示例显示如何使用RateLimiter和CircuitBreaker装饰feign接口：\npublic interface MyService { @RequestLine(\u0026#34;GET /greeting\u0026#34;) String getGreeting(); @RequestLine(\u0026#34;POST /greeting\u0026#34;) String createGreeting(); } CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults(\u0026#34;backendName\u0026#34;); RateLimiter rateLimiter = RateLimiter.ofDefaults(\u0026#34;backendName\u0026#34;); FeignDecorators decorators = FeignDecorators.builder() .withRateLimiter(rateLimiter) .withCircuitBreaker(circuitBreaker) .build(); MyService myService = Resilience4jFeign.builder(decorators).target(MyService.class, \u0026#34;http://localhost:8080/\u0026#34;); 调用MyService实例的任何方法将先调用CircuitBreaker，然后再调用RateLimiter。\n如果这些机制之一生效，则将引发相应的RuntimeException，例如CircuitBreakerOpenException或RequestNotPermitted（提示：这些不会扩展FeignException类）。 装扮器的顺序 装饰器的应用顺序与声明它们的顺序相对应。\n在构建FeignDecorators时，请注意这一点，因为顺序会影响最终的行为，这一点很重要。\nFeignDecorators decoratorsA = FeignDecorators.builder() .withCircuitBreaker(circuitBreaker) .withRateLimiter(rateLimiter) .build(); FeignDecorators decoratorsB = FeignDecorators.builder() .withRateLimiter(rateLimiter) .withCircuitBreaker(circuitBreaker) .build(); 使用decoratorsA时，将在CircuitBreaker之前调用RateLimiter。 这意味着即使CircuitBreaker打开，RateLimiter仍将限制呼叫速率。 decoratorsB应用相反的顺序。 这意味着一旦CircuitBreaker打开，RateLimiter将不再起作用。\nFallback 可以定义在抛出异常时调用的fallback。 当HTTP请求失败时，也可能在FeignDecorators中的一个激活时，例如CircuitBreaker，就会发生异常。\npublic interface MyService { @RequestLine(\u0026#34;GET /greeting\u0026#34;) String greeting(); } MyService requestFailedFallback = () -\u0026gt; \u0026#34;fallback greeting\u0026#34;; MyService circuitBreakerFallback = () -\u0026gt; \u0026#34;CircuitBreaker is open!\u0026#34;; CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults(\u0026#34;backendName\u0026#34;); FeignDecorators decorators = FeignDecorators.builder() .withFallback(requestFailedFallback, FeignException.class) .withFallback(circuitBreakerFallback, CircuitBreakerOpenException.class) .build(); MyService myService = Resilience4jFeign.builder(decorators).target(MyService.class, \u0026#34;http://localhost:8080/\u0026#34;, fallback); 在此示例中，当抛出FeignException时（通常在HTTP请求失败时）将调用requestFailedFallback，而仅在CircuitBreakerOpenException情况下才调用circuitBreakerFallback。 检查FeignDecorators类，以了解更多过滤后备的方法。\n所有回退必须实现在“目标”（Resilience4jFeign.Builder＃target）方法中声明的相同接口，否则将抛出IllegalArgumentException。\n可以分配多个回退来处理相同的Exception，并在前一个失败时调用下一个回退。\n如果需要，回退可以消耗抛出的Exception。 如果回退取决于异常可能具有不同的行为，或者仅记录异常，这将很有用。\n请注意，将为抛出的每个异常实例化这种回退。\npublic interface MyService { @RequestLine(\u0026#34;GET /greeting\u0026#34;) String greeting(); } public class MyFallback implements MyService { private Exception cause; public MyFallback(Exception cause) { this.cause = cause; } public String greeting() { if (cause instanceOf FeignException) { return \u0026#34;Feign Exception\u0026#34;; } else { return \u0026#34;Other exception\u0026#34;; } } } FeignDecorators decorators = FeignDecorators.builder() .withFallbackFactory(MyFallback::new) .build(); ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/resilience4j/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985672,"title":"Resilience4j"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"Spring Cloud Circuit breaker 提供了跨不同断路器实现的抽象。 它提供了在您的应用程序中使用的一致 API，让您（开发人员）可以选择最适合您的应用程序需求的断路器实现。\n可用的实现如下：\nResilience4J Sentinel Spring Retry 快速入门 在API中使用CircuitBreakerFactory 类创建CircuitBreaker断路器。当你添加实现了断路器的依赖时，会自动创建CircuitBreakerFactory bean，下面代码是使用例子：\n@Service public static class DemoControllerService { private RestTemplate rest; private CircuitBreakerFactory cbFactory; public DemoControllerService(RestTemplate rest, CircuitBreakerFactory cbFactory) { this.rest = rest; this.cbFactory = cbFactory; } public String slow() { return cbFactory.create(\u0026#34;slow\u0026#34;).run( //断路器的名称 () -\u0026gt; rest.getForObject(\u0026#34;/slow\u0026#34;, String.class), //业务方法 throwable -\u0026gt; \u0026#34;fallback\u0026#34; //后备方法 ); } } 如果reactor在你的classpath下，你可以使用ReactiveCircuitBreakerFactory 来处理响应式代码：\n@Service public static class DemoControllerService { private ReactiveCircuitBreakerFactory cbFactory; private WebClient webClient; public DemoControllerService(WebClient webClient, ReactiveCircuitBreakerFactory cbFactory) { this.webClient = webClient; this.cbFactory = cbFactory; } public Mono\u0026lt;String\u0026gt; slow() { return webClient.get().uri(\u0026#34;/slow\u0026#34;).retrieve().bodyToMono(String.class).transform( it -\u0026gt; cbFactory.create(\u0026#34;slow\u0026#34;).run(it, throwable -\u0026gt; return Mono.just(\u0026#34;fallback\u0026#34;))); } } ReactiveCircuitBreakerFactory.create 创建 ReactiveCircuitBreaker ，run方法接受 Mono或Flux类型的参数。\n自定义断路器 要为所有断路器提供默认配置，请创建一个自定义 bean，该 bean 传递 Resilience4JCircuitBreakerFactory 或 ReactiveResilience4JCircuitBreakerFactory。 configureDefault 方法可用于提供默认配置:\n@Bean public Customizer\u0026lt;Resilience4JCircuitBreakerFactory\u0026gt; defaultCustomizer() { return factory -\u0026gt; factory.configureDefault(id -\u0026gt; new Resilience4JConfigBuilder(id) .timeLimiterConfig(TimeLimiterConfig.custom().timeoutDuration(Duration.ofSeconds(4)).build()) .circuitBreakerConfig(CircuitBreakerConfig.ofDefaults()) .build()); } @Bean public Customizer\u0026lt;ReactiveResilience4JCircuitBreakerFactory\u0026gt; defaultCustomizer() { return factory -\u0026gt; factory.configureDefault(id -\u0026gt; new Resilience4JConfigBuilder(id) .circuitBreakerConfig(CircuitBreakerConfig.ofDefaults()) .timeLimiterConfig(TimeLimiterConfig.custom().timeoutDuration(Duration.ofSeconds(4)).build()).build()); } 与提供默认配置类似，您可以创建一个自定义 bean，它通过 Resilience4JCircuitBreakerFactory 或 ReactiveResilience4JCircuitBreakerFactory 传递。\n@Bean public Customizer\u0026lt;Resilience4JCircuitBreakerFactory\u0026gt; slowCustomizer() { return factory -\u0026gt; factory.configure(builder -\u0026gt; builder.circuitBreakerConfig(CircuitBreakerConfig.ofDefaults()) .timeLimiterConfig(TimeLimiterConfig.custom().timeoutDuration(Duration.ofSeconds(2)).build()), \u0026#34;slow\u0026#34;); } 除了配置创建的断路器之外，您还可以在断路器创建之后但在返回给调用者之前自定义断路器。 为此，您可以使用 addCircuitBreakerCustomizer 方法。 这对于将事件处理程序添加到 Resilience4J 断路器非常有用。\n@Bean public Customizer\u0026lt;Resilience4JCircuitBreakerFactory\u0026gt; slowCustomizer() { return factory -\u0026gt; factory.addCircuitBreakerCustomizer(circuitBreaker -\u0026gt; circuitBreaker.getEventPublisher() .onError(normalFluxErrorConsumer).onSuccess(normalFluxSuccessConsumer), \u0026#34;normalflux\u0026#34;); } @Bean public Customizer\u0026lt;ReactiveResilience4JCircuitBreakerFactory\u0026gt; slowCustomizer() { return factory -\u0026gt; { factory.configure(builder -\u0026gt; builder .timeLimiterConfig(TimeLimiterConfig.custom().timeoutDuration(Duration.ofSeconds(2)).build()) .circuitBreakerConfig(CircuitBreakerConfig.ofDefaults()), \u0026#34;slow\u0026#34;, \u0026#34;slowflux\u0026#34;); factory.addCircuitBreakerCustomizer(circuitBreaker -\u0026gt; circuitBreaker.getEventPublisher() .onError(normalFluxErrorConsumer).onSuccess(normalFluxSuccessConsumer), \u0026#34;normalflux\u0026#34;); }; } 每次调用 CircuitBreaker#run 时，某些 CircuitBreaker 实现（例如 Resilience4JCircuitBreaker）都会调用customize 方法。 它可能效率低下。 在这种情况下，您可以使用 CircuitBreaker#once 方法。\n下面的例子展示了每个 io.github.resilience4j.circuitbreaker.CircuitBreaker 消费事件的方式。\nCustomizer.once(circuitBreaker -\u0026gt; { circuitBreaker.getEventPublisher() .onStateTransition(event -\u0026gt; log.info(\u0026#34;{}: {}\u0026#34;, event.getCircuitBreakerName(), event.getStateTransition())); }, CircuitBreaker::getName) 您可以在应用程序的配置属性文件中配置 CircuitBreaker 和 TimeLimiter 实例。 属性配置比 Java 定制器配置具有更高的优先级。\nresilience4j.circuitbreaker: instances: backendA: registerHealthIndicator: true slidingWindowSize: 100 backendB: registerHealthIndicator: true slidingWindowSize: 10 permittedNumberOfCallsInHalfOpenState: 3 slidingWindowType: TIME_BASED recordFailurePredicate: io.github.robwin.exception.RecordFailurePredicate resilience4j.timelimiter: instances: backendA: timeoutDuration: 2s cancelRunningFuture: true backendB: timeoutDuration: 1s cancelRunningFuture: false 如果resilience4j-bulkhead 在类路径上，Spring Cloud CircuitBreaker 将使用Resilience4j Bulkhead 包装所有方法。 您可以通过将 spring.cloud.circuitbreaker.bulkhead.resilience4j.enabled 设置为 false 来禁用 Resilience4j Bulkhead。\nSpring Cloud CircuitBreaker Resilience4j 提供了两种舱壁模式的实现：\n使用信号量的 SemaphoreBulkhead 使用有界队列和固定线程池的 FixedThreadPoolBulkhead。 默认情况下，Spring Cloud CircuitBreaker Resilience4j 使用 FixedThreadPoolBulkhead。\nCustomizer 可用于提供默认的 Bulkhead 和 ThreadPoolBulkhead 配置。\n@Bean public Customizer\u0026lt;Resilience4jBulkheadProvider\u0026gt; defaultBulkheadCustomizer() { return provider -\u0026gt; provider.configureDefault(id -\u0026gt; new Resilience4jBulkheadConfigurationBuilder() .bulkheadConfig(BulkheadConfig.custom().maxConcurrentCalls(4).build()) .threadPoolBulkheadConfig(ThreadPoolBulkheadConfig.custom().coreThreadPoolSize(1).maxThreadPoolSize(1).build()) .build() ); } 与默认的“Bulkhead”或“ThreadPoolBulkhead”配置类似，您可以创建一个自定义 bean，该 bean 传递给 Resilience4jBulkheadProvider。\n@Bean public Customizer\u0026lt;Resilience4jBulkheadProvider\u0026gt; slowBulkheadProviderCustomizer() { return provider -\u0026gt; provider.configure(builder -\u0026gt; builder .bulkheadConfig(BulkheadConfig.custom().maxConcurrentCalls(1).build()) .threadPoolBulkheadConfig(ThreadPoolBulkheadConfig.ofDefaults()), \u0026#34;slowBulkhead\u0026#34;); } 除了配置创建的 Bulkhead 之外，您还可以在它们被创建之后但在返回给调用者之前自定义它们。 为此，您可以使用 addBulkheadCustomizer 和 addThreadPoolBulkheadCustomizer 方法。\n@Bean public Customizer\u0026lt;Resilience4jBulkheadProvider\u0026gt; customizer() { return provider -\u0026gt; provider.addBulkheadCustomizer(bulkhead -\u0026gt; bulkhead.getEventPublisher() .onCallRejected(slowRejectedConsumer) .onCallFinished(slowFinishedConsumer), \u0026#34;slowBulkhead\u0026#34;); } @Bean public Customizer\u0026lt;Resilience4jBulkheadProvider\u0026gt; slowThreadPoolBulkheadCustomizer() { return provider -\u0026gt; provider.addThreadPoolBulkheadCustomizer(threadPoolBulkhead -\u0026gt; threadPoolBulkhead.getEventPublisher() .onCallRejected(slowThreadPoolRejectedConsumer) .onCallFinished(slowThreadPoolFinishedConsumer), \u0026#34;slowThreadPoolBulkhead\u0026#34;); } 您可以在应用程序的配置属性文件中配置 ThreadPoolBulkhead 和 SemaphoreBulkhead 实例。 属性配置比 Java 定制器配置具有更高的优先级。\nresilience4j.thread-pool-bulkhead: instances: backendA: maxThreadPoolSize: 1 coreThreadPoolSize: 1 resilience4j.bulkhead: instances: backendB: maxConcurrentCalls: 10 Spring Cloud Circuit Breaker Resilience4j 包括自动配置以设置指标收集，只要正确的依赖项位于类路径上。 要启用指标收集，您必须包含 org.springframework.boot:spring-boot-starter-actuator 和 io.github.resilience4j:resilience4j-micrometer。 有关存在这些依赖项时生成的指标的更多信息，请参阅 Resilience4j 文档。\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-cloud-circuit-breaker/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985643,"title":"Spring-Cloud-Circuit-Breaker"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"Spring Cloud 提供了自己的客户端负载均衡器抽象和实现。 对于负载均衡机制，添加了 ReactiveLoadBalancer 接口，从响应式的ServiceInstanceListSupplier 中选择实例，并为其提供了基于 Round 和 Random 的实现。 目前，我们支持基于服务发现的ServiceInstanceListSupplier，该实现使用类路径中可用的发现发现客户端检索可用实例。\n如何切换负载均衡算法 默认使用的 ReactiveLoadBalancer 实现是 RoundRobinLoadBalancer。 要为选定的服务或所有服务切换到不同的实现，您可以使用自定义 LoadBalancer 配置机制。\n例如，可以通过@LoadBalancerClient的configuration 属性配置RandomLoadBalancer：\npublic class CustomLoadBalancerConfiguration { //注意不要添加 @Configuration @Bean ReactorLoadBalancer\u0026lt;ServiceInstance\u0026gt; randomLoadBalancer(Environment environment, LoadBalancerClientFactory loadBalancerClientFactory) { String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME); return new RandomLoadBalancer(loadBalancerClientFactory .getLazyProvider(name, ServiceInstanceListSupplier.class), name); } } 如何集成负载均衡客户端 为了方便使用 Spring Cloud LoadBalancer，我们提供了可与 WebClient 一起使用的 ReactorLoadBalancerExchangeFilterFunction 和与 RestTemplate 一起使用的 BlockingLoadBalancerClient。 您可以在以下部分中查看更多信息和用法示例：\nRestTemplate @Configuration public class MyConfiguration { @LoadBalanced @Bean RestTemplate restTemplate() { return new RestTemplate(); } } public class MyClass { @Autowired private RestTemplate restTemplate; public String doOtherStuff() { String results = restTemplate.getForObject(\u0026#34;http://stores/stores\u0026#34;, String.class); return results; } } URI 需要使用虚拟主机名（即服务名，而不是主机名）。 BlockingLoadBalancerClient 用于创建完整的物理地址。\n多个实例的情况 @Configuration public class MyConfiguration { @LoadBalanced @Bean RestTemplate loadBalanced() { return new RestTemplate(); } @Primary @Bean RestTemplate restTemplate() { return new RestTemplate(); } } public class MyClass { @Autowired private RestTemplate restTemplate; @Autowired @LoadBalanced private RestTemplate loadBalanced; public String doOtherStuff() { return loadBalanced.getForObject(\u0026#34;http://stores/stores\u0026#34;, String.class); } public String doStuff() { return restTemplate.getForObject(\u0026#34;http://example.com\u0026#34;, String.class); } } WebClient @Configuration public class MyConfiguration { @Bean @LoadBalanced public WebClient.Builder loadBalancedWebClientBuilder() { return WebClient.builder(); } } public class MyClass { @Autowired private WebClient.Builder webClientBuilder; public Mono\u0026lt;String\u0026gt; doOtherStuff() { return webClientBuilder.build().get().uri(\u0026#34;http://stores/stores\u0026#34;) .retrieve().bodyToMono(String.class); } } URI 需要使用虚拟主机名（即服务名，而不是主机名）。 Spring Cloud LoadBalancer 用于创建完整的物理地址。\n多个实例的情况 @Configuration public class MyConfiguration { @LoadBalanced @Bean WebClient.Builder loadBalanced() { return WebClient.builder(); } @Primary @Bean WebClient.Builder webClient() { return WebClient.builder(); } } public class MyClass { @Autowired private WebClient.Builder webClientBuilder; @Autowired @LoadBalanced private WebClient.Builder loadBalanced; public Mono\u0026lt;String\u0026gt; doOtherStuff() { return loadBalanced.build().get().uri(\u0026#34;http://stores/stores\u0026#34;) .retrieve().bodyToMono(String.class); } public Mono\u0026lt;String\u0026gt; doStuff() { return webClientBuilder.build().get().uri(\u0026#34;http://example.com\u0026#34;) .retrieve().bodyToMono(String.class); } } Spring WebFlux 可以使用反应式和非反应式 WebClient 配置.\n您可以将 WebClient 配置为使用 ReactiveLoadBalancer。 如果您将 Spring Cloud LoadBalancer starter 添加到您的项目中并且如果 spring-webflux 在类路径上，则 ReactorLoadBalancerExchangeFilterFunction 是自动配置的。 以下示例显示了如何配置 WebClient 以使用反应式负载均衡器：\npublic class MyClass { @Autowired private ReactorLoadBalancerExchangeFilterFunction lbFunction; public Mono\u0026lt;String\u0026gt; doOtherStuff() { return WebClient.builder().baseUrl(\u0026#34;http://stores\u0026#34;) .filter(lbFunction) .build() .get() .uri(\u0026#34;/stores\u0026#34;) .retrieve() .bodyToMono(String.class); } } URI 需要使用虚拟主机名（即服务名，而不是主机名）。 ReactorLoadBalancer 用于创建完整的物理地址。\n如果 spring-webflux 在类路径上，LoadBalancerExchangeFilterFunction 是自动配置的。 但是请注意，这在后台使用了一个非反应式客户端。 以下示例显示如何配置 WebClient 以使用负载均衡器：\npublic class MyClass { @Autowired private LoadBalancerExchangeFilterFunction lbFunction; public Mono\u0026lt;String\u0026gt; doOtherStuff() { return WebClient.builder().baseUrl(\u0026#34;http://stores\u0026#34;) .filter(lbFunction) .build() .get() .uri(\u0026#34;/stores\u0026#34;) .retrieve() .bodyToMono(String.class); } } URI 需要使用虚拟主机名（即服务名，而不是主机名）。 LoadBalancerClient 用于创建完整的物理地址。\nServiceInstanceListSupplier 缓存实例信息的负载均衡器 实现类：CachingServiceInstanceListSupplier\n除了在每次必须选择实例时，通过 DiscoveryClient 检索实例的 ServiceInstanceListSupplier 实现之外，我们还提供了两个缓存实现。\nCaffeine-based实现：需要com.github.ben-manes.caffeine:caffeine在classpath。 DefaultLoadBalancerCache： 默认使用 spring.cloud.loadbalancer.cache.ttl 设置缓存的过期时间，默认35s\nspring.cloud.loadbalancer.cache.capacity 设置缓存的初始容量。默认256\nspring.cloud.loadbalancer.cache.enabled： 是否启用缓存。\n尽管基本的非缓存实现对于原型设计和测试很有用，但它的效率远低于缓存版本，因此我们建议始终在生产中使用缓存版本。\nzone-based 的负载均衡 为了启用基于区域的负载平衡，我们提供了 ZonePreferenceServiceInstanceListSupplier。 我们使用 DiscoveryClient 特定的区域配置（例如，eureka.instance.metadata-map.zone）来选择滤可用服务实例的。\n您还可以通过设置 spring.cloud.loadbalancer.zone 属性的值来覆盖特定于 DiscoveryClient 的区域设置。目前仅支持Eureka\nZonePreferenceServiceInstanceListSupplier 过滤检索到的实例并只返回同一区域内的实例。 如果该区域为空或同一区域内没有实例，则返回所有检索到的实例。\n为了使用基于区域的负载平衡方法，您必须在自定义配置中实例化 ZonePreferenceServiceInstanceListSupplier bean。\n我们使用委托来处理 ServiceInstanceListSupplier bean。 我们建议在 ZonePreferenceServiceInstanceListSupplier 的构造函数中传递一个 DiscoveryClientServiceInstanceListSupplier 委托，然后用 CachingServiceInstanceListSupplier 包装后者以利用 LoadBalancer 缓存机制。\npublic class CustomLoadBalancerConfiguration { @Bean public ServiceInstanceListSupplier discoveryClientServiceInstanceListSupplier( ConfigurableApplicationContext context) { return ServiceInstanceListSupplier.builder() .withDiscoveryClient() .withZonePreference() .withCaching() .build(context); } } @Configuration @LoadBalancerClient(value = \u0026#34;stores\u0026#34;, configuration = CustomLoadBalancerConfiguration.class) public class MyConfiguration { @Bean @LoadBalanced public WebClient.Builder loadBalancedWebClientBuilder() { return WebClient.builder(); } } 配置多个：\n@Configuration @LoadBalancerClients({@LoadBalancerClient(value = \u0026#34;stores\u0026#34;, configuration = StoresLoadBalancerClientConfiguration.class), @LoadBalancerClient(value = \u0026#34;customers\u0026#34;, configuration = CustomersLoadBalancerClientConfiguration.class)}) public class MyConfiguration { @Bean @LoadBalanced public WebClient.Builder loadBalancedWebClientBuilder() { return WebClient.builder(); } } 负载均衡的健康检查 可以为 LoadBalancer 启用计划的 HealthCheck。 为此提供了 HealthCheckServiceInstanceListSupplier。 它会定期验证ServiceInstanceListSupplier 提供的实例是否仍然存在并且只返回健康的实例。\n这种机制在使用 SimpleDiscoveryClient 时特别有用。 对于由实际 Service Registry 支持的客户端，没有必要使用，因为我们在查询外部 ServiceDiscovery 后已经获得了健康的实例。\nHealthCheckServiceInstanceListSupplier 使用以 spring.cloud.loadbalancer.health-check 为前缀的属性。 您可以为调度程序设置 initialDelay 和interval 。 您可以通过设置 spring.cloud.loadbalancer.health-check.path.default 属性的值来设置健康检查 URL 的默认路径。 您还可以通过设置 spring.cloud.loadbalancer.health-check.path.[SERVICE_ID] 属性的值，将 [SERVICE_ID] 替换为您的服务的正确 ID，为任何给定服务设置特定值。 如果未设置路径，则默认使用 /actuator/health。\n为了使用健康检查调度程序方法，您必须在自定义配置中实例化 HealthCheckServiceInstanceListSupplier bean。\n我们使用委托来处理 ServiceInstanceListSupplier bean。 我们建议在 HealthCheckServiceInstanceListSupplier 的构造函数中传递一个 DiscoveryClientServiceInstanceListSupplier 委托。\n您可以使用此示例配置进行设置：\npublic class CustomLoadBalancerConfiguration { @Bean public ServiceInstanceListSupplier discoveryClientServiceInstanceListSupplier( ConfigurableApplicationContext context) { return ServiceInstanceListSupplier.builder() .withDiscoveryClient() .withHealthChecks() .build(context); } } 具有粘性的负载均衡器 您可以设置 LoadBalancer，使其更喜欢先前选择的实例（如果该实例可用）。\n为此，您需要使用 SameInstancePreferenceServiceInstanceListSupplier。 您可以通过将 spring.cloud.loadbalancer.configurations 的值设置为 same-instance-preference 或提供您自己的 ServiceInstanceListSupplier bean — 来配置它，例如：\npublic class CustomLoadBalancerConfiguration { @Bean public ServiceInstanceListSupplier discoveryClientServiceInstanceListSupplier( ConfigurableApplicationContext context) { return ServiceInstanceListSupplier.builder() .withDiscoveryClient() .withSameInstancePreference() .build(context); } } session粘性的负载均衡器 您可以设置 LoadBalancer，使其更喜欢在请求 cookie 中提供 instanceId 的实例。 请求通过 ClientRequestContext 或 ServerHttpRequestContext 传递给 LoadBalancer，达到负载目的，SC LoadBalancer 交换过滤器组件和过滤器使用它们。\n为此，您需要使用 RequestBasedStickySessionServiceInstanceListSupplier。 您可以通过将 spring.cloud.loadbalancer.configurations 的值设置为 request-based-sticky-session 或通过提供您自己的 ServiceInstanceListSupplier bean — 来配置它，例如：\npublic class CustomLoadBalancerConfiguration { @Bean public ServiceInstanceListSupplier discoveryClientServiceInstanceListSupplier( ConfigurableApplicationContext context) { return ServiceInstanceListSupplier.builder() .withDiscoveryClient() .withRequestBasedStickySession() .build(context); } } 对于该功能，在转发请求之前更新选定的服务实例（如果原始请求 cookie 不可用，则该实例可能与原始请求 cookie 中的实例不同）很有用。 为此，请将 spring.cloud.loadbalancer.sticky-session.add-service-instance-cookie 的值设置为 true。\n默认情况下，cookie 的名称是 sc-lb-instance-id。 您可以通过更改 spring.cloud.loadbalancer.instance-id-cookie-name 属性的值来修改它。\n根据请求信息选择负载均衡器 Spring Cloud LoadBalancer 允许你在request对象中传递提示字符串，被ReactiveLoadBalancer 获取并使用。\n通过spring.cloud.loadbalancer.hint.default为所有服务设置\n通过spring.cloud.loadbalancer.hint.[SERVICE_ID] 为具体服务设置\nHintBasedServiceInstanceListSupplier实现了该功能。HintBasedServiceInstanceListSupplier 检查提示请求标头（默认标头名称为 X-SC-LB-Hint，但您可以通过更改 spring.cloud.loadbalancer.hint-header-name 属性的值来修改它），如果是 找到一个提示请求头，使用头中传递的提示值过滤服务实例。\n如果没有添加提示头，HintBasedServiceInstanceListSupplier 使用属性中的提示值来过滤服务实例。\n如果头或属性没有设置提示，则返回委托提供的所有服务实例。\n在过滤时，HintBasedServiceInstanceListSupplier 查找在其 metadataMap 中的hint key下设置了匹配值的服务实例。 如果没有找到匹配的实例，则返回委托提供的所有实例。\npublic class CustomLoadBalancerConfiguration { @Bean public ServiceInstanceListSupplier discoveryClientServiceInstanceListSupplier( ConfigurableApplicationContext context) { return ServiceInstanceListSupplier.builder() .withDiscoveryClient() .withHints() .withCaching() .build(context); } } 失败重试 负载均衡的 RestTemplate 可以配置为重试失败的请求。 默认情况下，此逻辑被禁用。 对于非响应式版本（使用 RestTemplate），您可以通过将 Spring Retry 添加到应用程序的类路径来启用它。 对于响应式版本（使用 WebTestClient），您需要设置 spring.cloud.loadbalancer.retry.enabled=true 。\n如果您想在类路径上使用 Spring Retry 或 Reactive Retry 禁用重试逻辑，您可以设置 spring.cloud.loadbalancer.retry.enabled=false。\n对于非响应式实现，如果您想在重试中实现 BackOffPolicy，您需要创建一个 LoadBalancedRetryFactory 类型的 bean 并覆盖 createBackOffPolicy() 方法。\n对于反应式实现，您只需要通过将 spring.cloud.loadbalancer.retry.backoff.enabled 设置为 false 来启用它。\nspring.cloud.loadbalancer.retry.maxRetriesOnSameServiceInstance - 指示应在同一个 ServiceInstance 上重试请求的次数（为每个选定的实例单独计数） spring.cloud.loadbalancer.retry.maxRetriesOnNextServiceInstance - 指示应重试新选择的 ServiceInstance 请求的次数 spring.cloud.loadbalancer.retry.retryableStatusCodes - 始终重试失败请求的状态代码。 响应式还有另外的属性：\nspring.cloud.loadbalancer.retry.backoff.minBackoff：设置最小退避持续时间（默认为 5 毫秒） spring.cloud.loadbalancer.retry.backoff.maxBackoff： 设置最大退避持续时间（默认情况下，最大长度值为毫秒） spring.cloud.loadbalancer.retry.backoff.jitter：- 设置用于计算每次调用的实际退避持续时间的抖动（默认为 0.5）。 对于反应式实现，您还可以实现自己的 LoadBalancerRetryPolicy 以更详细地控制负载平衡的调用重试。\n@Configuration public class MyConfiguration { @Bean LoadBalancedRetryFactory retryFactory() { return new LoadBalancedRetryFactory() { @Override public BackOffPolicy createBackOffPolicy(String service) { return new ExponentialBackOffPolicy(); } }; } } 对于负载平衡重试，默认情况下，我们使用 RetryAwareServiceInstanceListSupplier 包装 ServiceInstanceListSupplier bean，以从先前选择的实例中选择一个不同的实例（如果可用）。 您可以通过将 spring.cloud.loadbalancer.retry.avoidPreviousInstance 的值设置为 false 来禁用此行为。\n如果您想将一个或多个 RetryListener 实现添加到您的重试功能中，您需要创建一个 LoadBalancedRetryListenerFactory 类型的 bean 并返回您想用于给定服务的 RetryListener 数组，如以下示例所示：\n@Configuration public class MyConfiguration { @Bean LoadBalancedRetryListenerFactory retryListenerFactory() { return new LoadBalancedRetryListenerFactory() { @Override public RetryListener[] createRetryListeners(String service) { return new RetryListener[]{new RetryListener() { @Override public \u0026lt;T, E extends Throwable\u0026gt; boolean open(RetryContext context, RetryCallback\u0026lt;T, E\u0026gt; callback) { //TODO Do you business... return true; } @Override public \u0026lt;T, E extends Throwable\u0026gt; void close(RetryContext context, RetryCallback\u0026lt;T, E\u0026gt; callback, Throwable throwable) { //TODO Do you business... } @Override public \u0026lt;T, E extends Throwable\u0026gt; void onError(RetryContext context, RetryCallback\u0026lt;T, E\u0026gt; callback, Throwable throwable) { //TODO Do you business... } }}; } }; } } 个人心得： 建议开启失败重试，重试的次数为1 ，对timeout、网络异常、服务异常等错误开启切换到不同的服务重试。其他类型的异常不要开启重试。另外，post请求需要慎重重试。\n思考： 服务实例发生异常之后，该服务实例会从Supply中删除吗？ 答案是没有。spring 没有提供相关机制，只有服务实例不在线的时候，才会不去请求该服务。\n对负载的请求进行转换 您可以使用选定的 ServiceInstance 来转换负载均衡的 HTTP 请求。\n对于 RestTemplate，需要实现和定义 LoadBalancerRequestTransformer 如下：\n@Bean public LoadBalancerRequestTransformer transformer() { return new LoadBalancerRequestTransformer() { @Override public HttpRequest transformRequest(HttpRequest request, ServiceInstance instance) { return new HttpRequestWrapper(request) { @Override public HttpHeaders getHeaders() { HttpHeaders headers = new HttpHeaders(); headers.putAll(super.getHeaders()); headers.add(\u0026#34;X-InstanceId\u0026#34;, instance.getInstanceId()); return headers; } }; } }; } 对于WebClient，需要实现和定义LoadBalancerClientRequestTransformer如下：\n@Bean public LoadBalancerClientRequestTransformer transformer() { return new LoadBalancerClientRequestTransformer() { @Override public ClientRequest transformRequest(ClientRequest request, ServiceInstance instance) { return ClientRequest.from(request) .header(\u0026#34;X-InstanceId\u0026#34;, instance.getInstanceId()) .build(); } }; } 如果定义了多个转换器，它们将按照定义 Bean 的顺序应用。 或者，您可以使用 LoadBalancerRequestTransformer.DEFAULT_ORDER 或 LoadBalancerClientRequestTransformer.DEFAULT_ORDER 来指定顺序。\n负载均衡的生命周期方法 LoadBalancerLifecycle 提供了生命周期的回调方法：\nonStart(Request\u0026lt;RC\u0026gt; request), onStartRequest(Request\u0026lt;RC\u0026gt; request, Response\u0026lt;T\u0026gt; lbResponse) onComplete(CompletionContext\u0026lt;RES, T, RC\u0026gt; completionContext) supports(Class requestContextClass, Class responseClass, Class serverTypeClass) Request包含服务实例数据，传递给下游的请求 completionContext： 包含 LoadBalancer 响应，包括选定的服务实例、针对该服务实例执行的请求的状态和（如果可用）返回到下游客户端的响应，以及（如果发生异常）相应的 Throwable。 我们提供了一个名为 MicrometerStatsLoadBalancerLifecycle 的 LoadBalancerLifecycle bean，它使用 Micrometer 为负载平衡调用提供统计信息。\n为了将此 bean 添加到您的应用程序上下文中，请将 spring.cloud.loadbalancer.stats.micrometer.enabled 的值设置为 true 并使用 MeterRegistry（例如，通过将 Spring Boot Actuator 添加到您的项目中）。注册的指标：\nloadbalancer.requests.active：允许您监控任何服务实例的当前活动请求数量的gauge （服务实例数据可通过标签获得）； loadbalancer.requests.success：一个计时器，用于测量已结束将响应传递给底层客户端的任何负载平衡请求的执行时间； loadbalancer.requests.failed：一个计时器，用于测量以异常结束的任何负载平衡请求的执行时间； loadbalancer.requests.discard：一个计数器，用于测量被丢弃的负载平衡请求的数量，即负载均衡器尚未检索到运行请求的服务实例的请求。 只要可用，有关服务实例、请求数据和响应数据的附加信息就会通过标签添加到指标中。\n源码 @FunctionalInterface public interface Supplier\u0026lt;T\u0026gt; { T get(); } public interface ServiceInstanceListSupplier extends Supplier\u0026lt;Flux\u0026lt;List\u0026lt;ServiceInstance\u0026gt;\u0026gt;\u0026gt; { //获取服务的ID String getServiceId(); //扩展无参数的get方法，使其可以根据请求选择服务实例 default Flux\u0026lt;List\u0026lt;ServiceInstance\u0026gt;\u0026gt; get(Request request) { return get(); } //构建ServiceInstanceListSupplier实例 static ServiceInstanceListSupplierBuilder builder() { return new ServiceInstanceListSupplierBuilder(); } } 具体的实现类：\n我们来看DiscoveryClientServiceInstanceListSupplier的具体实现：\npublic static final String SERVICE_DISCOVERY_TIMEOUT = \u0026#34;spring.cloud.loadbalancer.service-discovery.timeout\u0026#34;; private static final Log LOG = LogFactory.getLog(DiscoveryClientServiceInstanceListSupplier.class); private Duration timeout = Duration.ofSeconds(30); private final String serviceId; private final Flux\u0026lt;List\u0026lt;ServiceInstance\u0026gt;\u0026gt; serviceInstances; public DiscoveryClientServiceInstanceListSupplier(DiscoveryClient delegate, Environment environment) { this.serviceId = environment.getProperty(PROPERTY_NAME); resolveTimeout(environment); this.serviceInstances = Flux.defer(() -\u0026gt; Flux.just(delegate.getInstances(serviceId))) .subscribeOn(Schedulers.boundedElastic()).timeout(timeout, Flux.defer(() -\u0026gt; { logTimeout(); return Flux.just(new ArrayList\u0026lt;\u0026gt;()); })).onErrorResume(error -\u0026gt; { logException(error); return Flux.just(new ArrayList\u0026lt;\u0026gt;()); }); } @Override public String getServiceId() { return serviceId; } @Override public Flux\u0026lt;List\u0026lt;ServiceInstance\u0026gt;\u0026gt; get() { return serviceInstances; } spring.cloud.loadbalancer.service-discovery.timeout是 loadblancer调用DiscoveryClient获取服务实例列表的超时时间，超时则返回空的服务实例列表 ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-cloud-loadbalancer/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985608,"title":"Spring-Cloud-LoadBalancer"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"@EnableDiscoveryClient Spring Cloud Commons 提供了 @EnableDiscoveryClient 注解。 这会在META-INF/spring.factories（org.springframework.cloud.client.discovery.EnableDiscoveryClient是key，value是具体的实现） 文件中搜索 DiscoveryClient 和 ReactiveDiscoveryClient 接口的实现。 DiscoveryClient 实现的示例包括 Spring Cloud Netflix Eureka、Spring Cloud Consul Discovery 和 Spring Cloud Zookeeper Discovery。\n默认情况下，Spring Cloud 将提供阻塞和反应式服务发现客户端。 您可以通过设置 spring.cloud.discovery.blocking.enabled=false 或 spring.cloud.discovery.reactive.enabled=false 轻松禁用阻塞和/或反应客户端。 要完全禁用服务发现，您只需设置 spring.cloud.discovery.enabled=false。\n默认情况下， DiscoveryClient 的实现会自动向远程发现服务器注册本地 Spring Boot 应用。 可以通过在 @EnableDiscoveryClient 中设置 autoRegister=false 来禁用此行为。\n@EnableDiscoveryClient不需要显示声明。 只需要在类路径上放置一个 DiscoveryClient 实现。\n健康检查 spring.cloud.discovery.client.health-indicator.enabled=false.禁用健康检查 要禁用描述字段，请设置 spring.cloud.discovery.client.health-indicator.include-description=false。 否则，它可能会冒泡作为汇总的 HealthIndicator 的描述。 要禁用服务检索，请设置 spring.cloud.discovery.client.health-indicator.use-services-query=false。 默认情况下，指标调用客户端的 getServices 方法。 在具有许多注册服务的部署中，在每次检查期间检索所有服务的成本可能太高。 这将跳过服务检索，而是使用客户端的探测方法。 DiscoveryCompositeHealthContributor复合健康指标基于所有已注册的 DiscoveryHealthIndicator bean。 要禁用，请设置 spring.cloud.discovery.client.composite-indicator.enabled=false。 DiscoveryClientHealthIndicator里面实现：\npublic Health health() { Health.Builder builder = new Health.Builder(); if (this.discoveryInitialized.get()) { try { DiscoveryClient client = this.discoveryClient.getIfAvailable(); String description = (this.properties.isIncludeDescription()) ? client.description() : \u0026#34;\u0026#34;; if (properties.isUseServicesQuery()) { List\u0026lt;String\u0026gt; services = client.getServices(); builder.status(new Status(\u0026#34;UP\u0026#34;, description)).withDetail(\u0026#34;services\u0026#34;, services); } else { client.probe(); // ==client.getServices(); builder.status(new Status(\u0026#34;UP\u0026#34;, description)); } } catch (Exception e) { this.log.error(\u0026#34;Error\u0026#34;, e); builder.down(e); } } else { builder.status(new Status(Status.UNKNOWN.getCode(), \u0026#34;Discovery Client not initialized\u0026#34;)); } return builder.build(); } 发现客户端的顺序 DiscoveryClient 接口扩展了 Ordered。 这在使用多个发现客户端时很有用，因为它允许您定义返回的发现客户端的顺序，类似于如何对 Spring 应用程序加载的 bean 进行排序。 默认情况下，任何 DiscoveryClient 的顺序设置为 0。如果您想为自定义 DiscoveryClient 实现设置不同的顺序，您只需覆盖 getOrder() 方法，以便它返回适合您设置的值。 除此之外，您可以使用属性来设置 Spring Cloud 提供的 DiscoveryClient 实现的顺序，其中包括 ConsulDiscoveryClient、EurekaDiscoveryClient 和 ZookeeperDiscoveryClient。 为此，您只需将 spring.cloud.{clientIdentifier}.discovery.order （或 Eureka 的 eureka.client.order）属性设置为所需的值。\nSimpleDiscoveryClient 如果类路径中没有 Service-Registry-backed DiscoveryClient，将使用 SimpleDiscoveryClient 实例，它使用属性来获取有关服务和实例的信息。\n有关可用实例的信息应按以下格式通过属性传递：\nspring.cloud.discovery.client.simple.instances.service1[0].uri=http://s11:8080，其中spring.cloud.discovery.client.simple.instances为公共前缀，那么service1代表服务ID，而 [0] 表示实例的索引号（如示例中可见，索引从 0 开始），然后 uri 的值是实例可用的实际 URI。\n注册 Commons 现在提供了一个 ServiceRegistry 接口，该接口提供 register(Registration) 和 deregister(Registration) 等方法，让您可以提供自定义注册服务。\n@Configuration @EnableDiscoveryClient(autoRegister=false) public class MyConfiguration { private ServiceRegistry registry; public MyConfiguration(ServiceRegistry registry) { this.registry = registry; } // called through some external process, such as an event or a custom actuator endpoint public void register() { Registration registration = constructRegistration(); this.registry.register(registration); } } ZookeeperRegistration used with ZookeeperServiceRegistry EurekaRegistration used with EurekaServiceRegistry ConsulRegistration used with ConsulServiceRegistry 默认情况下，ServiceRegistry 实现会自动注册正在运行的服务。 要禁用该行为，您可以设置： @EnableDiscoveryClient(autoRegister=false) 以永久禁用自动注册。 spring.cloud.service-registry.auto-registration.enabled=false 禁用行为。\n服务自动注册时将触发两个事件。 第一个事件称为 InstancePreRegisteredEvent，在注册服务之前触发。 第二个事件称为 InstanceRegisteredEvent，在注册服务后触发。 您可以注册一个 ApplicationListener(s) 来监听和响应这些事件。\nSpring Cloud Commons 提供了一个 /service-registry 执行器端点。 此端点依赖于 Spring 应用程序上下文中的注册 bean。 使用 GET 调用 /service-registry 会返回注册的状态。 对具有 JSON 正文的同一端点使用 POST 会将当前注册的状态更改为新值。 JSON 正文必须包含具有首选值的状态字段。 请参阅更新状态和状态返回值时用于允许值的 ServiceRegistry 实现的文档。 例如，Eureka 支持的状态是 UP、DOWN、OUT_OF_SERVICE 和 UNKNOWN。\n忽略网络接口 有时，忽略某些命名的网络接口很有用，以便它们可以从服务发现注册中排除（例如，在 Docker 容器中运行时）。 可以设置正则表达式列表以导致所需的网络接口被忽略。 以下配置忽略了 docker0 接口和所有以 veth 开头的接口：\nspring: cloud: inetutils: ignoredInterfaces: - docker0 - veth.* 您还可以通过使用正则表达式列表强制仅使用指定的网络地址，如以下示例所示：\nspring: cloud: inetutils: preferredNetworks: - 192.168 - 10.0 您还可以强制仅使用站点本地地址，如以下示例所示：\nspring: cloud: inetutils: useOnlySiteLocalInterfaces: true 创建http client的工厂 Spring Cloud Commons 提供了用于创建 Apache HTTP 客户端 (ApacheHttpClientFactory) 和 OK HTTP 客户端 (OkHttpClientFactory) 的 bean。 只有当 OK HTTP jar 位于类路径上时，才会创建 OkHttpClientFactory bean。 此外，Spring Cloud Commons 提供了用于创建两个客户端使用的连接管理器的 bean：ApacheHttpClientConnectionManagerFactory 用于 Apache HTTP 客户端，OkHttpClientConnectionPoolFactory 用于 OK HTTP 客户端。 如果您想自定义如何在下游项目中创建 HTTP 客户端，您可以提供您自己的这些 bean 的实现。 此外，如果您提供类型为 HttpClientBuilder 或 OkHttpClient.Builder 的 bean，则默认工厂使用这些构建器作为返回到下游项目的构建器的基础。 您还可以通过将 spring.cloud.httpclientfactories.apache.enabled 或 spring.cloud.httpclientfactories.ok.enabled 设置为 false 来禁用这些 bean 的创建。\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-cloud-discovery/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985584,"title":"Spring-Cloud-Discovery"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"访问日志解码请求参数 打印post请求的请求体信息 默认的日志打印不包含请求体的内容,如果要打印改值,只需要在log_format中添加$request_body 即可,更多日志打印变量参考官方文档\n另外,即使打印出来请求体,内容不支持中文,都是经过url编码后的字符串.\n添加或启动新模块 nginx不支持动态安装、加载模块的，所以当你安装第三方模块或者启动nginx本身的新模块功能的时候，都是覆盖nginx的；所以，一定要注意：首先查看你已经安装的nginx模块！然后安装新东西的时候，要把已安装的，再次配置。\n1.查看ngnix已经安装的模块./nginx -V\n2.执行configure和make\n./configure --prefix=/usr/local/nginx \\ --with-http_stub_status_module \\ --with-http_ssl_module --with-http_realip_module \\ --with-http_image_filter_module \\ --add-module=../ngx_pagespeed-master make 3.替换nginx二进制文件\ncp /root/nginx-1.8.1/objs/nginx /usr/local/nginx/sbin/nginx X-Forwarded-For 和 X-Real-IP X-Forwarded-For:被代理服务器使用,用来记录经过的代理服务信息. X-Real-IP:被代理服务器使用,用来记录客户端的真实IP地址.\n举例: 现在有ngnix代理服务器A和B,请求先请过A[10.187.144.41],然后B[10.187.112.151],最后到达服务器[10.176.175.149]处理该请求.\nA的ngnix配置\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; B的ngnix配置\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 服务器的响应\nx-forwarded-for:114.141.166.125, 10.187.144.41 host:10.176.175.149:8080 connection:close x-real-ip:114.141.166.125 getRemoteAddr:10.187.112.151 getRemoteHost:10.187.112.151 getServerName:10.176.175.149 变动1:如果B的配置也加上proxy_set_header X-Real-IP $remote_addr呢,服务器收到的请求头信息会是神马呢?\nx-real-ip:10.187.144.41 x-forwarded-for:114.141.166.125, 10.187.144.41 host:10.176.175.149:8080 getRemoteAddr:10.187.112.151 getRemoteHost:10.187.112.151 getServerName:10.176.175.149 需要注意的是x-forwarded-for并没有把最后一个代理添加上去\n我们看到x-real-ip的地址发生改变,不再是真实的客户端ip,而是代理A的ip,说明此时的$remote_addr的值是代理A的IP,如何修改这个值为真实的IP呢? 可以使用ngx_http_realip_module模块\nngx_http_realip_module模块 安装请参考模块安装,A配置不变,B配置如下:\nset_real_ip_from 10.187.144.41 real_ip_header X-Real-IP ; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; set_real_ip_from:指定真实IP的地址是在哪个代理机器上 real_ip_header:真实IP所在的请求头字段\nHttpGeoIP模块 1.安装\n#下载免费的geo_city数据库 wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz #下载免费的geo_coundty数据库 wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz #在debian中安装libgeoip: sudo apt-get install libgeoip-dev #其它系统，你可以下载并编译一个源文件 wget http://geolite.maxmind.com/download/geoip/api/c/GeoIP.tar.gz #编译 ./configure --with-http_geoip_module 2.配置数据源\nhttp { geoip_country GeoIP.dat; #放在ngnix home目录下面 geoip_city GeoLiteCity.dat; 3.使用举例\nserver { ... location / { root /home/vpsee/www; if ($geoip_country_code = CN) { root /home/vpsee/cn; } ... } ... } 这样，当来自中国的 IP 访问网站后就自动访问到预定的 /home/vpsee/cn 页面\npost_action请求后置处理器 该指令可以在响应完成之后跳转到另外的location上,可用于接口调用统计等.\nserver { listen 80; server_name www.a.com; location /aa { proxy_set_header Host \u0026#34;www.a-upstream.com\u0026#34;; proxy_pass http://127.0.0.1:8000; post_action @action; } location @action { proxy_set_header Host \u0026#34;www.a-post-action.com\u0026#34;; proxy_pass http://127.0.0.1:8001; } } 上面的aa请求在发送给8000端口之后,也会发送给8001端口一份\nngx_http_stub_status_module监控ngnix处理的请求数 默认没有开启该模块，需要编译添加，添加之后,在文件中配置:\nlocation /basic_status { stub_status; } Active connections: 291 server accepts handled requests 16630948 16630948 31070465 Reading: 6 Writing: 179 Waiting: 106 Active connections: 活动状态的连接数； accepts：已经接受的客户端握手的总数；accepts和handled相等，代表链接没有丢失 handled：已经处理完成的客户端请求的总数； requests：客户端发来的总的请求数； Reading：处于读取客户端请求报文首部的连接的连接数； Writing：处于向客户端发送响应报文过程中的连接数； Waiting：开启keepalive时，处于等待客户端发出请求的空闲连接数；此时连接已经处理完请求，但是并没有关闭，等待下一次请求重用该连接（需要客户端配合才可以）。 http_random_index_module 随机页面返回 处理以斜杠（\u0026rsquo;/\u0026rsquo;）结尾的请求，并从目录中随机选择一个html文件作为返回。 该模块在ngx_http_index_module模块之前进行处理。 默认情况下未构建此模块，应使用—with-http_random_index_module配置参数启用它。\n语法\nSyntax:\trandom_index on | off; Default: random_index off; Context:\tlocation 示例\nlocation / { random_index on; } http_sub_module 替换响应 ngx_http_sub_module模块是一个过滤器，它通过将一个指定的字符串替换为另一个指定的字符串来修改响应。 默认情况下未构建此模块，应使用—with-http_sub_module配置参数启用它。\n语法 Syntax:\tsub_filter string replacement; Default:\t— Context:\thttp, server, location 设置要替换的字符串和替换字符串。 替换忽略大小写。 要替换的字符串和替换字符串可以包含变量。 可以在一个配置级别上指定多个sub_filter伪指令。 当且仅当当前级别上未定义sub_filter指令时，这些指令才从上一级继承。\nSyntax:\tsub_filter_once on | off; Default: sub_filter_once on; Context:\thttp, server, location 指示替换匹配的一个还是全部。\nSyntax:\tsub_filter_last_modified on | off; Default: sub_filter_last_modified off; Context:\thttp, server, location This directive appeared in version 1.5.1. 允许在替换期间从原始响应中保留“最后修改的”标头字段，以方便响应缓存。 默认情况下，在处理期间修改响应的内容时，将删除标头字段。\nSyntax:\tsub_filter_types mime-type ...; Default: sub_filter_types text/html; Context:\thttp, server, location 除了“ text / html”之外，还可以在具有指定MIME类型的响应中启用字符串替换。 特殊值“ *”与任何MIME类型（0.8.29）匹配。\n示例\nlocation / { sub_filter \u0026#39;\u0026lt;a href=\u0026#34;http://127.0.0.1:8080/\u0026#39; \u0026#39;\u0026lt;a href=\u0026#34;https://$host/\u0026#39;; sub_filter \u0026#39;\u0026lt;img src=\u0026#34;http://127.0.0.1:8080/\u0026#39; \u0026#39;\u0026lt;img src=\u0026#34;https://$host/\u0026#39;; sub_filter_once on; } ngx_http_limit_conn_module限制客户端连接数 ngx_http_limit_conn_module模块用于限制每个已定义key的连接数，特别是来自单个IP地址的连接数.但是，并非所有连接都被计算在内 ，只有在服务器处理了请求并且整个请求头已经被读取的情况下才计算连接。\nSyntax:\tlimit_conn_zone key zone=name:size; Default:\t— Context:\thttp 定义内存区域存储客户端的信息，例如指定key的当前连接数， key可以包含文本，变量及其组合。 key值为空的请求不予考虑。下面是一个示例：\nlimit_conn_zone $binary_remote_addr zone=addr:10m; 客户端IP作为key值，为什么不使用$remote_addr呢？\n$remote_addr大小为7~15byte。 $binary_remote_addr相对IPV4始终是4个字节，IPV6是16字节。 1M的区域可以保留大约3.2万个32字节状态或大约1.6万个64字节状态。 如果区域存储空间已用完，服务器将把错误返回给所有其他请求。 Syntax:\tlimit_conn zone number; Default:\t— Context:\thttp, server, location 设置共享内存区域和最大允许连接数。 当超过此限制时，服务器将返回错误以回复请求。 例如\nlimit_conn_zone $binary_remote_addr zone=addr:10m; server { location /download/ { limit_conn addr 1; } 同一时间只允许客户段IP有一个连接。\n可能有几个limit_conn指令。 例如，以下配置将限制每个客户端IP与服务器的连接数，并同时限制与虚拟服务器的连接总数：\nlimit_conn_zone $binary_remote_addr zone=perip:10m; limit_conn_zone $server_name zone=perserver:10m; server { ... limit_conn perip 10; limit_conn perserver 100; } 当且仅当当前级别上没有limit_conn指令时，这些指令才从上一级继承。\nSyntax:\tlimit_conn_status code; Default: limit_conn_status 503; Context:\thttp, server, location This directive appeared in version 1.3.15. 连接被拒绝后，nginx的响应状态码。\nSyntax:\tlimit_conn_log_level info | notice | warn | error; Default: limit_conn_log_level error; Context:\thttp, server, location This directive appeared in version 0.8.18. 连接被拒绝后，记录该请求的日志级别\nSyntax:\tlimit_conn_dry_run on | off; Default: limit_conn_dry_run off; Context:\thttp, server, location This directive appeared in version 1.17.6. 启用空运行模式。 在这种模式下，连接数不受限制，但是，在共享内存区域中，过多连接的数将照常计算。\nhttp_limit_req_module 限制请求速率 ngx_http_limit_req_module模块用于限制请求处理速率，特别是来自单个IP地址的请求的处理速率。 使用“漏斗”方法完成限制。\nSyntax:\tlimit_req_zone key zone=name:size rate=rate [sync]; Default:\t— Context:\thttp 定义内存区域存储客户端的信息，例如指定key的当前请求数， key可以包含文本，变量及其组合。 key值为空的请求不予考虑。下面是一个示例：\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; 请求速率是每秒一个。\nSyntax:\tlimit_req zone=name [burst=number] [nodelay | delay=number]; Default:\t— Context:\thttp, server, location 设置共享内存区域和请求的最大突发大小。 如果请求速率超过为区域配置的速率，则会延迟其处理，以便以定义的速率处理请求。 过多的请求将被延迟，直到其数量超过最大突发大小为止，在这种情况下，该请求将因错误而终止。 默认情况下，最大突发大小等于零。 例如，指令\nlimit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server { location /search/ { limit_req zone=one burst=5; } 平均每秒最多允许不超过1个请求，并且突发不超过5个请求。\n如果不需要在限制请求时延迟过多的请求，则应使用参数nodelay：\nlimit_req zone=one burst=5 nodelay; delay参数指定一个限制，在该限制下，过多的请求将被延迟。 默认值为零，即所有多余的请求都会延迟。\n可能有几个limit_req指令。 例如，以下配置将限制来自单个IP地址的请求的处理速度，同时限制虚拟服务器的请求处理速度：\nlimit_req_zone $binary_remote_addr zone=perip:10m rate=1r/s; limit_req_zone $server_name zone=perserver:10m rate=10r/s; server { ... limit_req zone=perip burst=5 nodelay; limit_req zone=perserver burst=10; } Syntax:\tlimit_req_status code; Default: limit_req_status 503; Context:\thttp, server, location This directive appeared in version 1.3.15. 请求被拒绝后，nginx的响应状态码。\nSyntax:\tlimit_req_log_level info | notice | warn | error; Default: limit_req_log_level error; Context:\thttp, server, location This directive appeared in version 0.8.18. 请求被拒绝后，记录该请求的日志级别\nSyntax:\tlimit_req_dry_run on | off; Default: limit_req_dry_run off; Context:\thttp, server, location This directive appeared in version 1.17.1. 启用空运行模式。 在这种模式下，请求数不受限制，但是，在共享内存区域中，过多请求的数将照常计算。\nhttp_access_module 访问控制 ngx_http_access_module模块允许限制对某些客户端地址的访问。\n语法 Syntax:\tallow address | CIDR | unix: | all; Default:\t— Context:\thttp, server, location, limit_except 允许访问 指定的网络或地址。 如果指定特殊值unix：，则允许访问所有UNIX域套接字。\nSyntax:\tdeny address | CIDR | unix: | all; Default:\t— Context:\thttp, server, location, limit_except 拒绝访问 指定的网络或地址。 如果指定了特殊值unix：，则拒绝所有UNIX域套接字的访问。\n示例\nlocation / { deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; } 依次检查规则，直到找到第一个匹配项。 在此示例中，仅对IPv4网络 10.1.1.0/16 和 192.168.1.0/24（地址192.168.1.1除外）和IPv6网络 2001:0db8::/32 允许访问。 在有很多规则的情况下，最好使用ngx_http_geo_module模块变量。\n该模块存在一定的局限性，如果应用经过一层代理，则真实IP不可达，需要我们在代理上配置一定规则将真是的IP传递 http_auth_basic_module 认证用户 ngx_http_auth_basic_module模块允许通过使用“ HTTP基本身份验证”协议验证用户名和密码来限制对资源的访问。\nSyntax:\tauth_basic string | off; Default: auth_basic off; Context:\thttp, server, location, limit_except 使用“ HTTP基本认证”协议启用用户名和密码的验证。 指定的参数用作realm。 参数值可以包含变量。 特殊值off允许取消从先前配置级别继承的auth_basic指令的效果。\nSyntax:\tauth_basic_user_file file; Default:\t— Context:\thttp, server, location, limit_except 以以下格式指定保存用户名和密码的文件：\n# comment name1:password1 name2:password2:comment name3:password3 file名称可以包含变量。 支持一下密码类型：\n用crypt（）函数加密； 可以使用Apache HTTP Server发行版中的“ htpasswd”实用程序或“ openssl passwd”命令生成。 使用基于MD5的密码算法（apr1）的Apache变体进行哈希处理； 可以使用相同的工具生成； 由RFC 2307中所述的“ {scheme} data”语法（1.0.3+）指定； 当前实施的方案包括一些软件包使用的PLAIN（不应该使用示例1），SHA（1.3.13）（不应该使用普通SHA-1哈希）和SSHA（盐化的SHA-1哈希）。 OpenLDAP和Dovecot）。 示例\nlocation / { auth_basic \u0026#34;closed site\u0026#34;; auth_basic_user_file conf/htpasswd; } 由于密码认证是通过本地文件，所以速度慢，且不好管理。可以使用Lua脚本来做。 secure_link_module 索引静态目录 location / { #不能是其他路径 autoindex on; } nginx架构模型 epoll模型 worker_processes 配置 use 配置 connection 配置\nformat日志变量\n静态资源 sendfile 指定是否使用sendfile系统调用来传输文件。 sendfile系统调用在两个文件描述符之间直接传递数据(完全在内核中操作)，从而避免了数据在内核缓冲区和用户缓冲区之间的拷贝，操作效率很高，被称之为零拷贝\ntcp_nopush 和 tcp_nodelay gzip 压缩 Syntax:\tgzip on | off; Default: gzip off; Context:\thttp, server, location, if in location 是否开启gzip压缩\nSyntax:\tgzip_buffers number size; Default: gzip_buffers 32 4k|16 8k; Context:\thttp, server, location 设置用于压缩响应的缓冲区的数量和大小。 默认情况下，缓冲区大小等于一个内存页。 根据平台的不同，它可以是4K或8K。建议此项不设置，使用默认值。\nSyntax:\tgzip_comp_level level; Default: gzip_comp_level 1; Context:\thttp, server, location 设置压缩比率，最小为1；9为最大压缩比; 压缩比越大，压缩后的文件越小，但是压缩过程比较慢，消耗CPU\nSyntax:\tgzip_disable regex ...; Default:\t— Context:\thttp, server, location This directive appeared in version 0.6.23. 如果“User-Agent”头字段内容匹配任何指定的正则表达式，则禁用gzip。\nSyntax:\tgzip_http_version 1.0 | 1.1; Default: gzip_http_version 1.1; Context:\thttp, server, location 设置压缩响应所需的最低HTTP请求版本。\nSyntax:\tgzip_min_length length; Default: gzip_min_length 20; Context:\thttp, server, location 超过该长度的响应会被压缩。 长度仅由“ Content-Length”响应头字段确定。\nSyntax:\tgzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...; Default: gzip_proxied off; Context:\thttp, server, location 根据请求或响应，决定反向代理是否对返回结果进行gzip压缩。是否进行gzip压缩是通过是否存在可变的请求头来决定的。该指令可以接受多个值。\noff:禁用压缩 expired：如果响应头中包含“ Expires”字段且其值禁用了缓存，则启用压缩； no-cache：如果响应头包含带有“Cache-Control: no-cache”字段，则启用压缩； no-store: 如果响应头包含带有“Cache-Control: no-store”字段，则启用压缩； private: 如果响应头包含带有“Cache-Control: private”字段，则启用压缩； no_last_modified: 如果响应头不包含“ Last-Modified”字段，则启用压缩； no_etag: 如果响应头不包含“ ETag”字段，则启用压缩； auth: 如果请求标头包含“ Authorization”字段，则启用压缩； any: 为所有代理请求启用压缩。 Syntax:\tgzip_types mime-type ...; Default: gzip_types text/html; Context:\thttp, server, location 除了“text/html”之外，还对指定的MIME类型启用gzipping响应。 特殊值“*”与任何MIME类型匹配。 始终会压缩“text/html”类型的响应。\nSyntax:\tgzip_vary on | off; Default: gzip_vary off; Context:\thttp, server, location 如果指令gzip，gzip_static或gunzip处于活动状态，则启用或禁用插入“Vary：Accept-Encoding”响应标头字段。\ngzip_static_module 模块 ngx_http_gzip_static_module模块允许优先发送扩展名为“.gz”的预压缩文件。简单来说，nginx会先查找相同目录下，是否存在该文件以“.gz”结尾的压缩文件，存在则返回，不存在则使用原文件。默认情况下未构建此模块，应使用—with-http_gzip_static_module配置参数启用它。\nSyntax:\tgzip_static on | off | always; Default: gzip_static off; Context:\thttp, server, location 启用（“ on”）或禁用（“ off”）检查是否存在预压缩文件。 还考虑了以下指令：gzip_http_version，gzip_proxied，gzip_disable和gzip_vary。\n使用“always”值，在所有情况下都使用压缩文件，而无需检查客户端是否支持它。\n可以使用gzip命令或任何其他兼容的命令压缩文件。 建议原始文件和压缩文件的修改日期和时间相同。\ngunzip_module 模块 ngx_http_gunzip_module模块是一个过滤器，用于对不支持“gzip”编码方法的客户端使用“ Content-Encoding：gzip”解压缩后返回响应。 现在的客户端基本都支持，该模块用途很小。\n缓存 Syntax: expires [modified] time； expires epoch|max|off； Default: expires off； # 静态缓存 Context: http，server，location，if in location 指定过期时间。会在响应头中添加“Expires”（http1.0之前的）和“Cache-Control”（http1.1之后）\ntime的值是负值，“Cache-Control: no-cache” time的值是正值t: Cache-Control: max-age=t\n“Expires”字段中的时间计算为当前时间与指令中指定的时间之和。\nepoch参数将“ Expires”设置为值“ Thu，1970年1月1日00:00:01 GMT”，将“ Cache-Control”设置为“ no-cache”。 max参数将“ Expires”设置为值“ Thu，2037年12月31日23:55:55 GMT”，将“ Cache-Control”设置为10年。 off参数禁用添加或修改“ Expires”和“ Cache-Control”响应头字段。 跨站 add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Headers X-Requested-With; add_header Access-Control-Allow-Methods GET,POST,OPTIONS; 防盗链 Syntax:\tvalid_referers none | blocked | server_names | string ...; Default:\t— Context:\tserver, location 匹配请求头中的“Referer”，匹配则 $valid_referers 的值为空，否则为1.\nnone:请求标头中缺少“ Referer”字段； blocked: 请求标头中存在“ Referer”字段，但其值已被防火墙或代理服务器删除； 这些值是不以“ http：//”或“ https：//”开头的字符串； server_names: “ Referer”请求标头字段包含任一服务器名称； 任意字符串：定义服务器名称和可选的URI前缀。 服务器名称的开头或结尾可以带有“ *”。 在检查过程中，“ Referer”字段中的服务器端口将被忽略； 正则：第一个符号应为“〜”。 应当注意，表达式将与“ http：//”或“ https：//”之后的文本匹配。 示例：\nvalid_referers none blocked *.source.com source.com; if ($invalid_referer) { return 403 ; } 反向代理 负载均衡 缓存 日志文件分割 默认情况下,nginx的日志文件不支持按天或者按大小切分,这对我们排查错误非常不便.这里提供一种在配置文件中分割日志文件的方式(此外还有cron定时切分日志文件的方式):\nif ($time_iso8601 ~ \u0026#34;^(\\d{4})-(\\d{2})-(\\d{2})\u0026#34;) { set $year $1; set $month $2; set $day $3; } access_log /usr/local/nginx/logs/www.ttlsa.com-$year-$month-$day-access.log; 此外需要注意的是,默认情况下,ngnix的权限用户并不是root,那么将无法生成日志文件,所有需要指定user为root.例如:\nnginx灰度测试 灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test就是一种灰度发布方式，让一部分用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。\n灰度发布常见一般有三种方式:\nNginx+LUA方式 根据Cookie实现灰度发布 根据来路IP实现灰度发布 本文主要将讲解根据Cookie和来路IP这两种方式实现简单的灰度发布。这两种的实现原理是相同的,这里只介绍一种即可：\nupstream hilinux_01 { server 192.168.1.100:8080 max_fails=1 fail_timeout=60; } upstream hilinux_02 { server 192.168.1.200:8080 max_fails=1 fail_timeout=60; } upstream default { server 192.168.1.100:8080 max_fails=1 fail_timeout=60; } server { listen 80; server_name www.hi-linux.com; access_log logs/www.hi-linux.com.log main; #match cookie set $group \u0026#34;default\u0026#34;; if ($http_cookie ~* \u0026#34;version=V1\u0026#34;){ set $group hilinux_01; } if ($http_cookie ~* \u0026#34;version=V2\u0026#34;){ set $group hilinux_02; } location / { proxy_pass http://$group; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; index index.html index.htm; } } ngx_http_map_module 默认情况下安装 nginx 都会安装该模块。\nmap 的主要作用是创建自定义变量，通过使用 nginx 的内置变量，去匹配某些特定规则，如果匹配成功则设置某个值给自定义变量。 而这个自定义变量又可以作于他用。\n直接看个例子理解起来比较清晰：\n场景： 匹配请求 url 的参数，如果参数是 debug 则设置 $foo = 1 ，默认设置 $foo = 0\nmap $args $foo { default 0; debug 1; } $args 是nginx内置变量，就是获取的请求 url 的参数。 如果 $args 匹配到 debug 那么 $foo 的值会被设为 1 ，如果 $args 一个都匹配不到 $foo 就是default 定义的值，在这里就是 0.\n使用map也可以用作灰度测试：\nupstream hilinux_01 { server 192.168.1.100:8080 max_fails=1 fail_timeout=60; } upstream hilinux_02 { server 192.168.1.200:8080 max_fails=1 fail_timeout=60; } upstream default { server 192.168.1.100:8080 max_fails=1 fail_timeout=60; } map $COOKIE_version $group { ~*V1$ hilinux_01; ~*V2$ hilinux_02; default default; } server { listen 80; server_name www.hi-linux.com; access_log logs/www.hi-linux.com.log main; location / { proxy_pass http://$group; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; index index.html index.htm; } } 使用nginx进行AB测试 根据请求的路径来选择路由的首页:\nhttp { split_clients \u0026#34;${remote_addr}AAA\u0026#34; $variant { 0.5% .one; 2.0% .two; * \u0026#34;\u0026#34;; } server { location / { index index${variant}.html; 原始字符串的值使用MurmurHash2散列。 在给出的例子中，从0到21474835（0.5％）的散列值对应于$ variant变量的值“.one”，从21474836到107374180（2％）的散列值对应于值“.two”，散列值 从107374181到4294967295的值对应于值“”（一个空字符串）。\nnginx请求镜像 请求镜像就是nginx在接受到客户端请求进行反向代理的时候分别代理到原地址和镜像地址一次。镜像地址的返回结果不会返回到客户端。看下图：\n利用这一功能我们就可以将线上实时访问流量拷贝至其它环境，基于这些流量可以做版本发布前的预先验证或者进行流量放大后的压测等等。\nmirror模块配置分为两部分，源地址和镜像地址配置，配置位置可以为nginx配置文件的http, server, location上下文，配置示例为：\nlocation /user { mirror /mirror ; mirror_request_body off; proxy_pass http://localhost:8080 ; } location /mirror { internal; proxy_pass http://127.0.0.1:8081$request_uri; proxy_set_header X-Original-URI $request_uri; } 1.original配置\nlocation /指定了源uri为/ mirror /mirror指定镜像uri为/mirror mirror_request_body off | on 指定是否镜像请求body部分，此选项与proxy_request_buffering、fastcgi_request_buffering、scgi_request_buffering和 uwsgi_request_buffering冲突，一旦开启mirror_request_body为on，则请求自动缓存; 2.mirror配置\ninternal 指定此location只能被“内部的”请求调用，外部的调用请求会返回”Not found” (404) proxy_pass 指定上游server的地址 proxy_set_header 设置镜像流量的头部 rewrite指令 last： url重写后，马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变 break: url重写后，直接使用当前资源，执行location里余下的语句，完成本次请求(不会再次进入server块)，地址栏url不变 redirect ： 返回302临时重定向，地址栏显示重定向后的url，爬虫不会更新url（因为是临时） permanent ： 返回301永久重定向, 地址栏显示重定向后的url，爬虫更新url nginx 的 rewrite log 是记录在 error log 文件中，而不是access log中。\nnginx 开启 rewrite 日志的方法(在server段中添加）:首先，打开 error_log 日志：\nerror_log logs/error.log notice; 然后打开 rewrite_log 开关:\nrewrite_log on; nginx文件上传 ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/nginx/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985490,"title":"Nginx"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"快速入门 第一步：依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 第二步：编写测试controller @RestController @RequestMapping(\u0026#34;/hello\u0026#34;) public class HelloController { @GetMapping public String hello() { return \u0026#34;hello\u0026#34;; } } 第三步启动并测试 浏览器中输入： http://localhost:8080/hello 浏览器会呈现登录页，如下： 用户名是 user ，密码在启动的控制台中打印。\n至此，一个安全的web应用就产生了。接下来，我们来看一下spring默认的配置。\nspring boot 自动配置 启用 Spring Security 的默认配置，它创建一个 servlet 过滤器（名为 springSecurityFilterChain 的 bean）。 此 bean 负责应用程序中的所有安全性（保护应用程序 URL、验证提交的用户名和密码、重定向到登录表单等）。 使用用户名 user 和随机生成的密码创建一个 UserDetailsService bean，该密码登录到控制台。 使用名为 springSecurityFilterChain 的 bean 向 Servlet 容器注册过滤器。 Spring Boot 配置的并不多，但是却做了很多。 功能摘要如下：\n需要经过身份验证的用户才能与应用程序进行任何交互\n为您生成默认登录表单\n让用户名 user 和登录到控制台的密码的用户使用基于表单的身份验证进行身份验证\n使用 BCrypt 保护密码存储\n让用户登出\nCSRF 攻击预防\n会话固定保护\n安全标头集成\n用于安全请求的 HTTP 严格传输安全 X-Content-Type-Options 集成 缓存控制（稍后可以由您的应用程序覆盖以允许缓存静态资源） X-XSS-保护集成 X-Frame-Options 集成有助于防止点击劫持 与以下 Servlet API 方法集成：\nHttpServletRequest#getRemoteUser() HttpServletRequest.html#getUserPrincipal() HttpServletRequest.html#isUserInRole(java.lang.String) [HttpServletRequest.html#login(java.lang.String, java.lang.String)](https://docs.oracle.com/javaee/6/api/javax/servlet/http/HttpServletRequest.html#login(java.lang.String, java.lang.String)) HttpServletRequest.html#logout() 架构 客户端向应用程序发送请求，spring容器创建一个 FilterChain，该FilterChain包含多个Filters和一个处理请求的 Servlet 。 在 Spring MVC 应用程序中，该Servlet 是 DispatcherServlet 的一个实例。其中的一个Filter实现是DelegatingFilterProxy ，DelegatingFilterProxy 从spring 容器中查找 filter bean 并调用。 伪代码如下：\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) { // Lazily get Filter that was registered as a Spring Bean // For the example in DelegatingFilterProxy delegate is an instance of Bean Filter0 Filter delegate = getFilterBean(someBeanName); // delegate work to the Spring Bean delegate.doFilter(request, response); } Servlet 容器在启动的时候注册Filter，但此时，spring容器还未启动，自然不知道 Spring 定义的 filter Bean。 DelegatingFilterProxy使用延时加载将spring中实现的filter绑定到Servlet 容器生命周期（不是servlet中的注册Filter）。\nDelegatingFilterProxy 本身并不工作，他委托给SecurityFilterChain（Filter的一个实例），SecurityFilterChain将请求传递到filter 链路中\nFilterChainProxy 使用 SecurityFilterChain 来确定应为此请求调用哪些 Spring 安全过滤器。\n事实上，FilterChainProxy 可以用来确定应该使用哪个 SecurityFilterChain。 这允许为应用程序的不同部分提供完全独立的配置。\n图中，FilterChainProxy 决定应该使用哪个 SecurityFilterChain。 只会调用匹配的第一个 SecurityFilterChain。 如果请求 /api/messages/ 的 URL，它将首先匹配 SecurityFilterChain0 的 /api/ 模式，即使它也匹配 SecurityFilterChainn，也只会调用 SecurityFilterChain0。 如果请求 /messages/ 的 URL，它与 SecurityFilterChain****0 的 /api/ 模式不匹配，因此 FilterChainProxy 将继续尝试每个 SecurityFilterChain。 假设没有其他与 SecurityFilterChainn 匹配的 ，SecurityFilterChainn 实例将被调用。\n那么spring security到底提供了那些Filter供我们使用呢？\n以下是 Spring Security Filter 排序的完整列表：\nChannelProcessingFilter WebAsyncManagerIntegrationFilter SecurityContextPersistenceFilter HeaderWriterFilter CorsFilter CsrfFilter LogoutFilter OAuth2AuthorizationRequestRedirectFilter Saml2WebSsoAuthenticationRequestFilter X509AuthenticationFilter AbstractPreAuthenticatedProcessingFilter CasAuthenticationFilter OAuth2LoginAuthenticationFilter Saml2WebSsoAuthenticationFilter UsernamePasswordAuthenticationFilter OpenIDAuthenticationFilter DefaultLoginPageGeneratingFilter DefaultLogoutPageGeneratingFilter ConcurrentSessionFilter DigestAuthenticationFilter BearerTokenAuthenticationFilter BasicAuthenticationFilter RequestCacheAwareFilter SecurityContextHolderAwareRequestFilter JaasApiIntegrationFilter RememberMeAuthenticationFilter AnonymousAuthenticationFilter OAuth2AuthorizationCodeGrantFilter SessionManagementFilter ExceptionTranslationFilter FilterSecurityInterceptor SwitchUserFilter 常用的Filter ExceptionTranslationFilter ExceptionTranslationFilter 允许将 AccessDeniedException 和 AuthenticationException 转换为 HTTP 响应。\nExceptionTranslationFilter 调用 FilterChain.doFilter(request, response) 来调用应用程序的其余部分。 如果用户未通过身份验证或者是 AuthenticationException，则启动身份验证。 SecurityContextHolder 被清除 HttpServletRequest 保存在 RequestCache 中。 当用户认证成功时，RequestCache 用于重放原始请求。 AuthenticationEntryPoint 用于向客户端请求身份凭据。 例如，它可能会重定向到登录页面或发送 WWW-Authenticate 标头。 否则，如果它是 AccessDeniedException，则拒绝访问。 调用 AccessDeniedHandler 来处理拒绝访问。 认证 下面是认证相关的组件：\nSecurityContextHolder ：SecurityContextHolder 是 Spring Security 存储认证人员详细信息的地方。 SecurityContext ：从 SecurityContextHolder 获取并包含当前已验证用户的身份验证。 Authentication ：，存储用户的具体信息，例如用户名和权限信息。 GrantedAuthority ：授予主体的权限（即角色、范围等） AuthenticationManager ：Spring Security 的filter 使用该组件验证用户的身份信息。 ProviderManager ：AuthenticationManager 最常见的实现。 AuthenticationProvider ：由 ProviderManager 用于执行特定类型的身份验证。 AuthenticationEntryPoint ：向客户端请求凭据（即重定向到登录页面、发送 WWW-Authenticate 响应等） AbstractAuthenticationProcessingFilter ：用于身份验证的基本过滤器。 可以查看该类了解身份验证流程以及各个组件如何协同工作。 SecurityContextHolder SecurityContextHolder 存储所有已认证用户的信息。下面是SecurityContextHolder 设置用户信息的API\nSecurityContext context = SecurityContextHolder.createEmptyContext(); Authentication authentication = new TestingAuthenticationToken(\u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;, \u0026#34;ROLE_USER\u0026#34;); context.setAuthentication(authentication); SecurityContextHolder.setContext(context); SecurityContext context = SecurityContextHolder.getContext(); Authentication authentication = context.getAuthentication(); String username = authentication.getName(); Object principal = authentication.getPrincipal(); Collection\u0026lt;? extends GrantedAuthority\u0026gt; authorities = authentication.getAuthorities(); 默认情况下，SecurityContextHolder 使用 ThreadLocal 来存储这些详细信息，这意味着 SecurityContext 始终可用于同一线程中的方法，即使 SecurityContext 没有作为参数显式传递给这些方法。 如果在处理当前主体的请求后清除线程，以这种方式使用 ThreadLocal 是非常安全的。 Spring Security 的 FilterChainProxy 确保始终清除 SecurityContext。\n某些应用程序并不完全适合使用 ThreadLocal，因为它们使用线程的特定方式。 可以在启动时使用策略配置 SecurityContextHolder 以指定您希望如何存储上下文。\n对于独立应用程序，您可以使用 SecurityContextHolder.MODE_GLOBAL 策略。 其他应用程序可能希望安全线程产生的线程也采用相同的安全身份。 这是通过使用 SecurityContextHolder.MODE_INHERITABLETHREADLOCAL 实现的。 您可以通过两种方式更改策略。 第一个是设置系统属性，第二个是调用 SecurityContextHolder 上的静态方法。\nSecurityContext Authentication Authentication 在 Spring Security 中有两个主要目的：\n作为AuthenticationManager 的输入，用于用户身份验证的凭据。 在这种情况下，isAuthenticated() 返回 false。 代表当前经过身份验证的用户。 当前的身份验证可以从 SecurityContext 中获取。 Authentication包含：\nprincipal：- 识别用户。 当使用用户名/密码进行身份验证时，这通常是 UserDetails 的一个实例。 credentials：通常是密码。 在许多情况下，这将在用户通过身份验证后被清除，以确保它不会泄露。 authorities：- GrantedAuthoritys 是授予用户的高级权限。 一些示例是角色或范围。 GrantedAuthority GrantedAuthoritys 可以从 Authentication.getAuthorities() 方法获得。 此方法提供了 GrantedAuthority 对象的集合。 毫无疑问，GrantedAuthority 是授予主体的权限。 此类权限通常是“角色”，例如 ROLE_ADMINISTRATOR 或 ROLE_HR_SUPERVISOR。 当使用基于用户名/密码的身份验证时，GrantedAuthoritys 通常由 UserDetailsService 加载。\n通常 GrantedAuthority 是说用户对应用程序的权限。 它们并不特定于给定的域对象（数据权限）。 因此，您不可能有一个 GrantedAuthority 来表示对 Employee 对象编号 54 的权限，因为如果有数千个这样的权限，您将很快耗尽内存。\nAuthenticationManager AuthenticationManager 是定义 Spring Security 的过滤器如何执行身份验证的 API。 控制器（spring security filter）调用 AuthenticationManager 认证用户，返回 Authentication，然后设置 在SecurityContextHolder 中。AuthenticationManager 最常见的实现是 ProviderManager。\nProviderManager ProviderManager 支持多种类型的身份验证，他委托 AuthenticationProvider 列表工作。 每个 AuthenticationProvider 执行特定的身份验证，都有机会表明身份验证应该成功、失败或表明它无法做出决定并允许下游 AuthenticationProvider 做出决定。 如果配置的 AuthenticationProvider列表都无法进行身份验证，则身份验证将失败并显示 ProviderNotFoundException，这是一个特殊的 AuthenticationException。\nProviderManager 还允许配置一个可选的父 AuthenticationManager，在没有 AuthenticationProvider 可以执行身份验证的情况下咨询它。 parent 可以是任何类型的 AuthenticationManager，但它通常是 ProviderManager 的实例。\n事实上，多个 ProviderManager 实例可能共享同一个父 AuthenticationManager。 这在有多个 SecurityFilterChain 实例具有一些共同的身份验证（共享父 AuthenticationManager）但也有不同的身份验证机制（不同的 ProviderManager 实例）的情况下很常见。\n默认情况下，ProviderManager 将尝试从成功的身份验证请求返回的 Authentication 对象中清除任何敏感凭据信息。 这可以防止密码等信息在 HttpSession 中保留的时间超过所需时间。\nAuthenticationProvider AuthenticationEntryPoint 客户端没有登录，访问未经身份验证的请求时，AuthenticationEntryPoint 实现会执行重定向到登录页面，使用 WWW-Authenticate 标头等进行响应。\nAbstractAuthenticationProcessingFilter 当用户提交他们的凭据时，AbstractAuthenticationProcessingFilter 从 HttpServletRequest 创建一个 Authentication 以进行身份验证。 创建的身份验证类型取决于 AbstractAuthenticationProcessingFilter 的子类。 例如，UsernamePasswordAuthenticationFilter 根据在 HttpServletRequest 中提交的用户名和密码创建一个 UsernamePasswordAuthenticationToken。 接下来，将 Authentication 传递到 AuthenticationManager 进行身份验证。 如果身份验证失败，则失败 SecurityContextHolder 被清除。 调用 RememberMeServices.loginFail。 如果记住我没有配置，这是一个空操作。 AuthenticationFailureHandler 被调用。 如果身份验证成功，则成功。 SessionAuthenticationStrategy 收到新登录通知。 身份验证是在 SecurityContextHolder 上设置的。 稍后 SecurityContextPersistenceFilter 将 SecurityContext 保存到 HttpSession。 调用 RememberMeServices.loginSuccess 。 如果记住我没有配置，这是一个空操作。 ApplicationEventPublisher 发布 InteractiveAuthenticationSuccessEvent。 AuthenticationSuccessHandler 被调用。 用户密码认证 Spring Security 提供了以下内置机制来从 HttpServletRequest 读取用户名和密码：\nForm Login Basic Authentication Digest Authentication 表单登录 首先，用户向其未授权的资源 /private 发出未经身份验证的请求。 Spring Security 的 FilterSecurityInterceptor 通过抛出 AccessDeniedException 指示未经身份验证的请求被拒绝。 由于用户未通过身份验证，ExceptionTranslationFilter 启动启动身份验证并使用已配置的 AuthenticationEntryPoint 将重定向发送到登录页面。 在大多数情况下，AuthenticationEntryPoint 是 LoginUrlAuthenticationEntryPoint 的一个实例。 然后浏览器将请求它重定向到的登录页面。 呈现登录页面 提交用户名和密码后，UsernamePasswordAuthenticationFilter 会验证用户名和密码。 UsernamePasswordAuthenticationFilter 扩展了 AbstractAuthenticationProcessingFilter。\nimg 当用户提交他们的用户名和密码时，UsernamePasswordAuthenticationFilter 通过从 HttpServletRequest 中提取用户名和密码来创建一个 UsernamePasswordAuthenticationToken，这是一种Authentication。 接下来，将 UsernamePasswordAuthenticationToken 传递到 AuthenticationManager 进行身份验证。 AuthenticationManager 的详细信息取决于用户信息的存储方式。 如果身份验证失败，则失败 SecurityContextHolder 被清除。 调用 RememberMeServices.loginFail。如果记住我没有配置，这是一个空操作。 AuthenticationFailureHandler 被调用。 如果身份验证成功，则成功。 SessionAuthenticationStrategy 收到新登录通知。 身份验证是在 SecurityContextHolder 上设置的。 调用 RememberMeServices.loginSuccess 。如果记住我没有配置，这是一个空操作。 ApplicationEventPublisher 发布 InteractiveAuthenticationSuccessEvent。 AuthenticationSuccessHandler 被调用。通常，这是一个 SimpleUrlAuthenticationSuccessHandler，当我们重定向到登录页面时，它将重定向到 ExceptionTranslationFilter 保存的请求。 默认情况下启用 Spring Security 表单登录。 但是，一旦提供了任何基于 servlet 的配置，就必须明确提供基于表单的登录。 可以在下面找到一个最小的、显式的 Java 配置：\nprotected void configure(HttpSecurity http) { http // ... .formLogin(withDefaults()); } 下面的配置演示了如何提供自定义登录表单:\nprotected void configure(HttpSecurity http) throws Exception { http // ... .formLogin(form -\u0026gt; form .loginPage(\u0026#34;/login\u0026#34;) .permitAll() ); } 上面配置的登录页面如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns=\u0026#34;http://www.w3.org/1999/xhtml\u0026#34; xmlns:th=\u0026#34;https://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Please Log In\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Please Log In\u0026lt;/h1\u0026gt; \u0026lt;div th:if=\u0026#34;${param.error}\u0026#34;\u0026gt; Invalid username and password.\u0026lt;/div\u0026gt; \u0026lt;div th:if=\u0026#34;${param.logout}\u0026#34;\u0026gt; You have been logged out.\u0026lt;/div\u0026gt; \u0026lt;form th:action=\u0026#34;@{/login}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; placeholder=\u0026#34;Username\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34; placeholder=\u0026#34;Password\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Log in\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 表单应提交到 /login 的 该表单包含一个由 Thymeleaf 自动包含的 CSRF 令牌。 表单应在名为 username 的参数中指定用户名 表单应在名为 password 的参数中指定密码 如果发现HTTP参数错误，说明用户未能提供有效的用户名/密码 如果找到 HTTP 参数 logout，则表示用户已成功注销 许多用户只需要自定义登录页面即可。 但是，如果需要，以上所有内容都可以通过其他配置进行自定义。\nBasic 认证 首先，用户向其未授权的资源 /private 发出未经身份验证的请求。 Spring Security 的 FilterSecurityInterceptor 通过抛出 AccessDeniedException 指示未经身份验证的请求被拒绝。 由于用户未通过身份验证，ExceptionTranslationFilter处理异常。 配置的 AuthenticationEntryPoint 是 BasicAuthenticationEntryPoint 的一个实例，它发送 WWW-Authenticate 标头。 RequestCache 通常是一个 NullRequestCache，它不保存请求，因为客户端能够重放它最初请求的请求。 当客户端收到 WWW-Authenticate 标头时，它知道它应该使用用户名和密码重试。\n默认情况下启用 Spring Security 的 HTTP 基本身份验证支持。 但是，一旦提供了任何基于 servlet 的配置，就必须明确提供 HTTP Basic。\nDigest 认证 您不应使用摘要式身份验证，因为它被认为是不安全的。 最明显的问题是您必须以明文、加密或 MD5 格式存储密码。 所有这些存储格式都被认为是不安全的。 相反，您应该使用摘要式身份验证不支持的单向自适应密码哈希（即 bCrypt、PBKDF2、SCrypt 等）存储密码。\n摘要式身份验证尝试解决basic身份验证的许多弱点，特别是以非明文形式通过网络发送凭据。 许多浏览器都支持摘要式身份验证。摘要式身份验证的核心是“nonce”, 这是服务器生成的值。 Spring Security 的 nonce 采用以下格式：\nbase64(expirationTime + \u0026#34;:\u0026#34; + md5Hex(expirationTime + \u0026#34;:\u0026#34; + key)) expirationTime:nonce 过期的日期和时间，以毫秒表示 key:防止修改 nonce 令牌的私钥 @Autowired UserDetailsService userDetailsService; DigestAuthenticationEntryPoint entryPoint() { DigestAuthenticationEntryPoint result = new DigestAuthenticationEntryPoint(); result.setRealmName(\u0026#34;My App Relam\u0026#34;); result.setKey(\u0026#34;3028472b-da34-4501-bfd8-a355c42bdf92\u0026#34;); } DigestAuthenticationFilter digestAuthenticationFilter() { DigestAuthenticationFilter result = new DigestAuthenticationFilter(); result.setUserDetailsService(userDetailsService); result.setAuthenticationEntryPoint(entryPoint()); } protected void configure(HttpSecurity http) throws Exception { http // ... .exceptionHandling(e -\u0026gt; e.authenticationEntryPoint(authenticationEntryPoint())) .addFilterBefore(digestFilter()); } 内存存储认证信息 InMemoryUserDetailsManager 实现了 UserDetailsService 以提供在内存中检索的基于用户名/密码的身份验证的支持。 InMemoryUserDetailsManager 通过实现 UserDetailsManager 接口提供对 UserDetails 的管理。 当 Spring Security 配置为接受用户名/密码进行身份验证时，将使用基于 UserDetails 的身份验证。\n@Bean public UserDetailsService users() { UserDetails user = User.builder() .username(\u0026#34;user\u0026#34;) .password(\u0026#34;{bcrypt}$2a$10$GRLdNijSQMUvl/au9ofL.eDwmoohzzS7.rmNSJZ.0FxO/BTk76klW\u0026#34;) .roles(\u0026#34;USER\u0026#34;) .build(); UserDetails admin = User.builder() .username(\u0026#34;admin\u0026#34;) .password(\u0026#34;{bcrypt}$2a$10$GRLdNijSQMUvl/au9ofL.eDwmoohzzS7.rmNSJZ.0FxO/BTk76klW\u0026#34;) .roles(\u0026#34;USER\u0026#34;, \u0026#34;ADMIN\u0026#34;) .build(); return new InMemoryUserDetailsManager(user, admin); } JDBC存储认证信息 JdbcDaoImpl 实现了 UserDetailsService 以提供对使用 JDBC 检索的基于用户名/密码的身份验证的支持。 JdbcUserDetailsManager 继承 JdbcDaoImpl 并实现UserDetailsManager 接口提供对 UserDetails 的管理。 当 Spring Security 配置为接受用户名/密码进行身份验证时，将使用基于 UserDetails 的身份验证。\n默认的SQL:\ncreate table users( username varchar_ignorecase(50) not null primary key, password varchar_ignorecase(500) not null, enabled boolean not null ); create table authorities ( username varchar_ignorecase(50) not null, authority varchar_ignorecase(50) not null, constraint fk_authorities_users foreign key(username) references users(username) ); create unique index ix_auth_username on authorities (username,authority); create table groups ( id bigint generated by default as identity(start with 0) primary key, group_name varchar_ignorecase(50) not null ); create table group_authorities ( group_id bigint not null, authority varchar(50) not null, constraint fk_group_authorities_group foreign key(group_id) references groups(id) ); create table group_members ( id bigint generated by default as identity(start with 0) primary key, username varchar(50) not null, group_id bigint not null, constraint fk_group_members_group foreign key(group_id) references groups(id) ); java配置如下：\n@Bean UserDetailsManager users(DataSource dataSource) { UserDetails user = User.builder() .username(\u0026#34;user\u0026#34;) .password(\u0026#34;{bcrypt}$2a$10$GRLdNijSQMUvl/au9ofL.eDwmoohzzS7.rmNSJZ.0FxO/BTk76klW\u0026#34;) .roles(\u0026#34;USER\u0026#34;) .build(); UserDetails admin = User.builder() .username(\u0026#34;admin\u0026#34;) .password(\u0026#34;{bcrypt}$2a$10$GRLdNijSQMUvl/au9ofL.eDwmoohzzS7.rmNSJZ.0FxO/BTk76klW\u0026#34;) .roles(\u0026#34;USER\u0026#34;, \u0026#34;ADMIN\u0026#34;) .build(); JdbcUserDetailsManager users = new JdbcUserDetailsManager(dataSource); users.createUser(user); users.createUser(admin); return users; } UserDetails UserDetails 由 UserDetailsService 返回。 DaoAuthenticationProvider 验证 UserDetails，然后返回具有主体的Authentication ，该主体是配置的 UserDetailsService 返回的 UserDetails。\nUserDetailsService DaoAuthenticationProvider 使用 UserDetailsService 来检索用户名、密码和其他属性，以使用用户名和密码进行身份验证。 Spring Security 提供了 UserDetailsService 的内存和 JDBC 实现。\n您可以通过将自定义 UserDetailsService 公开为 bean 来定义自定义身份验证。 例如，假设 CustomUserDetailsService 实现 UserDetailsService，以下将自定义身份验证：\n@Bean CustomUserDetailsService customUserDetailsService() { return new CustomUserDetailsService(); } PasswordEncoder Spring Security 的 servlet 通过与 PasswordEncoder 集成来支持安全存储密码。 可以通过公开 PasswordEncoder Bean 来自定义 Spring Security 使用的 PasswordEncoder 实现。\nDaoAuthenticationProvider DaoAuthenticationProvider 是一个 AuthenticationProvider 实现，它利用 UserDetailsService 和 PasswordEncoder 来验证用户名和密码。\n我们来看看 DaoAuthenticationProvider 在 Spring Security 中是如何工作的。 该图详细说明了来自读取用户名和密码的图中的 AuthenticationManager 如何工作。\n来自读取用户名和密码的身份验证过滤器将 UsernamePasswordAuthenticationToken 传递给由 ProviderManager 实现的 AuthenticationManager。 ProviderManager 被配置为使用 DaoAuthenticationProvider 类型的 AuthenticationProvider。 DaoAuthenticationProvider 从 UserDetailsService 中查找 UserDetails。 DaoAuthenticationProvider 然后使用 PasswordEncoder 验证上一步返回的 UserDetails 上的密码。 当身份验证成功时，返回的身份验证类型为 UsernamePasswordAuthenticationToken 并且具有一个主体，即配置的 UserDetailsService 返回的 UserDetails。 最终，返回的 UsernamePasswordAuthenticationToken 将由身份验证过滤器在 SecurityContextHolder 上设置。 授权 GrantedAuthority 代表主体的权限信息，由 AuthenticationManager 插入到 Authentication 对象中，稍后在做出授权决定时由 AccessDecisionManager 读取。GrantedAuthority是一个接口：\nString getAuthority(); 此方法允许 AccessDecisionManager 获得表示权限的精确字符串。 大多数权限都可以使用字符串表示，极少部分复杂的权限不能用是字符串表示，此时 getAuthority() 必须返回 null。\nSimpleGrantedAuthority是具体的 GrantedAuthority 实现。 这允许将任何用户指定的字符串转换为 GrantedAuthority。 架构中包含的所有 AuthenticationProvider 都使用 SimpleGrantedAuthority 来填充 Authentication 对象。\nAccessDecisionManager Spring Security 提供拦截器来控制对安全对象的访问，例如方法调用或 Web 请求。 AccessDecisionManager 做出关于是否允许调用继续进行的调用前决定。\nAccessDecisionManager 由 AbstractSecurityInterceptor 调用，负责做出最终的访问控制决策。AccessDecisionManager 接口包含三个方法：\nint vote(Authentication authentication, Object object, Collection\u0026lt;ConfigAttribute\u0026gt; attrs); boolean supports(ConfigAttribute attribute); boolean supports(Class clazz); AccessDecisionManager 的decide方法传递了它需要的所有相关信息，以便做出授权决定。 object传递安全对象，例如此时对方法进行鉴权，此时的object是MethodInvocation，可以很轻松的获取方法上的信息，和实际入参。 Supports(ConfigAttribute) 方法在启动时被 AbstractSecurityInterceptor 调用，以确定 AccessDecisionManager 是否可以处理传递的 ConfigAttribute。 supports(Class) 方法由security interceptor实现调用，以确保配置的 AccessDecisionManager 支持secure object 类型。 基于投票的 AccessDecisionManager 实现 虽然用户可以实现他们自己的 AccessDecisionManager 来控制授权的所有方面，但 Spring Security 包括几个基于投票的 AccessDecisionManager 实现。\n使用这种方法，一系列 AccessDecisionVoter 实现被轮询授权决策。 AccessDecisionManager 评估投票结果决定是否抛出 AccessDeniedException。AccessDecisionVoter 接口如下：\nint vote(Authentication authentication, Object object, Collection\u0026lt;ConfigAttribute\u0026gt; attrs); boolean supports(ConfigAttribute attribute); boolean supports(Class clazz); vote方法返回的int值是ACCESS_ABSTAIN、ACCESS_DENIED 和ACCESS_GRANTED。 如果对授权决定没有意见，投票实现将返回 ACCESS_ABSTAIN。 如果它确实有意见，则必须返回 ACCESS_DENIED 或 ACCESS_GRANTED。\nAccessDecisionManager 有三个具体的实现：\nConsensusBased ：排除ACCESS_ABSTAIN票，统计ACCESS_DENIED 和 ACCESS_GRANTED票数授权。此外，提供属性以控制票数相等或所有票数都弃权时的行为。 AffirmativeBased ：只要收到一个ACCESS_GRANTED，则同意授权。同样，提供参数控制当所有都弃权时的决定。 UnanimousBased ：只要有ACCESS_DENIED ，则授权不通过。同样，提供参数控制当所有都弃权时的决定。 可以实现自定义的 AccessDecisionManager 来计算投票。 例如，来自特定 AccessDecisionVoter 的投票可能会获得额外的权重，而来自特定选民的拒绝投票可能具有否决权。\nRoleVoter\nRoleVoter是最常用的AccessDecisionVoter ，配置是角色名称，用户拥有该角色，则授权通过。ConfigAttribute 以 ROLE_ 开头，则进行投票，否则丢弃，视为弃权。\nAuthenticatedVoter\n可用于区分匿名、完全身份验证和记住我身份验证的用户。 许多站点允许在记住我身份验证下进行某些有限访问，但要求用户通过登录以获取完全访问权限来确认其身份。当我们使用属性 IS_AUTHENTICATED_ANONYMOUSLY 授予匿名访问权限时，该属性正在由 AuthenticatedVoter 处理。\n自定义投票器\n虽然 AccessDecisionManager 在安全对象调用之前由 AbstractSecurityInterceptor 调用，但一些应用程序需要一种修改安全对象调用实际返回的对象的方法。 虽然您可以轻松实现自己的 AOP 关注来实现这一点，但 Spring Security 提供了一个方便的钩子，它具有几个与其 ACL 功能集成的具体实现。\nAfterInvocationManager 有一个具体的实现 AfterInvocationProviderManager，它轮询 AfterInvocationProvider 的列表。 允许每个 AfterInvocationProvider 修改返回对象或抛出 AccessDeniedException。前一个提供者修改后的结果被传递到列表中的下一个。\n应用程序中的特定角色应该自动“包含”其他角色是一个常见的要求。 例如，在具有“管理员”和“用户”角色概念的应用程序中，您可能希望管理员能够执行普通用户可以执行的所有操作。 为此，您可以确保所有管理员用户也都被分配了“用户”角色。 如果您的应用程序中有很多不同的角色，这会变得非常复杂。\n角色层次结构的使用允许您配置哪些角色（或权限）应该包括其他角色（或权限）。 RoleVoter 的扩展版本 RoleHierarchyVoter 配置了 RoleHierarchy，从中获取分配给用户的所有“可访问权限”。 典型的配置可能如下所示：\n\u0026lt;bean id=\u0026#34;roleVoter\u0026#34; class=\u0026#34;org.springframework.security.access.vote.RoleHierarchyVoter\u0026#34;\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;roleHierarchy\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;roleHierarchy\u0026#34; class=\u0026#34;org.springframework.security.access.hierarchicalroles.RoleHierarchyImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;hierarchy\u0026#34;\u0026gt; \u0026lt;value\u0026gt; ROLE_ADMIN \u0026gt; ROLE_STAFF ROLE_STAFF \u0026gt; ROLE_USER ROLE_USER \u0026gt; ROLE_GUEST \u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 这里我们在层次结构中有四个角色 ROLE_ADMIN ⇒ ROLE_STAFF ⇒ ROLE_USER ⇒ ROLE_GUEST。 当针对使用上述 RoleHierarchyVoter 配置的 AccessDecisionManager 评估安全约束时，使用 ROLE_ADMIN 进行身份验证的用户将表现得好像他们拥有所有四个角色。 \u0026gt; 符号可以被认为是“包括”的意思。\nweb权限控制 FilterSecurityInterceptor 为 HttpServletRequests 提供授权。 它作为安全过滤器之一插入到 FilterChainProxy 中\n首先，FilterSecurityInterceptor 从 SecurityContextHolder 获得一个 Authentication。 其次，根据传递到 FilterSecurityInterceptor 的 HttpServletRequest、HttpServletResponse 和 FilterChain 创建一个 FilterInvocation。 接下来，它将 FilterInvocation 传递给 SecurityMetadataSource 以获取 ConfigAttributes。 最后，它将 Authentication、FilterInvocation 和 ConfigAttributes 传递给 AccessDecisionManager。 如果授权被拒绝，则抛出 AccessDeniedException。 在这种情况下，ExceptionTranslationFilter 处理 AccessDeniedException。 如果访问被授予，FilterSecurityInterceptor 将继续使用 FilterChain，这允许应用程序正常处理。 默认情况下，Spring Security 的授权将要求对所有请求进行身份验证。 显式配置如下所示：\nprotected void configure(HttpSecurity http) throws Exception { http // ... .authorizeRequests(authorize -\u0026gt; authorize .anyRequest().authenticated() ); } 我们可以通过按优先顺序添加更多规则来配置 Spring Security 以具有不同的规则:\nprotected void configure(HttpSecurity http) throws Exception { http // ... .authorizeRequests(authorize -\u0026gt; authorize .mvcMatchers(\u0026#34;/resources/**\u0026#34;, \u0026#34;/signup\u0026#34;, \u0026#34;/about\u0026#34;).permitAll() .mvcMatchers(\u0026#34;/admin/**\u0026#34;).hasRole(\u0026#34;ADMIN\u0026#34;) .mvcMatchers(\u0026#34;/db/**\u0026#34;).access(\u0026#34;hasRole(\u0026#39;ADMIN\u0026#39;) and hasRole(\u0026#39;DBA\u0026#39;)\u0026#34;) .anyRequest().denyAll() ); } 权限表达式 使用EL表达式来支持权限控制。表达式根对象的基类是 SecurityExpressionRoot。 这提供了一些在 Web 和方法安全中都可用的常用表达式。\nExpression Description hasRole(String role) 如果当前主体具有指定的角色，则返回 true。例如，hasRole('admin')默认情况下，如果提供的角色不以 \u0026lsquo;ROLE_\u0026rsquo; 开头，它将被添加。 这可以通过修改 DefaultWebSecurityExpressionHandler 上的 defaultRolePrefix 来自定义。 hasAnyRole(String… roles) 如果当前主体具有任何提供的角色（以逗号分隔的字符串列表形式给出），则返回 true。例如，hasAnyRole('admin', 'user')默认情况下，如果提供的角色未启动 带有“ROLE_”，它将被添加。 这可以通过修改 DefaultWebSecurityExpressionHandler 上的 defaultRolePrefix 来自定义。 hasAuthority(String authority) 如果当前主体具有指定的权限，则返回 true。例如，hasAuthority('read') hasAnyAuthority(String… authorities) 如果当前主体具有任何提供的权限（以逗号分隔的字符串列表形式给出），则返回 true 例如，hasAnyAuthority('read', 'write') principal 允许直接访问代表当前用户的主体对象 authentication 允许直接访问从“SecurityContext”获得的当前“Authentication”对象 permitAll 始终评估为“true” denyAll 始终评估为“false” isAnonymous() 如果当前主体是匿名用户，则返回 true isRememberMe() 如果当前主体是记住我的用户，则返回 true isAuthenticated() 如果用户不是匿名的，则返回 true isFullyAuthenticated() 如果用户不是匿名用户或记住我的用户，则返回 true hasPermission(Object target, Object permission) 如果用户有权访问给定权限的提供目标，则返回 true。 例如，hasPermission(domainObject, 'read') hasPermission(Object targetId, String targetType, Object permission) 如果用户有权访问给定权限的提供目标，则返回 true。 例如，hasPermission(1, 'com.example.domain.Message', 'read') 如果您希望扩展更多的表达式，您可以轻松引用您公开的任何 Spring Bean。 例如，假设您有一个名为 webSecurity 的 Bean，其中包含以下方法签名：\npublic class WebSecurity { public boolean check(Authentication authentication, HttpServletRequest request) { ... } } 您可以使用以下方式引用该方法：\nhttp .authorizeRequests(authorize -\u0026gt; authorize .antMatchers(\u0026#34;/user/**\u0026#34;).access(\u0026#34;@webSecurity.check(authentication,request)\u0026#34;) ... ) 有时，能够在 URL 中引用路径变量是件好事。 例如，考虑一个 RESTful 应用程序，它通过格式 /user/{userId} 的 URL 路径中的 id 查找用户。\n您可以通过将它放在模式中来轻松引用路径变量。 例如，如果您有一个名为 webSecurity 的 Bean，其中包含以下方法签名：\nhttp .authorizeRequests(authorize -\u0026gt; authorize .antMatchers(\u0026#34;/user/{userId}/**\u0026#34;).access(\u0026#34;@webSecurity.checkUserId(authentication,#userId)\u0026#34;) ... ); 方法上的安全表达式 方法安全性比简单的允许或拒绝规则要复杂一些。 Spring Security 3.0 引入了一些新的注解，以便全面支持表达式的使用。\n@Pre and @Post 有四个注解支持表达式属性，以允许调用前和调用后授权检查，并支持过滤提交的集合参数或返回值。 它们是@PreAuthorize、@PreFilter、@PostAuthorize 和@PostFilter。 它们的使用是通过 global-method-security 命名空间元素启用的：\n@PreAuthorize(\u0026#34;hasRole(\u0026#39;USER\u0026#39;)\u0026#34;) public void create(Contact contact); 这意味着只有具有“ROLE_USER”角色的用户才能访问。\n@PreAuthorize(\u0026#34;hasPermission(#contact, \u0026#39;admin\u0026#39;)\u0026#34;) public void deletePermission(Contact contact, Sid recipient, Permission permission); 在这里，我们实际上使用方法参数作为表达式的一部分来确定当前用户是否具有给定Contact的“admin”权限。 内置 hasPermission() 表达式通过应用程序上下文链接到 Spring Security ACL 模块，我们将在下面看到。 您可以按名称作为表达式变量访问任何方法参数。\nSpring Security 可以通过多种方式解析方法参数。 Spring Security 使用 DefaultSecurityParameterNameDiscoverer 来发现参数名称。 默认情况下，对整个方法尝试以下选项。\n如果 Spring Security 的 @P 注释存在于该方法的单个参数上，则将使用该值。 这对于使用 JDK 8 之前的 JDK 编译的接口非常有用，这些接口不包含任何有关参数名称的信息。 例如：\nimport org.springframework.security.access.method.P; ... @PreAuthorize(\u0026#34;#c.name == authentication.name\u0026#34;) public void doSomething(@P(\u0026#34;c\u0026#34;) Contact contact); 在幕后，这是使用 AnnotationParameterNameDiscoverer 实现的.\n如果 Spring Data 的 @Param 注释存在于该方法的至少一个参数上，则将使用该值。 这对于使用 JDK 8 之前的 JDK 编译的接口非常有用，这些接口不包含任何有关参数名称的信息。 例如：\nimport org.springframework.data.repository.query.Param; ... @PreAuthorize(\u0026#34;#n == authentication.name\u0026#34;) Contact findContactByName(@Param(\u0026#34;n\u0026#34;) String name); 在幕后，这是使用 AnnotationParameterNameDiscoverer 实现的\n如果使用 JDK 8 编译带有 -parameters 参数的源代码并且使用 Spring 4+，则使用标准 JDK 反射 API 来发现参数名称。 这适用于类和接口。\n最后，如果代码是用debug符号编译的，参数名称将使用调试符号被发现。 这不适用于接口，因为它们没有关于参数名称的调试信息。 对于接口，必须使用注释或 JDK 8 方法。\n表达式中可以使用任何 Spring-EL 功能，因此您还可以访问参数上的属性。 例如，如果你想要一个特定的方法只允许访问用户名与联系人匹配的用户，你可以写:\n@PreAuthorize(\u0026#34;#contact.name == authentication.name\u0026#34;) public void doSomething(Contact contact); 这里我们访问另一个内置表达式，authentication，它是存储在安全上下文中的 Authentication。 您还可以使用表达式 principal 直接访问其“principal”属性。 该值通常是一个 UserDetails 实例，因此您可以使用诸如 principal.username 或 principal.enabled 之类的表达式。\n不太常见的是，您可能希望在调用方法后执行访问控制检查。 这可以使用@PostAuthorize 注释来实现。 要访问方法的返回值，请在表达式中使用内置名称 returnObject。\n@PreFilter and @PostFilter Spring Security 支持使用表达式过滤集合、数组、映射和流。 这通常在方法的返回值上执行。 例如：\n@PreAuthorize(\u0026#34;hasRole(\u0026#39;USER\u0026#39;)\u0026#34;) @PostFilter(\u0026#34;hasPermission(filterObject, \u0026#39;read\u0026#39;) or hasPermission(filterObject, \u0026#39;admin\u0026#39;)\u0026#34;) public List getAll(); 使用 @PostFilter 注释时，Spring Security 会遍历返回的集合或map，并删除表达式为 false 的元素。 对于数组，将返回一个包含过滤元素的新数组实例。 名称 filterObject 指的是集合中的当前对象。 如果使用map，它将引用当前的 Map.Entry 对象，该对象允许在表达式中使用 filterObject.key 或 filterObject.value。 您还可以在方法调用之前使用 @PreFilter 进行过滤，尽管这是一个不太常见的要求。 语法是一样的，但是如果有多个参数是集合类型，那么您必须使用此注释的 filterTarget 属性按名称选择一个。\n请注意，过滤显然不能替代调整您的数据检索查询。 如果您要过滤大型集合并删除许多条目，那么这可能效率低下。\n有一些特定于方法安全性的内置表达式，我们已经在上面使用过。 filterTarget 和 returnValue 值很简单，但是 hasPermission() 表达式的使用值得仔细研究。\nhasPermission() 表达式被委托给 PermissionEvaluator 的一个实例。 它旨在在表达式系统和 Spring Security 的 ACL 系统之间架起桥梁，允许您根据抽象权限指定对域对象的授权约束。 它对 ACL 模块没有显式依赖，因此您可以根据需要将其替换为替代实现。 该接口有两种方法：\nboolean hasPermission(Authentication authentication, Object targetDomainObject, Object permission); boolean hasPermission(Authentication authentication, Serializable targetId, String targetType, Object permission); 第一种用于访问被控制的域对象已经加载的情况。 如果当前用户对该对象具有给定的权限，则表达式将返回 true。 第二个版本用于未加载对象但其标识符已知的情况。 还需要域对象的抽象“类型”说明符，以允许加载正确的 ACL 权限。 这在传统上是对象的 Java 类，但只要与加载权限的方式一致，就不必如此。\n@Secured 我们可以在任何 @Configuration 实例上使用 @EnableGlobalMethodSecurity 启用基于注解的安全性。 例如，以下将启用 Spring Security 的 @Secured 注解。\n@EnableGlobalMethodSecurity(securedEnabled = true) public class MethodSecurityConfig { // ... } 向方法（在类或接口上）添加注释将相应地限制对该方法的访问。 Spring Security 的原生注解支持为该方法定义了一组属性。 这些将传递给 AccessDecisionManager 以供其做出实际决定：\npublic interface BankService { @Secured(\u0026#34;IS_AUTHENTICATED_ANONYMOUSLY\u0026#34;) public Account readAccount(Long id); @Secured(\u0026#34;IS_AUTHENTICATED_ANONYMOUSLY\u0026#34;) public Account[] findAccounts(); @Secured(\u0026#34;ROLE_TELLER\u0026#34;) public Account post(Account account, double amount); } 这些是基于标准的，允许应用简单的基于角色的约束，但没有 Spring Security 的原生注释的能力。 要使用新的基于表达式的语法，您可以使用:\n@EnableGlobalMethodSecurity(prePostEnabled = true) public class MethodSecurityConfig { // ... } public interface BankService { @PreAuthorize(\u0026#34;isAnonymous()\u0026#34;) public Account readAccount(Long id); @PreAuthorize(\u0026#34;isAnonymous()\u0026#34;) public Account[] findAccounts(); @PreAuthorize(\u0026#34;hasAuthority(\u0026#39;ROLE_TELLER\u0026#39;)\u0026#34;) public Account post(Account account, double amount); } 加密 加密历史 多年来，存储密码的标准机制不断发展。起初，密码以纯文本形式存储。密码被认为是安全的，因为密码被保存在访问它所需的凭据中。但是，恶意用户能够使用 SQL 注入等攻击获取大量用户名和密码的方法。随着越来越多的用户凭证泄露，我们意识到我们需要做更多的工作来保护用户的密码。\n然后鼓励开发人员通过单向哈希（例如 SHA-256）加密后存储密码。当用户尝试进行身份验证时，散列密码将与他们键入的密码的散列进行比较。这意味着系统只需要存储密码的单向哈希。如果发生违规，则仅暴漏密码的一种散列方式。由于散列是一种方式，并且在给定散列的情况下猜测密码在计算上很困难，因此不值得努力找出系统中的每个密码。为了打败这个新系统，恶意用户决定创建称为彩虹表的查找表。他们不是每次都猜测每个密码，而是计算一次密码并将其存储在查找表中。\n为了降低 Rainbow Tables 的有效性，鼓励开发人员使用加盐密码。不是只使用密码作为散列函数的输入，而是会为每个用户的密码生成随机字节（称为盐）。盐和用户的密码将通过哈希函数运行，产生唯一的哈希值。盐将以明文形式与用户密码一起存储。然后，当用户尝试进行身份验证时，散列密码将与存储的盐和他们键入的密码的散列进行比较。独特的盐意味着彩虹表不再有效，因为每个盐和密码组合的哈希值都不同。\n在现代，我们意识到加密哈希（如 SHA-256）不再安全。原因是使用现代硬件，我们可以每秒执行数十亿次哈希计算。这意味着我们可以轻松地单独破解每个密码。\n现在鼓励开发人员利用自适应单向函数来存储密码。使用自适应单向函数验证密码会过多占用资源（即 CPU、内存等）的。自适应单向函数允许配置“工作系数”，该系数可以随着硬件的改进而增长。建议将“工作系数”调整为大约需要 1 秒来验证系统上的密码。这种权衡是为了让攻击者难以破解密码，但成本不会高到给您自己的系统带来过大的负担。 Spring Security 试图为“工作系数”提供一个良好的起点，但鼓励用户为他们自己的系统定制“工作系数”，因为性能会因系统而异。应该使用的自适应单向函数的示例包括 bcrypt、PBKDF2、scrypt 和 argon2。\n由于自适应单向函数有意占用大量资源，因此为每个请求验证用户名和密码将显着降低应用程序的性能。 Spring Security（或任何其他库）无法加速密码验证，因为通过使验证资源密集型来获得安全性。鼓励用户将长期凭据（即用户名和密码）交换为短期凭据（即会话、OAuth 令牌等）。短期凭证可以快速验证，而不会造成任何安全损失。\nDelegatingPasswordEncoder Spring Security 的 PasswordEncoder 接口用于执行密码的单向转换，以允许安全地存储密码。 鉴于 PasswordEncoder 是一种单向转换，不能反向解密。 PasswordEncoder还提供了比较密码功能。\nSpring Security 默认使用 DelegatingPasswordEncoder。 但是，这可以通过将 PasswordEncoder 公开为 Spring bean 来定制。\n在 Spring Security 5.0 之前，默认的 PasswordEncoder 是 NoOpPasswordEncoder，它不对密码进行加密。 根据 Password History 部分，您可能期望默认 PasswordEncoder 是 BCryptPasswordEncoder。 然而，这忽略了三个问题：\n有许多应用程序使用无法轻松迁移的旧密码编码 密码存储的最佳做法将再次改变。 作为一个框架，Spring Security 不能频繁地进行重大更改 Spring Security 引入了 DelegatingPasswordEncoder，它通过以下方式解决了所有问题：\n确保使用当前的密码存储建议对密码进行编码 允许验证现代和传统格式的密码 允许将来升级编码 创建默认的实例：\nPasswordEncoder passwordEncoder = PasswordEncoderFactories.createDelegatingPasswordEncoder(); 你也可以自定义：\nString idForEncode = \u0026#34;bcrypt\u0026#34;; Map encoders = new HashMap\u0026lt;\u0026gt;(); encoders.put(idForEncode, new BCryptPasswordEncoder()); encoders.put(\u0026#34;noop\u0026#34;, NoOpPasswordEncoder.getInstance()); encoders.put(\u0026#34;pbkdf2\u0026#34;, new Pbkdf2PasswordEncoder()); encoders.put(\u0026#34;scrypt\u0026#34;, new SCryptPasswordEncoder()); encoders.put(\u0026#34;sha256\u0026#34;, new StandardPasswordEncoder()); PasswordEncoder passwordEncoder = new DelegatingPasswordEncoder(idForEncode, encoders); 密码存储的格式 DelegatingPasswordEncoder 存储的格式：{id}encodedPassword\n这样 id 是用于查找应该使用哪个 PasswordEncoder 的标识符，encodedPassword 是所选 PasswordEncoder 编码后的密码。 id 必须在密码的开头，以 { 开头，以 } 结尾。 如果找不到 id，则 id 将为空。 例如，以下可能是使用不同 id 编码的密码列表。 所有原始密码都是“password”。\n{bcrypt}$2a$10$dXJ3SW6G7P50lGmMkkmwe.20cQQubK3.HZWzG3YB1tlRy.fqvM/BG {noop}password {pbkdf2}5d923b44a6d129f3ddf3e3c8d29412723dcbde72445e8ef6bf3b508fbf17fa4ed4d6b99ca763d8dc {scrypt}$e0801$8bWJaSu2IKSn9Z9kM+TPXfOc/9bdYSrN1oD9qfVThWEwdRTnO7re7Ei+fUZRJ68k9lTyuTeUp4of4g24hHnazw==$OAOec05+bXxvuu/1qZ6NUR+xQYvYv7BeL1QxwRpY5Pc= {sha256}97cde38028ad898ebc02e690819fa220e88c62e0699403e94fff291cfffaf8410849f27605abcbc0 一些用户可能会担心存储格式可能为潜在的黑客利用。 这不是问题，因为密码的存储不依赖于算法是秘密。 此外，攻击者无需前缀即可轻松找出大多数格式。 例如，BCrypt 密码通常以 开头。\n匹配是基于 {id} 和 id 对应的 PasswordEncoder 来完成的。 默认情况下，使用密码和未映射的id（包括空id）调用matches(CharSequence, String)的结果将导致IllegalArgumentException。 可以使用 DelegatingPasswordEncoder.setDefaultPasswordEncoderForMatches(PasswordEncoder) 自定义此行为。\n慎重选择加密方式，密码哈希的设计使得没有简单的方法来恢复明文。 由于无法恢复明文，因此很难迁移密码。\n默认存储加密器：\nbcrypt - BCryptPasswordEncoder (Also used for encoding) ldap - LdapShaPasswordEncoder MD4 - Md4PasswordEncoder MD5 - new MessageDigestPasswordEncoder(\u0026quot;MD5\u0026quot;) noop - NoOpPasswordEncoder pbkdf2 - Pbkdf2PasswordEncoder scrypt - SCryptPasswordEncoder SHA-1 - new MessageDigestPasswordEncoder(\u0026quot;SHA-1\u0026quot;) SHA-256 - new MessageDigestPasswordEncoder(\u0026quot;SHA-256\u0026quot;) sha256 - StandardPasswordEncoder 漏洞保护 跨站请求伪造 (CSRF) 假设您的银行网站提供了一个表单，允许将资金从当前登录的用户转移到另一个银行账户。 例如，转账表格可能如下所示：\n\u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;/transfer\u0026#34;\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;amount\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;routingNumber\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;account\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Transfer\u0026#34;/\u0026gt;\u0026lt;/form\u0026gt; HTTP请求如下：\nPOST /transfer HTTP/1.1Host: bank.example.comCookie: JSESSIONID=randomidContent-Type: application/x-www-form-urlencodedamount=100.00\u0026amp;routingNumber=1234\u0026amp;account=9876 现在假设您对银行网站进行了身份验证，然后在不注销的情况下访问一个邪恶的网站。 该邪恶网站包含一个 HTML 页面，其格式如下：\n\u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;https://bank.example.com/transfer\u0026#34;\u0026gt;\u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;amount\u0026#34; value=\u0026#34;100.00\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;routingNumber\u0026#34; value=\u0026#34;evilsRoutingNumber\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;account\u0026#34; value=\u0026#34;evilsAccountNumber\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Win Money!\u0026#34;/\u0026gt;\u0026lt;/form\u0026gt; 你喜欢赢钱，所以你点击提交按钮。 在此过程中，您无意中向恶意用户转移了 100 美元。 发生这种情况的原因是，虽然恶意网站无法看到您的 cookie，但与您的银行关联的 cookie 仍会随请求一起发送。\n最糟糕的是，这整个过程本可以使用 JavaScript 实现自动化。 这意味着您甚至不需要单击按钮。 此外，在访问作为 XSS 攻击受害者的诚实站点时，它也很容易发生。 那么我们如何保护我们的用户免受此类攻击呢？\n如果防止CSRF 之所以可能发生CSRF攻击，是因为受害者网站的HTTP请求和攻击者网站的请求完全相同。 为了防止 CSRF 攻击，我们需要确保请求中存在恶意站点无法提供的内容，以便我们可以区分这两个请求。\nSpring 提供了两种机制来防止 CSRF 攻击：\n同步器令牌模式 在会话 cookie 上指定 SameSite 属性 为了使针对 CSRF 的保护起作用，应用程序必须确保“安全”的 HTTP 方法是幂等的。 这意味着使用 HTTP 方法 GET、HEAD、OPTIONS 和 TRACE 的请求不应更改应用程序的状态。\n同步器令牌模式\n防止 CSRF 攻击的主要和最全面的方法是使用同步器令牌模式。 该解决方案是HTTP 请求中必须存在一个安全的随机生成值，称为 CSRF 令牌。\n提交 HTTP 请求时，服务器必须查找预期的 CSRF 令牌并将其与 HTTP 请求中的实际 CSRF 令牌进行比较。 如果值不匹配，则应拒绝 HTTP 请求。\n让我们看看我们的示例在使用 Synchronizer Token Pattern 时会发生什么变化。 假设实际的 CSRF 令牌需要位于名为 _csrf 的 HTTP 参数中。 我们应用程序如下所示：\n\u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;/transfer\u0026#34;\u0026gt;\u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;_csrf\u0026#34; value=\u0026#34;4bfd1575-3ad1-4d21-96c7-4ef2d9f86721\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;amount\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;routingNumber\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;account\u0026#34;/\u0026gt;\u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Transfer\u0026#34;/\u0026gt;\u0026lt;/form\u0026gt; 该表单现在包含一个带有 CSRF 令牌值的隐藏输入。 外部站点无法读取 CSRF 令牌，因为同源策略确保恶意站点无法读取。\nPOST /transfer HTTP/1.1 Host: bank.example.com Cookie: JSESSIONID=randomid Content-Type: application/x-www-form-urlencoded amount=100.00\u0026amp;routingNumber=1234\u0026amp;account=9876\u0026amp;_csrf=4bfd1575-3ad1-4d21-96c7-4ef2d9f86721 一种防止 CSRF 攻击的新兴方法是在 cookie 上指定 SameSite 属性。 服务器可以在设置 cookie 时指定 SameSite 属性，以指示当来自外部站点时不应发送 cookie。\nSpring Security 不直接控制会话 cookie 的创建，因此它不提供对 SameSite 属性的支持。 Spring Session 为基于 servlet 的应用程序中的 SameSite 属性提供支持。 Spring Framework 的 CookieWebSessionIdResolver 为基于 WebFlux 的应用程序中的 SameSite 属性提供开箱即用的支持。\n例如，具有 SameSite 属性的 HTTP 响应标头可能如下所示：\nSet-Cookie: JSESSIONID=randomid; Domain=bank.example.com; Secure; HttpOnly; SameSite=Lax SameSite 属性的有效值为：\nStrict - 指定时，来自同一站点的任何请求都将包含 cookie。 否则，cookie 将不会包含在 HTTP 请求中。 Lax - 当来自同一站点或请求来自顶级导航并且该方法是幂等的时，将发送指定的 cookie。 否则，cookie 将不会包含在 HTTP 请求中。 将 SameSite 属性设置为 Strict 可提供更强大的防御，但可能会使用户感到困惑。 考虑一个用户保持登录到托管在 https://social.example.com 的社交媒体网站。 用户在 https://email.example.org 收到一封电子邮件，其中包含指向社交媒体网站的链接。 如果用户点击链接，他们理所当然地希望通过社交媒体网站的身份验证。 但是，如果 SameSite 属性为 Strict，则不会发送 cookie，因此不会对用户进行身份验证。\n什么时候使用CSRF 防护 一个常见的问题是“我是否需要保护 javascript 发出的 JSON 请求？” 简短的回答是，视情况而定。 但是，您必须非常小心，因为存在可能影响 JSON 请求的 CSRF 漏洞。 例如，恶意用户可以使用以下形式使用 JSON 创建 CSRF：\n\u0026lt;form action=\u0026#34;https://bank.example.com/transfer\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;text/plain\u0026#34;\u0026gt; \u0026lt;input name=\u0026#39;{\u0026#34;amount\u0026#34;:100,\u0026#34;routingNumber\u0026#34;:\u0026#34;evilsRoutingNumber\u0026#34;,\u0026#34;account\u0026#34;:\u0026#34;evilsAccountNumber\u0026#34;, \u0026#34;ignore_me\u0026#34;:\u0026#34;\u0026#39; value=\u0026#39;test\u0026#34;}\u0026#39; type=\u0026#39;hidden\u0026#39;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Win Money!\u0026#34;/\u0026gt;\u0026lt;/form\u0026gt; 提交的json如下：\n{ \u0026#34;amount\u0026#34;: 100,\u0026#34;routingNumber\u0026#34;: \u0026#34;evilsRoutingNumber\u0026#34;,\u0026#34;account\u0026#34;: \u0026#34;evilsAccountNumber\u0026#34;,\u0026#34;ignore_me\u0026#34;: \u0026#34;=test\u0026#34;} 如果应用程序没有验证 Content-Type，那么它就会暴露在这个漏洞中。 根据设置，验证 Content-Type 的 Spring MVC 应用程序仍然可以通过更新 URL 后缀以 .json 结尾来利用，如下所示：\n\u0026lt;form action=\u0026#34;https://bank.example.com/transfer.json\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;text/plain\u0026#34;\u0026gt; \u0026lt;input name=\u0026#39;{\u0026#34;amount\u0026#34;:100,\u0026#34;routingNumber\u0026#34;:\u0026#34;evilsRoutingNumber\u0026#34;,\u0026#34;account\u0026#34;:\u0026#34;evilsAccountNumber\u0026#34;, \u0026#34;ignore_me\u0026#34;:\u0026#34;\u0026#39; value=\u0026#39;test\u0026#34;}\u0026#39; type=\u0026#39;hidden\u0026#39;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Win Money!\u0026#34;/\u0026gt;\u0026lt;/form\u0026gt; CSRF注意事项 登录\n为了防止伪造登录请求，应保护 HTTP 请求中的登录免受 CSRF 攻击。 防止伪造登录请求是必要的，以便恶意用户无法读取受害者的敏感信息。 攻击执行如下：\n恶意用户使用恶意用户的凭据执行 CSRF 登录。 受害者现在被认证为恶意用户。 恶意用户然后诱骗受害者访问受感染的网站并输入敏感信息 该信息与恶意用户的帐户相关联，因此恶意用户可以使用自己的凭据登录并查看受害者的敏感信息 登出\n为了防止伪造注销请求，注销 HTTP 请求应该受到保护以防止 CSRF 攻击。 防止伪造注销请求是必要的，这样恶意用户就无法读取受害者的敏感信息。 有关攻击的详细信息，请参阅此文章。\nCSRF 和会话超时\n通常，预期的 CSRF 令牌存储在会话中。 这意味着一旦会话过期，服务器将找不到预期的 CSRF 令牌并拒绝 HTTP 请求。 有许多选项可以解决超时问题，每个选项都需要权衡。\n缓解超时的最佳方法是使用 JavaScript 在表单提交时请求 CSRF 令牌。 然后使用 CSRF 令牌更新表单并提交。 另一种选择是使用一些 JavaScript 来让用户知道他们的会话即将到期。 用户可以单击按钮继续并刷新会话。 最后，预期的 CSRF 令牌可以存储在 cookie 中。 这允许预期的 CSRF 令牌比会话更长。 有人可能会问，为什么预期的 CSRF 令牌默认没有存储在 cookie 中。 这是因为存在一些已知的漏洞，其中标头（例如，指定 cookie）可以由另一个域设置。 这与当标头 X-Requested-With 存在时 Ruby on Rails 不再跳过 CSRF 检查的原因相同。 有关如何漏洞利用的详细信息，请参阅此 webappsec.org 。 另一个缺点是，通过删除状态（即超时），如果令牌泄露，您将失去强制使令牌无效的能力。\n文件上传 保护多部分请求（文件上传）免受 CSRF 攻击会导致鸡和蛋的问题。 为了防止 CSRF 攻击的发生，必须读取 HTTP 请求的正文以获取实际的 CSRF 令牌。 但是，读取正文意味着文件将被上传，这意味着外部站点可以上传文件。\n对 multipart/form-data 使用 CSRF 保护有两种选择。 每个选项都有其权衡。\n在正文中放置 CSRF 令牌： 通过将 CSRF 令牌放在正文中，将在执行授权之前读取正文。 这意味着任何人都可以在您的服务器上放置临时文件。 但是，只有授权用户才能提交由您的应用程序处理的文件。 一般来说，这是推荐的方法，因为临时文件上传对大多数服务器的影响可以忽略不计。 在 URL 中放置 CSRF Token：如果不允许未经授权的用户上传临时文件，另一种方法是在表单的 action 属性中包含预期的 CSRF 令牌作为查询参数。 这种方法的缺点是查询参数可能会泄露。 更一般地说，最好的做法是将敏感数据放在正文或标题中，以确保不会泄露。 其他信息可以在 RFC 2616 第 15.1.3 节在 URI 中编码敏感信息中找到。 安全的http响应头 有许多 HTTP 响应头可用于提高 Web 应用程序的安全性。 本节专门介绍 Spring Security 提供明确支持的各种 HTTP 响应标头。 如有必要，还可以配置 Spring Security 以提供自定义标头。\n默认的Security Headers Spring Security 提供了一组默认的与安全相关的 HTTP 响应头来提供安全的默认值。Spring Security 的默认值是包含以下标头：\nCache-Control: no-cache, no-store, max-age=0, must-revalidatePragma: no-cacheExpires: 0X-Content-Type-Options: nosniffStrict-Transport-Security: max-age=31536000 ; includeSubDomainsX-Frame-Options: DENYX-XSS-Protection: 1; mode=block Strict-Transport-Security 仅添加到 HTTPS 请求上\n如果默认值不能满足您的需要，您可以轻松地从这些默认值中删除、修改或添加。 有关这些标题中的每一个的更多详细信息，请参阅相应的部分.\nCache Control Spring Security 的默认设置是禁用缓存以保护用户的内容。\n如果用户通过身份验证查看敏感信息然后注销，我们不希望恶意用户能够点击后退按钮查看敏感信息。 默认发送的缓存控制头是：\nCache-Control: no-cache, no-store, max-age=0, must-revalidatePragma: no-cacheExpires: 0 为了安全，Spring Security 默认添加这些标头。 但是，如果您的应用程序提供了自己的缓存控制标头，则 Spring Security 将退出。 这允许应用程序确保可以缓存 CSS 和 JavaScript 等静态资源。\nContent Type 从历史上看，包括 Internet Explorer 在内的浏览器会尝试使用内容嗅探来猜测请求的内容类型。 这允许浏览器通过猜测未指定内容类型的资源的内容类型来改善用户体验。 例如，如果浏览器遇到没有指定内容类型的 JavaScript 文件，它可以猜测内容类型然后运行它。\n内容嗅探的问题在于，这允许恶意用户使用多语言（例如文件上传的类型）来执行 XSS 攻击。 例如，某些站点可能允许用户向网站提交有效的 postscript 文档并进行查看。 恶意用户可能会创建一个 postscript 文档，该文档也是一个有效的 JavaScript 文件，并使用它执行 XSS 攻击。\n默认情况下，Spring Security 通过向 HTTP 响应添加以下标头来禁用内容嗅探：\nX-Content-Type-Options: nosniff HTTP 严格传输安全 (HSTS) 当您输入银行网站时，您是输入 mybank.example.com 还是输入 https://mybank.example.com？ 如果省略 https 协议，则可能容易受到中间人攻击。 即使网站执行重定向到 https://mybank.example.com，恶意用户也可以拦截初始 HTTP 请求并操纵响应（例如重定向到 https://mibank.example.com 并窃取他们的凭据）。\n许多用户省略了 https 协议，这就是创建 HTTP 严格传输安全 (HSTS) 的原因。 一旦将 mybank.example.com 添加为 HSTS 主机，浏览器就可以提前知道对 mybank.example.com 的任何请求都应被解释为 https://mybank.example.com。 这大大降低了中间人攻击发生的可能性。\n根据 RFC6797，HSTS 标头仅注入到 HTTPS 响应中。 为了让浏览器确认标头，浏览器必须首先信任签署用于建立连接的 SSL 证书（不仅仅是 SSL 证书）的 CA。\n将站点标记为 HSTS 主机的一种方法是将主机预加载到浏览器中。 另一种方法是将 Strict-Transport-Security 标头添加到响应中。 例如，Spring Security 的默认行为是添加以下标头，指示浏览器将域视为 HSTS 主机一年（一年大约有 31536000 秒）：\nStrict-Transport-Security: max-age=31536000 ; includeSubDomains ; preload 可选的 includeSubDomains 指令指示浏览器子域（例如 secure.mybank.example.com）也应被视为 HSTS 域。\n可选的 preload 指令指示浏览器应该将域作为 HSTS 域预加载到浏览器中。 有关 HSTS 预加载的更多详细信息，请参阅 https://hstspreload.org。\nHTTP 公钥固定 (HPKP) HTTP 公钥锁定 (HPKP) 向 Web 客户端指定与特定 Web 服务器一起使用的公钥，以防止使用伪造证书的中间人 (MITM) 攻击。 如果使用得当，HPKP 可以增加额外的保护层，防止证书受损。 然而，由于 HPKP 的复杂性，许多专家不再推荐使用它，Chrome 甚至取消了对它的支持。\n有关不再推荐 HPKP 的更多详细信息，请阅读 HTTP 公钥锁定是否已死？ 我要放弃 HPKP。\nX-Frame-Options 允许将您的网站添加到frame 可能是一个安全问题。 例如，使用巧妙的 CSS 样式用户可能会被诱骗点击他们不想要的东西。 例如，登录银行的用户可能会单击授予其他用户访问权限的按钮。 这种攻击被称为点击劫持。\n有多种方法可以缓解点击劫持攻击。 例如，为了保护旧浏览器免受点击劫持攻击，您可以使用断帧代码。 虽然不完美，但对于旧版浏览器，断帧代码是您可以做的最好的事情。\n解决点击劫持的更现代方法是使用 X-Frame-Options 标头。 默认情况下，Spring Security 使用以下标头禁用 iframe 中的渲染页面：\nX-Frame-Options: DENY X-XSS-Protection 一些浏览器内置过滤 XSS 攻击的支持。 这绝不是万无一失的，但确实有助于 XSS 保护。\n过滤通常默认启用，因此添加标头通常只是确保启用它并指示浏览器在检测到 XSS 攻击时执行什么操作。 例如，过滤器可能会尝试以侵入性最小的方式更改内容以仍然呈现所有内容。 有时，这种类型的替换本身就可能成为 XSS 漏洞。 相反，最好阻止内容而不是尝试修复它。 默认情况下，Spring Security 使用以下标头阻止内容：\nX-XSS-Protection: 1; mode=block 内容安全策略 (CSP) 内容安全策略 (CSP) 是一种机制，Web 应用程序可以利用它来缓解内容注入漏洞，例如跨站点脚本 (XSS)。 CSP 是一种声明性策略，它为 Web 应用程序作者提供了一种工具，可以声明并最终通知客户端（用户代理）Web 应用程序期望加载资源的来源。\n内容安全策略并非旨在解决所有内容注入漏洞。 相反，可以利用 CSP 来帮助减少内容注入攻击造成的危害。 作为第一道防线，Web 应用程序作者应该验证他们的输入并对他们的输出进行编码。\nWeb 应用程序可以通过在响应中包含以下 HTTP 标头之一来使用 CSP：\nContent-Security-Policy Content-Security-Policy-Report-Only 这些标头中的每一个都用作向客户端提供安全策略的机制。 安全策略包含一组安全策略指令，每个指令负责声明对特定资源表示的限制。\n例如，Web 应用程序可以声明它希望从特定的、受信任的来源加载脚本，方法是在响应中包含以下标头：\nContent-Security-Policy: script-src https://trustedscripts.example.com 用户代理将阻止从其他源加载脚本的尝试。 此外，如果在安全策略中声明了 report-uri 指令，则用户代理将向声明的 URL 报告违规行为。\n例如，如果 Web 应用程序违反了声明的安全策略，以下响应头将指示用户代理将违规报告发送到策略的 report-uri 指令中指定的 URL。\nContent-Security-Policy: script-src https://trustedscripts.example.com; report-uri /csp-report-endpoint/ 违规报告是标准的 JSON 结构，可以由 Web 应用程序自己的 API 或公共托管的 CSP 违规报告服务（例如 https://report-uri.com/）捕获。\nContent-Security-Policy-Report-Only 标头为 Web 应用程序作者和管理员提供了监控安全策略的能力，而不是强制执行它们。 此标头通常用于为站点试验和/或开发安全策略时。 当一个策略被认为有效时，它可以通过使用 Content-Security-Policy 头字段来强制执行。\n给定以下响应标头，该策略声明可以从两个可能来源之一加载脚本。\nContent-Security-Policy-Report-Only: script-src \u0026#39;self\u0026#39; https://trustedscripts.example.com; report-uri /csp-report-endpoint/ 如果站点违反此策略，尝试从 evil.com 加载脚本，用户代理将向由 report-uri 指令指定的声明 URL 发送违规报告，但仍然允许加载违规资源。\n将内容安全策略应用于 Web 应用程序通常是一项非常重要的任务。 以下资源可以为您的站点制定有效的安全策略提供进一步的帮助。\nAn Introduction to Content Security Policy\nCSP Guide - Mozilla Developer Network\nW3C Candidate Recommendation\nReferrer Policy Referrer 策略是一种机制，Web 应用程序可以利用该机制来管理Referrer 字段，该字段包含用户所在的最后一个页面。\nSpring Security 的做法是使用 Referrer Policy header，它提供了不同的策略：\nReferrer-Policy: same-origin Referrer-Policy 响应头指示浏览器让目的地知道用户之前所在的来源。\nFeature Policy 功能策略是一种机制，允许 Web 开发人员有选择地启用、禁用和修改浏览器中某些 API 和 Web 功能的行为。\nFeature-Policy: geolocation \u0026#39;self\u0026#39; 借助功能策略，开发人员可以选择加入一组“策略”，以便浏览器强制执行整个站点中使用的特定功能。 这些政策限制了网站可以访问的 API 或修改浏览器某些功能的默认行为。\nPermissions Policy 权限策略是一种机制，允许 Web 开发人员有选择地启用、禁用和修改浏览器中某些 API 和 Web 功能的行为。\nPermissions-Policy: geolocation=(self) 借助权限策略，开发人员可以为浏览器选择一组“策略”，以强制执行整个站点中使用的特定功能。 这些政策限制了网站可以访问的 API 或修改浏览器某些功能的默认行为。\n清除站点数据 清除站点数据是一种机制，当 HTTP 响应包含此标头时，可以通过该机制删除任何浏览器端数据（cookie、本地存储等）：\nClear-Site-Data: \u0026#34;cache\u0026#34;, \u0026#34;cookies\u0026#34;, \u0026#34;storage\u0026#34;, \u0026#34;executionContexts\u0026#34; 这是在注销时执行的一个很好的清理操作。\nSpring Security 有一些机制可以方便地将更常见的安全标头添加到您的应用程序中。 但是，它还提供挂钩以启用添加自定义标头。\nHTTP 所有基于 HTTP 的通信，包括静态资源，都应该使用 TLS 进行保护。\n作为一个框架，Spring Security 不处理 HTTP 连接，因此不直接提供对 HTTPS 的支持。 但是，它确实提供了许多有助于使用 HTTPS 的功能。\n重定向到HTTPS 当客户端使用 HTTP 时，Spring Security 可以配置为在 Servlet 和 WebFlux 环境中重定向到 HTTPS。\n代理服务器配置 使用代理服务器时，确保您已正确配置应用程序很重要。 例如，许多应用程序都会有一个负载均衡器，通过将请求转发到位于 https://192.168.1:8080 的应用程序服务器来响应对 https://example.com/ 的请求。如果没有适当的配置，应用程序服务器将不会 知道负载均衡器存在并将请求视为客户端请求 https://192.168.1:8080。\n要解决此问题，您可以使用 RFC 7239 来指定正在使用负载平衡器。 要使应用程序意识到这一点，您需要配置应用程序服务器以识别 X-Forwarded 标头。 例如，Tomcat 使用 RemoteIpValve，而 Jetty 使用 ForwardedRequestCustomizer。 或者，Spring 用户可以利用 ForwardedHeaderFilter。\nSpring Boot 用户可以使用 server.use-forward-headers 属性来配置应用程序。 有关更多详细信息，请参阅 Spring Boot 文档。\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-security/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985401,"title":"Spring-Security"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/completablefuture/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985321,"title":"CompletableFuture"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"集合 List操作 // 创建ArrayList ArrayList\u0026lt;String\u0026gt; arrayList1 = Lists.newArrayList(); ArrayList\u0026lt;String\u0026gt; arrayList2 = Lists.newArrayList(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;); ArrayList\u0026lt;String\u0026gt; arrayList3 = Lists.newArrayList(arrayList1); ArrayList\u0026lt;String\u0026gt; arrayList4 = Lists.newArrayListWithCapacity(10); //创建LinkedList LinkedList\u0026lt;Object\u0026gt; linkedList1 = Lists.newLinkedList(); LinkedList\u0026lt;String\u0026gt; linkedList2 = Lists.newLinkedList(arrayList1); //创建CopyOnWriteArrayList CopyOnWriteArrayList\u0026lt;Object\u0026gt; copyOnWriteArrayList1 = Lists.newCopyOnWriteArrayList(); CopyOnWriteArrayList\u0026lt;String\u0026gt; copyOnWriteArrayList2 = Lists.newCopyOnWriteArrayList(arrayList1); //反转list List\u0026lt;String\u0026gt; reverse = Lists.reverse(arrayList2); System.err.println(reverse); //[3, 2, 1] //切分list List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; partition = Lists.partition(arrayList2, 2); System.err.println(partition); //[[1, 2], [3]] //笛卡尔集 List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; lists = Lists.cartesianProduct(Lists.newArrayList(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;), arrayList2); System.err.println(lists);//[[A, 1], [A, 2], [A, 3], [B, 1], [B, 2], [B, 3]] //转化集合元素 List\u0026lt;String\u0026gt; transform = Lists.transform(arrayList2, item -\u0026gt; \u0026#34;Prefix\u0026#34; + item); System.err.println(transform); //[Prefix1, Prefix2, Prefix3] //将字符串拆成单个字符 ImmutableList\u0026lt;Character\u0026gt; abc = Lists.charactersOf(\u0026#34;ABC\u0026#34;); System.err.println(abc);//[A, B, C] Map操作 Map map = new HashMap(); HashMap\u0026lt;Object, Object\u0026gt; hashMap1 = Maps.newHashMap(); HashMap\u0026lt;Object, Object\u0026gt; hashMap2 = Maps.newHashMap(map); HashMap\u0026lt;Object, Object\u0026gt; hashMap3 = Maps.newHashMapWithExpectedSize(10); LinkedHashMap\u0026lt;Object, Object\u0026gt; linkedHashMap1 = Maps.newLinkedHashMap(); LinkedHashMap\u0026lt;Object, Object\u0026gt; linkedHashMap2 = Maps.newLinkedHashMap(map); LinkedHashMap\u0026lt;Object, Object\u0026gt; linkedHashMap3 = Maps.newLinkedHashMapWithExpectedSize(10); ConcurrentMap\u0026lt;Object, Object\u0026gt; concurrentMap = Maps.newConcurrentMap(); EnumMap\u0026lt;MAN, Object\u0026gt; manObjectEnumMap = Maps.newEnumMap(MAN.class); EnumMap enumMap = Maps.newEnumMap(map); TreeMap\u0026lt;Comparable, Object\u0026gt; treeMap1 = Maps.newTreeMap(); TreeMap\u0026lt;Integer, String\u0026gt; treeMap2 = Maps.newTreeMap((a,b)-\u0026gt;Integer.compare(a,b)); IdentityHashMap\u0026lt;Object, Object\u0026gt; identityHashMap = Maps.newIdentityHashMap(); Multimap 一个key可以映射多个value的hashMap:\nArrayListMultimap\u0026lt;Object, Object\u0026gt; multimap = ArrayListMultimap.create(); multimap.put(\u0026#34;key\u0026#34;,1); multimap.put(\u0026#34;key\u0026#34;,2); multimap.put(\u0026#34;key\u0026#34;,2); List\u0026lt;Object\u0026gt; value = multimap.get(\u0026#34;key\u0026#34;); System.err.println(value); //[1, 2, 2] Map\u0026lt;Object, Collection\u0026lt;Object\u0026gt;\u0026gt; objectCollectionMap = multimap.asMap(); System.err.println(objectCollectionMap); //{key=[1, 2, 2]} BiMap 一种连value也不能重复的HashMap\nHashBiMap\u0026lt;Object, Object\u0026gt; biMap = HashBiMap.create(); biMap.put(\u0026#34;key\u0026#34;,\u0026#34;value\u0026#34;); // biMap.put(\u0026#34;key2\u0026#34;,\u0026#34;value\u0026#34;); 抛出异常 biMap.forcePut(\u0026#34;key2\u0026#34;,\u0026#34;value\u0026#34;); //{key2=value} System.err.println(biMap); BiMap\u0026lt;Object, Object\u0026gt; inverse = biMap.inverse(); System.err.println(inverse); //{key2=value} Table 相当于mysql中的表：\nHashBasedTable\u0026lt;Object, Object, Object\u0026gt; table = HashBasedTable.create(); table.put(\u0026#34;id_1\u0026#34;,\u0026#34;name\u0026#34;,\u0026#34;zzq\u0026#34;); table.put(\u0026#34;id_1\u0026#34;,\u0026#34;age\u0026#34;,\u0026#34;12\u0026#34;); table.put(\u0026#34;id_1\u0026#34;,\u0026#34;addr\u0026#34;,\u0026#34;henan\u0026#34;); System.err.println(table); //{id_1={name=zzq, age=12, addr=henan}} Object o = table.get(\u0026#34;id_1\u0026#34;, \u0026#34;name\u0026#34;); System.err.println(o); //zzq Map\u0026lt;Object, Object\u0026gt; addr = table.column(\u0026#34;addr\u0026#34;); System.err.println(addr); //{id_1=henan} Multiset 一种用来计数的Set:\nHashMultiset\u0026lt;Object\u0026gt; multiset = HashMultiset.create(); multiset.add(\u0026#34;apple\u0026#34;); multiset.add(\u0026#34;apple\u0026#34;); multiset.add(\u0026#34;orange\u0026#34;); System.err.println(multiset.count(\u0026#34;apple\u0026#34;)); //2 Set\u0026lt;Object\u0026gt; elementSet = multiset.elementSet(); System.err.println(elementSet); // [orange, apple] ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/guava/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985294,"title":"Guava"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":" 响应式编程是观察者设计模式的扩展 对比迭代器模式，一个重要区别是，迭代器基于拉模式，reactive streams基于推模式 使用迭代器是一种命令式编程，即必须通过Iterable访问值，这就需要开发者手动next()访问值。reactive streams采用的是Publisher-Subscriber：发布者在新的可用值到来时通知订阅者，这种基于推的模式是响应式编程的核心。此外，应用于推送值的操作是以声明的方式而不是命令的方式表达的，程序员表达计算的逻辑而不是描述其确切的控制流程。\n发布者可以向其订阅者推送新值（通过调用 onNext），但也可以发出错误（通过调用 onError）或完成（通过调用 onComplete信号。 错误和完成信号都会终止序列。 这可以总结如下：\nonNext x 0..N [onError | onComplete] reactor实现了两种Publisher：\nFlux: 0..N个item的响应式序列 Mono: 0..1个item的响应式序列 这两种类型更多的是语义上的区别。例如，一个http请求仅产生一个响应，这时候使用Mono比 Flux更好，毕竟前者表示了0或1的意思。两者之间也可以相互转化，例如count操作符，Flux执行count返回 Mono\n下面是Flux的基本弹珠图：\n所有的事件，甚至终止事件，都是可选的：\n没有onNext事件，只有OnComplete事件，表示一个空序列。 没有任何事件，表示一个空的无限序列。 同样，无限序列不一定为空。 例如，Flux.interval（Duration）产生Flux ，它是无限的并从时钟发出规则的滴答声。 Mono是一个特殊的Publisher，它通过onNext信号最多发出一项，然后以onComplete信号（成功的Mono）终止，或仅发出一个onError信号（失败的Mono）。\n订阅 subscribe(); //订阅并触发序列 subscribe(Consumer\u0026lt;? super T\u0026gt; consumer); //对每个产生的价值做一些事情。 subscribe(Consumer\u0026lt;? super T\u0026gt; consumer, Consumer\u0026lt;? super Throwable\u0026gt; errorConsumer); //处理值的同时也要对错误做出反应。 subscribe(Consumer\u0026lt;? super T\u0026gt; consumer, Consumer\u0026lt;? super Throwable\u0026gt; errorConsumer, Runnable completeConsumer); //处理值和错误，但也会在序列成功完成时运行一些代码。 subscribe(Consumer\u0026lt;? super T\u0026gt; consumer, Consumer\u0026lt;? super Throwable\u0026gt; errorConsumer, Runnable completeConsumer, Consumer\u0026lt;? super Subscription\u0026gt; subscriptionConsumer); //处理值、错误和成功完成，但也要对由此 subscribe 调用产生的 Subscription 做一些事情。 这些方法返回Disposable，您可以使用它取消订阅。 调用dispose() 方法，发出停止生成元素的信号。 但是，它不能保证是立即的：某些源可能会非常快地生成元素，以至于它们甚至可以在收到取消指令之前完成。\nDisposables.swap() 创建了一个 Disposable 包装器，让您可以原子地取消和替换成新的Disposable。 例如，在 UI 场景中，您希望在用户单击按钮时取消请求并将其替换为新请求。\nDisposables.composite(… )允许您收集多个 Disposable ，并在以后一次性处理所有这些请求。\nFlux\u0026lt;Integer\u0026gt; ints = Flux.range(1, 4); ints.subscribe(i -\u0026gt; System.out.println(i), error -\u0026gt; System.err.println(\u0026#34;Error \u0026#34; + error), () -\u0026gt; System.out.println(\u0026#34;Done\u0026#34;), sub -\u0026gt; sub.request(10)); 当我们订阅时，我们会收到一个Subscription。request(10)表示我们希望获取源中最多 10 个元素（实际上会发出 4 个元素就发出完成信号）。\nBaseSubscriber 还有一个额外的 subscribe 方法更通用，它需要一个完整的 Subscriber 而不是从 lambdas 中组合一个。 为了帮助编写这样的订阅者，我们提供了一个名为 BaseSubscriber 的可扩展类。\nBaseSubscriber 的实例（或其子类）是一次性的，这意味着如果 BaseSubscriber实例订阅了第二个发布者，它会取消对第一个发布者的订阅。 这是因为使用一个实例使用两次会违反 Reactive Streams 规则，即不能并行调用 Subscriber 的 onNext 方法。\npublic class SampleSubscriber\u0026lt;T\u0026gt; extends BaseSubscriber\u0026lt;T\u0026gt; { public void hookOnSubscribe(Subscription subscription) { System.out.println(\u0026#34;Subscribed\u0026#34;); request(1); } public void hookOnNext(T value) { System.out.println(value); request(1); } } SampleSubscriber\u0026lt;Integer\u0026gt; ss = new SampleSubscriber\u0026lt;Integer\u0026gt;(); Flux\u0026lt;Integer\u0026gt; ints = Flux.range(1, 4); ints.subscribe(ss); 它还有额外的钩子：hookOnComplete、hookOnError、hookOnCancel 和 hookFinally（当序列终止时总是调用它， SignalType作为参数传入）\n背压 在 Reactor 中实现背压时，消费者压力传播回源的方式是通过向上游Oprator发送request。 当前request的总和(即调用 request(n) 函数)被称为 当前需求 。默认 ，需求上限为 Long.MAX_VALUE，代表一个无限的请求（意思是“尽可能快地生产” — 基本上禁用背压）。\nFlux.range(1, 10) .doOnRequest(r -\u0026gt; System.out.println(\u0026#34;request of \u0026#34; + r)) .subscribe(new BaseSubscriber\u0026lt;Integer\u0026gt;() { @Override public void hookOnSubscribe(Subscription subscription) { request(1); } @Override public void hookOnNext(Integer integer) { System.out.println(\u0026#34;Cancelling after having received \u0026#34; + integer); cancel(); } }); 结果打印：\nrequest of 1 Cancelling after having received 1 需要记住的是，上游链中的每个操作符都可以重塑订阅级别表达的需求。 例如 buffer(N) 运算符：如果它接收到 request(2)的请求，则将其解释为对两个完整缓冲区的需求。 因此，由于缓冲区需要 N 个元素才能被视为已满，因此缓冲区运算符将request重塑为 2 x N。\n您可能还注意到，某些运算符的变体采用称为 prefetch 的 int 输入参数。 这是另一类修改下游请求的操作符。 这些通常是处理内部序列的运算符，从每个传入元素（如 flatMap）派生一个发布者。prefetch 是一种调整对这些内部序列发出的初始请求的方法。 如果未指定，这些运算符中的大多数都以 32 的需求开始。\n这些算子通常也实施补货优化：一旦算子看到 75% 的预取请求得到满足，它就会从上游重新请求 75%。 这是一种启发式优化，以便这些Oprator主动预测即将到来的请求。\n最后，有几个运算符可以让您直接调整请求：limitRate 和 limitRequest:\nlimitRate(N) 拆分下游请求，以便它们以较小的批次向上游传播。 例如，对 limitRate(10) 发出的 100 个请求将导致最多 10 个 10 个请求传播到上游。 请注意，在这种形式中，limitRate 实际上实现了前面讨论的补充优化。有一个变体，它也可以让您调整补给量（在变体中称为低潮）：limitRate(highTide, lowTide)。 选择 0 的低潮会导致严格的高潮请求批次，而不是由补货策略进一步返工的批次。 另一方面，limitRequest(N) 将下游请求限制为最大总需求。 它将请求加起来最多为 N。如果单个请求没有使总需求溢出 N，则该特定请求将完全向上游传播。 在源发出该数量后，limitRequest 认为序列已完成，向下游发送 onComplete 信号，并取消源。 手动创建序列 创建Flux的时候手动定义关联的事件（OnNext,OnError和onComplete），所有这些方法都有一个共同点，即它们公开了一个 API 来触发我们称为Sink(接收器)的事件。\n同步generate Flux\u0026lt;String\u0026gt; flux = Flux.generate( () -\u0026gt; 0, //Supplier\u0026lt;S\u0026gt; (state, sink) -\u0026gt; { //BiFunction\u0026lt;S, SynchronousSink\u0026lt;T\u0026gt;, S\u0026gt; sink.next(\u0026#34;3 x \u0026#34; + state + \u0026#34; = \u0026#34; + 3*state); if (state == 10) sink.complete(); return state + 1; }); 结果：\n3 x 0 = 0 3 x 1 = 3 3 x 2 = 6 3 x 3 = 9 3 x 4 = 12 3 x 5 = 15 3 x 6 = 18 3 x 7 = 21 3 x 8 = 24 3 x 9 = 27 3 x 10 = 30 同步且一对一发射，这意味着sink是SynchronousSink ，每次回调的时候，只能调用一次next()方法，error(Throwable) 或complete(),是可选的.\n你还可以使用可变值：\nFlux\u0026lt;String\u0026gt; flux = Flux.generate( AtomicLong::new, (state, sink) -\u0026gt; { long i = state.getAndIncrement(); sink.next(\u0026#34;3 x \u0026#34; + i + \u0026#34; = \u0026#34; + 3*i); if (i == 10) sink.complete(); return state; }); 异步多线程 create create 是一种更高级的 Flux 编程创建形式，适用于每轮多次发射，甚至来自多个线程。它公开了一个 FluxSink，以及它的 next、error 和 complete 方法。 与generate相反，它没有基于state的变体。 另一方面，它可以在回调中触发多线程事件。\ninterface MyEventListener\u0026lt;T\u0026gt; { void onDataChunk(List\u0026lt;T\u0026gt; chunk); void processComplete(); } Flux\u0026lt;String\u0026gt; bridge = Flux.create(sink -\u0026gt; { myEventProcessor.register( new MyEventListener\u0026lt;String\u0026gt;() { public void onDataChunk(List\u0026lt;String\u0026gt; chunk) { for(String s : chunk) { sink.next(s); //多次调用 } } public void processComplete() { sink.complete(); } }); }); 异步单线程push push 是 generate 和 create 之间的中间地带，适用于处理来自单个生产者的事件。 它与 create 类似，因为它也可以是异步的，并且可以使用 create 支持的任何溢出策略来管理背压。 但是，一次只有一个生产线程可以调用 next、complete 或 error。\nFlux\u0026lt;String\u0026gt; bridge = Flux.push(sink -\u0026gt; { myEventProcessor.register( new SingleThreadEventListener\u0026lt;String\u0026gt;() { public void onDataChunk(List\u0026lt;String\u0026gt; chunk) { for(String s : chunk) { sink.next(s); } } public void processComplete() { sink.complete(); } public void processError(Throwable e) { sink.error(e); } }); }); 对于多数的操作符，例如create,是混合的push/pull模型，大多数情况下是push，一小部分是pull，例如request(n);\n消费者从源中pull数据，因为它在第一次请求之前不会发出任何东西。 当数据可用时，源将数据推送给消费者，但在其请求的数量范围内。\nHandle handle 方法有点不同：它是一个实例方法，这意味着它链接在现有源上（与常见运算符一样）。 它存在于 Mono 和 Flux 中。\n它接近于generate，因为它使用 SynchronousSink 并且只允许一对一。 但是，handle 可用于从每个源元素中生成任意值，可能会跳过某些元素。 通过这种方式，它可以作为 map 和 filter 的组合。 句柄签名如下：\nFlux\u0026lt;R\u0026gt; handle(BiConsumer\u0026lt;T, SynchronousSink\u0026lt;R\u0026gt;\u0026gt;); 让我们考虑一个例子。 规范不允许序列中出现空值。 如果您想执行map但又想使用预先存在的方法作为map函数，并且该方法有时返回 null，该怎么办？\npublic String alphabet(int letterNumber) { if (letterNumber \u0026lt; 1 || letterNumber \u0026gt; 26) { return null; } int letterIndexAscii = \u0026#39;A\u0026#39; + letterNumber - 1; return \u0026#34;\u0026#34; + (char) letterIndexAscii; } Flux\u0026lt;String\u0026gt; alphabet = Flux.just(-1, 30, 13, 9, 20) .handle((i, sink) -\u0026gt; { String letter = alphabet(i); if (letter != null) sink.next(letter); }); alphabet.subscribe(System.out::println); 线程和调度 获得 Flux 或 Mono 并不一定意味着它在专用线程中运行。 相反，大多数运算符继续在前一个运算符执行的线程中工作。 除非指定，否则最顶层的运算符（源）本身运行在进行 subscribe() 调用的线程上。 以下示例在新线程中运行 Mono：\npublic static void main(String[] args) throws InterruptedException { final Mono\u0026lt;String\u0026gt; mono = Mono.just(\u0026#34;hello \u0026#34;); //在main线程中创建 Thread t = new Thread(() -\u0026gt; mono .map(msg -\u0026gt; msg + \u0026#34;thread \u0026#34;) .subscribe(v -\u0026gt; //在Thread-0中进行subscribe System.out.println(v + Thread.currentThread().getName()) ) ) t.start(); t.join(); } 输出：\nhello thread Thread-0 在reactor中，执行模型和执行发生的位置由使用的Scheduler决定。Scheduler 具有类似于 ExecutorService 的调度职责，但拥有专用的抽象可以让它做更多的事情。\nSchedulers 类具有静态方法，可以访问以下执行上下文：\n没有执行上下文（Schedulers.immediate()）：在处理时，提交的 Runnable 将被直接执行，有效地在当前 Thread 上运行它们（可以看作是一个“空对象”或 no-op Scheduler）。 单个可重用线程 (Scheduler.single())。请注意，此方法为所有调用者重用相同的线程，直到调度程序被释放。 如果您想要每次调用的专用线程，请为每次调用使用 Schedulers.newSingle()。 一个无界的弹性线程池（Schedulers.elastic()）。 随着 Schedulers.boundedElastic() 的引入，这个不再受欢迎，因为它倾向于隐藏背压问题并导致线程过多（见下文）。 有界弹性线程池 (Scheduler.boundedElastic())。 与其前身 elastic() 一样，它根据需要创建新的工作池并重用空闲的工作池。 闲置时间过长（默认为 60 秒）的工作池也会被处理掉。 与它的 elastic() 前身不同，它对它可以创建的支持线程的数量有一个上限（默认为 CPU 内核数 x 10）。 达到上限后提交的多达 100 000 个任务被排队，并在线程可用时重新调度（当调度延迟时，延迟在线程可用时开始）。 这是 I/O 阻塞工作的更好选择。 Schedulers.boundedElastic() 是一种方便的方法，可以为阻塞进程提供自己的线程，这样它就不会占用其他资源。 请参阅如何包装同步阻塞调用？，但不会对系统施加太大的新线程压力。 针对并行工作（Schedulers.parallel()）进行调整的固定工作线程池。 它会创建与 CPU 内核一样多的工作线程。 此外，您可以使用 Schedulers.fromExecutorService(ExecutorService) 从任何预先存在的 ExecutorService 中创建调度程序。 （您也可以从 Executor 创建一个，但不鼓励这样做。）\n您还可以使用 newXXX 方法创建各种调度程序类型的新实例。 例如，Schedulers.newParallel(yourScheduleName) 创建一个名为 yourScheduleName 的新并行调度程序。\n默认情况下，某些操作符使用 Schedulers 中的特定调度程序（并且通常会为您提供提供不同调度程序的选项）。 例如，调用 Flux.interval(Duration.ofMillis(300)) 工厂方法会产生一个每 300 毫秒滴答一次的 Flux。 默认情况下，这是由 Schedulers.parallel() 启用的。 以下行将 Scheduler 更改为类似于 Schedulers.single() 的新实例：\nFlux.interval(Duration.ofMillis(300), Schedulers.newSingle(\u0026#34;test\u0026#34;)) Reactor 提供了两种在反应链中切换执行上下文（或调度器）的方法：publishOn 和 subscribeOn。 两者都采用调度程序并让您将执行上下文切换到该调度程序。 但是publishOn 在链中的位置很重要，而subscribeOn 的位置则无关紧要。 要了解这种差异，您首先必须记住，在您订阅之前什么都不会发生。\n在 Reactor 中，当您链接运算符时，您可以根据需要将尽可能多的 Flux 和 Mono 实现相互包装。 订阅后，将创建一个 Subscriber 对象链，向后（沿链向上）到第一个发布者。 这实际上是对你隐藏的。 你所能看到的只是 Flux（或 Mono）和 Subscription 的外层，但这些中间特定运算符的订阅者才是真正的工作发生的地方。\npublishOn 在订阅者链的中，publishOn 的应用方式与任何其他运算符相同。 它从上游获取信号并在下游重放它们，同时从关联的调度程序对工作线程执行回调。 因此，它会影响后续操作符的执行位置（直到链接到另一个 publishOn），如下所示：\n将执行上下文更改为调度程序选择的一个线程 根据规范，onNext 调用按顺序发生，因此这会占用一个线程 除非它们在特定的调度程序上工作，否则 publishOn 之后的操作符会继续在同一线程上执行 Scheduler s = Schedulers.newParallel(\u0026#34;parallel-scheduler\u0026#34;, 4); //1 final Flux\u0026lt;String\u0026gt; flux = Flux .range(1, 2) .map(i -\u0026gt; 10 + i) //2 .publishOn(s) //3 .map(i -\u0026gt; \u0026#34;value \u0026#34; + i); //4 new Thread(() -\u0026gt; flux.subscribe(System.out::println)); 创建Scheduler ，里面包含4个线程 map 运行在 5中 创建的线程上 publishOn 在从 1 选取的线程上切换整个序列。 第二个映射在 1 的线程上运行。 这个匿名线程是订阅发生的地方。 打印发生在最新的执行上下文中，即来自 publishOn 的上下文。 subscribeOn subscribeOn 适用于订阅过程，当反向链被构建时。 因此，无论您将 subscribeOn 放在链中的哪个位置，它始终会影响源发射的上下文。 然而，这并不影响随后对publishOn 的调用的行为—— 它们仍然为之后的链部分切换执行上下文。\n更改整个运算符链订阅的线程 从调度程序中选择一个线程 Scheduler s = Schedulers.newParallel(\u0026#34;parallel-scheduler\u0026#34;, 4); //1 final Flux\u0026lt;String\u0026gt; flux = Flux .range(1, 2) .map(i -\u0026gt; 10 + i) //2 .subscribeOn(s) //3 .map(i -\u0026gt; \u0026#34;value \u0026#34; + i); //4 new Thread(() -\u0026gt; flux.subscribe(System.out::println)); //5 创建一个由四个线程支持的新调度程序。 map在这四个线程之一上运行\u0026hellip;\u0026hellip; 因为 subscribeOn 从订阅时间 (\u0026lt;5\u0026gt;) 开始切换整个序列。 map 运行在相同线程（第一个map的线程） 这个匿名线程是最初发生订阅的线程，但 subscribeOn 立即将其转移到四个调度程序线程之一。 完全并行怎么达到？？？？ publishOn\n处理异常 Reactive Streams规范中，异常是终止事件。一旦发生错误，它就会停止序列并沿着运算符链向下传播到最后一步，即您定义的 Subscriber 及其 onError 方法。\n如果未定义，onError 将抛出 UnsupportedOperationException。 您可以使用 Exceptions.isErrorCallbackNotImplemented 方法进一步检测和分类它。\nReactor 还提供了错误处理运算符。 以下示例显示了如何执行此操作：\nFlux.just(1, 2, 0, 8) .map(i -\u0026gt; \u0026#34;100 / \u0026#34; + i + \u0026#34; = \u0026#34; + (100 / i)) //this triggers an error with 0 .onErrorReturn(\u0026#34;Divided by zero :(\u0026#34;) .subscribe(System.err::println); 输出：\n100 / 1 = 100 100 / 2 = 50 Divided by zero :( 在您了解错误处理运算符之前，您必须记住，反应序列中的任何错误都是一个终止事件。 即使使用了错误处理运算符，它也不会让原始序列继续。 相反，它将 onError 信号转换为新序列的开始。 换句话说，它替换了它上游的终止序列。\n错误处理操作符 您可能熟悉在 try-catch 块中处理异常的几种方法。这些包括以下内容：\n捕获并返回静态值 捕获然后执行fallback方法 捕获并动态计算fallback值 捕获，然后包装异常成BusinessException，重新抛出 捕获，记录日志，重新抛出 使用 finally 块来清理资源或 Java 7 “try-with-resource” 构造。 以上所有在ractor中都有对应的运算符。\n订阅时，链末尾的 onError 回调类似于 catch 块。 在那里，如果抛出异常，执行会跳到捕获，如下例所示：\nFlux\u0026lt;String\u0026gt; s = Flux.range(1, 10) .map(v -\u0026gt; doSomethingDangerous(v)) .map(v -\u0026gt; doSecondTransform(v)); s.subscribe(value -\u0026gt; System.out.println(\u0026#34;RECEIVED \u0026#34; + value), error -\u0026gt; System.err.println(\u0026#34;CAUGHT \u0026#34; + error) ); 上面的例子等同于：\ntry { for (int i = 1; i \u0026lt; 11; i++) { String v1 = doSomethingDangerous(i); String v2 = doSecondTransform(v1); System.out.println(\u0026#34;RECEIVED \u0026#34; + v2); } } catch (Throwable t) { System.err.println(\u0026#34;CAUGHT \u0026#34; + t); } 静态 fallback值 捕获并返回静态值：\ntry { return doSomethingDangerous(10); } catch (Throwable error) { return \u0026#34;RECOVERED\u0026#34;; } 等同于：\nFlux.just(10) .map(this::doSomethingDangerous) .onErrorReturn(\u0026#34;RECOVERED\u0026#34;); 还有一个扩展方法：\nFlux.just(10) .map(this::doSomethingDangerous) .onErrorReturn(e -\u0026gt; e.getMessage().equals(\u0026#34;boom10\u0026#34;), \u0026#34;recovered10\u0026#34;); fallback 方法 捕获然后执行fallback方法\nString v1; try { v1 = callExternalService(\u0026#34;key1\u0026#34;); } catch (Throwable error) { v1 = getFromCache(\u0026#34;key1\u0026#34;); } String v2; try { v2 = callExternalService(\u0026#34;key2\u0026#34;); } catch (Throwable error) { v2 = getFromCache(\u0026#34;key2\u0026#34;); } 等同于：\nFlux.just(\u0026#34;key1\u0026#34;, \u0026#34;key2\u0026#34;) .flatMap(k -\u0026gt; callExternalService(k) .onErrorResume(e -\u0026gt; getFromCache(k)) ); 动态fallback值 try { Value v = erroringMethod(); return MyWrapper.fromValue(v); } catch (Throwable error) { return MyWrapper.fromError(error); } 等效：\nerroringFlux.onErrorResume(error -\u0026gt; Mono.just( MyWrapper.fromError(error) )); 捕获并重新抛出 try { return callExternalService(k); } catch (Throwable error) { throw new BusinessException(\u0026#34;oops, SLA exceeded\u0026#34;, error); } Flux.just(\u0026#34;timeout1\u0026#34;) .flatMap(k -\u0026gt; callExternalService(k)) .onErrorResume(original -\u0026gt; Flux.error( new BusinessException(\u0026#34;oops, SLA exceeded\u0026#34;, original)) ); 等同：\nFlux.just(\u0026#34;timeout1\u0026#34;) .flatMap(k -\u0026gt; callExternalService(k)) .onErrorMap(original -\u0026gt; new BusinessException(\u0026#34;oops, SLA exceeded\u0026#34;, original)); 记录日志后抛出 try { return callExternalService(k); } catch (RuntimeException error) { //make a record of the error log(\u0026#34;uh oh, falling back, service failed for key \u0026#34; + k); throw error; } LongAdder failureStat = new LongAdder(); Flux\u0026lt;String\u0026gt; flux = Flux.just(\u0026#34;unknown\u0026#34;) .flatMap(k -\u0026gt; callExternalService(k) .doOnError(e -\u0026gt; { failureStat.increment(); log(\u0026#34;uh oh, falling back, service failed for key \u0026#34; + k); }) ); finally Stats stats = new Stats(); stats.startTimer(); try { doSomethingDangerous(); } finally { stats.stopTimerAndRecordTiming(); } 等同：\nStats stats = new Stats(); LongAdder statsCancel = new LongAdder(); Flux\u0026lt;String\u0026gt; flux = Flux.just(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;) .doOnSubscribe(s -\u0026gt; stats.startTimer()) .doFinally(type -\u0026gt; { stats.stopTimerAndRecordTiming(); if (type == SignalType.CANCEL) statsCancel.increment(); }) .take(1); 对于“try-with-resource”,还可以使用using\nFlux\u0026lt;String\u0026gt; flux = Flux.using( () -\u0026gt; disposableInstance, disposable -\u0026gt; Flux.just(disposable.toString()), Disposable::dispose ); 重试 要记住的是，它通过重新订阅上游 Flux 来工作。 这确实是一个不同的序列，原始的仍然终止。 为了验证这一点，我们可以重用前面的示例并附加一个 retry(1) 来重试一次，而不是使用 onErrorReturn。\nFlux.interval(Duration.ofMillis(250)) .map(input -\u0026gt; { if (input \u0026lt; 3) return \u0026#34;tick \u0026#34; + input; throw new RuntimeException(\u0026#34;boom\u0026#34;); }) .retry(1) .elapsed() //elapsed 将每个值与自上一个值发出以来的持续时间相关联。 .subscribe(System.out::println, System.err::println); Thread.sleep(2100); 结果：\n259,tick 0 249,tick 1 251,tick 2 506,tick 0 248,tick 1 253,tick 2 java.lang.RuntimeException: boom 从前面的示例中可以看出，retry(1) 只是重新订阅了原始间隔一次，从 0 重新开始计时。第二次，由于异常仍然发生，它放弃向下游传播错误。\n有一个更高级的重试版本（称为 retryWhen），它使用“伴随” Flux 来判断特定的失败是否应该重试。 这个伴随 Flux 由操作符创建但由用户修饰，以自定义重试条件。\n伴随的 Flux 是一个 Flux，它被传递给一个 Retry 策略/函数，作为 retryWhen 的唯一参数提供。 作为用户，您定义该函数并使其返回一个新的 Publisher。 Retry 类是一个抽象类，但如果您想使用简单的 lambda (Retry.from(Function)) 来转换同伴，它提供了一个工厂方法。\nFlux\u0026lt;String\u0026gt; flux = Flux .\u0026lt;String\u0026gt;error(new IllegalArgumentException()) .doOnError(System.out::println) //发生异常时，打印异常 .retryWhen(Retry.from(companion -\u0026gt; companion.take(3))); //在这里，我们将前三个错误视为可重试（take(3)） 每次发生错误（提供重试的可能性）时，都会向伴随的 Flux 发出一个 RetrySignal，该 Flux 已由您的函数装饰。 这里有一个 Flux 可以鸟瞰到目前为止的所有尝试。 RetrySignal 可以访问错误及其周围的元数据。 如果伴随 Flux 发出一个值，则会发生重试。 如果伴随 Flux 完成，则错误被吞并，重试循环停止，结果序列也完成。 如果伴随 Flux 产生错误 (e)，则重试循环停止并且由此产生的序列错误为 e。 处理运算符或函数中的异常 通常，所有操作符本身都可以包含可能触发异常的代码，或者调用用户定义的回调也可能失败，因此它们都包含某种形式的错误处理。\n根据经验，未经检查的异常总是通过 onError 传播。 例如，在 map 函数中抛出 RuntimeException 会转换为 onError 事件，如下面的代码所示：\nFlux.just(\u0026#34;foo\u0026#34;) .map(s -\u0026gt; { throw new IllegalArgumentException(s); }) .subscribe(v -\u0026gt; System.out.println(\u0026#34;GOT VALUE\u0026#34;), e -\u0026gt; System.out.println(\u0026#34;ERROR: \u0026#34; + e)); 然而，Reactor 定义了一组总是被认为是致命的异常（例如 OutOfMemoryError）。 请参阅 Exceptions.throwIfFatal 方法。 这些错误意味着 Reactor 无法继续运行并被抛出而不是传播。\n如果您需要调用一些声明抛出异常的方法，您仍然必须在 try-catch 块中处理这些异常。 不过，您有多种选择：\n捕获异常并从中恢复。 该序列继续正常。 捕获异常，将其包装成未经检查的异常，然后抛出（中断序列）。 Exceptions 实用程序类可以帮助您解决这个问题（我们接下来会讲到）。 如果您需要返回 Flux（例如，您在 flatMap 中），请将异常包装在产生错误的 Flux 中，如下所示：return Flux.error(checkedException)。 （该序列也终止。） Reactor 有一个 Exceptions 实用程序类，您可以使用它来确保仅当异常是已检查异常时才包装异常：\n如有必要，使用 Exceptions.propagate 方法包装异常。 它还首先调用 throwIfFatal 并且不包装 RuntimeException。 使用 Exceptions.unwrap 方法获取原始未包装异常（回到特定于反应器的异常层次结构的根本原因）。 public String convert(int i) throws IOException { if (i \u0026gt; 3) { throw new IOException(\u0026#34;boom \u0026#34; + i); } return \u0026#34;OK \u0026#34; + i; } 现在假设您想在map中使用该方法。 您现在必须显式捕获异常，并且您的 map 函数不能重新抛出它。 因此，您可以将其作为 RuntimeException 传播到地图的 onError 方法，如下所示：\nFlux\u0026lt;String\u0026gt; converted = Flux .range(1, 10) .map(i -\u0026gt; { try { return convert(i); } catch (IOException e) { throw Exceptions.propagate(e); } }); 稍后，当订阅前面的 Flux 并对错误做出反应时，如果您想为 IOExceptions 做一些特殊的事情，您可以恢复到原始异常。 以下示例显示了如何执行此操作：\nconverted.subscribe( v -\u0026gt; System.out.println(\u0026#34;RECEIVED: \u0026#34; + v), e -\u0026gt; { if (Exceptions.unwrap(e) instanceof IOException) { System.out.println(\u0026#34;Something bad happened with I/O\u0026#34;); } else { System.out.println(\u0026#34;Something bad happened\u0026#34;); } } ); Processors和Sinks Processors 既是 Publisher 又是**Subscriber，**它们最初旨在作为中间步骤的可能表示，然后可以在 Reactive Streams 实现之间共享。 然而，在 Reactor 中，这些步骤更像是由 Publisher 运算符来表示。\n第一次遇到 Processor 时的一个常见错误是试图从 Subscriber 接口直接调用公开的 onNext、onComplete 和 onError 方法。应该小心进行此类手动调用，尤其是关于 Reactive Streams 规范的调用外部同步。 Processors 实际上可能用处不大，除非遇到基于响应式流的 API，该 API 需要传递订阅者，而不是公开发布者。\nsink通常是更好的选择。 在 Reactor 中，sink是一个允许安全手动触发信号的类。 它可以与订阅相关联（来自操作符内部）或完全独立。\n使用 Sinks.One 和 Sinks.Many 从多线程安全生产 reactor-core 公开的 Sink 的默认风格确保检测到多线程使用，并且不会从下游订阅者的角度导致规范违规或未定义的行为。 使用 tryEmit* API 时，并行调用会快速失败。 当使用emit* API 时，提供的EmissionFailureHandler 可能允许重试争用（例如，忙循环），否则sink将因错误而终止。\n这是对 Processor.onNext 的改进，它必须在外部同步，否则从下游订阅者的角度来看会导致未定义的行为。\nSinks 构建器为主要支持的生产者类型提供了一个引导式 API。 您将认识到 Flux 中的一些行为，例如 onBackpressureBuffer。\nSinks.Many\u0026lt;Integer\u0026gt; replaySink = Sinks.many().replay().all(); 多个生产者线程可以通过执行以下操作在sink上并发生成数据：\n//thread1 sink.emitNext(1, FAIL_FAST); //thread2, later sink.emitNext(2, FAIL_FAST); //thread3, concurrently with thread 2 EmitResult result = sink.tryEmitNext(3); //would return FAIL_NON_SERIALIZED Sinks.Many 可以作为 Flux 呈现给下游消费者，如下例所示：\nFlux\u0026lt;Integer\u0026gt; fluxView = replaySink.asFlux(); fluxView .takeWhile(i -\u0026gt; i \u0026lt; 10) .log() .blockLast(); 类似地，可以使用 asMono() 方法将 Sinks.Empty 和 Sinks.One 风格视为 Mono。\nsink类别是：\nmany().multicast()：它只向订阅者传输新推送的数据，尊重他们的背压（在“订阅者订阅后”开始推送）。 many().unicast()：与上面相同，但在第一个订阅者注册之前推送的数据被缓冲。 many().replay()：它将向新订阅者重播特定历史大小的推送数据，然后继续实时推送新数据。 one()：将向其订阅者播放单个元素的接收器 empty()：一个只向其订阅者播放终端信号的接收器（错误或完成），但仍然可以被视为 Mono（注意泛型类型 ）。 可用的Sink Sinks.many().unicast().onBackpressureBuffer(args?) 单播 Sinks.Many 可以通过使用内部缓冲区来处理背压。 权衡是它最多可以有一个订阅者。\n基本的单播接收器是通过 Sinks.many().unicast().onBackpressureBuffer() 创建的。 但是在 Sinks.many().unicast() 中有一些额外的单播静态工厂方法可以进行更好的调整。\n例如，默认情况下，它是无限的：如果您在其订阅者尚未请求数据时通过它推送任何数量的数据，它会缓冲所有数据。 您可以通过为 Sinks.many().unicast().onBackpressureBuffer(Queue) factory 方法 中的内部缓冲提供自定义 Queue 实现来改变这一点，如果该队列是有界的，则当缓冲区已满并且没有收到足够的下游请求时，接收器可以拒绝推送值。\nSinks.many().multicast().onBackpressureBuffer(args?) 多播 Sinks.Many 可以向多个订阅者发送，同时为每个订阅者提供背压。 订阅者在订阅后只接收通过接收器推送的信号。\n基本的多播接收器是通过 Sinks.many().multicast().onBackpressureBuffer() 创建的。\n默认情况下，如果它的所有订阅者都被取消（这基本上意味着他们都取消了订阅），它会清除其内部缓冲区并停止接受新订阅者。 您可以通过在 Sinks.many().multicast() 下的多播静态工厂方法中使用 autoCancel 参数来调整它。\nSinks.many().multicast().directAllOrNothing() 具有简单处理背压的多播 Sinks.Many：如果任何订阅者太慢（零需求），则所有订阅者的 onNext 都会被丢弃。\n但是，慢速订阅者不会终止，一旦慢速订阅者再次开始请求，所有将继续接收从那里推送的元素。\n一旦 Sinks.Many 终止（通常通过调用其 emitError(Throwable) 或 emitComplete() 方法），它会让更多订阅者订阅但立即向他们重播终止信号。\nSinks.many().multicast().directBestEffort() 多播接收器。许多尽最大努力处理背压：如果订阅者太慢（零需求），则仅针对此慢速订阅者丢弃 onNext。\n但是，慢速订阅者不会终止，一旦他们再次开始请求，他们将继续接收新推送的元素。\n一旦 Sinks.Many 终止（通常通过调用其 emitError(Throwable) 或 emitComplete() 方法），它会让更多订阅者订阅但立即向他们重播终止信号。\nSinks.many().replay() 重播 Sinks.Many 缓存发出的元素并将它们重播给迟到的订阅者。\n它可以在多种配置中创建：\n缓存有限历史（Sinks.many().replay().limit(int)）或无限历史（Sinks.many().replay().all()）。 缓存基于时间的重播窗口 (Sinks.many().replay().limit(Duration))。 缓存历史大小和时间窗口的组合（Sinks.many().replay().limit(int, Duration)）。 还可以在 Sinks.many().replay() 下找到用于微调上述内容的其他重载，以及允许缓存单个元素的变体（latest() 和 latestOrDefault(T)）。\nSinks.unsafe().many() 高级用户和操作符构建者可能需要考虑使用 Sinks.unsafe().many() ，它将提供相同的 Sinks.Many 工厂，而无需额外的生产者线程安全。 因此，每个接收器的开销将更少，因为线程安全接收器必须检测多线程访问。\n库开发人员不应该公开不安全的接收器，而是可以在受控调用环境中在内部使用它们，在那里他们可以确保导致 onNext、onComplete 和 onError 信号的调用的外部同步，这与 Reactive Streams 规范有关。\nSinks.one() 该方法直接构造了一个简单的 Sinks.One 实例。 这种 Sink 的风格可以作为 Mono 来查看（通过它的 asMono() 视图方法），并且有稍微不同的发射方法来更好地传达这种类似 Mono 的语义：\nemitValue(T value) 生成一个 onNext(value) 信号并且 - 在大多数实现中 - 也会触发一个隐式的 onComplete() emitEmpty() 生成一个孤立的 onComplete() 信号，旨在生成一个空 Mono 的等效信号 emitError(Throwable t) 生成一个 onError(t) 信号 Sinks.one() 接受这些方法中的任何一个的调用，有效地生成一个 Mono ，它要么用一个值完成，要么完成为空或失败。\nSinks.empty() 该方法直接构造了一个简单的 Sinks.Empty 实例。 这种类型的 Sinks 类似于 Sinks.One，只是它不提供 emitValue 方法。\n因此，它只能生成一个完成为空或失败的 Mono。\n尽管无法触发 onNext，但接收器仍然使用通用 进行类型化，因为它允许轻松组合并包含在需要特定类型的运算符链中。\n测试 三个核心类：\n使用 StepVerifier 逐步测试序列是否遵循给定场景。 生成数据以使用 TestPublisher 测试下游运算符（包括您自己的运算符）的行为。 在可以通过多个替代发布者的序列中（例如，使用 switchIfEmpty 的链，探测这样的发布者以确保它被使用（即订阅）。 使用StepVerifier进行场景测试 public \u0026lt;T\u0026gt; Flux\u0026lt;T\u0026gt; appendBoomError(Flux\u0026lt;T\u0026gt; source) { return source.concatWith(Mono.error(new IllegalArgumentException(\u0026#34;boom\u0026#34;))); } 我希望这个 Flux 首先发出 thing1，然后发出 thing2，然后产生一个错误消息，boom。 订阅并验证这些期望。\n@Test public void testAppendBoomError() { Flux\u0026lt;String\u0026gt; source = Flux.just(\u0026#34;thing1\u0026#34;, \u0026#34;thing2\u0026#34;); StepVerifier.create( appendBoomError(source)) .expectNext(\u0026#34;thing1\u0026#34;) .expectNext(\u0026#34;thing2\u0026#34;) .expectErrorMessage(\u0026#34;boom\u0026#34;) .verify(); } StepVerifier 从create方法开始，传入待测试的序列，然后提供一系列方法：\n表达对接下来出现的信号的期望。 如果接收到任何其他信号（或信号的内容与预期不符），则整个测试失败并显示有意义的 AssertionError。 例如，您可以使用 expectNext(T… ) 和 expectNextCount(long)。 消费下一个信号。 当您想跳过序列的一部分或想对信号的内容应用自定义断言时（例如，检查是否存在 onNext 事件并断言发出的项目是大小列表 5）。 例如，您可以使用consumeNextWith(Consumer)。 采取杂项操作，例如暂停或运行任意代码。 例如，如果您想操作特定于测试的状态或上下文。 为此，您可以使用 thenAwait(Duration) 和 then(Runnable)。 对于terminal 事件，相应的期望方法（expectComplete() 和 expectError() 及其所有变体）切换到您无法再表达期望的 API。 在最后一步中，您所能做的就是在 StepVerifier 上执行一些额外的配置，然后触发验证，通常使用 verify() 或其变体之一。\n默认情况下，verify() 方法和派生的快捷方法（verifyThenAssertThat、verifyComplete() 等）没有超时。 他们可以无限期地阻塞。 您可以使用 StepVerifier.setDefaultTimeout(Duration) 为这些方法全局设置超时，或者使用 verify(Duration) 在每次调用的基础上指定一个超时。\n更好地识别测试失败 StepVerifier 提供了两个选项来更好地准确识别导致测试失败的期望步骤：\nas(String)：在大多数 expect* 方法之后使用，用于对前面的期望进行描述。 如果期望失败，则其错误消息包含描述。 终端期望和验证不能这样描述。 StepVerifierOptions.create().scenarioName(String)：通过使用 StepVerifierOptions 创建您的 StepVerifier，您可以使用 sceneName 方法为整个场景命名，该名称也用于断言错误消息中。 请注意，在这两种情况下，只有在 StepVerifier 方法产生自己的 AssertionError 时才保证在消息中使用描述或名称（例如，手动或通过 assertNext 中的断言库抛出异常不会将描述或名称添加到 错误消息）。\n操纵时间 您可以将 StepVerifier 与基于时间的运算符一起使用，以避免相应测试的运行时间过长。 您可以通过 StepVerifier.withVirtualTime 构建器执行此操作。\nStepVerifier.withVirtualTime(() -\u0026gt; Mono.delay(Duration.ofDays(1))) 此虚拟时间功能插入 Reactor 的调度器工厂中的自定义调度器。 由于这些定时运算符通常使用默认的 Schedulers.parallel() 调度程序，因此将其替换为 VirtualTimeScheduler 即可。 然而，一个重要的先决条件是在激活虚拟时间调度程序后实例化操作符。\n为了增加这种情况正确发生的机会，StepVerifier 不会将简单的 Flux 作为输入。 withVirtualTime 需要一个操作符，它会引导您在完成调度程序设置后懒惰地创建测试通量的实例。\n有两种处理时间的期望方法，它们在有或没有虚拟时间的情况下都是有效的：\n**thenAwait(Duration)：**暂停对步骤的评估（允许出现一些信号或延迟用完）。 **expectNoEvent(Duration)：**还让序列播放给定的持续时间，但如果在此期间出现任何信号，则测试失败。 expectNoEvent 也将订阅视为一个事件。 如果您将其用作第一步，它通常会失败，因为检测到订阅信号。 使用 expectSubscription().expectNoEvent(duration) 代替。\n这两种方法在经典模式下暂停线程给定的持续时间，并在虚拟模式下推进虚拟时钟。为了快速评估我们上面 Mono.delay 的行为，我们可以按如下方式编写代码：\nStepVerifier.withVirtualTime(() -\u0026gt; Mono.delay(Duration.ofDays(1))) .expectSubscription() .expectNoEvent(Duration.ofDays(1)) .expectNext(0L) .verifyComplete(); 我们可以使用上面的 thenAwait(Duration.ofDays(1))，但是 expectNoEvent 的好处是可以保证没有比它应该发生的更早发生。\n请注意，verify() 返回一个 Duration 值。 这是整个测试的实时持续时间。\n使用 StepVerifier 执行执行后断言 在描述了您的场景的最终期望后，您可以切换到补充断言 API，而不是触发 verify()。 为此，请改用 verifyThenAssertThat()。\nverifyThenAssertThat() 返回一个 StepVerifier.Assertions 对象，一旦整个场景成功播放，您就可以使用它来断言一些状态元素（因为它还调用了 verify()）。 典型的（尽管是高级的）用法是捕获被某些操作符删除的元素并断言它们（参见 Hooks 部分）。\n测试上下文 StepVerifier 对 Context 的传播有一些期望：\nexpectAccessibleContext：返回一个ContextExpectations 对象，您可以使用该对象在传播的上下文上设置期望。 一定要调用 then() 返回到序列期望的集合。 **expectNoAccessibleContext：**设置一个期望，即 NO Context 可以在被测操作符链上传播。 当被测发布者不是 Reactor 或没有任何可以传播上下文的操作符（例如，生成器源）时，这很可能发生。 此外，您可以通过使用 StepVerifierOptions 创建验证器，将特定于测试的初始上下文关联到 StepVerifier。\nStepVerifier.create(Mono.just(1).map(i -\u0026gt; i + 10), StepVerifierOptions.create().withInitialContext(Context.of(\u0026#34;thing1\u0026#34;, \u0026#34;thing2\u0026#34;))) .expectAccessibleContext() .contains(\u0026#34;thing1\u0026#34;, \u0026#34;thing2\u0026#34;) .then() .expectNext(11) .verifyComplete(); 使用 TestPublisher 手动发射 使用 PublisherProbe 检查执行路径 调试 reactor 跟踪栈 java.lang.IndexOutOfBoundsException: Source emitted more than one item at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:129) at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmitScalar(FluxFlatMap.java:445) at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:379) at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:121) at reactor.core.publisher.FluxRange$RangeSubscription.slowPath(FluxRange.java:154) at reactor.core.publisher.FluxRange$RangeSubscription.request(FluxRange.java:109) at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:162) at reactor.core.publisher.FluxFlatMap$FlatMapMain.onSubscribe(FluxFlatMap.java:332) at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:90) at reactor.core.publisher.FluxRange.subscribe(FluxRange.java:68) at reactor.core.publisher.FluxMapFuseable.subscribe(FluxMapFuseable.java:63) at reactor.core.publisher.FluxFlatMap.subscribe(FluxFlatMap.java:97) at reactor.core.publisher.MonoSingle.subscribe(MonoSingle.java:58) at reactor.core.publisher.Mono.subscribe(Mono.java:3096) at reactor.core.publisher.Mono.subscribeWith(Mono.java:3204) at reactor.core.publisher.Mono.subscribe(Mono.java:3090) at reactor.core.publisher.Mono.subscribe(Mono.java:3057) at reactor.core.publisher.Mono.subscribe(Mono.java:3029) at reactor.guide.GuideTests.debuggingCommonStacktrace(GuideTests.java:995) 我们可能会假设source时一个FLux或Mono，正如下一行提到的 MonoSingle 所证实的那样。 参考 Mono#single 运算符的 Javadoc，我们看到 single 有一个约定：源必须只发出一个元素。 看来我们有一个发出不止一个的源，因此违反了该合同。\n我们能否深入挖掘并确定该来源？ 以下几行不是很有帮助。通过浏览这些行，我们至少可以开始形成出错链的图片：它似乎涉及一个 MonoSingle、一个 FluxFlatMap 和一个 FluxRange（每个在跟踪中都有几行，但总的来说这三个 涉及类）。 那么 range().flatMap().single() 链可能吗？\n但是如果我们在应用程序中大量使用这种模式呢？ 这个还是没有告诉我们太多，单纯搜索single是不会发现问题的。 然后最后一行引用了我们的一些代码。 终于，我们越来越近了。\n不过，等一下。 当我们转到源文件时，我们看到的只是订阅了一个预先存在的 Flux，如下所示：\ntoDebug.subscribe(System.out::println, Throwable::printStackTrace); 所有这一切都发生在订阅时，但 Flux 本身并没有在那里声明。 更糟糕的是，当我们转到声明变量的位置时，我们会看到以下内容：\npublic Mono\u0026lt;String\u0026gt; toDebug; //please overlook the public class attribute 变量在声明的地方没有被实例化。 我们必须假设最坏的情况，我们发现可能有几个不同的代码路径在应用程序中设置它。 我们仍然不确定是哪一个导致了问题。\n我们想要更容易地找出操作符添加到链中的位置 - 即 Flux 被声明的位置。 我们通常将其称为 Flux 的“组装”\n激活调试模式 - 又名回溯 尽管堆栈跟踪仍然能够为有一定经验的人传达一些信息，但我们可以看到，在更高级的情况下，它本身并不理想。\n幸运的是，Reactor 带有专为调试而设计的汇编时检测。\n这是通过在应用程序启动时自定义 Hooks.onOperator 钩子来完成的（或至少在被指控的 Flux 或 Mono 可以被实例化之前），如下所示：\nHooks.onOperatorDebug(); 这开始通过包装运算符的构造并在那里捕获堆栈跟踪来检测对 Flux（和 Mono）运算符方法的调用（它们被组装到链中）。 由于这是在声明操作符链时完成的，因此应在此之前激活钩子，因此最安全的方法是在应用程序开始时激活它。\n稍后，如果发生异常，失败的运算符能够引用该捕获并将其附加到堆栈跟踪中。 我们将此捕获的程序集信息称为回溯。\n在下一节中，我们将看到堆栈跟踪有何不同以及如何解释这些新信息。\n阅读堆栈信息 当我们重用初始示例但激活 operatorStacktrace 调试功能时，堆栈跟踪如下：\njava.lang.IndexOutOfBoundsException: Source emitted more than one item at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:129) at reactor.core.publisher.FluxOnAssembly$OnAssemblySubscriber.onNext(FluxOnAssembly.java:375) \u0026lt;1\u0026gt; ... \u0026lt;2\u0026gt; ... at reactor.core.publisher.Mono.subscribeWith(Mono.java:3204) at reactor.core.publisher.Mono.subscribe(Mono.java:3090) at reactor.core.publisher.Mono.subscribe(Mono.java:3057) at reactor.core.publisher.Mono.subscribe(Mono.java:3029) at reactor.guide.GuideTests.debuggingActivated(GuideTests.java:1000) Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \u0026lt;3\u0026gt; Assembly trace from producer [reactor.core.publisher.MonoSingle] : \u0026lt;4\u0026gt; reactor.core.publisher.Flux.single(Flux.java:6676) reactor.guide.GuideTests.scatterAndGather(GuideTests.java:949) reactor.guide.GuideTests.populateDebug(GuideTests.java:962) org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55) org.junit.rules.RunRules.evaluate(RunRules.java:20) Error has been observed by the following operator(s): \u0026lt;5\u0026gt; |_\tFlux.single ⇢ reactor.guide.GuideTests.scatterAndGather(GuideTests.java:949) \u0026lt;6\u0026gt; 这是新的：我们看到了捕获堆栈的包装器运算符。 除此之外，堆栈跟踪的第一部分在大多数情况下仍然相同，显示了一些运算符的内部结构（因此我们在这里删除了一些代码段）。 这是回溯开始出现的地方。 首先，我们获得了有关操作符在哪里组装的一些详细信息。 我们还可以在错误通过操作符链传播时从第一个到最后一个（错误站点到订阅站点）获得错误的回溯。 每个看到错误的操作符都与用户类和使用它的行一起被提及。 捕获的堆栈跟踪作为抑制的 OnAssemblyException 附加到原始错误。 它有两个部分，但第一部分是最有趣的。 它显示了触发异常的操作符的构造路径。 在这里，它表明导致我们问题的single 是在 scatterAndGather 方法中创建的，该方法本身是从通过 JUnit 执行的 populateDebug 方法调用的。\n现在我们有了足够的信息来找到罪魁祸首，我们可以对 scatterAndGather 方法进行有意义的研究：\nprivate Mono\u0026lt;String\u0026gt; scatterAndGather(Flux\u0026lt;String\u0026gt; urls) { return urls.flatMap(url -\u0026gt; doRequest(url)) .single(); } 现在我们可以看到错误的根本原因是一个 flatMap 对几个 URL 执行了多次 HTTP 调用，但是它用 single 链接，这太严格了。 在简短的 git blame 和与该行作者的快速讨论之后，我们发现他打算使用限制较少的 take(1) 来代替。\n高级特性 组合运算符 从干净代码的角度来看，代码重用通常是一件好事。 Reactor 提供了一些模式，可以帮助您重用和共享代码，特别是对于您可能希望在代码库中定期应用的运算符或运算符组合。 如果您将一系列运算符视为一个配方，则可以创建一个运算符配方的“食谱”。\ntransform 转换运算符让您可以将运算符链的一部分封装到一个函数中。 该函数在汇编时应用于原始运算符链，以使用封装的运算符对其进行扩充。 这样做对序列的所有订阅者应用相同的操作，基本上等同于直接链接操作符。 以下代码显示了一个示例：\nFunction\u0026lt;Flux\u0026lt;String\u0026gt;, Flux\u0026lt;String\u0026gt;\u0026gt; filterAndMap = f -\u0026gt; f.filter(color -\u0026gt; !color.equals(\u0026#34;orange\u0026#34;)) .map(String::toUpperCase); Flux.fromIterable(Arrays.asList(\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;purple\u0026#34;)) .doOnNext(System.out::println) .transform(filterAndMap) .subscribe(d -\u0026gt; System.out.println(\u0026#34;Subscriber to Transformed MapAndFilter: \u0026#34;+d)); 下图显示了变换运算符如何封装流：\n结果：\nblue Subscriber to Transformed MapAndFilter: BLUE green Subscriber to Transformed MapAndFilter: GREEN orange purple Subscriber to Transformed MapAndFilter: PURPLE transformDeferred transformDeferred 运算符与transform 类似，还允许您将运算符封装在函数中。 主要区别在于，此功能是基于每个订阅者应用于原始序列的。 这意味着该函数实际上可以为每个订阅生成不同的操作符链（通过维护一些状态）。 以下代码显示了一个示例：\nAtomicInteger ai = new AtomicInteger(); Function\u0026lt;Flux\u0026lt;String\u0026gt;, Flux\u0026lt;String\u0026gt;\u0026gt; filterAndMap = f -\u0026gt; { if (ai.incrementAndGet() == 1) { return f.filter(color -\u0026gt; !color.equals(\u0026#34;orange\u0026#34;)) .map(String::toUpperCase); } return f.filter(color -\u0026gt; !color.equals(\u0026#34;purple\u0026#34;)) .map(String::toUpperCase); }; Flux\u0026lt;String\u0026gt; composedFlux = Flux.fromIterable(Arrays.asList(\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;purple\u0026#34;)) .doOnNext(System.out::println) .transformDeferred(filterAndMap); composedFlux.subscribe(d -\u0026gt; System.out.println(\u0026#34;Subscriber 1 to Composed MapAndFilter :\u0026#34;+d)); composedFlux.subscribe(d -\u0026gt; System.out.println(\u0026#34;Subscriber 2 to Composed MapAndFilter: \u0026#34;+d)); 输出结果：\nblue Subscriber 1 to Composed MapAndFilter :BLUE green Subscriber 1 to Composed MapAndFilter :GREEN orange purple Subscriber 1 to Composed MapAndFilter :PURPLE blue Subscriber 2 to Composed MapAndFilter: BLUE green Subscriber 2 to Composed MapAndFilter: GREEN orange Subscriber 2 to Composed MapAndFilter: ORANGE purple HOT vs Cold 到目前为止，我们认为所有的 Flux（和 Mono）都是一样的：它们都代表一个异步的数据序列，在你订阅之前什么都不会发生。\n不过，确实有两大类publishers：热的和冷的。\n前面的描述适用于cold的publishers。 他们为每个订阅重新生成数据。 如果未创建订阅，则永远不会生成数据。\n想想一个 HTTP 请求：每个新订阅者都会触发一个 HTTP 调用，但如果没有人对结果感兴趣，则不会进行调用。\n另一方面，hot publisher不依赖订阅者的数量。 他们可能会立即开始发布数据，并且会在新订阅者进入时继续这样做（在这种情况下，订阅者只会看到订阅后发出的新元素）。 对于hot出 publisher，在您订阅之前确实会发生一些事情。\nReactor 中为数不多的hot操作符例子just：它在组装时直接捕获值，然后将其重播给任何订阅它的人。 再次使用 HTTP 调用类比，如果捕获的数据是 HTTP 调用的结果，则仅进行一次网络调用，仅在实例化时just。\n要想转变为cold publisher，你可以使用 defer。 它将我们示例中的 HTTP 请求推迟到订阅时间（并且会导致每个新订阅的单独网络调用）。\n相反，share() 和 replay(… ) 可用于将cold发布者转变为hot发布者（至少在第一次订阅发生后）。 这两个在 Sinks 类中也有 Sinks.Many 等价物，允许以编程方式提供序列。\n考虑两个示例，一个演示冷通量，另一个使用汇来模拟热通量。 以下代码显示了第一个示例：\nFlux\u0026lt;String\u0026gt; source = Flux.fromIterable(Arrays.asList(\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;purple\u0026#34;)) .map(String::toUpperCase); source.subscribe(d -\u0026gt; System.out.println(\u0026#34;Subscriber 1: \u0026#34;+d)); source.subscribe(d -\u0026gt; System.out.println(\u0026#34;Subscriber 2: \u0026#34;+d)); 输出结果：\nSubscriber 1: BLUE Subscriber 1: GREEN Subscriber 1: ORANGE Subscriber 1: PURPLE Subscriber 2: BLUE Subscriber 2: GREEN Subscriber 2: ORANGE Subscriber 2: PURPLE 下图显示了重放行为：\n两个订阅者都捕获所有四种颜色，因为每个订阅者都会导致 Flux 上的运算符定义的进程运行。\n将第一个示例与第二个示例进行比较，如下面的代码所示：\nSinks.Many\u0026lt;String\u0026gt; hotSource = Sinks.unsafe().many().multicast().directBestEffort(); Flux\u0026lt;String\u0026gt; hotFlux = hotSource.asFlux().map(String::toUpperCase); hotFlux.subscribe(d -\u0026gt; System.out.println(\u0026#34;Subscriber 1 to Hot Source: \u0026#34;+d)); hotSource.emitNext(\u0026#34;blue\u0026#34;, FAIL_FAST); hotSource.tryEmitNext(\u0026#34;green\u0026#34;).orThrow(); hotFlux.subscribe(d -\u0026gt; System.out.println(\u0026#34;Subscriber 2 to Hot Source: \u0026#34;+d)); hotSource.emitNext(\u0026#34;orange\u0026#34;, FAIL_FAST); hotSource.emitNext(\u0026#34;purple\u0026#34;, FAIL_FAST); hotSource.emitComplete(FAIL_FAST); 结果：\nSubscriber 1 to Hot Source: BLUE Subscriber 1 to Hot Source: GREEN Subscriber 1 to Hot Source: ORANGE Subscriber 2 to Hot Source: ORANGE Subscriber 1 to Hot Source: PURPLE Subscriber 2 to Hot Source: PURPLE 使用 ConnectableFlux 向多个订阅者广播 有时，您可能不希望仅将某些处理推迟到一个订阅者的订阅时间，但您实际上可能希望其中几个人会合，然后触发订阅和数据生成。\n这就是 ConnectableFlux 的用途。 Flux API 中涵盖了返回 ConnectableFlux 的两种主要模式：publish和replay。\npublish动态地尝试尊重其各种订阅者的需求,在背压方面，通过将这些请求转发到源。 最值得注意的是，如果任何订阅者的未决需求为 0，则发布将暂停其对源的请求。 replay : 缓冲通过第一次订阅看到的数据，最多可配置限制（时间和缓冲区大小）。 它将数据重播给后续订阅者。 ConnectableFlux 提供了额外的方法来管理下游订阅与原始源订阅。 这些额外的方法包括：\n一旦您获得足够的 Flux 订阅，就可以手动调用 connect()。 这会触发对上游源的订阅。 一旦完成了 n 个订阅，autoConnect(n) 就可以自动完成相同的工作。 refCount(n) 不仅会自动跟踪传入的订阅，还会检测这些订阅何时被取消。 如果没有跟踪到足够多的订阅者，则源将“断开连接”，如果出现其他订阅者，则稍后会导致对源进行新订阅。 refCount(int, Duration) 添加了一个“宽限期”。 一旦被跟踪的订阅者数量变得太少，它会在断开源之前等待 Duration，这可能允许足够多的新订阅者进入并再次跨越连接阈值。 Flux\u0026lt;Integer\u0026gt; source = Flux.range(1, 3) .doOnSubscribe(s -\u0026gt; System.out.println(\u0026#34;subscribed to source\u0026#34;)); ConnectableFlux\u0026lt;Integer\u0026gt; co = source.publish(); co.subscribe(System.out::println, e -\u0026gt; {}, () -\u0026gt; {}); co.subscribe(System.out::println, e -\u0026gt; {}, () -\u0026gt; {}); System.out.println(\u0026#34;done subscribing\u0026#34;); Thread.sleep(500); System.out.println(\u0026#34;will now connect\u0026#34;); co.connect(); 输出：\none subscribing will now connect subscribed to source 1 1 2 2 3 3 下面使用autoConnect\nFlux\u0026lt;Integer\u0026gt; source = Flux.range(1, 3) .doOnSubscribe(s -\u0026gt; System.out.println(\u0026#34;subscribed to source\u0026#34;)); Flux\u0026lt;Integer\u0026gt; autoCo = source.publish().autoConnect(2); autoCo.subscribe(System.out::println, e -\u0026gt; {}, () -\u0026gt; {}); System.out.println(\u0026#34;subscribed first\u0026#34;); Thread.sleep(500); System.out.println(\u0026#34;subscribing second\u0026#34;); autoCo.subscribe(System.out::println, e -\u0026gt; {}, () -\u0026gt; {}); 结果：\nsubscribed first subscribing second subscribed to source 1 1 2 2 3 3 三种批处理 当您有很多元素并且想要将它们分成批次时，您可以在 Reactor 中提供三种广泛的解决方案：分组、窗口化和缓冲。 这三个在概念上很接近，因为它们将 Flux 重新分配到聚合中。 分组和窗口创建一个 Flux\u0026lt;Flux\u0026gt;，缓冲聚合到一个 Collection 中。\nFlux","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/reactor/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985223,"title":"Reactor"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"为了理解OAuth的适用场合，让我举一个假设的例子。\n有一个\u0026quot;云冲印\u0026quot;的网站，可以将用户储存在Google的照片，冲印出来。用户为了使用该服务，必须让\u0026quot;云冲印\u0026quot;读取自己储存在Google上的照片。\n问题是只有得到用户的授权，Google才会同意\u0026quot;云冲印\u0026quot;读取这些照片。那么，\u0026ldquo;云冲印\u0026quot;怎样获得用户的授权呢？\n传统方法是，用户将自己的Google用户名和密码，告诉\u0026quot;云冲印\u0026rdquo;，后者就可以读取用户的照片了。这样的做法有以下几个严重的缺点:\n\u0026ldquo;云冲印\u0026quot;为了后续的服务，会保存用户的密码，这样很不安全。 \u0026ldquo;云冲印\u0026quot;拥有了获取用户储存在Google所有资料的权力，用户没法限制\u0026quot;云冲印\u0026quot;获得授权的范围和有效期。 用户只有修改密码，才能收回赋予\u0026quot;云冲印\u0026quot;的权力。但是这样做，会使得其他所有获得用户授权的第三方应用程序全部失效。 只要有一个第三方应用程序被破解，就会导致用户密码泄漏，以及所有被密码保护的数据泄漏。 OAuth就是为了解决上面这些问题而诞生的。\n名词定义 在详细讲解OAuth 2.0之前，需要了解几个专用名词。\nThird-party application：第三方应用程序，本文中又称\u0026quot;客户端\u0026rdquo;（client），即上门面的\u0026quot;云冲印\u0026rdquo;。 HTTP service：HTTP服务提供商（Provider），本文中简称\u0026quot;服务提供商\u0026quot;，即上一节例子中的Google。 Resource Owner：资源所有者，本文中又称\u0026quot;用户\u0026quot;（user）。 User Agent：用户代理，本文中就是指浏览器。 Authorization server：认证服务器，即服务提供商专门用来处理认证的服务器。 Resource server：资源服务器，即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。 OAuth的作用就是让\u0026quot;客户端\u0026quot;安全可控地获取\u0026quot;用户\u0026quot;的授权，与\u0026quot;服务商提供商\u0026quot;进行互动。\nOAuth在\u0026quot;客户端\u0026quot;与\u0026quot;服务提供商\u0026quot;之间，设置了一个授权层（authorization layer）。\u0026ldquo;客户端\u0026quot;不能直接登录\u0026quot;服务提供商\u0026rdquo;，只能登录授权层，以此将用户与客户端区分开来。\u0026ldquo;客户端\u0026quot;登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。\n\u0026ldquo;客户端\u0026quot;登录授权层以后，\u0026ldquo;服务提供商\u0026quot;根据令牌的权限范围和有效期，向\u0026quot;客户端\u0026quot;开放用户储存的资料。\n运行流程 OAuth 2.0的运行流程如下图，摘自RFC 6749。\n（A）用户打开客户端以后，客户端要求用户给予授权。\n（B）用户同意给予客户端授权。\n（C）客户端使用上一步获得的授权，向认证服务器申请令牌。\n（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。\n（E）客户端使用令牌，向资源服务器申请获取资源。\n（F）资源服务器确认令牌无误，同意向客户端开放资源。\n不难看出来，上面六个步骤之中，B是关键，即用户怎样才能给于客户端授权。有了这个授权以后，客户端就可以获取令牌，进而凭令牌获取资源。下面一一讲解客户端获取授权的四种模式。\n授权模式 客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0定义了四种授权方式。\n授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 授权码模式 授权码模式（authorization code）是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与\u0026quot;服务提供商\u0026quot;的认证服务器进行互动。\n（A）用户访问客户端，后者将用户重定向认证服务器。\n（B）用户选择是否给予客户端授权。\n（C）假设用户给予授权，认证服务器将用户导向客户端事先指定的\u0026quot;重定向URI\u0026rdquo;（redirection URI），同时附上一个授权码。\n（D）客户端收到授权码，附上早先的\u0026quot;重定向URI\u0026rdquo;，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。\n（E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和刷新令牌（refresh token）。\nA步骤中，客户端申请认证的URI，包含以下参数：\nresponse_type：表示授权类型，必选项，此处的值固定为\u0026quot;code\u0026rdquo; client_id：表示客户端的ID，必选项 redirect_uri：表示重定向URI，可选项 scope：表示申请的权限范围，可选项 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。 GET /authorize?response_type=code\u0026amp;client_id=s6BhdRkqt3\u0026amp;state=xyz \u0026amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1 Host: server.example.com C步骤中，服务器回应客户端的URI，包含以下参数：\ncode：表示授权码，必选项。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 HTTP/1.1 302 Found Location: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA \u0026amp;state=xyz D步骤中，客户端向认证服务器申请令牌的HTTP请求，包含以下参数：\ngrant_type：表示使用的授权模式，必选项，此处的值固定为\u0026quot;authorization_code\u0026quot;。 code：表示上一步获得的授权码，必选项。 redirect_uri：表示重定向URI，必选项，且必须与A步骤中的该参数值保持一致。 client_id：表示客户端ID，必选项。 POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=authorization_code\u0026amp;code=SplxlOBeZQQYbYS6WxSbIA \u0026amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb E步骤中，认证服务器发送的HTTP响应，包含以下参数：\naccess_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项，可以是bearer类型或mac类型。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。 HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;access_token\u0026#34;:\u0026#34;2YotnFZFEjr1zCsicMWpAA\u0026#34;, \u0026#34;token_type\u0026#34;:\u0026#34;example\u0026#34;, \u0026#34;expires_in\u0026#34;:3600, \u0026#34;refresh_token\u0026#34;:\u0026#34;tGzv3JOkF0XG5Qx2TlKWIA\u0026#34;, \u0026#34;example_parameter\u0026#34;:\u0026#34;example_value\u0026#34; } 从上面代码可以看到，相关参数使用JSON格式发送（Content-Type: application/json）。此外，HTTP头信息中明确指定不得缓存。\n简化模式 简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了\u0026quot;授权码\u0026quot;这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。\n（A）客户端将用户导向认证服务器。\n（B）用户决定是否给于客户端授权。\n（C）假设用户给予授权，认证服务器将用户导向客户端指定的\u0026quot;重定向URI\u0026quot;，并在URI的Hash部分包含了访问令牌。\n（D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。\n（E）资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。\n（F）浏览器执行上一步获得的脚本，提取出令牌。\n（G）浏览器将令牌发给客户端。\nA步骤中，客户端发出的HTTP请求，包含以下参数：\nresponse_type：表示授权类型，此处的值固定为\u0026quot;token\u0026quot;，必选项。 client_id：表示客户端的ID，必选项。 redirect_uri：表示重定向的URI，可选项。 scope：表示权限范围，可选项。 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。 GET /authorize?response_type=token\u0026amp;client_id=s6BhdRkqt3\u0026amp;state=xyz \u0026amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1 Host: server.example.com C步骤中，认证服务器回应客户端的URI，包含以下参数：\naccess_token：表示访问令牌，必选项。 token_type：表示令牌类型，该值大小写不敏感，必选项。 expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。 scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。 state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 HTTP/1.1 302 Found Location: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA \u0026amp;state=xyz\u0026amp;token_type=example\u0026amp;expires_in=3600 在上面的例子中，认证服务器用HTTP头信息的Location栏，指定浏览器重定向的网址。注意，在这个网址的Hash部分包含了令牌。\n根据上面的D步骤，下一步浏览器会访问Location指定的网址，但是Hash部分不会发送。接下来的E步骤，服务提供商的资源服务器发送过来的代码，会提取出Hash中的令牌。\n密码模式 密码模式（Resource Owner Password Credentials Grant）中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向\u0026quot;服务商提供商\u0026quot;索要授权。\n在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。\n（A）用户向客户端提供用户名和密码。\n（B）客户端将用户名和密码发给认证服务器，向后者请求令牌。\n（C）认证服务器确认无误后，向客户端提供访问令牌。\nB步骤中，客户端发出的HTTP请求，包含以下参数：\ngrant_type：表示授权类型，此处的值固定为\u0026quot;password\u0026quot;，必选项。 username：表示用户名，必选项。 password：表示用户的密码，必选项。 scope：表示权限范围，可选项。 POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=password\u0026amp;username=johndoe\u0026amp;password=A3ddj3w C步骤中，认证服务器向客户端发送访问令牌，下面是一个例子:\nHTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;access_token\u0026#34;:\u0026#34;2YotnFZFEjr1zCsicMWpAA\u0026#34;, \u0026#34;token_type\u0026#34;:\u0026#34;example\u0026#34;, \u0026#34;expires_in\u0026#34;:3600, \u0026#34;refresh_token\u0026#34;:\u0026#34;tGzv3JOkF0XG5Qx2TlKWIA\u0026#34;, \u0026#34;example_parameter\u0026#34;:\u0026#34;example_value\u0026#34; } 整个过程中，客户端不得保存用户的密码。\n客户端模式 客户端模式（Client Credentials Grant）指客户端以自己的名义，而不是以用户的名义，向\u0026quot;服务提供商\u0026quot;进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求\u0026quot;服务提供商\u0026quot;提供服务，其实不存在授权问题。\n（A）客户端向认证服务器进行身份认证，并要求一个访问令牌。\n（B）认证服务器确认无误后，向客户端提供访问令牌。\nA步骤中，客户端发出的HTTP请求，包含以下参数：\ngranttype：表示授权类型，此处的值固定为\u0026quot;clientcredentials\u0026quot;，必选项。 scope：表示权限范围，可选项。 POST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=client_credentials 认证服务器必须以某种方式，验证客户端身份。\nB步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。\nHTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache { \u0026#34;access_token\u0026#34;:\u0026#34;2YotnFZFEjr1zCsicMWpAA\u0026#34;, \u0026#34;token_type\u0026#34;:\u0026#34;example\u0026#34;, \u0026#34;expires_in\u0026#34;:3600, \u0026#34;example_parameter\u0026#34;:\u0026#34;example_value\u0026#34; } 刷新令牌 如果用户访问的时候，客户端的\u0026quot;访问令牌\u0026quot;已经过期，则需要使用\u0026quot;更新令牌\u0026quot;申请一个新的访问令牌。\n客户端发出更新令牌的HTTP请求，包含以下参数：\ngranttype：表示使用的授权模式，此处的值固定为\u0026quot;refreshtoken\u0026quot;，必选项。 refresh_token：表示早前收到的更新令牌，必选项。 scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。 下面是一个例子：\nPOST /token HTTP/1.1 Host: server.example.com Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW Content-Type: application/x-www-form-urlencoded grant_type=refresh_token\u0026amp;refresh_token=tGzv3JOkF0XG5Qx2TlKWIA ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/oauth2/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985148,"title":"Oauth2"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"跨域认证的问题 互联网服务离不开用户认证。一般流程是下面这样:\n1、用户向服务器发送用户名和密码。\n2、服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。\n3、服务器向用户返回一个 session_id，写入用户的 Cookie。\n4、用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。\n5、服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。\nJWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样:\n{ \u0026#34;姓名\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;角色\u0026#34;: \u0026#34;管理员\u0026#34;, \u0026#34;到期时间\u0026#34;: \u0026#34;2018年7月1日0点0分\u0026#34; } 以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名（详见后文）。服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。\n客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。\n此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面( Authorization: Bearer \u0026lt;token\u0026gt; )。\nJWT特点：\n（1）JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。\n（2）JWT 不加密的情况下，不能将隐秘数据写入 JWT。\n（3）JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。\n（4）JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。\n（5）JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。\n（6）为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。\nJWT 的数据结构 它是一个很长的字符串，中间用点（.）分隔成三个部分。注意，JWT 内部是没有换行的，这里只是为了便于展示，将它写成了几行。JWT 的三个部分依次如下：\nHeader（头部） Payload（负载） Signature（签名） 写成一行，就是这样子： Header.Payload.Signature\nHeader Header 部分是一个 JSON 对象，描述 JWT 的元数据，通常是下面的样子：\n{ \u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } 上面代码中，alg属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）；typ属性表示这个令牌（token）的类型（type），JWT 令牌统一写为JWT。最后，将上面的 JSON 对象使用 Base64URL 算法（详见后文）转成字符串。\nPayload Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用:\niss (issuer)：签发人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 除了官方字段，你还可以在这个部分定义私有字段，下面就是一个例子:\n{ \u0026#34;sub\u0026#34;: \u0026#34;1234567890\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;admin\u0026#34;: true } 注意，JWT 默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。这个 JSON 对象也要使用 Base64URL 算法转成字符串。\nSignature Signature 部分是对前两部分的签名，防止数据篡改。\n首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。\nHMACSHA256(base64UrlEncode(header) + \u0026#34;.\u0026#34; +base64UrlEncode(payload),secret) 算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用\u0026quot;点\u0026quot;（.）分隔，就可以返回给用户。\nBase64URL 前面提到，Header 和 Payload 串型化的算法是 Base64URL。这个算法跟 Base64 算法基本类似，但有一些小的不同。\nJWT 作为一个令牌（token），有些场合可能会放到 URL（比如 api.example.com/?token=xxx）。Base64 有三个字符 +、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_ 。这就是 Base64URL 算法。\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/json-web-token/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985109,"title":"Json-Web-Token"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"OAuth2的配置属性 Spring Boot 2.x ClientRegistration spring.security.oauth2.client.registration.[registrationId] registrationId spring.security.oauth2.client.registration.[registrationId].client-id clientId spring.security.oauth2.client.registration.[registrationId].client-secret clientSecret spring.security.oauth2.client.registration.[registrationId].client-authentication-method clientAuthenticationMethod spring.security.oauth2.client.registration.[registrationId].authorization-grant-type authorizationGrantType spring.security.oauth2.client.registration.[registrationId].redirect-uri redirectUri spring.security.oauth2.client.registration.[registrationId].scope scopes spring.security.oauth2.client.registration.[registrationId].client-name clientName spring.security.oauth2.client.provider.[providerId].authorization-uri providerDetails.authorizationUri spring.security.oauth2.client.provider.[providerId].token-uri providerDetails.tokenUri spring.security.oauth2.client.provider.[providerId].jwk-set-uri providerDetails.jwkSetUri spring.security.oauth2.client.provider.[providerId].issuer-uri providerDetails.issuerUri spring.security.oauth2.client.provider.[providerId].user-info-uri providerDetails.userInfoEndpoint.uri spring.security.oauth2.client.provider.[providerId].user-info-authentication-method providerDetails.userInfoEndpoint.authenticationMethod spring.security.oauth2.client.provider.[providerId].user-name-attribute providerDetails.userInfoEndpoint.userNameAttributeName 配置举例：\nspring: security: oauth2: client: registration: okta: client-id: okta-client-id client-secret: okta-client-secret provider: okta:\tauthorization-uri: https://your-subdomain.oktapreview.com/oauth2/v1/authorize token-uri: https://your-subdomain.oktapreview.com/oauth2/v1/token user-info-uri: https://your-subdomain.oktapreview.com/oauth2/v1/userinfo user-name-attribute: sub jwk-set-uri: https://your-subdomain.oktapreview.com/oauth2/v1/keys OAuth2ClientAutoConfiguration 类主要做了下面的工作：\n注册 ClientRegistrationRepository@Bean，该Bean由配置的OAuth客户端属性中的ClientRegistry组成。 注册 SecurityFilterChain@Bean，并通过httpSecurity.oauth2Login()启用OAuth 2.0登录。 如果你想覆盖自动配置可以通过下面的方式：\n注册 ClientRegistrationRepository bean 注册 SecurityFilterChain bean 完全覆盖自动注册类 注册 ClientRegistrationRepository bean @Configuration public class OAuth2LoginConfig { @Bean public ClientRegistrationRepository clientRegistrationRepository() { return new InMemoryClientRegistrationRepository(this.googleClientRegistration()); } private ClientRegistration googleClientRegistration() { return ClientRegistration.withRegistrationId(\u0026#34;google\u0026#34;) .clientId(\u0026#34;google-client-id\u0026#34;) .clientSecret(\u0026#34;google-client-secret\u0026#34;) .clientAuthenticationMethod(ClientAuthenticationMethod.CLIENT_SECRET_BASIC) .authorizationGrantType(AuthorizationGrantType.AUTHORIZATION_CODE) .redirectUri(\u0026#34;{baseUrl}/login/oauth2/code/{registrationId}\u0026#34;) .scope(\u0026#34;openid\u0026#34;, \u0026#34;profile\u0026#34;, \u0026#34;email\u0026#34;, \u0026#34;address\u0026#34;, \u0026#34;phone\u0026#34;) .authorizationUri(\u0026#34;https://accounts.google.com/o/oauth2/v2/auth\u0026#34;) .tokenUri(\u0026#34;https://www.googleapis.com/oauth2/v4/token\u0026#34;) .userInfoUri(\u0026#34;https://www.googleapis.com/oauth2/v3/userinfo\u0026#34;) .userNameAttributeName(IdTokenClaimNames.SUB) .jwkSetUri(\u0026#34;https://www.googleapis.com/oauth2/v3/certs\u0026#34;) .clientName(\u0026#34;Google\u0026#34;) .build(); } } 注册 SecurityFilterChain bean 以下示例显示如何使用@EnableWebSecurity注册SecurityFilterChain@Bean，并通过httpSecurity.oauth2Login() 启用OAuth 2.0登录：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .authorizeHttpRequests(authorize -\u0026gt; authorize .anyRequest().authenticated() ) .oauth2Login(withDefaults()); return http.build(); } } 完全覆盖自动注册类 以下示例显示了如何通过注册ClientRegistrationRepository@Bean和SecurityFilterChain@Bean来完全覆盖自动配置。\n@Configuration public class OAuth2LoginConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .authorizeHttpRequests(authorize -\u0026gt; authorize .anyRequest().authenticated() ) .oauth2Login(withDefaults()); return http.build(); } @Bean public ClientRegistrationRepository clientRegistrationRepository() { return new InMemoryClientRegistrationRepository(this.googleClientRegistration()); } private ClientRegistration googleClientRegistration() { return ClientRegistration.withRegistrationId(\u0026#34;google\u0026#34;) .clientId(\u0026#34;google-client-id\u0026#34;) .clientSecret(\u0026#34;google-client-secret\u0026#34;) .clientAuthenticationMethod(ClientAuthenticationMethod.CLIENT_SECRET_BASIC) .authorizationGrantType(AuthorizationGrantType.AUTHORIZATION_CODE) .redirectUri(\u0026#34;{baseUrl}/login/oauth2/code/{registrationId}\u0026#34;) .scope(\u0026#34;openid\u0026#34;, \u0026#34;profile\u0026#34;, \u0026#34;email\u0026#34;, \u0026#34;address\u0026#34;, \u0026#34;phone\u0026#34;) .authorizationUri(\u0026#34;https://accounts.google.com/o/oauth2/v2/auth\u0026#34;) .tokenUri(\u0026#34;https://www.googleapis.com/oauth2/v4/token\u0026#34;) .userInfoUri(\u0026#34;https://www.googleapis.com/oauth2/v3/userinfo\u0026#34;) .userNameAttributeName(IdTokenClaimNames.SUB) .jwkSetUri(\u0026#34;https://www.googleapis.com/oauth2/v3/certs\u0026#34;) .clientName(\u0026#34;Google\u0026#34;) .build(); } } 如果您无法使用Spring Boot 2.x，并且希望在CommonOAuth2Provider（例如，Google）中配置一个预定义的提供程序，请应用以下配置：\n@EnableWebSecurity public class OAuth2LoginConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .authorizeHttpRequests(authorize -\u0026gt; authorize .anyRequest().authenticated() ) .oauth2Login(withDefaults()); return http.build(); } @Bean public ClientRegistrationRepository clientRegistrationRepository() { return new InMemoryClientRegistrationRepository(this.googleClientRegistration()); } @Bean public OAuth2AuthorizedClientService authorizedClientService( ClientRegistrationRepository clientRegistrationRepository) { return new InMemoryOAuth2AuthorizedClientService(clientRegistrationRepository); } @Bean public OAuth2AuthorizedClientRepository authorizedClientRepository( OAuth2AuthorizedClientService authorizedClientService) { return new AuthenticatedPrincipalOAuth2AuthorizedClientRepository(authorizedClientService); } private ClientRegistration googleClientRegistration() { return CommonOAuth2Provider.GOOGLE.getBuilder(\u0026#34;google\u0026#34;) .clientId(\u0026#34;google-client-id\u0026#34;) .clientSecret(\u0026#34;google-client-secret\u0026#34;) .build(); } } HttpSecurity.oauth2Login() 为自定义OAuth 2.0登录提供了许多配置选项。主要配置选项被分组到其协议端点对应项中。例如，oauth2Login().authorizationEndpoint()允许配置授权端点，而oauth2Login().tokenEndpoin()允许配置令牌端点。如下面代码：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Login(oauth2 -\u0026gt; oauth2 .authorizationEndpoint(authorization -\u0026gt; authorization ... ) .redirectionEndpoint(redirection -\u0026gt; redirection ... ) .tokenEndpoint(token -\u0026gt; token ... ) .userInfoEndpoint(userInfo -\u0026gt; userInfo ... ) ); return http.build(); } } oauth2Login() DSL的主要目标是与规范中定义的命名紧密一致。\nOAuth 2.0授权框架将协议端点定义如下：\n授权过程使用授权服务器两个端点（HTTP资源）：\n授权端点：由客户端使用，通过用户代理重定向，从资源所有者获得授权。 令牌端点：客户端用于获取访问令牌，通常携带客户端身份信息。 此外还有一个客户端端点:\n重定向端点：授权服务器使用它通过资源所有者用户代理向客户端返回包含授权凭据的响应。 OpenID Connect Core 1.0规范对UserInfo端点的定义如下：\nUserInfo端点是一个OAuth 2.0受保护的资源，它返回关于经过身份验证的最终用户的声明。为了获得有关最终用户的请求声明，客户端使用通过OpenID Connect身份验证获得的访问令牌向UserInfo端点发出请求。这些声明通常由一个JSON对象表示，该对象包含声明的键-值对集合。\n以下代码显示了oauth2Login() DSL可用的完整配置选项：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Login(oauth2 -\u0026gt; oauth2 .clientRegistrationRepository(this.clientRegistrationRepository()) .authorizedClientRepository(this.authorizedClientRepository()) .authorizedClientService(this.authorizedClientService()) .loginPage(\u0026#34;/login\u0026#34;) .authorizationEndpoint(authorization -\u0026gt; authorization .baseUri(this.authorizationRequestBaseUri()) .authorizationRequestRepository(this.authorizationRequestRepository()) .authorizationRequestResolver(this.authorizationRequestResolver()) ) .redirectionEndpoint(redirection -\u0026gt; redirection .baseUri(this.authorizationResponseBaseUri()) ) .tokenEndpoint(token -\u0026gt; token .accessTokenResponseClient(this.accessTokenResponseClient()) ) .userInfoEndpoint(userInfo -\u0026gt; userInfo .userAuthoritiesMapper(this.userAuthoritiesMapper()) .userService(this.oauth2UserService()) .oidcUserService(this.oidcUserService()) ) ); return http.build(); } } 登录页配置 默认情况下，OAuth 2.0登录页面由DefaultLoginPageGeneratingFilter自动生成。默认登录页面显示每个配置的OAuth客户端及其ClientRegistration.clientName作为链接，能够启动授权请求（或OAuth 2.0登录）。\n为了让DefaultLoginPageGeneratingFilter显示配置的OAuth客户端的链接，注册的ClientRegistrationRepository还需要实现Iterable。有关参考信息，请参阅InMemoryClientRegistrationRepository。\n每个OAuth客户端的链接目标默认为：\nOAuth2AuthorizationRequestRedirectFilter.DEFAULT_AUTHORIZATION_REQUEST_BASE_URI + \u0026ldquo;/{registrationId}\u0026rdquo;\n例如下面的示例：\n\u0026lt;a href=\u0026#34;/oauth2/authorization/google\u0026#34;\u0026gt;Google\u0026lt;/a\u0026gt; 要覆盖默认登录页面，请配置oauth2Login().loginPage() 和（可选）oauth2Login().authizationEndpoint().baseUri()。例如：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Login(oauth2 -\u0026gt; oauth2 .loginPage(\u0026#34;/login/oauth2\u0026#34;) ... .authorizationEndpoint(authorization -\u0026gt; authorization .baseUri(\u0026#34;/login/oauth2/authorization\u0026#34;) ... ) ); return http.build(); } } 您需要提供一个带有@RequestMapping（“/login/oauth2”）的@Controller，它能够呈现自定义登录页面。\n重定向端点 授权服务器使用重定向端点通过资源所有者用户代理向客户端返回授权响应（包含授权凭据）。\nOAuth 2.0登录利用授权代码授予。因此，授权凭证就是授权码。\n默认的授权响应baseUri（重定向端点）是/login/oauth2/code/*，它在OAuth2LoginAuthenticationFilter.default_FILTER_PROCESSES_URI中定义。\n如果要自定义授权响应baseUri，请按以下示例所示进行配置：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Login(oauth2 -\u0026gt; oauth2 .redirectionEndpoint(redirection -\u0026gt; redirection .baseUri(\u0026#34;/login/oauth2/callback/*\u0026#34;) ... ) ); return http.build(); } } 您还需要确保ClientRegistration.redirectUri与自定义授权响应baseUri匹配。\n以下列表显示了一个示例：\nreturn CommonOAuth2Provider.GOOGLE.getBuilder(\u0026#34;google\u0026#34;) .clientId(\u0026#34;google-client-id\u0026#34;) .clientSecret(\u0026#34;google-client-secret\u0026#34;) .redirectUri(\u0026#34;{baseUrl}/login/oauth2/callback/{registrationId}\u0026#34;) .build(); 用户信息端点 UserInfo端点包括许多配置选项，我们会在下面的小结中描述。\n映射用户权限 用户成功使用OAuth 2.0 Provider进行身份验证后，OAuth2User.getAuthorities（）（或OidcUser.getauthorites（））可能会映射到一组新的GrantedAuthority实例，在完成身份验证时，这些实例将提供给OAuth2AuthenticationToken。\nOAuth2AuthenticationToken.getAuthorities（）用于授权请求，例如在hasRole（\u0026lsquo;USER\u0026rsquo;）或hasRoel（\u0026lsquo;ADMIN\u0026rsquo;）中。\n映射用户权限时有几个选项可供选择：\n使用GrantedAuthoritiesMapper OAuth2UserService基于委派的策略 使用GrantedAuthoritiesMapper 提供GrantedAuthoritiesMapper的实现并对其进行配置，如以下示例所示：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Login(oauth2 -\u0026gt; oauth2 .userInfoEndpoint(userInfo -\u0026gt; userInfo .userAuthoritiesMapper(this.userAuthoritiesMapper()) ... ) ); return http.build(); } private GrantedAuthoritiesMapper userAuthoritiesMapper() { return (authorities) -\u0026gt; { Set\u0026lt;GrantedAuthority\u0026gt; mappedAuthorities = new HashSet\u0026lt;\u0026gt;(); authorities.forEach(authority -\u0026gt; { if (OidcUserAuthority.class.isInstance(authority)) { OidcUserAuthority oidcUserAuthority = (OidcUserAuthority)authority; OidcIdToken idToken = oidcUserAuthority.getIdToken(); OidcUserInfo userInfo = oidcUserAuthority.getUserInfo(); // Map the claims found in idToken and/or userInfo // to one or more GrantedAuthority\u0026#39;s and add it to mappedAuthorities } else if (OAuth2UserAuthority.class.isInstance(authority)) { OAuth2UserAuthority oauth2UserAuthority = (OAuth2UserAuthority)authority; Map\u0026lt;String, Object\u0026gt; userAttributes = oauth2UserAuthority.getAttributes(); // Map the attributes found in userAttributes // to one or more GrantedAuthority\u0026#39;s and add it to mappedAuthorities } }); return mappedAuthorities; }; } } 或者，您可以注册GrantedAuthoritiesMapper@Bean，使其自动应用于配置，如以下示例所示：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Login(withDefaults()); return http.build(); } @Bean public GrantedAuthoritiesMapper userAuthoritiesMapper() { ... } } OAuth2UserService基于委派的策略 与使用GrantedAuthoritiesMapper相比，此策略是先进的，但是，它也更灵活，因为它允许您访问OAuth2UserRequest和OAuth2User（当使用OAuth 2.0 UserService时）或OidcUserRequest与OidcUser（在使用OpenID Connect 1.0 UserServices时）。\nOAuth2UserRequest（和OidcUserRequest）为您提供了对关联OAuth2AccessToken的访问，这在委托人需要从受保护的资源中获取权限信息，然后才能映射用户的自定义权限的情况下非常有用。\n以下示例显示如何使用OpenID Connect 1.0 UserService实施和配置基于委派的策略：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Login(oauth2 -\u0026gt; oauth2 .userInfoEndpoint(userInfo -\u0026gt; userInfo .oidcUserService(this.oidcUserService()) ... ) ); return http.build(); } private OAuth2UserService\u0026lt;OidcUserRequest, OidcUser\u0026gt; oidcUserService() { final OidcUserService delegate = new OidcUserService(); return (userRequest) -\u0026gt; { // Delegate to the default implementation for loading a user OidcUser oidcUser = delegate.loadUser(userRequest); OAuth2AccessToken accessToken = userRequest.getAccessToken(); Set\u0026lt;GrantedAuthority\u0026gt; mappedAuthorities = new HashSet\u0026lt;\u0026gt;(); // TODO // 1) Fetch the authority information from the protected resource using accessToken // 2) Map the authority information to one or more GrantedAuthority\u0026#39;s and add it to mappedAuthorities // 3) Create a copy of oidcUser but use the mappedAuthorities instead oidcUser = new DefaultOidcUser(mappedAuthorities, oidcUser.getIdToken(), oidcUser.getUserInfo()); return oidcUser; }; } } OAuth 2.0 UserService DefaultOAuth2UserService是支持标准OAuth 2.0 Provider的OAuth2UserService的实现。\nOAuth2UserService从UserInfo端点获取最终用户（资源所有者）的用户属性（通过使用在授权流期间授予客户端的访问令牌），并以OAuth2User的形式返回AuthenticatedPrincipal。\nDefaultOAuth2UserService在UserInfo端点请求用户属性时使用RestOperations。\n如果需要自定义UserInfo请求的预处理，可以提供DefaultOAuth2UserService.setRequestEntityConverter（），带有自定义Converter\u0026lt;OAuth2UserRequest，RequestEntity\u0026lt;？\u0026raquo;。默认实现OAuth2UserRequestEntityConverter构建UserInfo请求的RequestEntity表示，默认情况下，该表示在Authorization头中设置OAuth2AccessToken。\n另一方面，如果需要自定义UserInfo响应的后期处理，则需要提供DefaultOAuth2UserService。带有自定义配置的RestOperations的setRestOperation（）。默认RestOperations配置如下：\nRestTemplate restTemplate = new RestTemplate(); restTemplate.setErrorHandler(new OAuth2ErrorResponseErrorHandler()); OAuth2ErrorResponseErrorHandler是可以处理OAuth 2.0错误（400错误请求）的Response ErrorHandlder。它使用OAuth2ErrorHttpMessageConverter将OAuth 2.0 Error参数转换为OAuth2错误。\n无论您是自定义DefaultOAuth2UserService还是提供自己的OAuth2UserService实现，都需要按以下示例所示进行配置：\n@EnableWebSecurity public class OAuth2LoginSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Login(oauth2 -\u0026gt; oauth2 .userInfoEndpoint(userInfo -\u0026gt; userInfo .userService(this.oauth2UserService()) ... ) ); return http.build(); } private OAuth2UserService\u0026lt;OAuth2UserRequest, OAuth2User\u0026gt; oauth2UserService() { ... } } DSL 提供了许多配置选项，用于自定义 OAuth 2.0 客户端使用的核心组件。此外，授权码允许自定义授权码授予。\n下面的代码显示了 DSL 提供的完整配置选项：\n@EnableWebSecurity public class OAuth2ClientSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .oauth2Client(oauth2 -\u0026gt; oauth2 .clientRegistrationRepository(this.clientRegistrationRepository()) .authorizedClientRepository(this.authorizedClientRepository()) .authorizedClientService(this.authorizedClientService()) .authorizationCodeGrant(codeGrant -\u0026gt; codeGrant .authorizationRequestRepository(this.authorizationRequestRepository()) .authorizationRequestResolver(this.authorizationRequestResolver()) .accessTokenResponseClient(this.accessTokenResponseClient()) ) ); return http.build(); } } OAuth2AuthorizedClientManager负责与一个或多个OAuth2AauthorizedClientProvider协作管理OAuth 2.0客户端的授权（或重新授权）。\n以下代码显示了如何注册OAuth2AuthorizedClientManager@Bean并将其与OAuth2AauthorizedClientProvider组合关联的示例，该组合提供对authorization_code、refresh_token、client_credentials和密码授权授予类型的支持：\n@Bean public OAuth2AuthorizedClientManager authorizedClientManager( ClientRegistrationRepository clientRegistrationRepository, OAuth2AuthorizedClientRepository authorizedClientRepository) { OAuth2AuthorizedClientProvider authorizedClientProvider = OAuth2AuthorizedClientProviderBuilder.builder() .authorizationCode() .refreshToken() .clientCredentials() .password() .build(); DefaultOAuth2AuthorizedClientManager authorizedClientManager = new DefaultOAuth2AuthorizedClientManager( clientRegistrationRepository, authorizedClientRepository); authorizedClientManager.setAuthorizedClientProvider(authorizedClientProvider); return authorizedClientManager; } Spring Security OAuth2.0 OAuth2.0协议 Spring Security OAuth2.0客户端 OAuth 2.0客户端特性为OAuth 2.0授权框架中定义的客户端角色提供支持。\n在高层，可用的核心功能包括：\n授权支持\nAuthorization Code Refresh Token Client Credentials Resource Owner Password Credentials JWT Bearer 客户端认证支持\nJWT Bearer HTTP客户端支持\nWebClient integration for Servlet Environments（请求受保护的资源） HttpSecurity.oauth2Client()DSL提供了许多配置选项，用于定制OAuth 2.0客户端使用的核心组件。此外，HttpSecurity.oauth2Client().authorizationCodeGrant()自定义授权码模式。\n@EnableWebSecurity public class OAuth2ClientSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .oauth2Client(oauth2 -\u0026gt; oauth2 .clientRegistrationRepository(this.clientRegistrationRepository()) .authorizedClientRepository(this.authorizedClientRepository()) .authorizedClientService(this.authorizedClientService()) .authorizationCodeGrant(codeGrant -\u0026gt; codeGrant .authorizationRequestRepository(this.authorizationRequestRepository()) .authorizationRequestResolver(this.authorizationRequestResolver()) .accessTokenResponseClient(this.accessTokenResponseClient()) ) ); } } OAuth2AuthorizedClientManager负责与一个或多个OAuth2AuthorizedClientProvider协作管理OAuth 2.0客户端的授权（或重新授权）。\n以下代码显示了如何注册OAuth2AuthorizedClientManager @Bean并将其与OAuth2AuthorizedClientProvider组合关联的示例，该组合提供对authorization_code, refresh_token, client_credentials, 和password授予类型的支持：\n@Bean public OAuth2AuthorizedClientManager authorizedClientManager( ClientRegistrationRepository clientRegistrationRepository, OAuth2AuthorizedClientRepository authorizedClientRepository) { OAuth2AuthorizedClientProvider authorizedClientProvider = OAuth2AuthorizedClientProviderBuilder.builder() .authorizationCode() .refreshToken() .clientCredentials() .password() .build(); DefaultOAuth2AuthorizedClientManager authorizedClientManager = new DefaultOAuth2AuthorizedClientManager( clientRegistrationRepository, authorizedClientRepository); authorizedClientManager.setAuthorizedClientProvider(authorizedClientProvider); return authorizedClientManager; } 核心类 ClientRegistration ClientRegistration是向OAuth 2.0或OpenID Connect 1.0提供程序注册的客户端的表示。\npublic final class ClientRegistration { private String registrationId;\t//表示客户端注册的唯一id private String clientId; //客户端id\tprivate String clientSecret;//客户端密码 //Provider验证客户端的方法。 //支持的值为client_secret_basic、client_secret_post、private_key_jwt、client_secret_jwt和none private ClientAuthenticationMethod clientAuthenticationMethod;\t//OAuth2.0授权框架定义了四种授权授予类型。 //支持的值包括authorization_code, client_credentials, password //以及扩展授权类型urn:ietf:params:oauth:grant-type:jwt-bearer。 private AuthorizationGrantType authorizationGrantType;\t//客户端的注册重定向URI，最终用户对客户端进行身份验证和授权访问后， // 授权服务器在将最终用户的用户代理重定向到该URI。 private String redirectUri;\t//客户端在授权请求流期间请求的范围，例如openid、电子邮件或概要文件。 private Set\u0026lt;String\u0026gt; scopes; private ProviderDetails providerDetails; //用于客户端的描述性名称。该名称可用于某些场景， //例如在自动生成的登录页面中显示客户端名称时。 private String clientName;\tpublic class ProviderDetails { //授权服务器的授权端点URI。 private String authorizationUri; //获取token的端点 private String tokenUri; //获取用户信息的端点\tprivate UserInfoEndpoint userInfoEndpoint; //从授权服务器获取JSON Web Key (JWK) Set，该信息 //包括\t验证JSON Web Signature (JWS) ID token的加密key和可选的用户信息 private String jwkSetUri;\t//返回OpenID Connect 1.0提供程序或OAuth 2.0授权服务器的颁发者标识符URI。\tprivate String issuerUri; // OPen ID配置信息\tprivate Map\u0026lt;String, Object\u0026gt; configurationMetadata; public class UserInfoEndpoint { //用于访问经过身份验证的最终用户的声明和属性的UserInfo端点URI。 private String uri;\t//将访问令牌发送到UserInfo端点时使用的身份验证方法。 /// 支持的值包括header, form, 和 query.。 private AuthenticationMethod authenticationMethod; //UserInfo响应中返回的属性的名称，该响应引用最终用户的名称或标识符。\tprivate String userNameAttributeName;\t} } } ClientRegistration提供了以这种方式配置ClientRegistration的方便方法，如下所示：\nClientRegistration clientRegistration = ClientRegistrations.fromIssuerLocation(\u0026#34;https://idp.example.com/issuer\u0026#34;).build(); ClientRegistrationRepository ClientRegistrationRepository用作OAuth 2.0/OpenID Connect 1.0 ClientRegistration的存储库。\n客户端注册信息最终由关联的授权服务器存储和拥有。此存储库提供检索主客户端注册信息子集的能力，该信息存储在授权服务器中。\nSpring Boot2.x绑定spring.security.oauth2.client.registration.[registrationId]下的属性到ClientRegistration 实例，然后由ClientRegistrationRepository组装\nClientRegistration存储库的默认实现是InMemoryClientRegistrationRepository。\n自动配置还将ClientRegistrationRepository注册为ApplicationContext中的@Bean，以便在应用程序需要时可用于依赖项注入。\n@Controller public class OAuth2ClientController { @Autowired private ClientRegistrationRepository clientRegistrationRepository; @GetMapping(\u0026#34;/\u0026#34;) public String index() { ClientRegistration oktaRegistration = this.clientRegistrationRepository.findByRegistrationId(\u0026#34;okta\u0026#34;); ... return \u0026#34;index\u0026#34;; } } OAuth2AuthorizedClient OAuth2AuthorizedClient是已授权客户端的表示。当最终用户（资源所有者）已授权客户端访问其受保护的资源时，客户端被视为已授权。\nOAuth2AuthorizedClient用于将OAuth2AccessToken（以及可选的OAuth2RefreshToken）关联到ClientRegistration（客户端）和资源所有者，后者是授予授权的主要最终用户。\nOAuth2AuthorizedClientRepository and OAuth2AuthorizedClientService OAuth2AuthorizedClientRepository 负责在web请求中持久化OAuth2AuthorizedClient(s) ，OAuth2AuthorizedClientservice的主要角色是在应用程序级别管理OAuth2AuthorizedClient。\n从开发人员的角度来看，OAuth2AuthorizedClientRepository或OAuth2AuthorizedClientService提供了查找与客户端关联的OAuth2AccessToken的功能，以便可以使用它来访问受保护的资源。\n下面是一个实例：\n@Controller public class OAuth2ClientController { @Autowired private OAuth2AuthorizedClientService authorizedClientService; @GetMapping(\u0026#34;/\u0026#34;) public String index(Authentication authentication) { OAuth2AuthorizedClient authorizedClient = this.authorizedClientService.loadAuthorizedClient(\u0026#34;okta\u0026#34;, authentication.getName()); OAuth2AccessToken accessToken = authorizedClient.getAccessToken(); ... return \u0026#34;index\u0026#34;; } } OAuth2AuthorizedClientservice的默认实现是InMemoryAuth2AuthorizedClientservice，它在内存中存储OAuth2AuthorizedClient对象。或者，您可以使用JDBCOAuth2AuthorizedClient。\nOAuth2AuthorizedClientManager and OAuth2AuthorizedClientProvider OAuth2AuthorizedClient管理器负责OAuth2AuthorizedClient的总体管理。主要职责包括：\n使用OAuth2AuthorizedClientProvider授权（或重新授权）OAuth 2.0客户端。 存储OAuth2AuthorizedClient，通常委托给OAuth2AuthorizedClientService or OAuth2AuthorizedClientRepository. 当OAuth 2.0客户端已成功授权（或重新授权）时，委托给OAuth2AuthorizationSuccessHandler。 当OAuth 2.0客户端无法授权（或重新授权）时，委托给OAuth2AuthorizationFailureHandler。 OAuth2AuthorizedClientProvider实现了授权（或重新授权）OAuth2.0客户端的策略。实现通常实现授权授予类型，例如authorization_code, client_credentials等。\nOAuth2AuthorizedClientManager的默认实现是DefaultOAuth2AuthorizedClientManager，它与OAuth2AuthorizedClientProvider关联，OAuth2AuthorizedClientManager可以使用基于委托的组合支持多种授权授予类型。您可以使用OAuth2AuthorizedClientProviderBuilder来配置和构建基于委托的组合。\n以下代码显示了如何配置和构建OAuth2AuthorizedClient Provider组合的示例，该组合提供对authorization_code, refresh_token, client_credentials, and password的支持：\n@Bean public OAuth2AuthorizedClientManager authorizedClientManager( ClientRegistrationRepository clientRegistrationRepository, OAuth2AuthorizedClientRepository authorizedClientRepository) { OAuth2AuthorizedClientProvider authorizedClientProvider = OAuth2AuthorizedClientProviderBuilder.builder() .authorizationCode() .refreshToken() .clientCredentials() .password() .build(); DefaultOAuth2AuthorizedClientManager authorizedClientManager = new DefaultOAuth2AuthorizedClientManager( clientRegistrationRepository, authorizedClientRepository); authorizedClientManager.setAuthorizedClientProvider(authorizedClientProvider); return authorizedClientManager; } 当授权成功时，DefaultOAuth2AuthorizedClientManager 委托给OAuth2AuthorizationSuccessHandler 进行后续处理 。 OAuth2AuthorizationSuccessHandler 默认使用 OAuth2AuthorizedClientRepository 保存OAuth2AuthorizedClient 。\n在重新授权失败的情况下（例如，刷新令牌不再有效），RemoveAuthorizedClientOAuth2AuthorizationFailureHandler 会将先前保存的OAuth2AuthorizedClient 从 OAuth2AuthorizedClientRepository 移除。\n你可以使用setAuthorizationSuccessHandler(OAuth2AuthorizationSuccessHandler) 和setAuthorizationFailureHandler(OAuth2AuthorizationFailureHandler) 自定义这些handler。\nDefaultOAuth2AuthorizedClientManager还与类型为Function\u0026lt;OAuth2AuthorizeRequest，Map\u0026lt;String，Object\u0026raquo;的contextAttributesMapper相关联，后者负责将属性从OAuth2AuthorizeRequest映射到要关联到OAuth2AuthorizationContext。当您需要为OAuth2AuthorizedClientProvider提供所需（支持的）属性时，这非常有用，例如，OAuth2AuthorizedClientProvider要求资源所有者的用户名和密码在OAuth2AuthorizationContext.getAttributes（）中可用。\n@Bean public OAuth2AuthorizedClientManager authorizedClientManager( ClientRegistrationRepository clientRegistrationRepository, OAuth2AuthorizedClientRepository authorizedClientRepository) { OAuth2AuthorizedClientProvider authorizedClientProvider = OAuth2AuthorizedClientProviderBuilder.builder() .password() .refreshToken() .build(); DefaultOAuth2AuthorizedClientManager authorizedClientManager = new DefaultOAuth2AuthorizedClientManager( clientRegistrationRepository, authorizedClientRepository); authorizedClientManager.setAuthorizedClientProvider(authorizedClientProvider); // Assuming the `username` and `password` are supplied as `HttpServletRequest` parameters, // map the `HttpServletRequest` parameters to `OAuth2AuthorizationContext.getAttributes()` authorizedClientManager.setContextAttributesMapper(contextAttributesMapper()); return authorizedClientManager; } private Function\u0026lt;OAuth2AuthorizeRequest, Map\u0026lt;String, Object\u0026gt;\u0026gt; contextAttributesMapper() { return authorizeRequest -\u0026gt; { Map\u0026lt;String, Object\u0026gt; contextAttributes = Collections.emptyMap(); HttpServletRequest servletRequest = authorizeRequest.getAttribute(HttpServletRequest.class.getName()); String username = servletRequest.getParameter(OAuth2ParameterNames.USERNAME); String password = servletRequest.getParameter(OAuth2ParameterNames.PASSWORD); if (StringUtils.hasText(username) \u0026amp;\u0026amp; StringUtils.hasText(password)) { contextAttributes = new HashMap\u0026lt;\u0026gt;(); // `PasswordOAuth2AuthorizedClientProvider` requires both attributes contextAttributes.put(OAuth2AuthorizationContext.USERNAME_ATTRIBUTE_NAME, username); contextAttributes.put(OAuth2AuthorizationContext.PASSWORD_ATTRIBUTE_NAME, password); } return contextAttributes; }; } DefaultOAuth2AuthorizedClientManager设计用于HttpServletRequest的上下文中。在HttpServletRequest上下文之外操作时，请改用AuthorizedClientServiceOAuth2AuthorizedClientManager。\n无交互的后台程序经常使用AuthorizedClientServiceOAuth2AuthorizedClientManager。这种程序经常使用client_credentials 授权模式，下面是使用举例：\n@Bean public OAuth2AuthorizedClientManager authorizedClientManager( ClientRegistrationRepository clientRegistrationRepository, OAuth2AuthorizedClientService authorizedClientService) { OAuth2AuthorizedClientProvider authorizedClientProvider = OAuth2AuthorizedClientProviderBuilder.builder() .clientCredentials() .build(); AuthorizedClientServiceOAuth2AuthorizedClientManager authorizedClientManager = new AuthorizedClientServiceOAuth2AuthorizedClientManager( clientRegistrationRepository, authorizedClientService); authorizedClientManager.setAuthorizedClientProvider(authorizedClientProvider); return authorizedClientManager; } OAuth 2.0 Resource Server Spring Security 支持使用两种形式的 OAuth 2.0 Bearer Tokens 来保护端点：\nJWT Opaque Tokens 这在应用程序将其权限管理委托给授权服务器（例如，Okta 或 Ping Identity）的情况下很方便。 资源服务器可以咨询此授权服务器以授权请求。 让我们看看 Bearer Token Authentication 在 Spring Security 中是如何工作的。 首先，我们看到，与基本身份验证一样，WWW-Authenticate 标头被发送回未经身份验证的客户端。 首先，用户向需要授权的资源/private 发出未经身份验证的请求。 Spring Security 的 FilterSecurityInterceptor 指示抛出 AccessDeniedException， 拒绝未经身份验证的请求。 由于用户未通过身份验证，因此 ExceptionTranslationFilter 会启动 Start Authentication。 配置的 AuthenticationEntryPoint 是 BearerTokenAuthenticationEntryPoint 的一个实例，它发送 WWW-Authenticate 标头。 RequestCache 通常是一个不保存请求的 NullRequestCache，因为客户端能够重放它最初请求的请求。 当客户端收到 WWW-Authenticate: Bearer 标头时，它知道应该使用bearer令牌重试。 以下是正在处理的bearer令牌的流程:\n当用户提交其持有者令牌时，BearerTokenAuthenticationFilter 通过从 HttpServletRequest 中提取令牌来创建一个 BearerTokenAuthenticationToken，这是一种身份验证。\n接下来，HttpServletRequest 被传递给 AuthenticationManagerResolver，它选择 AuthenticationManager。 BearerTokenAuthenticationToken 被传入 AuthenticationManager 进行认证。 AuthenticationManager 的详细信息取决于您是否配置了 JWT 或opaque token.。\n如果认证失败：\nSecurityContextHolder 被清除。 调用 AuthenticationEntryPoint 以触发再次发送 WWW-Authenticate 标头。 如果认证成功：\nAuthentication 在 SecurityContextHolder 上设置。 BearerTokenAuthenticationFilter 调用 FilterChain.doFilter(request,response) 以继续应用程序逻辑的其余部分。 ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-security-oauth2/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669985011,"title":"Spring-Security-Oauth2"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"构建时替换属性 您可以使用构建工具中设定的属性来替换应用属性，而不是对项目的生成配置中指定的某些属性进行硬编码。这在Maven和Gradle都是可能的。\nmaven 您可以通过使用资源过滤从Maven项目自动展开属性。如果使用spring-boot-starter-parent，则可以使用@..@占位符引用Maven的“project properties，如下例所示：\napp.encoding=@project.build.sourceEncoding@ app.java.version=@java.version@ 如果启用addResources标志，springboot:run目标可以将src/main/resources直接添加到类路径（用于热重新加载）。这样做可以避免资源筛选和此功能。相反，您可以使用exec:java目标或自定义插件的配置。有关详细信息，请参见插件使用页面。????\n如果不使用starter父级，则需要在pom.xml的＜build/＞元素中包含以下元素：\n\u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; 您还需要在＜plugins/＞中包含以下元素：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-resources-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;delimiters\u0026gt; \u0026lt;delimiter\u0026gt;@\u0026lt;/delimiter\u0026gt; \u0026lt;/delimiters\u0026gt; \u0026lt;useDefaultDelimiters\u0026gt;false\u0026lt;/useDefaultDelimiters\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; Gradle 您可以通过配置Java插件的processResources任务来自动扩展Gradle项目中的属性，如下例所示：\ntasks.named(\u0026#39;processResources\u0026#39;) { expand(project.properties) } 然后，可以使用占位符引用Gradle项目的属性，如以下示例所示：\napp.name=${name} app.description=${description} Gradle的expand方法使用Groovy的SimpleTemplateEngine，它转换${..}标记。${..}样式与Spring自己的属性占位符机制冲突。要将Spring属性占位符与自动扩展一起使用，请按如下方式转义Spring属性占位符：${..}。\n生成build信息 Maven插件和Gradle插件都允许生成包含项目坐标、名称和版本的构建信息。插件还可以通过配置文件添加附加属性。当存在这样的文件时，Spring Boot会自动配置BuildProperties bean。\n要使用Maven生成构建信息，请为执行添加build-info 目标，如下例所示：\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.5\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;build-info\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 以下示例对Gradle执行相同操作：\nspringBoot { buildInfo() } 生成git信息 Maven和Gradle都允许生成git.properties文件，其中包含有关项目生成时git源代码存储库状态的信息。\n对于Maven用户，spring-boot-starter-parent POM包括一个预配置的插件，用于生成 git.properties 文件。要使用它，请将以下声明添加到POM中：\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;pl.project13.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;git-commit-id-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; gradle 如下：\nplugins { id \u0026#34;com.gorylenko.gradle-git-properties\u0026#34; version \u0026#34;2.3.2\u0026#34; } 覆盖spring starter指定的版本 应用依赖项管理插件时，导入的spring-boot-dependencies bom来控制它管理的依赖项的版本。浏览Spring Boot参考中的Dependency版本附录，以获得这些属性的完整列表。\n要自定义托管版本，请设置其相应的属性。例如：\next[\u0026#39;slf4j.version\u0026#39;] = \u0026#39;1.7.20\u0026#39; ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-boot-how-to/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669984973,"title":"Spring-Boot-How-To"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"SpringApplication SpringApplication类提供了一种从main方法启动的Spring应用程序方法。在许多情况下，您可以委托给静态的SpringApplication.run方法，如下例所示：\n@SpringBootApplication public class MyApplication { public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } 当应用程序启动时，您应该会看到类似于以下输出的内容：\n. ____ _ __ _ _ /\\\\ / ___\u0026#39;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | \u0026#39;_ | \u0026#39;_| | \u0026#39;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) \u0026#39; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.5) 2022-10-20 12:40:17.841 INFO 16284 --- [ main] o.s.b.d.f.s.MyApplication : Starting MyApplication using Java 1.8.0_345 on myhost with PID 16284 (/opt/apps/myapp.jar started by myuser in /opt/apps/) 2022-10-20 12:40:17.849 INFO 16284 --- [ main] o.s.b.d.f.s.MyApplication : No active profile set, falling back to 1 default profile: \u0026#34;default\u0026#34; 2022-10-20 12:40:20.443 INFO 16284 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2022-10-20 12:40:20.455 INFO 16284 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2022-10-20 12:40:20.455 INFO 16284 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.68] 2022-10-20 12:40:20.716 INFO 16284 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2022-10-20 12:40:20.716 INFO 16284 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 2566 ms 2022-10-20 12:40:22.045 INFO 16284 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path \u0026#39;\u0026#39; 2022-10-20 12:40:22.073 INFO 16284 --- [ main] o.s.b.d.f.s.MyApplication : Started MyApplication in 4.937 seconds (JVM running for 6.049) 默认情况下，会显示INFO日志消息，包括一些相关的启动详细信息，例如启动应用程序的用户。应用程序版本是使用主应用程序类包中的实现版本确定的。通过设置spring.main.log-startup-info=false可以关闭启动信息日志。这也将关闭 active profiles 的日志信息。\n要在启动期间，添加更多的日志信息，可以重写SpringApplication类中的 logStartupInfo(boolean) 方法。\n启动失败 如果您的应用程序无法启动，注册的FailureAnalyzers将提供错误消息和解决方案。例如，如果您在端口8080上启动web应用程序，并且该端口已经在使用中，您应该会看到类似于以下消息的内容：\n*************************** APPLICATION FAILED TO START *************************** Description: Embedded servlet container failed to start. Port 8080 was already in use. Action: Identify and stop the process that is listening on port 8080 or configure this application to listen on another port. spring boot 提供了多种 FailureAnalyzer 实现，你也可以实现自己的，参考 howto 页面。\n如果没有故障分析器能够处理异常，您仍然可以显示完整的条件报告，以更好地了解出了什么问题。为此，需要为启用debug属性，或者设置org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener的日志级别为debug。\n例如，如果您使用 java -jar 运行应用程序，则可以按如下方式启用debug属性：\n$ java -jar myproject-0.0.1-SNAPSHOT.jar --debug 惰性初始化 SpringApplication允许应用程序惰性初始化。当启用惰性初始化时，bean将根据需要而不是在应用程序启动期间创建。因此，启用惰性初始化可以减少应用程序启动所需的时间。在web应用程序中，启用延迟初始化将导致许多与web相关的bean在收到HTTP请求之前未被初始化。\n惰性初始化的一个缺点是，它会延迟应用程序问题的发现。如果错误配置的bean被惰性初始化，那么在启动期间将不再发生故障，并且只有在bean被初始化时，问题才会变得明显。还必须注意确保JVM有足够的内存来容纳所有应用程序的bean，而不仅仅是那些在启动期间初始化的bean。出于这些原因，默认情况下不启用惰性初始化，建议在启用惰性初始化之前对JVM的堆大小进行微调。\n可以使用SpringApplicationBuilder上的lazyInitialization方法或SpringApplication上的setLazyIninitialization方法以编程方式启用Lazy初始化。或者，可以使用spring.main.lazy-initialization启用它。如下例所示：\nspring.main.lazy-initialization=true 如果希望在使用惰性初始化时禁用某些bean的惰性初始化，可以使用@lazy（false）注解。\n自定义Banner 启动时打印的横幅可以通过在类路径添加 banner.txt 文件，或通过spring.banner.location属性设置为此banner.txt文件的位置。如果文件的编码不是UTF-8，则可以设置spring.banner.charset。\n除了文本文件，您还可以在类路径添加 添加 banner.gif, banner.jpg, 或 banner.png 文件。或者通过spring.banner.image.location 显示指定图片位置。\n在你的banner.txt文件中，您可以使用环境中可用的任何键以及以下任何占位符：\nVariable Description ${application.version} 应用程序的版本号，如MANIFEST.MF中声明的。例如，Implementation-Version: 1.0 打印为1.0。 ${application.formatted-version} 在MANIFEST.MF中声明的应用程序的版本号。并格式化以供显示（用括号包围并以v为前缀）。例如（v1.0）。 ${spring-boot.version} spring boot的版本号 ${spring-boot.formatted-version} 您正在使用的Spring Boot版本，已格式化以供显示（用括号包围并以v为前缀）。例如（v2.7.5）。 ${Ansi.NAME} (or ${AnsiColor.NAME}, ${AnsiBackground.NAME}, ${AnsiStyle.NAME}) 其中，NAME是ANSI转义代码的名称。有关详细信息，请参见AnsiPropertySource。 ${application.title} 应用程序的标题，如MANIFEST.MF中声明的。例如， Implementation-Title: MyApp 打印为MyApp。 如果你想通过编程的方式设置banner可以调用SpringApplication.setBanner(…) 方法。\n你可以使用 spring.main.banner-mode 属性控制是否打印banner\nconsole: 使用 System.out 打印 log： off banner 被注册为名为springBootBanner 的单例bean。\n只有在使用Spring Boot启动器时，${application.version}和${appliation.formattedversion}属性才可用。如果您正在运行一个未打包的jar，并使用 java-cp＜classpath＞＜mainclass＞启动它，则这些值将无法解析。这就是为什么我们建议您总是使用java org.springframework.boot.loader.JarLauncher 启动未打包的jar。这将在构建classpath和启动应用程序之前 初始化application.* 变量 。\n自定义SpringApplication 如果SpringApplication默认值不符合您的口味，您可以创建一个本地实例并对其进行自定义。例如，要关闭banner：\nimport org.springframework.boot.Banner; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class MyApplication { public static void main(String[] args) { SpringApplication application = new SpringApplication(MyApplication.class); application.setBannerMode(Banner.Mode.OFF); application.run(args); } } 传递给SpringApplication的构造函数参数是Springbean的配置类。在大多数情况下，这些是对@Configuration类的引用，但它们也可以是对@Component类的直接引用。\n也可以使用application.properties配置SpringApplication。有关详细信息，请参阅外部化配置。\nFluent Builder API 如果您需要构建ApplicationContext层次结构（具有父/子关系的多个上下文），或者如果您更喜欢使用“流畅”的构建器API，可以使用SpringApplicationBuilder。\nSpringApplicationBuilder允许您将多个方法调用链接在一起，并包括允许您创建层次结构的父子上下文，如以下示例所示：\nnew SpringApplicationBuilder() .sources(Parent.class) .child(Application.class) .bannerMode(Banner.Mode.OFF) .run(args); 创建ApplicationContext层次结构时有一些限制。例如，Web组件必须包含在子上下文中，并且父上下文和子上下文都使用相同的 Environment 。有关详细信息，请参阅SpringApplicationBuilder Javadoc。\n应用可用性 在平台上部署时，应用程序可以使用Kubernetes Probes等基础设施向平台提供有关其可用性的信息。Spring Boot提供了“活跃（liveness）”和“就绪（readiness）”可用性状态开箱即用的支持。如果您正在使用Spring Boot的“actuator”支持，那么这些状态将作为健康端点组公开。\n此外，您还可以通过将ApplicationAvailability接口注入到自己的bean中来获得可用性状态。\n活跃状态 应用程序的“活跃性”状态指示其内部状态是否允许其正常工作，或者在当前出现故障时能否自行恢复。中断的“活动性”状态意味着应用程序处于无法恢复的状态，基础结构应该重新启动应用程序。\n通常，“活跃”状态不应基于外部检查，例如健康检查。如果是这样，失败的外部系统（数据库、Web API、外部缓存）将触发整个平台的大规模重启和级联故障。\nSpring Boot应用程序的内部状态主要由Spring ApplicationContext表示。如果应用程序上下文已成功启动，Spring Boot将假定应用程序处于有效状态。上下文刷新后，应用程序即被视为活跃，请参阅Spring Boot应用程序生命周期和相关应用程序事件。\n就绪状态 应用程序的“就绪”状态告诉应用程序是否准备好处理流量。失败的“就绪”状态告诉平台，目前不应将流量路由到应用程序。这通常发生在启动过程中，在处理CommandLineRunner和ApplicationRunner组件时，或者在应用程序确定其太忙而无法进行其他通信时。\n一旦调用了应用程序和命令行运行程序，就认为应用程序已经就绪，请参阅Spring Boot应用程序生命周期和相关的应用程序事件。\n预期在启动期间运行的任务应由CommandLineRunner和ApplicationRunner组件执行，而不是使用Spring组件生命周期回调（如@PostConstruct）。\n管理应用程序可用性状态 应用程序组件可以通过注入ApplicationAvailability接口并对其调用方法，随时检索当前可用性状态。更常见的情况是，应用程序希望侦听状态更新或更新应用程序的状态。\n例如，我们可以将应用程序的“就绪”状态导出到一个文件，以便Kubernetes“exec Probe”可以查看该文件：\nimport org.springframework.boot.availability.AvailabilityChangeEvent; import org.springframework.boot.availability.ReadinessState; import org.springframework.context.event.EventListener; import org.springframework.stereotype.Component; @Component public class MyReadinessStateExporter { @EventListener public void onStateChange(AvailabilityChangeEvent\u0026lt;ReadinessState\u0026gt; event) { switch (event.getState()) { case ACCEPTING_TRAFFIC: // create file /tmp/healthy break; case REFUSING_TRAFFIC: // remove file /tmp/healthy break; } } } 当应用程序中断且无法恢复时，我们还可以更新应用程序的状态：\nimport org.springframework.boot.availability.AvailabilityChangeEvent; import org.springframework.boot.availability.LivenessState; import org.springframework.context.ApplicationEventPublisher; import org.springframework.stereotype.Component; @Component public class MyLocalCacheVerifier { private final ApplicationEventPublisher eventPublisher; public MyLocalCacheVerifier(ApplicationEventPublisher eventPublisher) { this.eventPublisher = eventPublisher; } public void checkLocalCache() { try { // ... } catch (CacheCompletelyBrokenException ex) { AvailabilityChangeEvent.publish(this.eventPublisher, ex, LivenessState.BROKEN); } } } 应用程序事件和监听器 除了通常的Spring Framework事件（如ContextRefreshedEvent），SpringApplication还发送一些其他的应用程序事件。\n有些事件实际上是在ApplicationContext创建之前触发的，因此您不能将侦听器注册为@Bean。您可以使用SpringApplication.addListeners（…) 方法或SpringApplicationBuilder.listers（…) 方法来注册他们\n如果您希望自动注册这些侦听器，无论应用程序的创建方式如何，可以添加到 META-INF/spring.factories文件 ，并使用org.springframework.context.ApplicationListener 当作 key，如以下所示：org.springframework.context.ApplicationListener=com.example.project.MyListener\n应用程序事件在应用程序运行时按以下顺序发送：\nApplicationStartingEvent在运行开始时发送，但在任何处理之前发送(listeners 和 initializers 注册除外) 当上下文中要使用的环境已知但在创建上下文之前，将发送ApplicationEnvironmentPreparedEvent。 ApplicationContextInitializedEvent在ApplicationContext准备好并调用ApplicationContextInitializers时发送，但在加载任何bean定义之前。 ApplicationPreparedEvent在刷新开始之前但在加载bean定义之后发送。 ApplicationStartedEvent在上下文刷新后但在调用任何应用程序和命令行运行程序之前发送。 LivenessState.CORRECT表示应用程序被视为活动，随机发送AvailabilityChangeEvent 在调用任何应用程序和命令行运行程序后，将发送ApplicationReadyEvent。 ReadinessState.ACCEPTING_TRAFFIC 状态后，发送 AvailabilityChangeEvent 如果启动时出现异常，将发送ApplicationFailedEvent。 以上列表仅包括绑定到SpringApplication的SpringApplicationEvents。除此之外，以下事件也在ApplicationPreparedEvent之后和ApplicationStartedEvent之前发布：\nWebServerInitializedEvent在WebServer就绪后发送。ServletWebServerInitializedEvent和ReactiveWebServerIninitializedEvent分别是servlet和反应式变体。 刷新ApplicationContext时会发送ContextRefreshedEvent。 您通常不需要使用应用程序事件，但知道它们的存在会很方便。在内部，Spring Boot使用事件来处理各种任务。\n默认情况下，事件侦听器不应运行可能很长的任务，因为它们在同一线程中执行。请考虑改用应用程序和命令行运行程序。\n应用程序事件通过使用Spring Framework的事件发布机制发送。此机制的一部分确保了在子上下文中发布给侦听器的事件也发布给任何祖先上下文中的侦听器。因此，如果您的应用程序使用SpringApplication实例的层次结构，侦听器可能会接收相同类型的应用程序事件的多个实例。\n为了让侦听器区分其上下文的事件和后代上下文的事件，它应该在请求中注入其应用程序上下文，然后将注入的上下文与事件接受的上下文进行比较。上下文可以通过实现ApplicationContextAware来注入，如果侦听器是bean，则可以使用@Autowired来注入。\nweb环境 SpringApplication尝试代表您创建正确类型的ApplicationContext。用于确定WebApplicationType的算法如下：\n如果存在Spring MVC，则使用AnnotationConfigServletWebServerApplicationContext 如果Spring MVC不存在且Spring WebFlux存在，则使用AnnotationConfigReactiveWebServerApplicationContext 否则，将使用AnnotationConfigApplicationContext 这意味着，如果您在同一应用程序中使用SpringMVC和SpringWebFlux中的WebClient，则默认情况下将使用Spring MVC。您可以通过调用setWebApplicationType（WebApplicationType）轻松地覆盖它。\n可以用setApplicationContextClass(…) 完全控制 ApplicationContext 的类型。\n在JUnit测试中使用SpringApplication时，通常需要调用setWebApplicationType（WebApplicationType.NONE）。\n访问应用程序参数 如果您需要访问传递给SpringApplication.run(…）的应用程序参数。 您可以注入org.springframework.boot.ApplicationArguments bean。ApplicationArguments接口提供对原始String[]参数的解析，如以下示例所示：\nimport java.util.List; import org.springframework.boot.ApplicationArguments; import org.springframework.stereotype.Component; @Component public class MyBean { public MyBean(ApplicationArguments args) { boolean debug = args.containsOption(\u0026#34;debug\u0026#34;); List\u0026lt;String\u0026gt; files = args.getNonOptionArgs(); if (debug) { System.out.println(files); } // if run with \u0026#34;--debug logfile.txt\u0026#34; prints [\u0026#34;logfile.txt\u0026#34;] } } Spring Boot还向Spring Environment注册CommandLinePropertySource。这还允许您使用@Value注释注入单个应用程序参数。\nApplicationRunner 和 CommandLineRunner 如果需要在SpringApplication启动后运行某些特定代码，可以实现ApplicationRunner或CommandLineRunner接口。这两个接口的工作方式相同，并提供了单一的运行方法，该方法在SpringApplication.run(…) 调用完成前运行。\n此契约非常适合于在应用程序启动后但在它开始接受流量之前运行的任务。\nCommandLineRunner接口以字符串数组的形式提供对应用程序参数的访问，而ApplicationRunner使用前面讨论的ApplicationArguments接口。以下示例显示了带有run方法的CommandLineRunner：\nimport org.springframework.boot.CommandLineRunner; import org.springframework.stereotype.Component; @Component public class MyCommandLineRunner implements CommandLineRunner { @Override public void run(String... args) { // Do something... } } 如果定义了几个必须按特定顺序调用的CommandLineRunner或ApplicationRunner bean，则可以另外实现org.springframework.core.Ordered 接口或使用org.springframework.core.annotation.Order 注释。\n应用程序退出 每个SpringApplication向JVM注册一个关闭挂钩，以确保ApplicationContext在退出时正常关闭。保证所有标准Spring生命周期回调（例如DisposableBean接口或@PreDestroy注释）可以正常工作。\n此外，如果他们希望在调用SpringApplication.exit()时返回特定的退出代码,可以实现org.springframework.boot.ExitCodeGenerator接口。退出代码传递给 System.exit() 方法 返回，如以下示例所示：\nimport org.springframework.boot.ExitCodeGenerator; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; @SpringBootApplication public class MyApplication { @Bean public ExitCodeGenerator exitCodeGenerator() { return () -\u0026gt; 42; } public static void main(String[] args) { System.exit(SpringApplication.exit(SpringApplication.run(MyApplication.class, args))); } } 此外，ExitCodeGenerator接口可能由异常类实现。当遇到此类异常时，Spring Boot返回由getExitCode()方法提供的退出代码。\n如果存在多个ExitCodeGenerator，则使用生成的第一个非零退出代码。要控制生成器的调用顺序，则可以另外实现org.springframework.core.Ordered 接口或使用org.springframework.core.annotation.Order 注释。\n管理功能 通过指定spring.application.admin.enabled 属性 可以为应用程序启用与管理相关的功能。这将在MBeanServer平台上公开SpringApplicationAdminMXBean。您可以使用此功能远程管理Spring Boot应用程序。此特性对于任何服务包装器实现都可能有用。\n如果您想知道应用程序在哪个HTTP端口上运行，请使用local.server.port键获取该属性。\n应用程序启动跟踪 在应用程序启动期间，SpringApplication和ApplicationContext执行许多与应用程序生命周期、bean生命周期甚至处理应用程序事件相关的任务。使用ApplicationStartup，Spring Framework允许您使用StartupStep对象跟踪应用程序启动顺序。可以收集这些数据用于分析目的，或者只是为了更好地理解应用程序启动过程。\n您可以在设置SpringApplication实例时选择ApplicationStartup实现。例如，要使用BufferingApplicationStartup，您可以编写：\nimport org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.context.metrics.buffering.BufferingApplicationStartup; @SpringBootApplication public class MyApplication { public static void main(String[] args) { SpringApplication application = new SpringApplication(MyApplication.class); application.setApplicationStartup(new BufferingApplicationStartup(2048)); application.run(args); } } 第一个可用的实现FlightRecorderApplicationStartup由Spring Framework提供。它将特定于Spring的启动事件添加到Java Flight Recorder会话，用于分析应用程序并将其Spring上下文生命周期与JVM事件（例如分配、GC、类加载…). 配置后，您可以在启用飞行记录器的情况下运行应用程序来记录数据：\n$ java -XX:StartFlightRecording:filename=recording.jfr,duration=10s -jar demo.jar Spring Boot附带BufferingApplicationStartup变体；此实现用于缓冲启动步骤并将其排放到外部度量系统中。应用程序可以在任何组件中请求BufferingApplicationStartup类型的bean。\nSpring Boot还可以配置为公开一个startup端点，该端点以JSON文档的形式提供此信息。下面是一个示例信息：\n{ \u0026#34;springBootVersion\u0026#34;: \u0026#34;2.7.4\u0026#34;, \u0026#34;timeline\u0026#34;: { \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:38.916369700Z\u0026#34;, \u0026#34;events\u0026#34;: [ { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:38.948011400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0160168S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:38.931994600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.boot.application.starting\u0026#34;, \u0026#34;id\u0026#34;: 0, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;mainApplicationClass\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;com.example.graphql.GraphqlApplication\u0026#34; } ], \u0026#34;parentId\u0026#34;: null } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.167809700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.1416612S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.026148500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.boot.application.environment-prepared\u0026#34;, \u0026#34;id\u0026#34;: 1, \u0026#34;tags\u0026#34;: [], \u0026#34;parentId\u0026#34;: null } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.246328200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.246328200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.boot.application.context-prepared\u0026#34;, \u0026#34;id\u0026#34;: 2, \u0026#34;tags\u0026#34;: [], \u0026#34;parentId\u0026#34;: null } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.277586500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.277586500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.boot.application.context-loaded\u0026#34;, \u0026#34;id\u0026#34;: 3, \u0026#34;tags\u0026#34;: [], \u0026#34;parentId\u0026#34;: null } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.324487700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156507S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.308837Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 7, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory\u0026#34; } ], \u0026#34;parentId\u0026#34;: 6 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.340124900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0312879S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.308837Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 6, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.annotation.internalConfigurationAnnotationProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.support.BeanDefinitionRegistryPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.795760100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.450084S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.345676100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.config-classes.parse\u0026#34;, \u0026#34;id\u0026#34;: 9, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;classCount\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;113\u0026#34; } ], \u0026#34;parentId\u0026#34;: 8 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.811385800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.4712609S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.340124900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.beandef-registry.post-process\u0026#34;, \u0026#34;id\u0026#34;: 8, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.annotation.ConfigurationClassPostProcessor@7c041b41\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.811385800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.811385800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 10, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer$CachingMetadataReaderFactoryPostProcessor@7a231dfd\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.811385800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.811385800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 11, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer$ConfigurationWarningsPostProcessor@30814f43\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0352576S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.811385800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.config-classes.enhance\u0026#34;, \u0026#34;id\u0026#34;: 13, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;classCount\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;1\u0026#34; } ], \u0026#34;parentId\u0026#34;: 12 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0352576S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.811385800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 12, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.annotation.ConfigurationClassPostProcessor@7c041b41\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 14, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.SpringApplication$PropertySourceOrderingBeanFactoryPostProcessor@45667d98\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 15, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;propertySourcesPlaceholderConfigurer\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanFactoryPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 16, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.support.PropertySourcesPlaceholderConfigurer@3bbf9027\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 17, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanFactoryPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0120072S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.846643400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 18, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.sql.init.dependency.DatabaseInitializationDependencyConfigurer$DependsOnDatabaseInitializationPostProcessor@15e0fe05\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 19, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.event.internalEventListenerProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanFactoryPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 20, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;preserveErrorControllerTargetClassPostProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanFactoryPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 21, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;forceAutoProxyCreatorToUseClassProxying\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanFactoryPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 23, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.event.internalEventListenerFactory\u0026#34; } ], \u0026#34;parentId\u0026#34;: 22 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 22, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.event.EventListenerMethodProcessor@6d2dc9d2\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 24, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$PreserveErrorControllerTargetClassPostProcessor@b2f4ece\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.bean-factory.post-process\u0026#34;, \u0026#34;id\u0026#34;: 25, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;postProcessor\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$ClassProxyingConfiguration$$Lambda$424/0x0000000800372c40@7e1f584d\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 26, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.annotation.internalAutowiredAnnotationProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 27, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.annotation.internalCommonAnnotationProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 30, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.context.internalConfigurationPropertiesBinderFactory\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;class org.springframework.boot.context.properties.ConfigurationPropertiesBinder$Factory\u0026#34; } ], \u0026#34;parentId\u0026#34;: 29 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 29, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.context.internalConfigurationPropertiesBinder\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;class org.springframework.boot.context.properties.ConfigurationPropertiesBinder\u0026#34; } ], \u0026#34;parentId\u0026#34;: 28 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 28, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.015634S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.858650600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 31, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.aop.config.internalAutoProxyCreator\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 32, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;webServerFactoryCustomizerBeanPostProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 33, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;errorPageRegistrarBeanPostProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 34, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;healthEndpointGroupsBeanPostProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 35, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;meterRegistryPostProcessor\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.beans.factory.config.BeanPostProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 5 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.5810356S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.293249Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.beans.post-process\u0026#34;, \u0026#34;id\u0026#34;: 5, \u0026#34;tags\u0026#34;: [], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 38, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryConfiguration$EmbeddedTomcat\u0026#34; } ], \u0026#34;parentId\u0026#34;: 37 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.905535400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.905535400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 40, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 39 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.905535400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.905535400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 39, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;websocketServletWebServerCustomizer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 37 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.905535400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.905535400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 42, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 41 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 44, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.context.properties.BoundConfigurationProperties\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;class org.springframework.boot.context.properties.BoundConfigurationProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 43 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156268S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.905535400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 43, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;server-org.springframework.boot.autoconfigure.web.ServerProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 41 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156268S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.905535400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 41, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;servletWebServerFactoryCustomizer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 37 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 45, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tomcatServletWebServerFactoryCustomizer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 37 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 47, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$TomcatWebServerFactoryCustomizerConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 46 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 46, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tomcatWebServerFactoryCustomizer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 37 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 49, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 48 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.921162200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 48, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;localeCharsetMappingsCustomizer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 37 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 51, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 50 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 53, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletRegistrationConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 52 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 55, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 54 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 56, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 54 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0060056S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 54, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dispatcherServlet\u0026#34; } ], \u0026#34;parentId\u0026#34;: 52 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 59, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 58 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 58, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 57 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 57, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;multipartConfigElement\u0026#34; } ], \u0026#34;parentId\u0026#34;: 52 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0060056S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 52, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dispatcherServletRegistration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 50 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0060056S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.946792800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 50, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;errorPageCustomizer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 37 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.952798400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0785138S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 37, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tomcatServletWebServerFactory\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.boot.web.servlet.server.ServletWebServerFactory\u0026#34; } ], \u0026#34;parentId\u0026#34;: 36 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 62, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.metrics-org.springframework.boot.actuate.autoconfigure.metrics.MetricsProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 61 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 61, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.web.servlet.WebMvcMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 60 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 64, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.export.simple.SimpleMetricsExportAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 66, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.metrics.export.simple-org.springframework.boot.actuate.autoconfigure.metrics.export.simple.SimpleProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 65 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 65, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;simpleConfig\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 68, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.MetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 67 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 67, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;micrometerClock\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 69, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;propertiesMeterFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 71, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.web.client.HttpClientMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 70 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 70, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;metricsHttpClientUriTagFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 72, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;metricsHttpServerUriTagFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.140709100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156251S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 74, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.JvmMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 73 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.140709100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156251S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.125084Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 73, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jvmGcMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0065076S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.140709100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 75, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jvmHeapPressureMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 76, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jvmMemoryMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 77, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jvmThreadMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 78, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;classLoaderMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 80, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.LogbackMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 79 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 79, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;logbackMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 82, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.SystemMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 81 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 81, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;uptimeMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 83, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;processorMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 84, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;fileDescriptorMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.147216700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 85, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;diskSpaceMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 63 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.156725400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0472533S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 63, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;simpleMeterRegistry\u0026#34; } ], \u0026#34;parentId\u0026#34;: 60 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.156725400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.156725400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 86, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;webMvcTagsProvider\u0026#34; } ], \u0026#34;parentId\u0026#34;: 60 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.156725400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0472533S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.109472100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 60, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;webMvcMetricsFilter\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.boot.web.servlet.ServletContextInitializer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 36 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.156725400Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.156725400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 88, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 87 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156331S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.156725400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 89, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.endpoints.web-org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 87 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 91, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointAutoConfiguration$WebEndpointServletConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 90 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 93, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 92 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 92, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;webEndpointPathMapper\u0026#34; } ], \u0026#34;parentId\u0026#34;: 90 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 95, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.endpoint.web.ServletEndpointManagementContextConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 94 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 94, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;servletExposeExcludePropertyEndpointFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 90 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.172358500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 90, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;servletEndpointDiscoverer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 87 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0312607S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.156725400Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 87, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;servletEndpointRegistrar\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface org.springframework.boot.web.servlet.ServletContextInitializer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 36 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 96, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;requestContextFilter\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface javax.servlet.Filter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 36 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 98, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 97 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 97, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;formContentFilter\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface javax.servlet.Filter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 36 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.187986100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 99, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;characterEncodingFilter\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface javax.servlet.Filter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 36 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.3449495S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.874284600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.boot.webserver.create\u0026#34;, \u0026#34;id\u0026#34;: 36, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;factory\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;class org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 100, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;graphqlApplication\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 101, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;bookController\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 102, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;testController\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 103, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.AutoConfigurationPackages\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 104, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 105, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 106, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.context.properties.EnableConfigurationPropertiesRegistrar.methodValidationExcludeFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 107, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 108, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 110, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 109 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 109, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;taskExecutorBuilder\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 111, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 112, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;error\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 113, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;beanNameViewResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.015625S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 115, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.web-org.springframework.boot.autoconfigure.web.WebProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 114 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.015625S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.219234100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 114, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 116, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;conventionErrorViewResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 117, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;errorAttributes\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 118, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;basicErrorController\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.247370500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.247370500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 120, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 119 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0035082S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.247370500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 121, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;metricsWebMvcConfigurer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 119 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 123, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.graphql-org.springframework.boot.autoconfigure.graphql.GraphQlProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 122 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 124, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.graphql.cors-org.springframework.boot.autoconfigure.graphql.GraphQlCorsProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 122 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 122, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.graphql.servlet.GraphQlWebMvcAutoConfiguration$GraphQlEndpointCorsConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 119 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0160196S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.234859100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 119, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$EnableWebMvcConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 126, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcContentNegotiationManager\u0026#34; } ], \u0026#34;parentId\u0026#34;: 125 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 127, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcConversionService\u0026#34; } ], \u0026#34;parentId\u0026#34;: 125 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 128, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcValidator\u0026#34; } ], \u0026#34;parentId\u0026#34;: 125 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 130, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 129 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 132, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration$StringHttpMessageConverterConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 131 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 131, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;stringHttpMessageConverter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 129 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 134, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration$MappingJackson2HttpMessageConverterConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 133 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 136, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 135 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 138, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperBuilderConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 137 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 140, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 139 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 141, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 139 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 139, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;standardJacksonObjectMapperBuilderCustomizer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 137 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 143, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$ParameterNamesModuleConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 142 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 142, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;parameterNamesModule\u0026#34; } ], \u0026#34;parentId\u0026#34;: 137 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.313387300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156223S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 145, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 144 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.313387300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156223S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 144, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jsonComponentModule\u0026#34; } ], \u0026#34;parentId\u0026#34;: 137 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.313387300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.313387300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 146, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jsonMixinModule\u0026#34; } ], \u0026#34;parentId\u0026#34;: 137 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.313387300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156223S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 137, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jacksonObjectMapperBuilder\u0026#34; } ], \u0026#34;parentId\u0026#34;: 135 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.329013Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.031248S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 135, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jacksonObjectMapper\u0026#34; } ], \u0026#34;parentId\u0026#34;: 133 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.329013Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.031248S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 133, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mappingJackson2HttpMessageConverter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 129 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.329013Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.031248S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.297765Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 129, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;messageConverters\u0026#34; } ], \u0026#34;parentId\u0026#34;: 125 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.329013Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.329013Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 147, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;applicationTaskExecutor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 125 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.354137600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.1032589S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.250878700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 125, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;requestMappingHandlerAdapter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.354137600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.354137600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 149, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcResourceUrlProvider\u0026#34; } ], \u0026#34;parentId\u0026#34;: 148 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.360679500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0065419S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.354137600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 148, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;welcomePageHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.360679500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.360679500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 150, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;localeResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.360679500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.360679500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 151, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;themeResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.360679500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.360679500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 152, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;flashMapManager\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156748S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.360679500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 153, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;requestMappingHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 154, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcPatternParser\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 155, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcUrlPathHelper\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 156, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcPathMatcher\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 157, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;viewControllerHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 158, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;beanNameHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 161, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.graphql.servlet.GraphQlWebMvcAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 160 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 165, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.graphql.GraphQlAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 164 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.391938600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.391938600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 168, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.graphql.GraphQlMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 167 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.391938600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.391938600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 169, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;graphQlTagsProvider\u0026#34; } ], \u0026#34;parentId\u0026#34;: 167 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.391938600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.391938600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 167, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;graphQlMetricsInstrumentation\u0026#34; } ], \u0026#34;parentId\u0026#34;: 166 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.407601600Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.015663S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.391938600Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 170, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;annotatedControllerConfigurer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 166 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.580240500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.2038862S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 166, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;graphQlSource\u0026#34; } ], \u0026#34;parentId\u0026#34;: 164 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.580240500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.580240500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 171, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;batchLoaderRegistry\u0026#34; } ], \u0026#34;parentId\u0026#34;: 164 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.580240500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.2038862S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 164, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;executionGraphQlService\u0026#34; } ], \u0026#34;parentId\u0026#34;: 163 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.580240500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.2038862S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 163, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;webGraphQlHandler\u0026#34; } ], \u0026#34;parentId\u0026#34;: 162 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.580240500Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.2038862S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 162, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;graphQlHttpHandler\u0026#34; } ], \u0026#34;parentId\u0026#34;: 160 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.2195105S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 160, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;graphQlRouterFunction\u0026#34; } ], \u0026#34;parentId\u0026#34;: 159 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.2195105S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.376354300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 159, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;routerFunctionMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 172, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;resourceHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 173, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;defaultServletHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 174, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;handlerFunctionAdapter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 175, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcUriComponentsContributor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 176, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;httpRequestHandlerAdapter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 177, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;simpleControllerHandlerAdapter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 178, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;handlerExceptionResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 179, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mvcViewResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156272S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.595864800Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 180, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;viewNameTranslator\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 181, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;defaultViewResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 183, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;viewResolver\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;exception\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;class org.springframework.beans.factory.BeanCurrentlyInCreationException\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;message\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;Error creating bean with name \u0026#39;viewResolver\u0026#39;: Requested bean is currently in creation: Is there an unresolvable circular reference?\u0026#34; } ], \u0026#34;parentId\u0026#34;: 182 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 182, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;viewResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 184, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.audit.AuditEventsEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 185, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 186, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;applicationAvailability\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 187, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.availability.AvailabilityHealthContributorAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 188, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.beans.BeansEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 189, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;beansEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 190, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.cache.CachesEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 191, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;cachesEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 192, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;cachesEndpointWebExtension\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 193, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.web.servlet.ServletManagementContextAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 194, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;servletWebChildContextFactory\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 195, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;managementServletContext\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 196, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.health.HealthEndpointConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 198, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.endpoint.health-org.springframework.boot.actuate.autoconfigure.health.HealthEndpointProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 197 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 197, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;healthStatusAggregator\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 199, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;healthHttpCodeStatusMapper\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156237S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.611492Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 200, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;healthEndpointGroups\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 203, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.system.DiskSpaceHealthContributorAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 202 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 204, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.health.diskspace-org.springframework.boot.actuate.autoconfigure.system.DiskSpaceHealthIndicatorProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 202 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 202, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;diskSpaceHealthIndicator\u0026#34; } ], \u0026#34;parentId\u0026#34;: 201 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 206, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.health.HealthContributorAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 205 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 205, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;pingHealthContributor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 201 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 201, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;healthContributorRegistry\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 207, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;healthEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 208, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.health.ReactiveHealthEndpointConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 209, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;reactiveHealthContributorRegistry\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 210, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.health.HealthEndpointWebExtensionConfiguration$MvcAdditionalHealthEndpointPathsConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 214, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.endpoint.EndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 213 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 213, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;endpointOperationParameterMapper\u0026#34; } ], \u0026#34;parentId\u0026#34;: 212 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 215, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;endpointMediaTypes\u0026#34; } ], \u0026#34;parentId\u0026#34;: 212 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 216, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;endpointCachingOperationInvokerAdvisor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 212 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 217, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;webExposeExcludePropertyEndpointFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 212 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.642740Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156243S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 212, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;webEndpointDiscoverer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 219, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.context.properties.ConfigurationPropertiesReportEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 218 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 220, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.endpoint.configprops-org.springframework.boot.actuate.autoconfigure.context.properties.ConfigurationPropertiesReportEndpointProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 218 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 218, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;configurationPropertiesReportEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 222, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.env.EnvironmentEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 221 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 223, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.endpoint.env-org.springframework.boot.actuate.autoconfigure.env.EnvironmentEndpointProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 221 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.648254Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 221, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;environmentEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 225, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.health.HealthEndpointWebExtensionConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 224 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 224, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;healthEndpointWebExtension\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 227, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.info.InfoEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 226 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 226, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;infoEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 229, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.condition.ConditionsReportEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 228 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 228, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;conditionsReportEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 230, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;configurationPropertiesReportEndpointWebExtension\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 231, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;environmentEndpointWebExtension\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 233, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.logging.LoggersEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 232 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 232, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;loggersEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 235, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.management.HeapDumpWebEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 234 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 234, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;heapDumpWebEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 237, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.management.ThreadDumpEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 236 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 236, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dumpEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 239, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.MetricsEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 238 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.658761900Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 238, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;metricsEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 241, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.scheduling.ScheduledTasksEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 240 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 240, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;scheduledTasksEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 243, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.startup.StartupEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 242 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 242, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;startupEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 245, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.web.mappings.MappingsEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 244 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 247, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.web.mappings.MappingsEndpointAutoConfiguration$ServletWebConfiguration$SpringMvcConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 246 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 246, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dispatcherServletMappingDescriptionProvider\u0026#34; } ], \u0026#34;parentId\u0026#34;: 244 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 249, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.web.mappings.MappingsEndpointAutoConfiguration$ServletWebConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 248 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 248, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;servletMappingDescriptionProvider\u0026#34; } ], \u0026#34;parentId\u0026#34;: 244 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 250, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;filterMappingDescriptionProvider\u0026#34; } ], \u0026#34;parentId\u0026#34;: 244 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 244, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mappingsEndpoint\u0026#34; } ], \u0026#34;parentId\u0026#34;: 211 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.047281S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.627115700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 211, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;healthEndpointWebMvcHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 251, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.health.HealthEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 253, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 252 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 252, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 254, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.info.InfoContributorAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 255, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.info-org.springframework.boot.actuate.autoconfigure.info.InfoContributorProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156254S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 257, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.jmx-org.springframework.boot.autoconfigure.jmx.JmxProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 256 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0156254S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.674396700Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 256, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 259, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;objectNamingStrategy\u0026#34; } ], \u0026#34;parentId\u0026#34;: 258 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 260, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mbeanServer\u0026#34; }, { \u0026#34;key\u0026#34;: \u0026#34;beanType\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;interface javax.management.MBeanServer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 258 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 258, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mbeanExporter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 262, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.endpoints.jmx-org.springframework.boot.actuate.autoconfigure.endpoint.jmx.JmxEndpointProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 261 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 261, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.endpoint.jmx.JmxEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 264, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jmxIncludeExcludePropertyEndpointFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 263 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 263, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jmxAnnotationEndpointDiscoverer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 265, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;endpointObjectNameFactory\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0312489S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.690022100Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 266, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;jmxMBeanExporter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 267, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;eagerlyInitializeJmxEndpointExporter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 269, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;controllerExposeExcludePropertyEndpointFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 268 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 268, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;controllerEndpointDiscoverer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 270, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;pathMappedEndpoints\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 271, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.logging.LogFileWebEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 272, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.endpoint.logfile-org.springframework.boot.actuate.autoconfigure.logging.LogFileWebEndpointProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 273, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.CompositeMeterRegistryAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 274, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.integration.IntegrationMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 275, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.startup.StartupTimeMetricsListenerAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 276, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;startupTimeMetrics\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 277, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 278, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;scheduledBeanLazyInitializationExcludeFilter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 280, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 279 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 279, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;taskSchedulerBuilder\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 281, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.task.TaskExecutorMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 282, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 283, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 284, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.web.client.RestTemplateMetricsConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 285, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;restTemplateExchangeTagsProvider\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 286, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;metricsRestTemplateCustomizer\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 287, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.metrics.web.tomcat.TomcatMetricsAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 288, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tomcatMetricsBinder\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 289, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.trace.http.HttpTraceEndpointAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 290, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.015626S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.721271Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 291, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;springApplicationAdminRegistrar\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 292, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$ClassProxyingConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 293, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.aop.AopAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 294, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 295, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 297, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.lifecycle-org.springframework.boot.autoconfigure.context.LifecycleProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 296 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 296, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;lifecycleProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 298, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.sql.init.SqlInitializationAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 299, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;spring.sql.init-org.springframework.boot.autoconfigure.sql.init.SqlInitializationProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 300, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 301, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;multipartResolver\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 302, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.endpoint.web.servlet.WebMvcEndpointManagementContextConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 304, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.endpoints.web.cors-org.springframework.boot.actuate.autoconfigure.endpoint.web.CorsEndpointProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 303 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0115083S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.736897Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 303, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;webEndpointServletHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 305, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;controllerEndpointHandlerMapping\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 306, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.web.server.ManagementContextAutoConfiguration$SameManagementContextConfiguration$EnableSameManagementContextConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 307, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.web.server.ManagementContextAutoConfiguration$SameManagementContextConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 308, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.web.server.ManagementContextAutoConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.instantiate\u0026#34;, \u0026#34;id\u0026#34;: 309, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;management.server-org.springframework.boot.actuate.autoconfigure.web.server.ManagementServerProperties\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.752912Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0.0045067S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.748405300Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.smart-initialize\u0026#34;, \u0026#34;id\u0026#34;: 310, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.context.event.internalEventListenerProcessor\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.752912Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.752912Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.smart-initialize\u0026#34;, \u0026#34;id\u0026#34;: 311, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;mbeanExporter\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.752912Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.752912Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.beans.smart-initialize\u0026#34;, \u0026#34;id\u0026#34;: 312, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;beanName\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;org.springframework.boot.actuate.autoconfigure.web.server.ManagementContextAutoConfiguration$SameManagementContextConfiguration\u0026#34; } ], \u0026#34;parentId\u0026#34;: 4 } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.784170200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT1.5065837S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:39.277586500Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.context.refresh\u0026#34;, \u0026#34;id\u0026#34;: 4, \u0026#34;tags\u0026#34;: [], \u0026#34;parentId\u0026#34;: null } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.784170200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.784170200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.boot.application.started\u0026#34;, \u0026#34;id\u0026#34;: 313, \u0026#34;tags\u0026#34;: [], \u0026#34;parentId\u0026#34;: null } }, { \u0026#34;endTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.784170200Z\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT0S\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2022-10-29T02:37:40.784170200Z\u0026#34;, \u0026#34;startupStep\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;spring.boot.application.ready\u0026#34;, \u0026#34;id\u0026#34;: 314, \u0026#34;tags\u0026#34;: [], \u0026#34;parentId\u0026#34;: null } } ] } } 外部配置化 Spring Boot允许外部化您的配置，以便您可以在不同的环境中使用相同的应用程序代码。您可以使用各种外部配置源，包括 Java 属性文件、YAML 文件、环境变量和命令行参数。\n属性值可以使用@Value注释直接注入到 bean 中，或者通过@ConfigurationProperties绑定到结构化对象。\n属性覆盖的顺序，优先级从从低到高：\n默认属性： SpringApplication.setDefaultProperties 设置的属性 @PropertySource标注的@Configuration类。请注意，在刷新应用程序上下文之前，此类属性源不会添加到环境中。配置某些属性可能为时已晚，如logging.* 和 spring.main.*，这些属性在刷新开始之前读取。 配置文件，例如 application.properties RandomValuePropertySource，只针对random.*属性 操作系统变量 Java 系统属性 System.getProperties(). -D 设置的参数 jndi属性 ， java:comp/env ServletContext 初始化参数 ServletConfig 初始化参数 来自SPRING_APPLICATION_JSON的属性（嵌入在环境变量或系统属性中的内联 JSON）。 命令行参数 测试属性，在@SpringBootTest和@Test上可用，用于测试应用程序的特定切片。 在测试中@TestPropertySource注释。 当开发工具处于活动状态时，$HOME/.config/spring-boot目录中的开发工具全局设置属性。 配置文件按以下顺序考虑：\n打包在 jar 中的应用程序属性（application.properties和 YAML 变体）。 打包在 jar 中的特定于配置文件的应用程序属性（application-{profile}.properties和 YAML 变体）。 打包的 jar 外部的应用程序属性（application.properties和 YAML 变体）。 打包的 jar 外部的特定于配置文件的应用程序属性（application-\u0026gt;{profile}.properties和 YAML 变体）。 建议为整个应用程序坚持使用一种格式。如果在同一位置具有同时具有 .properties 和 .yml 格式的配置文件，则 .properties 优先。\n访问命令行属性 默认情况下，Spring 应用程序会将任何命令行选项参数（即以 \u0026ndash;开头的参数，如 --server.port=9000）转换为属性，并将它们添加到 Spring 环境中。如前所述，命令行属性始终优先于基于文件的属性源。\n如果不希望将命令行属性添加到环境中，可以使用SpringApplication.setAddCommandLineProperties(false）禁用它们。\napplication json属性 环境变量和系统属性通常具有限制，这意味着某些属性名称不能使用。为了帮助解决这个问题，spring启动允许您将属性块编码为单个 JSON 结构。\n当应用程序启动时，任何 spring.application.json 或SPRING_APPLICATION_JSON属性都将被解析并添加到环境中。\n例如，可以在 UN*X shell 的命令行上将 SPRING_APPLICATION_JSON 属性作为环境变量提供：\n$ SPRING_APPLICATION_JSON=\u0026#39;{\u0026#34;my\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;test\u0026#34;}}\u0026#39; java -jar myapp.jar 在前面的示例中，您最终在sping环境中得到 my.name=test。\n也可以将相同的 JSON 作为系统属性提供：\n$ java -Dspring.application.json=\u0026#39;{\u0026#34;my\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;test\u0026#34;}}\u0026#39; -jar myapp.jar 或者，您可以使用命令行参数提供 JSON：\n$ java -jar myapp.jar --spring.application.json=\u0026#39;{\u0026#34;my\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;test\u0026#34;}}\u0026#39; 尽管 JSON 中的空值将添加到生成的属性源中，但属性源属性解决程序将空属性视为缺失值。这意味着 JSON 无法用空值覆盖来自低阶属性源的属性。\n外部属性 当您的应用程序启动时，spring boot将自动从以下位置查找并加载application.properties和application.yaml 文件(优先级从低到高)：\nclasspath\nclasspath root classpath /config package 当前目录\n当前目录 当前目录下的config子目录 当前目录下的config子目录的子目录 如果不喜欢application作为配置文件名，则可以通过指定 spring.config.name 环境属性切换到另一个文件名。例如，要查找myproject.properties和myproject.yaml文件，您可以按如下方式运行应用程序：\n$ java -jar myproject.jar --spring.config.name=myproject 还可以使用spring.config.location 环境属性来引用显式位置。此属性接受一个或多个逗号分隔列表。下面的示例演示如何指定两个不同的文件：\n$ java -jar myproject.jar --spring.config.location=\\ optional:classpath:/default.properties,\\ optional:classpath:/override.properties 如果spring.config.location包含目录（而不是文件），则它们应以/结尾。在运行时，它们将附加在从 spring.config.name 生成的名称之前。\n在大多数情况下，每个spring.config.location添加的位置项将引用单个文件或目录。位置按其定义的顺序进行处理，稍后的位置可以覆盖先前位置的值。\n如果您有一个复杂的位置设置，并且您使用了profile-specific的配置文件，那么您可能需要提供进一步的提示，以便Spring Boot知道应该如何对它们进行分组.位置组是在同一级别上考虑的所有位置的集合。例如，您可能希望对所有类路径位置进行分组，然后对所有外部位置进行分组。分组中的项目应以;分隔。\n使用spring.config.location的位置替换默认位置。例如，如果spring.config.location= optional:classpath:/custom-config/,optional:file:./custom-config/，考虑的完整位置集为：\noptional:classpath:custom-config/ optional:file:./custom-config/ 如果您希望添加其他位置，而不是替换它们，可以使用spring.config.additional-location。从其他位置加载的特性可以覆盖默认位置中的特性。例如，如果spring.config.additional-location=optional:classpath:/custom-config/,optional:file:./custom-config/，考虑的完整位置集为：\noptional:classpath:/;optional:classpath:/config/ optional:file:./;optional:file:./config/;optional:file:./config/*/ optional:classpath:custom-config/ optional:file:./custom-config/ 此搜索顺序允许您在一个配置文件中指定默认值，然后在另一个配置中选择性地覆盖这些值。您可以在application.properties为应用程序提供默认值。然后，可以在运行时使用位于其中一个自定义位置的不同文件覆盖这些默认值。\n如果使用环境变量而不是系统属性，大多数操作系统都不允许使用句点分隔的键名，但可以使用下划线（例如，SPRING_CONFIG_NAME而不是SPRING.CONFIG.NAME）。\n默认情况下，当指定的配置数据位置不存在时，Spring Boot将抛出ConfigDataLocationNotFoundException，应用程序将不会启动。\n如果您想指定一个位置，但不介意它不总是存在，可以使用optional:前缀。您可以将此前缀与spring.config.location和spring.config.additional-location属性以及spring.config.import声明一起使用。\n如果要忽略所有ConfigDataLocationNotFoundExceptions并始终继续启动应用程序，可以使用SpringApplication.setDefaultProperties(…) 或系统/环境变量设置 spring.config.on-not-found=ignore 。\nWildcard Locations 如果配置文件位置最后一个路径包含*字符，则它被视为通配符位置。加载配置时会展开通配符，以便也检查直接子目录。当存在多个配置属性源时，通配符位置在Kubernetes等环境中特别有用。\n例如，如果您有一些Redis配置和一些MySQL配置，您可能希望将这两个配置分开，同时要求这两个都存在于application.properties文件。这可能导致两个单独的application.properties安装在不同位置，如/config/redis/application.properties和/config/mysql/application.properties。在这种情况下，通配符位置为config/*/ 将导致两个文件都被处理。\n默认情况下，Spring Boot在默认搜索位置中包含config/*/。这意味着将搜索jar之外的/config目录的所有子目录。\n你可以在spring.config.location 和 spring.config.additional-location 属性上配置通配符位置。\n通配符位置只能包含一个*，对于目录搜索位置，必须以*/结尾；对于文件搜索位置，则必须以 */\u0026lt;filename\u0026gt; 结尾。带有通配符的位置根据文件名的绝对路径按字母顺序排序。\nProfile Specific Files 除了application 属性文件，Spring Boot还将尝试使用命名约定application-{profile}加载特定profile的文件。例如，如果您的application 激活了一个名为prod的概要文件并使用了YAML文件，那么application.yml 和 application-prod.yml 都会被激活\n如果指定了多个profile，则采用最后获胜策略。 例如 spring.profiles.active = prod,live，application-prod.properties文件中的属性会被 application-live.properties 覆盖。\n继续上面的prod、live示例，我们可能会有以下文件：\n/cfg application-live.properties /ext application-live.properties application-prod.properties 当spring.config.location=classpath:/cfg/,classpath:/ext/ 我们在所有/ext文件之前处理所有/cfg文件：\n/cfg/application-live.properties /ext/application-prod.properties /ext/application-live.properties 当spring.config.location=classpath:/cfg/;classpath:/ext/ :\n/ext/application-prod.properties /cfg/application-live.properties /ext/application-live.properties profiles 默认值是 default\nImporting Additional Data spring.config.import 可以指定其他的配置文件并导入。被导入的文件如果存在，则立即执行导入操作，并被视为在声明导入的文档的正下方插入的附加文档。\n例如，application.properties文件包含下面的内容：\nspring.application.name=myapp spring.config.import=optional:file:./dev.properties 这将触发当前目录中dev.properties文件的导入（如果存在这样的文件）。导入的dev.properties中的值将优先于触发导入的文件。在上面的例子中，dev.properties可以重新定义spring.application.name设置为不同的值。\n导入将只导入一次，无论它声明了多少次。在properties/yaml文件中的单个文档中定义导入的顺序并不重要。例如，下面的两个示例产生了相同的结果：\nspring.config.import=my.properties my.property=value my.property=value spring.config.import=my.properties 如果您想支持自己的位置，请参阅org.springframework.boot.context.config包中的ConfigDataLocationResolver和ConfigDataLoader类。\n导入无扩展名文件 某些云平台无法向 volume mounted files 添加文件扩展名。要导入这些无扩展名文件，您需要给Spring Boot一个提示，以便它知道如何加载它们。您可以通过将扩展提示放在方括号中来做到这一点。\n例如，假设您有一个/etc/config/myconfig文件，希望将其导入为yaml。您可以从应用程序导入它。属性使用以下属性：\nspring.config.import=file:/etc/config/myconfig[.yaml] 使用配置树 在云平台（如Kubernetes）上运行应用程序时，通常需要读取平台提供的配置值。为此目的使用环境变量并不少见，但这可能有缺点，特别是如果值应该保密的话。\n作为环境变量的替代方案，许多云平台现在允许您将配置映射到装载的数据卷中。例如，Kubernetes可以同时装载ConfigMaps和Secrets。\n可以使用两种常见的卷装载模式：\n单个文件包含一组完整的属性（通常写为YAML）。 多个文件被写入目录树，文件名成为“键”，内容成为“值”。 对于第一种情况，可以使用 pring.config.import 直接导入YAML或Properties文件。对于第二种情况，您需要使用 configtree:前缀，以便Spring Boot知道它需要将所有文件作为属性公开。\n举个例子，让我们假设Kubernetes已经挂载了以下卷：\netc/ config/ myapp/ username password username文件的内容是配置值，password 文件的内容是secret\n要导入这些属性，可以将以下内容添加到application.properties 或application.yaml文件：\nspring.config.import=optional:configtree:/etc/config/ 然后你可以在Environment 中访问 myapp.username 和 myapp.password 属性。\n如果要从同一父文件夹导入多个配置树，可以使用通配符快捷方式。任何以/*/结尾的configtree:位置都会将所有直接子级作为配置树导入。\netc/ config/ dbconfig/ db/ username password mqconfig/ mq/ username password spring.config.import=optional:configtree:/etc/config/*/ 这会添加 db.username, db.password, mq.username 和 mq.password 属性。\n配置树被docker secrets 使用。当 Docker swarm 被授权可以访问 secret 时，这个 secret 会被挂载到容器上。例如， 一个名为 db.password 的 secret 被挂载到 /run/secrets/ ，你可以用下面的配置：\nspring.config.import=optional:configtree:/run/secrets/ 属性占位符 语法：${name:default}\napp.name=MyApp app.description=${app.name} is a Spring Boot application written by ${username:Unknown} 假设username 属性未在别处设置，app.description 的实际值是：MyApp is a Spring Boot application written by Unknown.\n您应该始终使用占位符中的规范形式(kebab-case的全小写)引用属性名称，这和@ConfigurationProperties的绑定逻辑相同\n例如，${demo.item-price} 会从application.properties 查找 demo.item-price 和 demo.itemPrice 属性的值，以及从环境变量中查找DEMO_ITEMPRICE 。 如果你使用${demo.itemPrice} ，则 不会查找 demo.item-price 和 DEMO_ITEMPRICE\n使用多文档文件 Spring Boot允许您将单个物理文件拆分为多个逻辑文档，每个逻辑文档都独立添加。文档按从上到下的顺序处理。稍后的文档可以覆盖先前文档中定义的属性。\napplication.yml使用标准的YAML多文档语法。三个连续的连字符表示一个文档的结尾和下一个文档开始。\nspring: application: name: \u0026#34;MyApp\u0026#34; --- spring: application: name: \u0026#34;MyCloudApp\u0026#34; config: activate: on-cloud-platform: \u0026#34;kubernetes\u0026#34; application.properties 使用 #--- 或 !--- 注释 标记文档分割：\nspring.application.name=MyApp #--- spring.application.name=MyCloudApp spring.config.activate.on-cloud-platform=kubernetes 属性文件分隔符不能有任何前导空格，并且必须正好有三个连字符。分隔符前后的行不能是相同的注释前缀。\n多文档属性文件通常与激活属性（如spring.config.activate.on-profile）结合使用。\n无法使用@PropertySource或@TestProperty源批注加载多文档属性文件。\nActivation Properties 有时，仅在满足某些条件时激活给定的属性集是有用的。例如，您可能具有仅在特定配置文件处于活动状态时才使用相关的属性。\n您可以使用spring.config.activate.*有条件地激活属性文档。\non-profile: 表达式 on-cloud-platform：要使文档处于活动状态，必须检测到的CloudPlatform。 例如，以下内容指定第二个文档仅在Kubernetes上运行时处于活动状态，并且仅在“prod”或“staging”配置文件处于活动状态时才处于活动状态：\nmyprop=always-set #--- spring.config.activate.on-cloud-platform=kubernetes spring.config.activate.on-profile=prod | staging myotherprop=sometimes-set 加密属性 Spring Boot 不提供任何用于加密属性值的内置支持，但是，它确实提供了修改 Spring 环境中包含的值的挂钩点。环境后处理器接口允许您在应用程序启动之前操作环境。有关详细信息，请参阅文档。\n如果您需要一种安全的方式来存储凭据和密码，参考 Spring Cloud Vault\nyaml YAML 是 JSON 的超集，是指定分层配置数据的便捷格式。SpringApplication 类会自动支持 YAML 作为属性的替代方法，只要您的类路径上有YAML库。\nYAML文档需要从其分层格式转换为可以与Spring环境一起使用的平面结构。例如，请考虑以下 YAML 文档：\nenvironments: dev: url: \u0026#34;https://dev.example.com\u0026#34; name: \u0026#34;Developer Setup\u0026#34; prod: url: \u0026#34;https://another.example.com\u0026#34; name: \u0026#34;My Cool App\u0026#34; 为了从环境中访问这些属性，它们将被拼合，如下所示：\nenvironments.dev.url=https://dev.example.com environments.dev.name=Developer Setup environments.prod.url=https://another.example.com environments.prod.name=My Cool App 同样，YAML 列表也需要扁平化。它们表示为具有 [index] 的属性键。例如，请考虑以下 YAML：\nmy: servers: - \u0026#34;dev.example.com\u0026#34; - \u0026#34;another.example.com\u0026#34; 前面的示例将转换为以下属性：\nmy.servers[0]=dev.example.com my.servers[1]=another.example.com 使用 [索引] 表示法的属性可以使用spring boot的 Binder 类绑定到 Java List或Set对象。有关更多详细信息，请参阅下面的“类型安全的配置属性”部分。\n无法使用@PropertySource或@TestPropertySource注释加载 YAML 文件。因此，如果需要以这种方式加载值，则需要使用属性文件。\nspring框架提供了两个方便的类，可用于加载YAML文档。YamlPropertiesFactoryBean 将 YAML 加载为“属性”，YamlMapFactoryBean 将 YAML 作为Map 加载。如果要将 YAML 作为PropertySource加载，也可以使用 YamlPropertySourceLoader。\n随机数 RandomValuePropertySource 帮助我们在配置中输入随机值，支持integers, longs, uuids, 或 strings。例如：\nmy.secret=${random.value} my.number=${random.int} my.bignumber=${random.long} my.uuid=${random.uuid} my.number-less-than-ten=${random.int(10)} my.number-in-range=${random.int[1024,65536]} 系统环境属性 spring启动支持为环境属性设置前缀。如果系统环境由具有不同配置要求的多个 Spring Boot 应用程序共享，这将非常有用。系统环境属性的前缀可以直接在SpringApplication上设置。\n例如，如果将前缀设置为input，则在系统环境中，remote.timeout等属性也将解析为input.remote.timeout。\n属性绑定 使用@Value(\u0026quot;${property}\u0026quot;)注解来注入配置属性有时会很麻烦，特别是如果您正在处理多个属性或数据本质上是分层的。SpringBoot提供了一种使用属性的替代方法，该方法允许强类型bean管理和验证应用程序的配置。\nJavaBean 属性绑定 可以将属性直接绑定到javabean上，例如：\n@ConfigurationProperties(\u0026#34;my.service\u0026#34;) public class MyProperties { private boolean enabled; private InetAddress remoteAddress; private final Security security = new Security(); public boolean isEnabled() { return this.enabled; } public void setEnabled(boolean enabled) { this.enabled = enabled; } public InetAddress getRemoteAddress() { return this.remoteAddress; } public void setRemoteAddress(InetAddress remoteAddress) { this.remoteAddress = remoteAddress; } public Security getSecurity() { return this.security; } public static class Security { private String username; private String password; private List\u0026lt;String\u0026gt; roles = new ArrayList\u0026lt;\u0026gt;(Collections.singleton(\u0026#34;USER\u0026#34;)); public String getUsername() { return this.username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return this.password; } public void setPassword(String password) { this.password = password; } public List\u0026lt;String\u0026gt; getRoles() { return this.roles; } public void setRoles(List\u0026lt;String\u0026gt; roles) { this.roles = roles; } } } 前面的POJO定义了以下属性：\nmy.service.enabled : 默认值是false my.service.remote-address: 可以从spring转换的强制类型 my.service.security.username my.service.security.password my.service.security.roles 这种安排依赖于默认的空构造函数，getter和setter通常是强制的，因为绑定是通过标准JavaBeans属性描述符进行的，就像SpringMVC中一样。在以下情况下，可省略setter：\nmaps，只要被初始化，就需要一个getter，但不一定需要setter，因为它们可以被绑定器更改。 可以通过索引（通常使用YAML）的集合和数组或使用单个逗号分隔的值（属性）。在后一种情况下，setter是强制性的。我们建议始终为此类类型添加setter。如果您初始化一个集合，请确保它不是不可变的（如前面的示例所示）。 如果嵌套的POJO属性已初始化（如前面示例中的Security字段），则不需要setter。如果您希望绑定器使用其默认构造函数动态创建实例，则需要一个setter。 有些人使用Project Lombok自动添加getter和setter。确保Lombok不会为此类类型生成任何特定的构造函数，因为容器会自动使用它来实例化对象。\n最后，只考虑标准JavaBean属性，不支持绑定静态属性。\n构造函数绑定 上一节中的示例可以以不可变的方式重写，如以下示例所示：\nimport java.net.InetAddress; import java.util.List; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.context.properties.ConstructorBinding; import org.springframework.boot.context.properties.bind.DefaultValue; @ConstructorBinding @ConfigurationProperties(\u0026#34;my.service\u0026#34;) public class MyProperties { private final boolean enabled; private final InetAddress remoteAddress; private final Security security; public MyProperties(boolean enabled, InetAddress remoteAddress, Security security) { this.enabled = enabled; this.remoteAddress = remoteAddress; this.security = security; } public boolean isEnabled() { return this.enabled; } public InetAddress getRemoteAddress() { return this.remoteAddress; } public Security getSecurity() { return this.security; } public static class Security { private final String username; private final String password; private final List\u0026lt;String\u0026gt; roles; public Security(String username, String password, @DefaultValue(\u0026#34;USER\u0026#34;) List\u0026lt;String\u0026gt; roles) { this.username = username; this.password = password; this.roles = roles; } public String getUsername() { return this.username; } public String getPassword() { return this.password; } public List\u0026lt;String\u0026gt; getRoles() { return this.roles; } } } 在此设置中，@ConstructorBinding注释用于指示应使用构造函数绑定。如果您使用的是Java16或更高版本，那么构造函数绑定可以用于Record。一般情况下，除非您的记录有多个构造函数，否则不需要使用@ConstructorBinding。\n@ConstructorBinding类的嵌套成员（例如上面示例中的Security）也将通过其构造函数绑定。\n默认值可以在构造函数参数上使用@DefaultValue指定，或者在使用Java 16或更高版本时，使用Record组件指定。conversion service 将String值强制转换为缺少属性的目标类型。\n参考前面的示例，如果没有属性绑定到Security，则MyProperties实例将包含一个空的security。要使它包含一个非空的Security实例，即使没有属性绑定到它，请使用空的@DefaultValue注释：\npublic MyProperties(boolean enabled, InetAddress remoteAddress, @DefaultValue Security security) { this.enabled = enabled; this.remoteAddress = remoteAddress; this.security = security; } 若要使用构造函数绑定，必须使用@EnableConfigurationProperties或配置属性扫描类。 不能将构造函数绑定用于由常规Spring机制创建的Bean（例如@Component Bean、使用@Bean方法创建的beans或使用@Import加载的beans）？？？因为对象不可变。 如果类有多个构造函数，也可以直接在应该绑定的构造函数上使用@ConstructorBinding。 启用@ConfigurationProperties注释类型 Spring Boot提供了绑定@ConfigurationProperties类型并将其注册为bean的基础结构。您可以逐个类启用配置属性，也可以启用与组件扫描类似的扫描方式。\n有时，用@ConfigurationProperties注释的类可能不适合扫描，例如，如果您正在开发自己的自动配置，或者希望有条件地启用它们。在这些情况下，请使用@EnableConfigurationProperties注释指定要处理的类型列表。这可以在任何@Configuration类上完成，如以下示例所示：\nimport org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Configuration; @Configuration(proxyBeanMethods = false) @EnableConfigurationProperties(SomeProperties.class) public class MyConfiguration { } 要使用配置属性扫描，请将@ConfigurationPropertiesScan注释添加到应用程序中。通常，它被添加到带有@SpringBootApplication注释的主应用程序类中，但它可以添加到任何@Configuration类中。默认情况下，将从声明注释的类的包进行扫描。如果要定义要扫描的特定包，可以按以下示例所示进行操作：\nimport org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.context.properties.ConfigurationPropertiesScan; @SpringBootApplication @ConfigurationPropertiesScan({ \u0026#34;com.example.app\u0026#34;, \u0026#34;com.example.another\u0026#34; }) public class MyApplication { } 当使用配置属性扫描或通过@EnableConfigurationProperties注册@ConfigurationProperties bean时，bean有一个常规名称：＜prefix＞-＜fqn＞，其中＜prefix\u0026gt;是@configuration Properties注释中指定的环境密钥前缀，＜fqn\u0026gt;是bean的完全限定名称。如果注释没有提供任何前缀，则只使用bean的完全限定名称。\n上面的例子中bean的名称是：com.example.app-com.example.app.SomeProperties\n我们建议@ConfigurationProperties只处理环境属性，特别是不要从上下文中注入其他bean。对于特殊情况，可以使用setter注入或框架提供的任何*Aware接口（例如，如果需要访问环境，则使用EnvironmentAware）。如果您仍然希望使用构造函数注入其他bean，则必须使用@Component注释配置属性bean，并使用基于JavaBean的属性绑定。\n使用 @ConfigurationProperties-annotated 类型 这种类型的配置在SpringApplication外部YAML配置中尤其适用，如下例所示：\nmy: service: remote-address: 192.168.1.1 security: username: \u0026#34;admin\u0026#34; roles: - \u0026#34;USER\u0026#34; - \u0026#34;ADMIN\u0026#34; 要使用@ConfigurationProperties bean，您可以以与任何其他bean相同的方式注入它们，如下例所示：\n@Service public class MyService { private final SomeProperties properties; public MyService(SomeProperties properties) { this.properties = properties; } public void openConnection() { Server server = new Server(this.properties.getRemoteAddress()); server.start(); // ... } // ... } 第三方配置 除了使用@ConfigurationProperties注释类之外，您还可以在公共@Bean方法上使用它。当您希望将属性绑定到您无法控制的第三方组件时，这样做尤其有用。\n要从Environment属性配置bean，请将@ConfigurationProperties添加到注册bean的方法上，如下例所示：\n@Configuration(proxyBeanMethods = false) public class ThirdPartyConfiguration { @Bean @ConfigurationProperties(prefix = \u0026#34;another\u0026#34;) public AnotherComponent anotherComponent() { return new AnotherComponent(); } } 灵活的绑定方式 Spring Boot使用一些宽松的规则将Environment属性绑定到@ConfigurationProperties bean，因此Environmental属性名称和bean属性名称之间不需要完全匹配。常用的示例包括破折号分隔的环境属性（例如，context-path绑定到contextPath）和大写的环境属性，例如，PORT绑定到 port。\n@ConfigurationProperties(prefix = \u0026#34;my.main-project.person\u0026#34;) public class MyPersonProperties { private String firstName; public String getFirstName() { return this.firstName; } public void setFirstName(String firstName) { this.firstName = firstName; } } 对于前面的代码，以下属性名称都可以使用：\nProperty Note my.main-project.person.first-name Kebab案例，建议在.properties和.yml文件中使用。 my.main-project.person.firstName 标准驼峰大小写语法。 my.main-project.person.first_name 下划线表示法，这是一种用于.properties和.yml文件的替代格式。 MY_MAINPROJECT_PERSON_FIRSTNAME 大写格式，建议在使用系统环境变量时使用。 Property Source Simple List Properties Files Camel大小写、kebab大小写或下划线符号 使用[]或逗号分隔值的标准列表语法 YAML Files Camel大小写、kebab大小写或下划线符号 标准YAML列表语法或逗号分隔值 Environment Variables 以下划线为分隔符的大写格式（请参见从环境变量绑定）。 由下划线包围的数值（请参见从环境变量绑定） System properties Camel大小写、kebab大小写或下划线符号 使用[]或逗号分隔值的标准列表语法 我们建议在可能的情况下，属性以小写的kebab格式存储，例如my.person.first-name=Rod\nBinding Maps 当绑定到Map属性时，可能需要使用特殊的括号符号，以便保留原始键值。如果键未被[]包围，则将删除所有非字母数字、-或.的字符。\n例如，考虑将以下属性绑定到Map\u0026lt;String,String\u0026gt;：\nmy.map.[/key1]=value1 my.map.[/key2]=value2 my.map./key3=value3 对于YAML文件，括号需要用引号括起来，以便正确解析键。\n上面的属性将绑定到一个Map，其中/key1、/key2和key3作为Map中的键。斜线已从key3中删除，因为它没有被方括号包围。\n当绑定到标量值时，其中带有.的键不需要被[]包围。标量值包括枚举和java.lang包中所有的类型，Object除外。将a.b=c绑定到Map＜String，String＞将保留键中的.，并返回带有条目｛\u0026quot;a.b\u0026quot;=\u0026quot;c\u0026quot;｝的Map。对于任何其他类型，如果您的键包含.，则需要使用括号表示法。例如，将a.b=c绑定到Map＜String，Object＞将返回带有条目{\u0026quot;a\u0026quot;={\u0026quot;b\u0026quot;=\u0026quot;c\u0026quot;}}的Map，而[a.b]=c将返回带有条目{\u0026quot;a.b\u0026quot;=\u0026quot;c\u0026quot;}的Map。\n从环境变量绑定 大多数操作系统对可用于环境变量的名称实施严格的规则。例如，Linux shell变量只能包含字母（a到z或A到Z）、数字（0到9）或下划线（_）。按照惯例，Unix Shell变量的名称也将为大写。\nSpring Boot的宽松绑定规则尽可能与这些命名限制兼容。要将规范形式的属性名转换为环境变量名，可以遵循以下规则：\n使用 . 替换 _ 删除 - 转换成大写 例如，配置spring.main.log-startup-info 是一个名为SPRING_MAIN_LOGSTARTUPINFO的环境变量。\n绑定到对象列表时也可以使用环境变量。要绑定到列表，序号应在变量名中用下划线括起来。例如 my.service[0].other 对应 MY_SERVICE_0_OTHER\n合并复杂类型 当在多个位置配置列表时，通过替换整个列表来覆盖列表。\n例如，假设一个MyPojo对象的name 和 description属性默认为空。以下示例公开了MyProperties中的MyPojo对象列表：\n@ConfigurationProperties(\u0026#34;my\u0026#34;) public class MyProperties { private final List\u0026lt;MyPojo\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); public List\u0026lt;MyPojo\u0026gt; getList() { return this.list; } } 假如有如下配置：\nmy.list[0].name=my name my.list[0].description=my description #--- spring.config.activate.on-profile=dev my.list[0].name=my another name 如果dev profile未处于活动状态，MyProperties.list 包含一个MyPojo条目。但是，如果启用了dev profile，列表仍然只包含一个条目（name 为my another name，description 为空）。此配置不会向列表中添加第二个MyPojo实例，也不会合并项目。\n当在多个 profiles 中指定列表时，将使用优先级最高的profiles（并且仅使用该配置文件）。考虑以下示例：\nmy.list[0].name=my name my.list[0].description=my description my.list[1].name=another name my.list[1].description=another description #--- spring.config.activate.on-profile=dev my.list[0].name=my another name 在前面的示例中，如果dev profile处于活动状态，则为MyProperties.list包含一个MyPojo条目。对于YAML，逗号分隔列表和YAML列表都可以用于完全覆盖列表的内容。\n对于Map属性，你可以从多个配置源绑定，但是，在多个配置源中有相同的属性，就会发生覆盖。例如：\n@ConfigurationProperties(\u0026#34;my\u0026#34;) public class MyProperties { private final Map\u0026lt;String, MyPojo\u0026gt; map = new LinkedHashMap\u0026lt;\u0026gt;(); public Map\u0026lt;String, MyPojo\u0026gt; getMap() { return this.map; } } my.map.key1.name=my name 1 my.map.key1.description=my description 1 #--- spring.config.activate.on-profile=dev my.map.key1.name=dev name 1 my.map.key2.name=dev name 2 my.map.key2.description=dev description 2 dev profile 没有激活，MyProperties.map 只包括key1实体。 如果激活 dev, 则包括 key1和key2，其中key1的内容是 name=dev name 1\n属性转换 当Spring Boot绑定到@ConfigurationProperties bean时，它试图强制转换数据类型。如果需要自定义类型转换，可以提供ConversionService bean（名为conversionService的bean）或自定义属性编辑器（通过CustomEditorConfigurer bean），或自定义Converter（带有注释为@ConfigurationPropertiesBinding的bean定义）。\n由于这个bean是在应用程序生命周期的早期请求的，所以请确保限制您的ConversionService正在使用的依赖项。\n转换时间类型 Spring Boot支持持续时间。如果公开java.time.Duration属性，则应用程序属性中的以下格式可用：\nlong 类型，使用毫秒作为默认单位 java.time.Duration使用的标准ISO-8601格式 一种更可读的格式，其中值和单位是耦合的（10s表示10秒） @ConfigurationProperties(\u0026#34;my\u0026#34;) public class MyProperties { @DurationUnit(ChronoUnit.SECONDS) private Duration sessionTimeout = Duration.ofSeconds(30); private Duration readTimeout = Duration.ofMillis(1000); } 要指定30秒的会话超时，30、PT30S和30s都是等效的。500ms的读取超时可以以下列任何形式指定：500、PT0.5S和500ms。\n默认单位为毫秒，可以使用@DurationUnit覆盖，如上面的示例所示。\n如果您喜欢使用构造函数绑定，可以公开相同的属性，如以下示例所示：\n@ConfigurationProperties(\u0026#34;my\u0026#34;) @ConstructorBinding public class MyProperties { // fields... public MyProperties(@DurationUnit(ChronoUnit.SECONDS) @DefaultValue(\u0026#34;30s\u0026#34;) Duration sessionTimeout, @DefaultValue(\u0026#34;1000ms\u0026#34;) Duration readTimeout) { this.sessionTimeout = sessionTimeout; this.readTimeout = readTimeout; } // getters... } Converting Data Sizes Spring Framework具有以字节表示大小的DataSize值类型。如果公开DataSize属性，则应用程序属性中的以下格式可用：\nlong表示（除非指定了@DataSizeUnit，否则使用字节作为默认单位） 一种更可读的格式，其中值和单位是耦合的（10MB表示10 MB） @ConfigurationProperties(\u0026#34;my\u0026#34;) public class MyProperties { @DataSizeUnit(DataUnit.MEGABYTES) private DataSize bufferSize = DataSize.ofMegabytes(2); private DataSize sizeThreshold = DataSize.ofBytes(512); // getters/setters... } 要指定10 MB的缓冲区大小，10和10MB相当。256字节的大小阈值可以指定为256或256B。\n@ConfigurationProperties 校验 每当用Spring的@Validated注释@ConfigurationProperties类时，Spring Boot都会尝试验证它们。您可以使用JSR-303 javax.validation直接在配置类上添加验证约束。为此，请确保符合JSR-303的实现在您的类路径上，然后向字段添加约束注释，如下例所示：\n@ConfigurationProperties(\u0026#34;my.service\u0026#34;) @Validated public class MyProperties { @NotNull private InetAddress remoteAddress; // getters/setters... } 您还可以通过在@Bean方法使用@Validated注释来触发验证。\n为了确保始终为嵌套属性触发验证，即使找不到属性，关联字段也必须用@Valid进行注释。以下示例基于前面的MyProperties示例：\n@ConfigurationProperties(\u0026#34;my.service\u0026#34;) @Validated public class MyProperties { @NotNull private InetAddress remoteAddress; @Valid private final Security security = new Security(); // getters/setters... public static class Security { @NotEmpty private String username; // getters/setters... } } 您还可以通过创建名为configurationPropertiesValidator的bean定义来添加自定义SpringValidator。@Bean方法应声明为静态的。配置属性验证器是在应用程序生命周期的早期创建的，并且将@Bean方法声明为static可以创建Bean，而无需实例化@configuration类。这样做可以避免早期实例化可能导致的任何问题。\n@ConfigurationProperties vs. @Value @Value注释是一个核心容器特性，它不提供与类型安全配置属性相同的特性。下表总结了@ConfigurationProperties和@Value支持的功能：\nFeature @ConfigurationProperties @Value Relaxed binding Yes Limited (see note below) Meta-data support Yes No SpEL evaluation No Yes 如果您确实想使用@Value，我们建议您使用规范格式（仅使用小写字母的kebab大小写）来引用属性名称。这将允许Spring Boot使用与灵活绑定@ConfigurationProperties时相同的逻辑。\n例如，@Value(\u0026quot;${demo.item-price}\u0026quot;) 将获取demo.item-price 和demo.itemPrice 以及系统环境中的DEMO_ITEMPRICE。如果您使用@Value(\u0026quot;${demo.itemPrice}\u0026quot;)代替，demo.item-price和DEMO_ITEMPRICE将不予考虑。\n如果您为自己的组件定义了一组配置键，我们建议您将它们分组到带有@ConfigurationProperties注释的POJO中。这样做将为您提供结构化的、类型安全的对象，您可以将其注入到自己的bean中。\n在解析这些文件并填充环境时，不会处理应用程序属性文件中的SpEL表达式。但是，可以在@Value中编写SpEL表达式。如果应用程序属性文件中的属性值是SpEL表达式，则在使用@value时将对其求值。\nProfiles SpringProfiles提供了一种方法来隔离应用程序配置的各个部分，并使其仅在特定环境中可用。加载时，任何@Component、@Configuration或@ConfigurationProperties都可以用@Profile标记以限制，如以下示例所示：\n@Configuration(proxyBeanMethods = false) @Profile(\u0026#34;production\u0026#34;) public class ProductionConfiguration { // ... } 如果@ConfigurationProperties bean是通过@EnableConfigurationProperties而不是自动扫描注册的，则需要在具有@EnableConfigurationProperties注释的@Configuration类上指定@Profile注释。在扫描@ConfigurationProperties的情况下，可以在@ConfigurationProperties类本身上指定@Profile。\n您可以使用 spring.profiles.active Environment属性指定哪些配置文件处于活动状态。您可以使用本章前面描述的任何方法指定属性。例如，您可以将其包含在application.properties中，如以下示例所示：\nspring.profiles.active=dev,hsqldb 您还可以使用以下开关在命令行中指定它：--spring.profiles.active=dev,hsqldb。\n如果没有profile 文件处于活动状态，则会启用default profile 文件。默认配置文件的名称为default，可以使用 spring.profiles.default Environment 属性 对其进行修改。如以下示例所示：\nspring.profiles.default=none spring.profiles.active 和 spring.profiles.default 只能在non-profile 配置文件中使用 。例如：\n# this document is valid spring.profiles.active=prod #--- # this document is invalid spring.config.activate.on-profile=prod spring.profiles.active=metrics 添加 Active Profiles spring.profiles.active属性遵循与其他属性相同的排序规则：最高的PropertySource获胜。这意味着您可以在application.properties中指定活动配置文件，然后使用命令行开关替换它们。\n有时，将属性添加到active profile文件而不是替换它们是有用的。spring.profiles.include属性可用于在spring.profiles.active 的配置文件之上添加活动配置文件。SpringApplication入口点还具有用于设置其他profiles文件的JavaAPI。请参见SpringApplication中的setAdditionalProfiles（）方法。\n例如，当运行具有以下属性的应用程序时，即使使用 \u0026ndash;spring.profiles.active 开关运行，common 和 local profile也将被激活:\nspring.profiles.include[0]=common spring.profiles.include[1]=local 类似于spring.profiles.active，spring.profiles.include只能用于非profile文件。\nProfile Groups 有时，您在应用程序中定义和使用的profile文件过于细粒度，难以使用。例如，您可能有proddb和prodmq profile文件，用于独立启用数据库和消息功能。\n为了帮助实现这一点，Spring Boot允许您定义profile文件组。proflie文件组允许您为相关配置文件组定义逻辑名称。\n例如，我们可以创建一个由proddb和prodmq配置文件组成的production 组:\nspring.profiles.group.production[0]=proddb spring.profiles.group.production[1]=prodmq 现在可以使用--spring.profiles.active=production启动我们的应用程序，以一次性激活proddb和prodmq配置文件。\n编程的方式设置 proflies 您可以在应用程序运行之前 通过调用SpringApplication.setAdditionalProfiles(…) 以编程方式设置活动profile文件。还可以使用Spring的ConfigurableEnvironment接口激活配置文件。\n日志 Spring Boot使用Commons Logging进行所有内部日志记录，但保留底层日志实现的开放性。为Java Util Logging、Log4J2和Logback提供了默认配置。在每种情况下，记录器都预先配置为使用控制台输出，也可以使用可选的文件输出。\n默认情况下，如果使用“Starters”，则Logback用于日志记录。还包括适当的Logback路由，以确保使用Java Util Logging、Commons Logging，Log4J或SLF4J的依赖库都能正常工作。\n当您将应用程序部署到servlet容器或应用程序服务器时，使用Java Util logging API执行的日志不会路由到应用程序的日志中。这将防止容器或已部署到容器的其他应用程序执行的日志记录出现在应用程序的日志中。\n日志格式 默认的日志打印如下：\n2022-10-20 12:40:11.311 INFO 16138 --- [ main] o.s.b.d.f.s.MyApplication : Starting MyApplication using Java 1.8.0_345 on myhost with PID 16138 (/opt/apps/myapp.jar started by myuser in /opt/apps/) 2022-10-20 12:40:11.330 INFO 16138 --- [ main] o.s.b.d.f.s.MyApplication : No active profile set, falling back to 1 default profile: \u0026#34;default\u0026#34; 2022-10-20 12:40:13.056 INFO 16138 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 2022-10-20 12:40:13.070 INFO 16138 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 2022-10-20 12:40:13.070 INFO 16138 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.68] 2022-10-20 12:40:13.178 INFO 16138 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2022-10-20 12:40:13.178 INFO 16138 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1762 ms 2022-10-20 12:40:13.840 INFO 16138 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path \u0026#39;\u0026#39; 2022-10-20 12:40:13.850 INFO 16138 --- [ main] o.s.b.d.f.s.MyApplication Date and Time: 毫秒级精度，易于分拣。 Log Level: ERROR, WARN, INFO, DEBUG, or TRACE. Process ID. 一个---分隔符，用于区分实际日志消息的开头。 Thread name: Logger name: The log message: 控制台输出 默认的日志配置在写入消息时将消息回送到控制台。默认情况下，记录错误级别、警告级别和INFO级别的消息。您还可以通过使用--debug标志启动应用程序来启用“调试”模式。\n$ java -jar myapp.jar --debug 启用调试模式后，会配置一系列核心记录器（嵌入式容器、Hibernate和Spring Boot）以输出更多信息。启用调试模式不会将应用程序配置为记录所有debug级别的消息。\n或者，您可以通过使用\u0026ndash;trace标志（或application.properties中的trace=true）启动应用程序来启用“跟踪”模式。这样做可以为一系列核心记录器（嵌入式容器、Hibernate模式生成和整个Spring组合）启用跟踪日志记录。\n色彩输出 如果终端支持ANSI，则使用颜色输出来帮助可读性。您可以设置spring.output.ansi.enabled 为支持的值以覆盖自动检测。\n使用%clr转换字配置颜色编码。在最简单的形式中，转换器根据日志级别对输出进行着色，如下例所示：\n%clr(%5p)\n下表描述了日志级别到颜色的映射：\nLevel Color FATAL Red ERROR Red WARN Yellow INFO Green DEBUG Green TRACE Green 或者，您可以通过将其作为转换选项来指定应使用的颜色或样式。例如，要使文本变为黄色，请使用以下设置：\n%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){yellow}\n支持以下颜色和样式：\nblue cyan faint green magenta red yellow 文件输出 默认情况下，Spring Boot只记录到控制台，不写入日志文件。如果您想写入控制台输出之外的日志文件，则需要设置logging.file.name或logging.file.path属性（在application.properties中）\nlogging.file.name logging.file.path Example Description (none) (none) 输出到控制台 指定文件 (none) my.log 写入指定的日志文件。名称可以是精确的位置或相对于当前目录。 (none) 指定目录 /var/log 写入到指定的目录。名称可以是精确的位置或相对于当前目录。 当日志文件达到10MB时，它们会旋转，与控制台输出一样，默认情况下会记录ERROR级别、WARN级别和INFO级别的消息。\n文件轮转 如果使用的是Logback，则可以使用应用程序微调日志旋转设置。对于所有其他日志记录系统，您需要自己直接配置旋转设置（例如，如果您使用Log4J2，则可以添加Log4J2.xml或Log4J2-spring.xml文件）。\n支持以下轮换策略属性：\nName Description logging.logback.rollingpolicy.file-name-pattern 用于创建日志存档的文件名模式。 logging.logback.rollingpolicy.clean-history-on-start 如果应用程序启动时应进行日志归档清理。 logging.logback.rollingpolicy.max-file-size 归档前日志文件的最大大小。 logging.logback.rollingpolicy.total-size-cap 日志存档在被删除之前可以占用的最大大小。 logging.logback.rollingpolicy.max-history 要保留的存档日志文件的最大数量（默认为7）。 日志级别 通过使用logging.level.\u0026lt;logger name\u0026gt;=\u0026lt;level\u0026gt;设置日志记录级别，其中level是TRACE、DEBUG、INFO、WARN、ERROR、FATAL或OFF之一。可以使用logging.level.root配置根记录器。下面是参考示例：\nlogging.level.root=warn logging.level.org.springframework.web=debug logging.level.org.hibernate=error 还可以使用环境变量设置日志记录级别。例如，LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_WEB=DEBUG将设置org.springframework.web到debug级别。\n上述方法仅适用于包级日志记录。由于轻松绑定总是将环境变量转换为小写，因此不可能以这种方式为单个类配置日志记录。如果需要为类配置日志记录，可以使用SPRING_APPLICATION_JSON变量。\n日志分组 能够将相关的记录器分组在一起，以便它们可以同时配置，这通常很有用。例如，您可能通常会更改所有与Tomcat相关的记录器的日志级别，但您不容易记住顶级包。\n为了帮助实现这一点，Spring Boot允许您在Spring环境中定义日志组。例如，下面是如何通过将“tomcat”组添加到application.properties来定义它的方法：\nlogging.group.tomcat=org.apache.catalina,org.apache.coyote,org.apache.tomcat 定义后，您可以通过单行更改组中所有记录器的级别：\nlogging.level.tomcat=trace\nSpring Boot包括以下预定义的日志记录组，可以现成使用：\nweb org.springframework.core.codec, org.springframework.http, org.springframework.web, org.springframework.boot.actuate.endpoint.web, org.springframework.boot.web.servlet.ServletContextInitializerBeans sql org.springframework.jdbc.core, org.hibernate.SQL, org.jooq.tools.LoggerListener 使用日志的Shutdown 钩子 为了在应用程序终止时释放日志资源，提供了一个在JVM退出时触发日志系统清理的关闭挂钩。除非您的应用程序部署为war文件，否则此关闭挂钩将自动注册。如果您的应用程序具有复杂的上下文层次结构，则关闭挂钩可能无法满足您的需要。如果没有，请禁用关闭挂钩并调查底层日志记录系统直接提供的选项。例如，Logback提供了上下文选择器，允许在自己的上下文中创建每个Logger。您可以使用logging.register-shutdown-hook属性以禁用关机挂钩。\n自定义日志 可以通过在类路径上包含适当的库来激活各种日志记录系统，并且可以通过在classpath的根目录中或在以下Spring Environment 配置 logging.config 属性提供适当的配置文件来进一步定制。\n您可以使用org.springframework.Boot.logging.LoggingSystem强制Spring Boot使用特定的日志系统。该值应为LoggingSystem实现的完全限定类名。您还可以使用none值完全禁用Spring Boot的日志配置。\n由于日志是在创建ApplicationContext之前初始化的，因此无法从Spring@Configuration文件中的@PropertySources控制日志。更改或完全禁用日志记录系统的唯一方法是通过系统属性。\n根据您的日志记录系统，将加载以下文件：\nLogging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml, or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties 如果可能，我们建议您在日志配置中使用-spring变量（例如，logback-spring.xml而不是logback.xml）。如果使用标准配置位置，Spring无法完全控制日志初始化。\nJava Util Logging存在已知的类加载问题，这些问题会导致从“可执行jar”运行时出现问题。如果可能的话，我们建议您在从“可执行jar”运行时避免这种情况。\n为了帮助定制，将一些其他属性从Spring Environment转移到System属性，如下表所述：\nSpring Environment System Property Comments logging.exception-conversion-word LOG_EXCEPTION_CONVERSION_WORD 记录异常时使用的转换词。 logging.file.name LOG_FILE 如果已定义，它将在默认日志配置中使用。 logging.file.path LOG_PATH 如果已定义，它将在默认日志配置中使用。 logging.pattern.console CONSOLE_LOG_PATTERN 要在控制台上使用的日志模式（stdout）。 logging.pattern.dateformat LOG_DATEFORMAT_PATTERN 日志日期格式的附加模式。 logging.charset.console CONSOLE_LOG_CHARSET 用于控制台日志记录的字符集。 logging.pattern.file FILE_LOG_PATTERN 要在文件中使用的日志模式（如果启用了LOG_FILE ）。 logging.charset.file FILE_LOG_CHARSET 用于文件日志记录的字符集（如果启用了LOG_FILE ）。 logging.pattern.level LOG_LEVEL_PATTERN 渲染日志级别时使用的格式（默认为%5p）。 PID PID 当前进程ID（如果可能，并且尚未定义为操作系统环境变量时发现）。 如果使用Logback，还将传输以下属性：\nSpring Environment System Property Comments logging.logback.rollingpolicy.file-name-pattern LOGBACK_ROLLINGPOLICY_FILE_NAME_PATTERN Pattern for rolled-over log file names (default ${LOG_FILE}.%d{yyyy-MM-dd}.%i.gz). logging.logback.rollingpolicy.clean-history-on-start LOGBACK_ROLLINGPOLICY_CLEAN_HISTORY_ON_START Whether to clean the archive log files on startup. logging.logback.rollingpolicy.max-file-size LOGBACK_ROLLINGPOLICY_MAX_FILE_SIZE Maximum log file size. logging.logback.rollingpolicy.total-size-cap LOGBACK_ROLLINGPOLICY_TOTAL_SIZE_CAP Total size of log backups to be kept. logging.logback.rollingpolicy.max-history LOGBACK_ROLLINGPOLICY_MAX_HISTORY Maximum number of archive log files to keep. 所有受支持的日志记录系统在解析其配置文件时都可以查阅系统属性。请参见spring-boot.jar中的默认配置：\nLogback Log4j 2 Java Util logging 如果你想在日志属性中使用占位符，你应该使用SpringBoot的语法，而不是底层框架的语法。值得注意的是，如果使用Logback，则应使用:作为属性名称和默认值之间的分隔符，而不要使用:-。\nLogback 扩展 Spring Boot包括许多Logback扩展，可以帮助进行高级配置。您可以在logback-spring.xml中使用这些扩展。\n因为logback.xml文件过早被加载，你不能在其中使用扩展功能。\n扩展不能用于Logback的配置扫描。如果您尝试这样做，对配置文件进行更改将导致类似以下记录之一的错误：\nERROR in ch.qos.logback.core.joran.spi.Interpreter@4:71 - no applicable action for [springProperty], current ElementPath is [[configuration][springProperty]] ERROR in ch.qos.logback.core.joran.spi.Interpreter@4:71 - no applicable action for [springProfile], current ElementPath is [[configuration][springProfile]] Profile-specific配置 ＜springProfile＞标签允许您根据活动的Spring配置文件选择性地包括或排除配置部分。配置文件部分在＜configuration＞元素中的任何位置都受支持。使用name属性指定接受配置的profile。标记可以包含profile文件名称（例如staging）或profile文件表达式。配置文件表达式允许表达更复杂的配置文件逻辑，例如production\u0026amp;（eu central | eu west）。有关详细信息，请参阅参考指南。以下列表显示了三个示例配置文件：\n\u0026lt;springProfile name=\u0026#34;staging\u0026#34;\u0026gt; \u0026lt;!-- configuration to be enabled when the \u0026#34;staging\u0026#34; profile is active --\u0026gt; \u0026lt;/springProfile\u0026gt; \u0026lt;springProfile name=\u0026#34;dev | staging\u0026#34;\u0026gt; \u0026lt;!-- configuration to be enabled when the \u0026#34;dev\u0026#34; or \u0026#34;staging\u0026#34; profiles are active --\u0026gt; \u0026lt;/springProfile\u0026gt; \u0026lt;springProfile name=\u0026#34;!production\u0026#34;\u0026gt; \u0026lt;!-- configuration to be enabled when the \u0026#34;production\u0026#34; profile is not active --\u0026gt; \u0026lt;/springProfile\u0026gt; Environment 属性 ＜springProperty＞标记允许您从Spring Environment中公开属性，以便在Logback中使用。如果您想从application.propertie访问值，那么这样做很有用该标签的工作方式与Logback的标准＜property＞标签类似。但是，不是指定直接值，而是指定属性的源（来自环境）。如果需要将属性存储在本地范围以外的其他地方，可以使用scope属性。如果需要回退值（如果未在环境中设置该属性），可以使用defaultValue属性。以下示例显示了如何公开属性以在Logback中使用：\n\u0026lt;springProperty scope=\u0026#34;context\u0026#34; name=\u0026#34;fluentHost\u0026#34; source=\u0026#34;myapp.fluentd.host\u0026#34; defaultValue=\u0026#34;localhost\u0026#34;/\u0026gt; \u0026lt;appender name=\u0026#34;FLUENT\u0026#34; class=\u0026#34;ch.qos.logback.more.appenders.DataFluentAppender\u0026#34;\u0026gt; \u0026lt;remoteHost\u0026gt;${fluentHost}\u0026lt;/remoteHost\u0026gt; ... \u0026lt;/appender\u0026gt; 国际化 Spring Boot支持本地化消息，以便您的应用程序能够满足不同语言偏好的用户。默认情况下，Spring Boot在类路径的根目录中查找消息资源包的存在。\n当配置的资源包的默认属性文件可用（默认情况下为messages.properties）时，将应用自动配置。如果您的资源包仅包含特定于语言的属性文件，则需要添加默认值。如果未找到与任何已配置的基名称匹配的属性文件，则不会有自动配置的MessageSource。\n可以使用spring.messages配置资源包的basename以及其他几个属性。如下例所示：\nspring.messages.basename=messages,config.i18n.messages spring.messages.fallback-to-system-locale=false spring.messages.basename支持逗号分隔的位置列表，可以是包限定符，也可以是从类路径根解析的资源。\nJSON Spring Boot提供了三个JSON映射库的集成：\nGson Jackson JSON-B Jackson是首选和默认库。\nJackson 提供了Jackson的自动配置，Jackson是spring-boot-starter-json的一部分。当Jackson位于类路径上时，会自动配置ObjectMapper bean。提供了几个配置属性用于自定义ObjectMapper的配置。\n自定义 ObjectMapper 自定义序列化和反序列化 如果您使用Jackson序列化和反序列化JSON数据，您可能需要编写自己的JsonSerializer和JsonDeserializer类。定制序列化程序通常通过一个模块向Jackson注册，但Spring Boot提供了另一个@JsonComponent注释，使直接注册Spring Beans更容易。\n您可以直接在JsonSerializer、JsonDeserializer或KeyDeserializer实现上使用@JsonComponent注释。您还可以将其用于包含serializers/deserializers 作为内部类的类，如以下示例所示：\n@JsonComponent public class MyJsonComponent { public static class Serializer extends JsonSerializer\u0026lt;MyObject\u0026gt; { @Override public void serialize(MyObject value, JsonGenerator jgen, SerializerProvider serializers) throws IOException { jgen.writeStartObject(); jgen.writeStringField(\u0026#34;name\u0026#34;, value.getName()); jgen.writeNumberField(\u0026#34;age\u0026#34;, value.getAge()); jgen.writeEndObject(); } } public static class Deserializer extends JsonDeserializer\u0026lt;MyObject\u0026gt; { @Override public MyObject deserialize(JsonParser jsonParser, DeserializationContext ctxt) throws IOException { ObjectCodec codec = jsonParser.getCodec(); JsonNode tree = codec.readTree(jsonParser); String name = tree.get(\u0026#34;name\u0026#34;).textValue(); int age = tree.get(\u0026#34;age\u0026#34;).intValue(); return new MyObject(name, age); } } } ApplicationContext中的所有@JsonComponent bean都会自动向Jackson注册。因为@JsonComponent用@Component进行了元注释，所以通常的组件扫描规则适用。\nSpring Boot还提供了JsonObjectSerializer和JsonObjectDeserializer基类，它们在序列化对象时提供了标准Jackson版本的有用替代方案。有关详细信息，请参见Javadoc中的JsonObjectSerializer和JsonObjectDeserializer。\n上面的示例可以重写为使用JsonObjectSerializer/JsonObjectDeserializer，如下所示：\n@JsonComponent public class MyJsonComponent { public static class Serializer extends JsonObjectSerializer\u0026lt;MyObject\u0026gt; { @Override protected void serializeObject(MyObject value, JsonGenerator jgen, SerializerProvider provider) throws IOException { jgen.writeStringField(\u0026#34;name\u0026#34;, value.getName()); jgen.writeNumberField(\u0026#34;age\u0026#34;, value.getAge()); } } public static class Deserializer extends JsonObjectDeserializer\u0026lt;MyObject\u0026gt; { @Override protected MyObject deserializeObject(JsonParser jsonParser, DeserializationContext context, ObjectCodec codec, JsonNode tree) throws IOException { String name = nullSafeValue(tree.get(\u0026#34;name\u0026#34;), String.class); int age = nullSafeValue(tree.get(\u0026#34;age\u0026#34;), Integer.class); return new MyObject(name, age); } } } Mixins Jackson支持mixin，可用于将附加注释混合到目标类上已声明的注释中。Spring Boot的Jackson自动配置将扫描应用程序的包，查找用@JsonMixin注释的类，并将它们注册到自动配置的ObjectMapper中。注册由Spring Boot的JsonMixinModule执行。\n任务执行和调度 ThreadPoolTaskExecutor??\nAsyncConfigurer??\n在上下文中没有Executor bean的情况下，Spring Boot会自动配置ThreadPoolTaskExecuttor，使其具有可自动关联到异步任务执行（@EnableAsync）和Spring MVC异步请求处理。\n如果您在上下文中定义了自定义Executor，则常规任务执行（即@EnableAsync）将透明地使用它，但不会配置Spring MVC支持，因为它需要AsyncTaskExecuttor实现（命名为applicationTaskExecuter）。根据您的目标安排，您可以将执行器更改为ThreadPoolTaskExecutor，或者同时定义一个ThreadPool TaskExecuter和一个AsyncConfigurer来包装您的自定义执行器。\n线程池使用8个核心线程，可以根据负载增长和收缩。这些默认设置可以使用spring.task.execution命名空间进行微调，如下例所示：\nspring.task.execution.pool.max-size=16 spring.task.execution.pool.queue-capacity=100 spring.task.execution.pool.keep-alive=10s 这会将线程池更改为使用有界队列，这样当队列已满（100个任务）时，线程池将增加到最多16个线程。当线程空闲10秒（而不是默认的60秒）时，由于线程被回收，因此池的收缩更为严重。\n如果需要与计划任务执行关联，ThreadPoolTaskScheduler也可以自动配置（例如使用@EnableSchedule）。线程池默认使用一个线程，其设置可以使用spring.task.scheduling进行微调。如下例所示：\nspring.task.scheduling.thread-name-prefix=scheduling- spring.task.scheduling.pool.size=2 如果需要创建自定义执行器或调度器，则可以在上下文中使用TaskExecutorBuilder bean和TaskSchedulerBuilder bean。\n测试 Spring Boot提供了许多实用程序和注释，以在测试应用程序时提供帮助。测试支持由两个模块提供：spring-boot-test包含核心项目，spring-boot-test-autoconfigure 支持测试的自动配置。\n大多数开发人员都使用spring-boot-starter-test“starter”，它导入了SpringBoot测试模块以及JUnit Jupiter、AssertJ、Hamcrest和许多其他有用的库\n测试范围依赖项 spring-boot-starter-test 依赖下面的库：\nJUnit 5: 单元测试Java应用程序的事实标准。 Spring Test \u0026amp; Spring Boot Test: Spring Boot应用程序的实用程序和集成测试支持。 AssertJ: 流畅的断言库。 Hamcrest: 匹配器对象库（也称为约束或谓词）。 Mockito: Java模拟框架。 JSONassert: JSON的断言库。 JsonPath: XPath for JSON. 我们通常认为这些公共库在编写测试时很有用。如果这些库不适合您的需要，您可以添加自己的附加测试依赖项。\n测试spring 程序 依赖注入的一个主要优点是它应该使代码更容易进行单元测试。您可以使用new操作符实例化对象，甚至不需要涉及Spring。您还可以使用模拟对象而不是实际的依赖关系。\n通常，您需要跳过单元测试，开始集成测试（使用SpringApplicationContext）。能够在不需要部署应用程序或连接到其他基础设施的情况下执行集成测试是非常有用的。\nSpring Framework包括用于此类集成测试的专用测试模块。您可以直接向org.springframework:spring-test声明一个依赖项，或者使用spring-boot-starter-test “starter”将其传递进来。\n测试spring boot 程序 Spring Boot应用程序是一个Spring ApplicationContext，所以除了通常使用普通Spring上下文所做的测试之外，不需要做任何特别的事情来测试它。\nSpringBoot的外部属性、日志记录和其他特性默认情况下仅在使用SpringApplication创建时才安装在上下文中。\nSpringBoot提供了一个@SpringBootTest注释，当您需要Spring Boot特性时，它可以用作标准Spring test@ContextConfiguration注释的替代。注释的工作方式是通过SpringApplication创建测试中使用的ApplicationContext。除了@SpringBootTest之外，还提供了许多其他注释，用于测试应用程序的更具体部分。\n默认情况下，@SpringBootTest不会启动服务器。您可以使用@SpringBootTest的webEnvironment属性进一步细化测试的运行方式：\nMOCK(Default) : 加载web ApplicationContext并提供模拟web环境。使用此注释时，不会启动嵌入式服务器。如果类路径上没有可用的web环境，则此模式将透明地返回到创建常规的非web ApplicationContext。它可以与@AutoConfigureMockMvc或@AutoConfigureWebTestClient结合使用，用于web应用程序的模拟测试。 RANDOM_PORT: 加载WebServerApplicationContext并提供真实的web环境。嵌入式服务器启动并在随机端口上侦听。 DEFINED_PORT： 加载WebServerApplicationContext并提供真实的web环境。嵌入式服务器启动并在定义的端口（来自application.properties）或默认端口8080上侦听。 NONE: 使用SpringApplication加载ApplicationContext，但不提供任何web环境（模拟或其他）。 如果您的测试是@Transactional，默认情况下，它会在每个测试方法结束时回滚事务。然而，当与RANDOM_PORT或DEFINED_PORT一起使用时，隐含地提供了一个真实的servlet环境，HTTP客户端和服务器在单独的线程中运行，因此在单独的事务中运行。在这种情况下，在服务器上启动的任何事务都不会回滚。\n探测程序的web类型 如果Spring MVC可用，则会配置常规的基于MVC的应用程序上下文。如果您只有SpringWebFlux，我们将检测到这一点并配置基于WebFlux的应用程序上下文。\n如果两者都存在，则Spring MVC优先。如果要在此场景中测试反应式web应用程序，必须设置spring.main.web-application-type属性：\n@SpringBootTest(properties = \u0026#34;spring.main.web-application-type=reactive\u0026#34;) class MyWebFluxTests { // ... } 探测测试配置类 如果您熟悉Spring测试框架，您可能习惯使用@ContextConfiguration（classes=…) 以便指定要加载的Spring@Configuration。或者，您可能经常在测试中使用嵌套的@Configuration类。\n在测试Spring Boot应用程序时，这通常是不需要的。Spring Boot的@*Test 注释会在您没有显式定义主配置时自动搜索主配置。\n搜索算法从包含测试的包开始工作，直到找到一个用@SpringBootApplication或@SpringBootConfiguration注释的类。只要您以合理的方式构造代码，通常会找到您的主配置。\n如果要自定义主配置，可以使用嵌套的@TestConfiguration类。与嵌套的@Configuration类（它将用于代替应用程序的主配置）不同，嵌套的@TestConfiguration类将用于应用程序的主要配置。\nSpring的测试框架在测试之间缓存应用程序上下文。因此，只要您的测试共享相同的配置（无论如何发现），加载上下文的潜在耗时过程只会发生一次。\n排除测试配置类 如果您的应用程序使用组件扫描（例如，如果您使用@SpringBootApplication或@ComponentScan），您可能会发现您仅为特定测试创建的顶级配置类会意外地到处出现。\n正如我们前面所看到的，可以在测试的内部类上使用@TestConfiguration来定制主配置。当放置在顶级类上时，@TestConfiguration表示不应通过扫描来拾取src/test/java中的类。然后，您可以在需要的地方显式导入该类，如下例所示：\n@SpringBootTest @Import(MyTestsConfiguration.class) class MyTests { @Test void exampleTest() { // ... } } 使用程序的参数 如果应用程序需要参数，可以让@SpringBootTest使用args属性注入它们。\n@SpringBootTest(args = \u0026#34;--app.test=one\u0026#34;) class MyApplicationArgumentTests { @Test void applicationArgumentsPopulated(@Autowired ApplicationArguments args) { assertThat(args.getOptionNames()).containsOnly(\u0026#34;app.test\u0026#34;); assertThat(args.getOptionValues(\u0026#34;app.test\u0026#34;)).containsOnly(\u0026#34;one\u0026#34;); } } 使用模拟环境进行测试 默认情况下，@SpringBootTest不会启动服务器，而是为测试web端点设置模拟环境。\n使用Spring MVC，我们可以使用MockMvc或WebTestClient查询web端点，如下例所示：\n@SpringBootTest @AutoConfigureMockMvc class MyMockMvcTests { @Test void testWithMockMvc(@Autowired MockMvc mvc) throws Exception { mvc.perform(get(\u0026#34;/\u0026#34;)).andExpect(status().isOk()).andExpect(content().string(\u0026#34;Hello World\u0026#34;)); } // If Spring WebFlux is on the classpath, you can drive MVC tests with a WebTestClient @Test void testWithWebTestClient(@Autowired WebTestClient webClient) { webClient .get().uri(\u0026#34;/\u0026#34;) .exchange() .expectStatus().isOk() .expectBody(String.class).isEqualTo(\u0026#34;Hello World\u0026#34;); } } 如果您只想关注web层而不想启动完整的ApplicationContext，请考虑改用@WebMvcTest。\n对于Spring WebFlux端点，您可以使用WebTestClient，如以下示例所示：\n@SpringBootTest @AutoConfigureWebTestClient class MyMockWebTestClientTests { @Test void exampleTest(@Autowired WebTestClient webClient) { webClient .get().uri(\u0026#34;/\u0026#34;) .exchange() .expectStatus().isOk() .expectBody(String.class).isEqualTo(\u0026#34;Hello World\u0026#34;); } } 创建自动配置 如果您在一家开发共享库的公司工作，您可能希望开发自己的自动配置。自动配置类可以捆绑在外部jar中，由SpringBoot拾取。我们先熟悉自动配置的原理，然后再学习如何创建starter。\n自动配置类 实现自动配置的类用@AutoConfiguration注释。这个注释本身用@Configuration进行元注释，附加的@Conditional注释用于约束何时应用自动配置。通常，自动配置类使用@ConditionalOnClass和@ConditionalOnMissingBean注释。这可以确保只有在用户的@Configuration找不到声明的相关类时，自动配置才适用。下面是spring提供的RestTemplate的自动配置类\n@AutoConfiguration(after = HttpMessageConvertersAutoConfiguration.class) @ConditionalOnClass(RestTemplate.class) @Conditional(NotReactiveWebApplicationCondition.class) public class RestTemplateAutoConfiguration { @Bean @Lazy @ConditionalOnMissingBean public RestTemplateBuilderConfigurer restTemplateBuilderConfigurer( ObjectProvider\u0026lt;HttpMessageConverters\u0026gt; messageConverters, ObjectProvider\u0026lt;RestTemplateCustomizer\u0026gt; restTemplateCustomizers, ObjectProvider\u0026lt;RestTemplateRequestCustomizer\u0026lt;?\u0026gt;\u0026gt; restTemplateRequestCustomizers) { RestTemplateBuilderConfigurer configurer = new RestTemplateBuilderConfigurer(); configurer.setHttpMessageConverters(messageConverters.getIfUnique()); configurer.setRestTemplateCustomizers(restTemplateCustomizers.orderedStream().collect(Collectors.toList())); configurer.setRestTemplateRequestCustomizers( restTemplateRequestCustomizers.orderedStream().collect(Collectors.toList())); return configurer; } @Bean @Lazy @ConditionalOnMissingBean public RestTemplateBuilder restTemplateBuilder(RestTemplateBuilderConfigurer restTemplateBuilderConfigurer) { RestTemplateBuilder builder = new RestTemplateBuilder(); return restTemplateBuilderConfigurer.configure(builder); } static class NotReactiveWebApplicationCondition extends NoneNestedConditions { NotReactiveWebApplicationCondition() { super(ConfigurationPhase.PARSE_CONFIGURATION); } @ConditionalOnWebApplication(type = Type.REACTIVE) private static class ReactiveWebApplication { } } } 定位自动配置类 Spring Boot检查所有的jar是否存在 META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports 文件并读取。该文件列出自动配置类，每行一个类名，如下例所示：\ncom.mycorp.libx.autoconfigure.LibXAutoConfiguration com.mycorp.libx.autoconfigure.LibXWebAutoConfiguration 可以使用#字符添加注释。\n只能通过imports文件中来加载自动配置。确保它们是在特定的包空间中定义的，并且它们永远不是组件扫描的目标。此外，自动配置类不应启用组件扫描来查找其他组件。应改用特定的@Imports。\n自动配置的顺序问题 如果您的配置需要按特定顺序应用，您可以使用@AutoConfiguration注释上的before、beforeName、after和afterName属性，或专用的@AutoConfigureBefore和@AutoConfigureAfter注释。例如上面的RestTemplateAutoConfiguration，需要在HttpMessageConvertersAutoConfiguration之后应用类。\n如果您想排序某些不应该相互直接了解的自动配置，也可以使用@AutoConfigureOrder。该注释与常规@Order注释具有相同的语义，但为自动配置类提供了专用的顺序：\n@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10) public class WebMvcAutoConfiguration { .... } 与标准@Configuration类一样，自动配置类的应用顺序只影响其bean的定义顺序。随后创建这些bean的顺序不受影响，并由每个bean的依赖项和任何@DependsOn关系决定。\n条件注解 您总是希望在自动配置类中包含一个或多个@Conditional注释。@ConditionalOnMissingBean注释是一个常见的示例，它允许开发人员在不满意您的默认值时重写自动配置。\nSpringBoot包含许多@Conditional注释，注释@Configuration类或单个@Bean方法。\nClass Conditions @ConditionalOnClass和@ConditionalOnMissingClass注释允许根据特定类的存在或不存在来包含@Configuration类。由于注释元数据是使用ASM解析的，因此您可以使用value属性来引用真实的类，即使该类实际上可能不会出现在运行的应用程序类路径上。如果希望使用String值指定类名，也可以使用name属性。\n这种机制不适用于返回类型通常是条件目标的@Bean方法：在应用方法的条件之前，JVM将加载类并可能处理方法引用，如果类不存在，这些引用将失败。\n为了处理这种情况，可以使用单独的@Configuration类来隔离条件，如以下示例所示：\n@AutoConfiguration // Some conditions ... public class MyAutoConfiguration { // Auto-configured beans ... @Configuration(proxyBeanMethods = false) @ConditionalOnClass(SomeService.class) public static class SomeServiceConfiguration { @Bean @ConditionalOnMissingBean public SomeService someService() { return new SomeService(); } } } 如果使用@ConditionalOnClass或@Conditional OnMissingClass作为元注释的一部分来组成自己的合成注释，则必须使用名称，因为在这种情况下，引用的类不会被处理。\nBean Conditions @ConditionalOnBean和@Conditional OnMissingBean注释允许根据特定bean的存在或不存在来包含bean。您可以使用value属性按类型指定bean，name属性按名称指定beans。search属性允许您限制搜索bean时应考虑的ApplicationContext层次结构。\n当放置在@Bean方法上时，目标类型默认为该方法的返回类型，如下例所示：\n@AutoConfiguration public class MyAutoConfiguration { @Bean @ConditionalOnMissingBean public SomeService someService() { return new SomeService(); } } 在前面的示例中，如果ApplicationContext中没有someService类型的bean，那么将创建someService bean。\n您需要非常小心添加bean定义的顺序，因为这些条件是根据迄今为止处理的内容进行评估的。因此，我们建议在自动配置类上只使用@ConditionalOnBean和@ConditionalOnMissingBean注释（因为这些注释可以在添加任何用户定义的bean定义后加载）。\n@ConditionalOnBean和@ConditionalOnMissingBean不会阻止创建被@Configuration标注的类。在类级别使用这些条件和用注释标记每个包含的@Bean方法之间的唯一区别是，如果条件不匹配，前者会阻止将@Configuration类注册为Bean。\n在声明@Bean方法时，在方法的返回类型中提供尽可能多的类型信息。例如，如果bean的具体类实现了一个接口，那么bean方法的返回类型应该是具体类，而不是接口。当使用Bean条件时，在@Bean方法中提供尽可能多的类型信息尤其重要，因为它们的求值只能依赖于方法签名中可用的类型信息。\nProperty Conditions @ConditionalOnProperty注释允许基于Spring环境属性包含配置。使用prefix 和name属性指定应检查的属性。默认情况下，匹配任何存在且不等于false的属性。您还可以使用havingValue和matchIfMissing属性创建更高级的检查。\nResource Conditions @ConditionalOnResource注释仅允许在存在特定资源时包含配置。可以使用常见的Spring约定指定资源，如以下示例所示：file:/home/user/test.dat。\nWeb Application Conditions @ConditionalOnWebApplication和@ConditionalOnNotWebApplication注释允许根据应用程序是否为“web应用程序”来包含配置。基于servlet的web应用程序是使用Spring WebApplicationContext、定义会话范围或具有ConfigurableWebEnvironment的任何应用程序。反应式web应用程序是使用ReactiveWebApplicationContext或具有ConfigurableReactiveWeb环境的任何应用程序。\n@ConditionalOnWarDeployment注释允许根据应用程序是否是部署到容器的传统WAR应用程序来包含配置。对于使用嵌入式服务器运行的应用程序，此条件将不匹配。\nSpEL Expression Conditions @ConditionalOnExpression注释允许根据SpEL表达式的结果包含配置。\n在表达式中引用bean将导致该bean在上下文刷新处理中很早就被初始化。因此，bean将无法进行后期处理（如配置属性绑定），其状态可能不完整。\n测试自动配置 自动配置可能受到许多因素的影响：用户配置（@Bean定义和环境）、条件评估（特定库的存在）以及其他因素。具体来说，每个测试都应该创建一个定义良好的ApplicationContext，表示这些定制的组合。ApplicationContextRunner提供了一种很好的实现方法。\nApplicationContextRunner通常定义为测试类的一个字段，用于收集基本的通用配置。以下示例确保始终调用MyServiceAutoConfiguration：\nprivate final ApplicationContextRunner contextRunner = new ApplicationContextRunner() .withConfiguration(AutoConfigurations.of(MyServiceAutoConfiguration.class)); 如果必须定义多个自动配置，则无需对其声明进行排序，因为它们的调用顺序与运行应用程序时的顺序完全相同。\n每个测试都可以使用runner来表示特定的用例。例如，下面的示例调用用户配置（UserConfiguration）并检查自动配置是否正确回退。run方法提供了可与AssertJ一起使用的回调上下文。\n@Test void defaultServiceBacksOff() { this.contextRunner.withUserConfiguration(UserConfiguration.class).run((context) -\u0026gt; { assertThat(context).hasSingleBean(MyService.class); assertThat(context).getBean(\u0026#34;myCustomService\u0026#34;).isSameAs(context.getBean(MyService.class)); }); } @Configuration(proxyBeanMethods = false) static class UserConfiguration { @Bean MyService myCustomService() { return new MyService(\u0026#34;mine\u0026#34;); } } 还可以轻松自定义环境变量，如以下所示：\n@Test void serviceNameCanBeConfigured() { this.contextRunner.withPropertyValues(\u0026#34;user.name=test123\u0026#34;).run((context) -\u0026gt; { assertThat(context).hasSingleBean(MyService.class); assertThat(context.getBean(MyService.class).getName()).isEqualTo(\u0026#34;test123\u0026#34;); }); } runner 还可用于显示ConditionEvaluationReport。报告在INFO或DEBUG级别打印。以下示例显示如何使用ConditionEvaluationReportLoggingListener在自动配置测试中打印报告。\nclass MyConditionEvaluationReportingTests { @Test void autoConfigTest() { new ApplicationContextRunner() .withInitializer(new ConditionEvaluationReportLoggingListener(LogLevel.INFO)) .run((context) -\u0026gt; { // Test something... }); } } 模拟Web上下文 如果需要测试仅在servlet或反应式web应用程序上下文中运行的自动配置，请分别使用WebApplicationContextRunner或ReactiveWebApplicationContext Runner。\n覆盖类路径 还可以测试运行时不存在特定类和/或包时发生的情况。Spring Boot附带了一个FilteredClassLoader，可供runner轻松使用。在下面的示例中，我们断言如果MyService不存在，自动配置将被正确禁用：\n@Test void serviceIsIgnoredIfLibraryIsNotPresent() { this.contextRunner.withClassLoader(new FilteredClassLoader(MyService.class)) .run((context) -\u0026gt; assertThat(context).doesNotHaveBean(\u0026#34;myService\u0026#34;)); } 创建starter 典型的Spring Boot启动器包含用于自动配置和自定义给定技术的基础架构的代码，我们称之为“acme”。为了使其易于扩展，可以将专用命名空间中的许多配置键公开给环境。最后，提供单个“启动器”依赖项，以帮助用户尽可能轻松地入门。\n具体而言，自定义启动器可以包含以下内容：\n包含“acme”自动配置代码的autoconfigure模块。 依赖autoconfigure 模块和其他依赖关系的的starter模块。 如果自动配置相对简单并且没有可选功能，则在starter中合并两个模块绝对是一种选择。\n命名规范 自定义的start格式：acme-spring-boot-starter\n**官方的格式：**spring-boot-starter-web\n配置键 如果starter提供配置键，请为它们使用唯一的命名空间。特别是，不要将键包含在 Spring Boot 使用的命名空间中。\nimport java.time.Duration; import org.springframework.boot.context.properties.ConfigurationProperties; @ConfigurationProperties(\u0026#34;acme\u0026#34;) public class AcmeProperties { /** * Whether to check the location of acme resources. */ private boolean checkLocation = true; /** * Timeout for establishing a connection to the acme server. */ private Duration loginTimeout = Duration.ofSeconds(3); public boolean isCheckLocation() { return this.checkLocation; } public void setCheckLocation(boolean checkLocation) { this.checkLocation = checkLocation; } public Duration getLoginTimeout() { return this.loginTimeout; } public void setLoginTimeout(Duration loginTimeout) { this.loginTimeout = loginTimeout; } } 确保触发元数据（META-INF/spring-configuration-metadata.json）生成，以便 IDE 开启自动提示功能。\nautoconfigure模块 自动配置模块包含库所需的所有内容。它还可能包含配置键定义（如@ConfigurationProperties）和任何可用于进一步自定义组件初始化方式的回调接口。\n应将spring-boot-starter库的依赖项标记为可选，以便更轻松地在项目中包含自动配置模块。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-autoconfigure-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; spring-boot-starter使用注释处理器在元数据文件中收集有关自动配置的条件（META-INF/spring-autoconfigure-metadata.properties）。如果该文件存在，则用于预先筛选不匹配的自动配置，这将缩短启动时间。\norg.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration.AutoConfigureOrder=-2147483648 org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration= org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration.AutoConfigureOrder=-2147483648 org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration= org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration$JacksonConfiguration= org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration$JacksonConfiguration.ConditionalOnClass=com.fasterxml.jackson.databind.ObjectMapper org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration.AutoConfigureAfter=org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration.ConditionalOnClass=com.couchbase.client.java.Cluster dependencies { annotationProcessor \u0026#34;org.springframework.boot:spring-boot-autoconfigure-processor\u0026#34; } starter模块 starter是一个空jar。它的唯一目的是提供必要的依赖项来使用库。\n","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-boot-core/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669984926,"title":"Spring-Boot-Core"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"ObjectMapper 基本使用 public class Car { private String color; private String type; // standard getters setters } 序列化:\nObjectMapper objectMapper = new ObjectMapper(); Car car = new Car(\u0026#34;yellow\u0026#34;, \u0026#34;renault\u0026#34;); objectMapper.writeValue(new File(\u0026#34;target/car.json\u0026#34;), car); {\u0026#34;color\u0026#34;:\u0026#34;yellow\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;renault\u0026#34;} ObjectMapper类的writeValueAsString和writeValueAsBytes方法从Java对象生成JSON，并将生成的JSON作为字符串或字节数组返回：\nString carAsString = objectMapper.writeValueAsString(car); 反序列化：\nString json = \u0026#34;{ \\\u0026#34;color\\\u0026#34; : \\\u0026#34;Black\\\u0026#34;, \\\u0026#34;type\\\u0026#34; : \\\u0026#34;BMW\\\u0026#34; }\u0026#34;; Car car = objectMapper.readValue(json, Car.class);\treadValue函数还接受其他形式的输入，例如包含JSON字符串的文件：\nCar car = objectMapper.readValue(new File(\u0026#34;src/test/resources/json_car.json\u0026#34;), Car.class); 或者从URL中：\nCar car = objectMapper.readValue(new URL(\u0026#34;file:src/test/resources/json_car.json\u0026#34;), Car.class); JsonNode：json的表示对象 或者，可以将JSON解析为JsonNode对象，并用于从特定节点检索数据：\nString json = \u0026#34;{ \\\u0026#34;color\\\u0026#34; : \\\u0026#34;Black\\\u0026#34;, \\\u0026#34;type\\\u0026#34; : \\\u0026#34;FIAT\\\u0026#34; }\u0026#34;; JsonNode jsonNode = objectMapper.readTree(json); String color = jsonNode.get(\u0026#34;color\u0026#34;).asText(); // Output: color -\u0026gt; Black 更低层次的转换：\n@Test public void givenUsingLowLevelApi_whenParsingJsonStringIntoJsonNode_thenCorrect() throws JsonParseException, IOException { String jsonString = \u0026#34;{\u0026#34;k1\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;k2\u0026#34;:\u0026#34;v2\u0026#34;}\u0026#34;; ObjectMapper mapper = new ObjectMapper(); JsonFactory factory = mapper.getFactory(); JsonParser parser = factory.createParser(jsonString); JsonNode actualObj = mapper.readTree(parser); assertNotNull(actualObj); } 转换成集合类型 我们可以使用TypeReference将数组形式的JSON解析为Java对象列表：\nString jsonCarArray = \u0026#34;[{ \\\u0026#34;color\\\u0026#34; : \\\u0026#34;Black\\\u0026#34;, \\\u0026#34;type\\\u0026#34; : \\\u0026#34;BMW\\\u0026#34; }, { \\\u0026#34;color\\\u0026#34; : \\\u0026#34;Red\\\u0026#34;, \\\u0026#34;type\\\u0026#34; : \\\u0026#34;FIAT\\\u0026#34; }]\u0026#34;; List\u0026lt;Car\u0026gt; listCar = objectMapper.readValue(jsonCarArray, new TypeReference\u0026lt;List\u0026lt;Car\u0026gt;\u0026gt;(){}); String jsonCarArray = \u0026#34;[{ \\\u0026#34;color\\\u0026#34; : \\\u0026#34;Black\\\u0026#34;, \\\u0026#34;type\\\u0026#34; : \\\u0026#34;BMW\\\u0026#34; }, { \\\u0026#34;color\\\u0026#34; : \\\u0026#34;Red\\\u0026#34;, \\\u0026#34;type\\\u0026#34; : \\\u0026#34;FIAT\\\u0026#34; }]\u0026#34;; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.configure(DeserializationFeature.USE_JAVA_ARRAY_FOR_JSON_ARRAY, true); Car[] cars = objectMapper.readValue(jsonCarArray, Car[].class); // print cars 类似地，我们可以将JSON解析为Java Map：\nString json = \u0026#34;{ \\\u0026#34;color\\\u0026#34; : \\\u0026#34;Black\\\u0026#34;, \\\u0026#34;type\\\u0026#34; : \\\u0026#34;BMW\\\u0026#34; }\u0026#34;; Map\u0026lt;String, Object\u0026gt; map = objectMapper.readValue(json, new TypeReference\u0026lt;Map\u0026lt;String,Object\u0026gt;\u0026gt;(){}); 注解 常规注解 @JsonProperty 我们可以添加@JsonProperty注释，表示JSON中的属性名称。\npublic class MyBean { public int id; private String name; @JsonProperty(\u0026#34;name\u0026#34;) public void setTheName(String name) { this.name = name; } @JsonProperty(\u0026#34;name\u0026#34;) public String getTheName() { return name; } } @Test public void whenUsingJsonProperty_thenCorrect() throws IOException { MyBean bean = new MyBean(1, \u0026#34;My bean\u0026#34;); String result = new ObjectMapper().writeValueAsString(bean); assertThat(result, containsString(\u0026#34;My bean\u0026#34;)); assertThat(result, containsString(\u0026#34;1\u0026#34;)); MyBean resultBean = new ObjectMapper() .readerFor(MyBean.class) .readValue(result); assertEquals(\u0026#34;My bean\u0026#34;, resultBean.getTheName()); } @JsonFormat @JsonFormat注释指定序列化日期/时间值时的格式。\npublic class EventWithFormat { public String name; @JsonFormat( shape = JsonFormat.Shape.STRING, pattern = \u0026#34;dd-MM-yyyy hh:mm:ss\u0026#34;) public Date eventDate; } @Test public void whenSerializingUsingJsonFormat_thenCorrect() throws JsonProcessingException, ParseException { SimpleDateFormat df = new SimpleDateFormat(\u0026#34;dd-MM-yyyy hh:mm:ss\u0026#34;); df.setTimeZone(TimeZone.getTimeZone(\u0026#34;UTC\u0026#34;)); String toParse = \u0026#34;20-12-2014 02:30:00\u0026#34;; Date date = df.parse(toParse); EventWithFormat event = new EventWithFormat(\u0026#34;party\u0026#34;, date); String result = new ObjectMapper().writeValueAsString(event); assertThat(result, containsString(toParse)); } @JsonUnwrapped @JsonUnwrapped定义了序列化/反序列化时应展开/展平的值。\npublic class UnwrappedUser { public int id; @JsonUnwrapped public Name name; public static class Name { public String firstName; public String lastName; } } @Test public void whenSerializingUsingJsonUnwrapped_thenCorrect() throws JsonProcessingException, ParseException { UnwrappedUser.Name name = new UnwrappedUser.Name(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); UnwrappedUser user = new UnwrappedUser(1, name); String result = new ObjectMapper().writeValueAsString(user); assertThat(result, containsString(\u0026#34;John\u0026#34;)); assertThat(result, not(containsString(\u0026#34;name\u0026#34;))); } { \u0026#34;id\u0026#34;:1, \u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34; } @JsonView @JsonView指示将在其中包含属性以进行序列化/反序列化的视图。\npublic class Views { public static class Public {} public static class Internal extends Public {} } public class Item { @JsonView(Views.Public.class) public int id; @JsonView(Views.Public.class) public String itemName; @JsonView(Views.Internal.class) public String ownerName; } @Test public void whenSerializingUsingJsonView_thenCorrect() throws JsonProcessingException { Item item = new Item(2, \u0026#34;book\u0026#34;, \u0026#34;John\u0026#34;); String result = new ObjectMapper() .writerWithView(Views.Public.class) .writeValueAsString(item); assertThat(result, containsString(\u0026#34;book\u0026#34;)); assertThat(result, containsString(\u0026#34;2\u0026#34;)); assertThat(result, not(containsString(\u0026#34;John\u0026#34;))); } @JsonManagedReference, @JsonBackReference @JsonManagedReference和@JsonBackReference注释可以处理父/子关系并处理循环依赖。\npublic class ItemWithRef { public int id; public String itemName; @JsonManagedReference public UserWithRef owner; } public class UserWithRef { public int id; public String name; @JsonBackReference public List\u0026lt;ItemWithRef\u0026gt; userItems; } @Test public void whenSerializingUsingJacksonReferenceAnnotation_thenCorrect() throws JsonProcessingException { UserWithRef user = new UserWithRef(1, \u0026#34;John\u0026#34;); ItemWithRef item = new ItemWithRef(2, \u0026#34;book\u0026#34;, user); user.addItem(item); String result = new ObjectMapper().writeValueAsString(item); assertThat(result, containsString(\u0026#34;book\u0026#34;)); assertThat(result, containsString(\u0026#34;John\u0026#34;)); assertThat(result, not(containsString(\u0026#34;userItems\u0026#34;))); } {\u0026#34;id\u0026#34;:2,\u0026#34;itemName\u0026#34;:\u0026#34;book\u0026#34;,\u0026#34;owner\u0026#34;:{\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;zzq\u0026#34;}} {\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;zzq\u0026#34;} @JsonIdentityInfo @JsonIdentityInfo指出在序列化/反序列化值时应该使用对象标识，例如在处理无限递归类型的问题时。\n@JsonIdentityInfo( generator = ObjectIdGenerators.PropertyGenerator.class, property = \u0026#34;id\u0026#34;) public class ItemWithIdentity { public int id; public String itemName; public UserWithIdentity owner; } @JsonIdentityInfo( generator = ObjectIdGenerators.PropertyGenerator.class, property = \u0026#34;id\u0026#34;) public class UserWithIdentity { public int id; public String name; public List\u0026lt;ItemWithIdentity\u0026gt; userItems; } @Test public void whenSerializingUsingJsonIdentityInfo_thenCorrect() throws JsonProcessingException { UserWithIdentity user = new UserWithIdentity(1, \u0026#34;John\u0026#34;); ItemWithIdentity item = new ItemWithIdentity(2, \u0026#34;book\u0026#34;, user); user.addItem(item); String result = new ObjectMapper().writeValueAsString(item); assertThat(result, containsString(\u0026#34;book\u0026#34;)); assertThat(result, containsString(\u0026#34;John\u0026#34;)); assertThat(result, containsString(\u0026#34;userItems\u0026#34;)); } { \u0026#34;id\u0026#34;: 2, \u0026#34;itemName\u0026#34;: \u0026#34;book\u0026#34;, \u0026#34;owner\u0026#34;: { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;userItems\u0026#34;: [ 2 ] } } @JsonFilter @JsonFilter注释指定了在序列化过程中使用的过滤器。\n@JsonFilter(\u0026#34;myFilter\u0026#34;) public class BeanWithFilter { public int id; public String name; } @Test public void whenSerializingUsingJsonFilter_thenCorrect() throws JsonProcessingException { BeanWithFilter bean = new BeanWithFilter(1, \u0026#34;My bean\u0026#34;); FilterProvider filters = new SimpleFilterProvider().addFilter( \u0026#34;myFilter\u0026#34;, SimpleBeanPropertyFilter.filterOutAllExcept(\u0026#34;name\u0026#34;)); String result = new ObjectMapper() .writer(filters) .writeValueAsString(bean); assertThat(result, containsString(\u0026#34;My bean\u0026#34;)); assertThat(result, not(containsString(\u0026#34;id\u0026#34;))); } 序列化 @JsonAnyGetter @JsonAnyGetter允许灵活使用Map字段作为标准属性。\npublic class User { private String name; private Map\u0026lt;String, Object\u0026gt; others; } User user = new User(); user.setName(\u0026#34;zzq\u0026#34;); user.setOthers(Map.of(\u0026#34;age\u0026#34;, 12, \u0026#34;height\u0026#34;, 178)); String s = objectMapper.writeValueAsString(user); System.err.println(s); {\u0026#34;name\u0026#34;:\u0026#34;zzq\u0026#34;,\u0026#34;others\u0026#34;:{\u0026#34;age\u0026#34;:12,\u0026#34;height\u0026#34;:178}} @JsonGetter @JsonGetter注释是@JsonProperty注释的替代，将方法标记为getter方法。\npublic class MyBean { public int id; private String name; @JsonGetter(\u0026#34;name\u0026#34;) public String getTheName() { return name; } } MyBean bean = new MyBean(); bean.setName(\u0026#34;zzq\u0026#34;); bean.setId(1); String s = objectMapper.writeValueAsString(bean); System.err.println(s); {\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;zzq\u0026#34;} @JsonPropertyOrder 我们可以使用@JsonPropertyOrder注释来指定序列化时属性的顺序。\n@JsonPropertyOrder({ \u0026#34;name\u0026#34;, \u0026#34;id\u0026#34; }) public class MyBean { public int id; public String name; } MyBean bean = new MyBean(); bean.setName(\u0026#34;zzq\u0026#34;); bean.setId(1); String s = objectMapper.writeValueAsString(bean); System.err.println(s); {\u0026#34;name\u0026#34;:\u0026#34;zzq\u0026#34;,\u0026#34;id\u0026#34;:1} @JsonRawValue @JsonRawValue注释可以指示Jackson按原样序列化属性。\n在下面的示例中，我们使用@JsonRawValue嵌入一些自定义JSON作为实体s属性的值：\npublic class RawBean { public String name; @JsonRawValue public String json; } RawBean bean=new RawBean(); bean.setName(\u0026#34;zzq\u0026#34;); bean.setJson(\u0026#34;{\\\u0026#34;age\\\u0026#34;:33}\u0026#34;); String s = objectMapper.writeValueAsString(bean); System.err.println(s); {\u0026#34;name\u0026#34;:\u0026#34;zzq\u0026#34;,\u0026#34;json\u0026#34;:{\u0026#34;age\u0026#34;:33}} @JsonValue @JsonValue使用标注的方法序列化整个实例。例如，在枚举中，我们用@JsonValue注释getName，以便通过其名称序列化任何这样的实体：\npublic enum TypeEnumWithValue { TYPE1(1, \u0026#34;Type A\u0026#34;), TYPE2(2, \u0026#34;Type 2\u0026#34;); private Integer id; private String name; TypeEnumWithValue(int i, String s) { this.id = i; this.name = s; } @JsonValue public String getName() { return name; } } String s = objectMapper.writeValueAsString(TypeEnumWithValue.TYPE1); System.err.println(s); \u0026#34;Type A\u0026#34; @JsonRootName 如果启用了包装，则使用@JsonRootName注释来指定要使用的根包装的名称。\n@JsonRootName(value = \u0026#34;user\u0026#34;) public class MyBean { public int id; private String name; } objectMapper.enable(SerializationFeature.WRAP_ROOT_VALUE); MyBean bean = new MyBean(); bean.setName(\u0026#34;zzq\u0026#34;); bean.setId(1); String s = objectMapper.writeValueAsString(bean); System.err.println(s); {\u0026#34;user\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;zzq\u0026#34;,\u0026#34;id\u0026#34;:1}} @JsonSerialize @JsonSerialize指示编组实体时要使用的自定义序列化程序。\npublic class EventWithSerializer { public String name; @JsonSerialize(using = CustomDateSerializer.class) public Date eventDate; } public class CustomDateSerializer extends StdSerializer\u0026lt;Date\u0026gt; { private static SimpleDateFormat formatter = new SimpleDateFormat(\u0026#34;dd-MM-yyyy hh:mm:ss\u0026#34;); public CustomDateSerializer() { this(null); } public CustomDateSerializer(Class\u0026lt;Date\u0026gt; t) { super(t); } @Override public void serialize( Date value, JsonGenerator gen, SerializerProvider arg2) throws IOException, JsonProcessingException { gen.writeString(formatter.format(value)); } } @Test public void whenSerializingUsingJsonSerialize_thenCorrect() throws JsonProcessingException, ParseException { SimpleDateFormat df = new SimpleDateFormat(\u0026#34;dd-MM-yyyy hh:mm:ss\u0026#34;); String toParse = \u0026#34;20-12-2014 02:30:00\u0026#34;; Date date = df.parse(toParse); EventWithSerializer event = new EventWithSerializer(\u0026#34;party\u0026#34;, date); String result = new ObjectMapper().writeValueAsString(event); assertThat(result, containsString(toParse)); } 反序列化 @JsonCreator 我们可以使用@JsonCreator注释来调整反序列化中使用的构造函数或构造工厂。当我们需要反序列化与我们需要获取的目标实体不完全匹配的JSON时，这非常有用。\n让我们看一个例子。假设我们需要反序列化以下JSON：\n{ \u0026#34;id\u0026#34;:1, \u0026#34;theName\u0026#34;:\u0026#34;My bean\u0026#34; } 目标实体中没有theName 字段。只有name 字段。 现在我们不想改变实体本身，我们只需要用@JsonCreator注释构造函数，并使用@JsonProperty注释来对解组过程进行更多的控制：\npublic class BeanWithCreator { public int id; public String name; @JsonCreator public BeanWithCreator( @JsonProperty(\u0026#34;id\u0026#34;) int id, @JsonProperty(\u0026#34;theName\u0026#34;) String name) { this.id = id; this.name = name; } } @JacksonInject @JacksonInject表示属性将从注入而不是从JSON数据中获取其值。\n在下面的示例中，我们使用@JacksonInject注入属性id：\npublic class BeanWithInject { @JacksonInject public int id; public String name; } @Test public void whenDeserializingUsingJsonInject_thenCorrect() throws IOException { String json = \u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;My bean\\\u0026#34;}\u0026#34;; InjectableValues inject = new InjectableValues.Std() .addValue(int.class, 1); BeanWithInject bean = new ObjectMapper().reader(inject) .forType(BeanWithInject.class) .readValue(json); assertEquals(\u0026#34;My bean\u0026#34;, bean.name); assertEquals(1, bean.id); } @JsonAnySetter @JsonAnySetter允许我们灵活地使用Map作为标准属性。在反序列化时，JSON中的没有匹配的属性将简单地添加到Map中。\npublic class ExtendableBean { public String name; private Map\u0026lt;String, String\u0026gt; properties; @JsonAnySetter public void add(String key, String value) { properties.put(key, value); } } @Test public void whenDeserializingUsingJsonAnySetter_thenCorrect() throws IOException { String json = \u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;My bean\\\u0026#34;,\\\u0026#34;attr2\\\u0026#34;:\\\u0026#34;val2\\\u0026#34;,\\\u0026#34;attr1\\\u0026#34;:\\\u0026#34;val1\\\u0026#34;}\u0026#34;; ExtendableBean bean = new ObjectMapper() .readerFor(ExtendableBean.class) .readValue(json); assertEquals(\u0026#34;My bean\u0026#34;, bean.name); assertEquals(\u0026#34;val2\u0026#34;, bean.getProperties().get(\u0026#34;attr2\u0026#34;)); } @JsonSetter @JsonSetter是@JsonProperty的替代方法，它将该方法标记为setter方法。\n当我们需要读取一些JSON数据时，这非常有用，目标实体类与该数据不完全匹配，因此我们需要调整流程以使其适合。\npublic class MyBean { public int id; private String name; @JsonSetter(\u0026#34;name\u0026#34;) public void setTheName(String name) { this.name = name; } } @Test public void whenDeserializingUsingJsonSetter_thenCorrect() throws IOException { String json = \u0026#34;{\\\u0026#34;id\\\u0026#34;:1,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;My bean\\\u0026#34;}\u0026#34;; MyBean bean = new ObjectMapper() .readerFor(MyBean.class) .readValue(json); assertEquals(\u0026#34;My bean\u0026#34;, bean.getTheName()); } @JsonDeserialize @JsonDeserialize表示使用自定义反序列化程序。\npublic class EventWithSerializer { public String name; @JsonDeserialize(using = CustomDateDeserializer.class) public Date eventDate; } public class CustomDateDeserializer extends StdDeserializer\u0026lt;Date\u0026gt; { private static SimpleDateFormat formatter = new SimpleDateFormat(\u0026#34;dd-MM-yyyy hh:mm:ss\u0026#34;); public CustomDateDeserializer() { this(null); } public CustomDateDeserializer(Class\u0026lt;?\u0026gt; vc) { super(vc); } @Override public Date deserialize( JsonParser jsonparser, DeserializationContext context) throws IOException { String date = jsonparser.getText(); try { return formatter.parse(date); } catch (ParseException e) { throw new RuntimeException(e); } } } @Test public void whenDeserializingUsingJsonDeserialize_thenCorrect() throws IOException { String json = \u0026#34;{\u0026#34;name\u0026#34;:\u0026#34;party\u0026#34;,\u0026#34;eventDate\u0026#34;:\u0026#34;20-12-2014 02:30:00\u0026#34;}\u0026#34;; SimpleDateFormat df = new SimpleDateFormat(\u0026#34;dd-MM-yyyy hh:mm:ss\u0026#34;); EventWithSerializer event = new ObjectMapper() .readerFor(EventWithSerializer.class) .readValue(json); assertEquals( \u0026#34;20-12-2014 02:30:00\u0026#34;, df.format(event.eventDate)); } @JsonAlias @JsonAlias在反序列化期间为属性定义了一个或多个备选名称。\npublic class AliasBean { @JsonAlias({ \u0026#34;fName\u0026#34;, \u0026#34;f_name\u0026#34; }) private String firstName; private String lastName; } 这里我们有一个POJO，我们想将带有fName、f_name和firstName等值的JSON反序列化到POJO的firstName变量中。\n@Test public void whenDeserializingUsingJsonAlias_thenCorrect() throws IOException { String json = \u0026#34;{\\\u0026#34;fName\\\u0026#34;: \\\u0026#34;John\\\u0026#34;, \\\u0026#34;lastName\\\u0026#34;: \\\u0026#34;Green\\\u0026#34;}\u0026#34;; AliasBean aliasBean = new ObjectMapper().readerFor(AliasBean.class).readValue(json); assertEquals(\u0026#34;John\u0026#34;, aliasBean.getFirstName()); } 包含 @JsonIgnoreProperties @JsonIgnoreProperties是一个类级注释，用于标记忽略的属性或属性列表。序列化和反序列化都支持\n@JsonIgnoreProperties({ \u0026#34;id\u0026#34; }) public class BeanWithIgnore { public int id; public String name; } @Test public void whenSerializingUsingJsonIgnoreProperties_thenCorrect() throws JsonProcessingException { BeanWithIgnore bean = new BeanWithIgnore(1, \u0026#34;My bean\u0026#34;); String result = new ObjectMapper() .writeValueAsString(bean); assertThat(result, containsString(\u0026#34;My bean\u0026#34;)); assertThat(result, not(containsString(\u0026#34;id\u0026#34;))); } 忽略JSON输入中的任何未知属性，我们可以设置@JsonIgnoreProperties注释的ignoreUnknown=true。\n@JsonIgnore @JsonIgnore注释用于在字段级别标记要忽略的属性。序列化和反序列化都支持\npublic class BeanWithIgnore { @JsonIgnore public int id; public String name; } @Test public void whenSerializingUsingJsonIgnore_thenCorrect() throws JsonProcessingException { BeanWithIgnore bean = new BeanWithIgnore(1, \u0026#34;My bean\u0026#34;); String result = new ObjectMapper() .writeValueAsString(bean); assertThat(result, containsString(\u0026#34;My bean\u0026#34;)); assertThat(result, not(containsString(\u0026#34;id\u0026#34;))); } @JsonIgnoreType @JsonIgnoreType将注释类型的所有属性标记为忽略。序列化和反序列化都支持\npublic class User { public int id; public Name name; @JsonIgnoreType public static class Name { public String firstName; public String lastName; } } @Test public void whenSerializingUsingJsonIgnoreType_thenCorrect() throws JsonProcessingException, ParseException { User.Name name = new User.Name(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;); User user = new User(1, name); String result = new ObjectMapper() .writeValueAsString(user); assertThat(result, containsString(\u0026#34;1\u0026#34;)); assertThat(result, not(containsString(\u0026#34;name\u0026#34;))); assertThat(result, not(containsString(\u0026#34;John\u0026#34;))); } @JsonInclude 我们可以使用@JsonInclude排除具有空/null/default值的属性。\n@JsonInclude(Include.NON_NULL) public class MyBean { public int id; public String name; } public void whenSerializingUsingJsonInclude_thenCorrect() throws JsonProcessingException { MyBean bean = new MyBean(1, null); String result = new ObjectMapper() .writeValueAsString(bean); assertThat(result, containsString(\u0026#34;1\u0026#34;)); assertThat(result, not(containsString(\u0026#34;name\u0026#34;))); } @JsonAutoDetect @JsonAutoDetect可以覆盖哪些属性可见，哪些属性不可见的默认语义。\n@JsonAutoDetect(fieldVisibility = Visibility.ANY) public class PrivateBean { private int id; private String name; } @Test public void whenSerializingUsingJsonAutoDetect_thenCorrect() throws JsonProcessingException { PrivateBean bean = new PrivateBean(1, \u0026#34;My bean\u0026#34;); String result = new ObjectMapper() .writeValueAsString(bean); assertThat(result, containsString(\u0026#34;1\u0026#34;)); assertThat(result, containsString(\u0026#34;My bean\u0026#34;)); } 多态 @JsonTypeInfo–指示要在序列化中包含的类型信息的详细信息 @JsonSubTypes–指示带注释类型的子类型 @JsonTypeName–定义用于带注释类的逻辑类型名称 public class Zoo { public Animal animal; @JsonTypeInfo( use = JsonTypeInfo.Id.NAME, include = As.PROPERTY, property = \u0026#34;type\u0026#34;) @JsonSubTypes({ @JsonSubTypes.Type(value = Dog.class, name = \u0026#34;dog\u0026#34;), @JsonSubTypes.Type(value = Cat.class, name = \u0026#34;cat\u0026#34;) }) public static class Animal { public String name; } @JsonTypeName(\u0026#34;dog\u0026#34;) public static class Dog extends Animal { public double barkVolume; } @JsonTypeName(\u0026#34;cat\u0026#34;) public static class Cat extends Animal { boolean likesCream; public int lives; } } @Test public void whenSerializingPolymorphic_thenCorrect() throws JsonProcessingException { Zoo.Dog dog = new Zoo.Dog(\u0026#34;lacy\u0026#34;); Zoo zoo = new Zoo(dog); String result = new ObjectMapper() .writeValueAsString(zoo); assertThat(result, containsString(\u0026#34;type\u0026#34;)); assertThat(result, containsString(\u0026#34;dog\u0026#34;)); } 以下是使用Dog序列化Zoo实例的结果：\n{ \u0026#34;animal\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;dog\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;lacy\u0026#34;, \u0026#34;barkVolume\u0026#34;: 0 } } 现在进行反序列化。让我们从以下JSON输入开始：\n{ \u0026#34;animal\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;lacy\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;cat\u0026#34; } } @Test public void whenDeserializingPolymorphic_thenCorrect() throws IOException { String json = \u0026#34;{\\\u0026#34;animal\\\u0026#34;:{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;lacy\\\u0026#34;,\\\u0026#34;type\\\u0026#34;:\\\u0026#34;cat\\\u0026#34;}}\u0026#34;; Zoo zoo = new ObjectMapper() .readerFor(Zoo.class) .readValue(json); assertEquals(\u0026#34;lacy\u0026#34;, zoo.animal.name); assertEquals(Zoo.Cat.class, zoo.animal.getClass()); } 自定义注解 接下来，让我们看看如何创建自定义Jackson注释。我们可以使用@JacksonAnnotationsInside注释：\n@Retention(RetentionPolicy.RUNTIME) @JacksonAnnotationsInside @JsonInclude(Include.NON_NULL) @JsonPropertyOrder({ \u0026#34;name\u0026#34;, \u0026#34;id\u0026#34;, \u0026#34;dateCreated\u0026#34; }) public @interface CustomAnnotation {} 现在，如果我们在实体上使用新注释：\n@CustomAnnotation public class BeanWithCustomAnnotation { public int id; public String name; public Date dateCreated; } 我们可以看到它如何将现有注释组合成一个简单的自定义注释，我们可以将其用作速记：\n@Test public void whenSerializingUsingCustomAnnotation_thenCorrect() throws JsonProcessingException { BeanWithCustomAnnotation bean = new BeanWithCustomAnnotation(1, \u0026#34;My bean\u0026#34;, null); String result = new ObjectMapper().writeValueAsString(bean); assertThat(result, containsString(\u0026#34;My bean\u0026#34;)); assertThat(result, containsString(\u0026#34;1\u0026#34;)); assertThat(result, not(containsString(\u0026#34;dateCreated\u0026#34;))); } { \u0026#34;name\u0026#34;:\u0026#34;My bean\u0026#34;, \u0026#34;id\u0026#34;:1 } 混入 我们使用MixIn注释忽略User类型的属性：\npublic class Item { public int id; public String itemName; public User owner; } @JsonIgnoreType public class MyMixInForIgnoreType {} @Test public void whenSerializingUsingMixInAnnotation_thenCorrect() throws JsonProcessingException { Item item = new Item(1, \u0026#34;book\u0026#34;, null); String result = new ObjectMapper().writeValueAsString(item); assertThat(result, containsString(\u0026#34;owner\u0026#34;)); ObjectMapper mapper = new ObjectMapper(); mapper.addMixIn(User.class, MyMixInForIgnoreType.class); result = mapper.writeValueAsString(item); assertThat(result, not(containsString(\u0026#34;owner\u0026#34;))); } 其他 @JsonIdentityReference @JsonIdentityReference用于自定义对对象的引用，这些对象将序列化为对象标识，而不是完整的POJO。它与@JsonIdentityInfo协作，强制在每次序列化中使用对象标识，这与除了第一次缺少@JsonIdentityReference之外的所有序列化不同。当处理对象之间的循环依赖关系时，这两个注释非常有用。\n为了演示使用@JsonIdentityReference，我们将定义两个不同的bean类，不使用和使用该注释。\n@JsonIdentityInfo(generator = ObjectIdGenerators.PropertyGenerator.class, property = \u0026#34;id\u0026#34;) public class BeanWithoutIdentityReference { private int id; private String name; // constructor, getters and setters } BeanWithoutIdentityReference bean = new BeanWithoutIdentityReference(1, \u0026#34;Bean Without Identity Reference Annotation\u0026#34;); String jsonString = mapper.writeValueAsString(bean); { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Bean Without Identity Reference Annotation\u0026#34; } @JsonIdentityInfo(generator = ObjectIdGenerators.PropertyGenerator.class, property = \u0026#34;id\u0026#34;) @JsonIdentityReference(alwaysAsId = true) public class BeanWithIdentityReference { private int id; private String name; // constructor, getters and setters } BeanWithIdentityReference bean = new BeanWithIdentityReference(1, \u0026#34;Bean With Identity Reference Annotation\u0026#34;); String jsonString = mapper.writeValueAsString(bean); assertEquals(\u0026#34;1\u0026#34;, jsonString); @JsonAppend 当对象序列化时，@JsonAppend注释用于将虚拟属性添加到对象中，而不是常规属性。当我们想将补充信息直接添加到JSON字符串中，而不是更改类定义时，这是必要的。例如，将bean的版本元数据插入相应的JSON文档可能比为其提供附加属性更方便。\n假设我们有一个没有@JsonAppend的bean，如下所示：\npublic class BeanWithoutAppend { private int id; private String name; // constructor, getters and setters } 测试将确认，在缺少@JsonAppend注释的情况下，序列化输出不包含关于补充版本属性的信息，尽管我们试图将其添加到ObjectWriter对象：\nBeanWithoutAppend bean = new BeanWithoutAppend(2, \u0026#34;Bean Without Append Annotation\u0026#34;); ObjectWriter writer = mapper.writerFor(BeanWithoutAppend.class).withAttribute(\u0026#34;version\u0026#34;, \u0026#34;1.0\u0026#34;); String jsonString = writer.writeValueAsString(bean); { \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;Bean Without Append Annotation\u0026#34; } 现在，假设我们有一个用@JsonAppend注释的bean：\n@JsonAppend(attrs = { @JsonAppend.Attr(value = \u0026#34;version\u0026#34;) }) public class BeanWithAppend { private int id; private String name; // constructor, getters and setters } 与前一个类似的测试将验证当应用@JsonAppend注释时，在序列化后是否包含补充属性：\nBeanWithAppend bean = new BeanWithAppend(2, \u0026#34;Bean With Append Annotation\u0026#34;); ObjectWriter writer = mapper.writerFor(BeanWithAppend.class).withAttribute(\u0026#34;version\u0026#34;, \u0026#34;1.0\u0026#34;); String jsonString = writer.writeValueAsString(bean); 该序列化的输出显示已添加版本属性：\n{ \u0026#34;id\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;Bean With Append Annotation\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0\u0026#34; } @JsonNaming @JsonNaming注释用于选择序列化中属性的命名策略，覆盖默认值。使用value元素，我们可以指定任何策略，包括自定义策略。\n除了默认值LOWER_CAMEL_CASE之外，Jackson库还为我们提供了其他四种内置属性命名策略：\nKEBAB_CASE：名称元素用连字符(-)隔开，例如kebab-case.。 LOWER_CASE：所有字母都是小写，没有分隔符，例如小写。 SNAKE_CASE：所有字母均为小写，名称元素之间用下划线分隔，例如SNAKE_CASE。 UPPER_CAMEL_CASE：所有名称元素，包括第一个，都以大写字母开头，后跟小写字母，并且没有分隔符，例如UpperCamelCase。 此示例将说明使用sSNAKE_CASE 名称序列化属性的方法，其中名为beanName的属性被序列化为bean_name。\n@JsonNaming(PropertyNamingStrategies.SnakeCaseStrategy.class) public class NamingBean { private int id; private String beanName; // constructor, getters and setters } NamingBean bean = new NamingBean(3, \u0026#34;Naming Bean\u0026#34;); String jsonString = mapper.writeValueAsString(bean); assertThat(jsonString, containsString(\u0026#34;bean_name\u0026#34;)); { \u0026#34;id\u0026#34;: 3, \u0026#34;bean_name\u0026#34;: \u0026#34;Naming Bean\u0026#34; } @JsonPropertyDescription Jackson库能够在名为JSON schema的单独模块的帮助下为Java类型创建JSON模式。当我们希望在序列化Java对象时指定预期输出，或者在反序列化之前验证JSON文档时，该模式非常有用。\n@JsonPropertyDescription注释允许通过提供描述字段将人类可读的描述添加到创建的JSON模式中。\n本节使用下面声明的bean来演示@JsonPropertyDescription的功能：\npublic class PropertyDescriptionBean { private int id; @JsonPropertyDescription(\u0026#34;This is a description of the name property\u0026#34;) private String name; // getters and setters } 通过添加描述字段生成JSON模式的方法如下所示：\nSchemaFactoryWrapper wrapper = new SchemaFactoryWrapper(); mapper.acceptJsonFormatVisitor(PropertyDescriptionBean.class, wrapper); JsonSchema jsonSchema = wrapper.finalSchema(); String jsonString = mapper.writeValueAsString(jsonSchema); assertThat(jsonString, containsString(\u0026#34;This is a description of the name property\u0026#34;)); 如我们所见，JSON模式的生成是成功的：\n{ \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;urn:jsonschema:com:baeldung:jackson:annotation:extra:PropertyDescriptionBean\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;This is a description of the name property\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; } } } @JsonPOJOBuilder @JsonPOJOBuider注释用于配置构建器类，以便在命名约定与默认约定不同时自定义JSON文档的反序列化以恢复POJO。\n假设我们需要反序列化以下JSON字符串：\n{ \u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;POJO Builder Bean\u0026#34; } 该JSON源将用于创建POJOBuilderBean的实例：\n@JsonDeserialize(builder = BeanBuilder.class) public class POJOBuilderBean { private int identity; private String beanName; // constructor, getters and setters } bean属性的名称与JSON字符串中字段的名称不同。这就是@JsonPOJOBuider前来救援的地方。\n@JsonPOJOBuider注释附带两个属性：\nbuildMethodName: 将JSON字段绑定到预期bean的属性后，用于实例化该bean的无参数方法的名称。默认名称为build。 withPrefix: 用于自动检测JSON和bean属性之间匹配的名称前缀。默认前缀为with。 @JsonPOJOBuilder(buildMethodName = \u0026#34;createBean\u0026#34;, withPrefix = \u0026#34;construct\u0026#34;) public class BeanBuilder { private int idValue; private String nameValue; public BeanBuilder constructId(int id) { idValue = id; return this; } public BeanBuilder constructName(String name) { nameValue = name; return this; } public POJOBuilderBean createBean() { return new POJOBuilderBean(idValue, nameValue); } } 在上面的代码中，我们配置了@JsonPOJOBuilder以使用名为createBean的构建方法和匹配属性的构造前缀。\n@JsonPOJOBuilder对bean的应用程序描述和测试如下：\nString jsonString = \u0026#34;{\\\u0026#34;id\\\u0026#34;:5,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;POJO Builder Bean\\\u0026#34;}\u0026#34;; POJOBuilderBean bean = mapper.readValue(jsonString, POJOBuilderBean.class); assertEquals(5, bean.getIdentity()); assertEquals(\u0026#34;POJO Builder Bean\u0026#34;, bean.getBeanName()); @JsonTypeId @JsonTypeId注释用于指示在包含多态类型信息时，应将带注释的属性序列化为类型id，而不是常规属性。该多态元数据在反序列化期间用于重新创建与序列化前相同子类型的对象，而不是声明的超类型。\npublic class TypeIdBean { private int id; @JsonTypeId private String name; // constructor, getters and setters } mapper.enableDefaultTyping(DefaultTyping.NON_FINAL); TypeIdBean bean = new TypeIdBean(6, \u0026#34;Type Id Bean\u0026#34;); String jsonString = mapper.writeValueAsString(bean); assertThat(jsonString, containsString(\u0026#34;Type Id Bean\u0026#34;)); [ \u0026#34;Type Id Bean\u0026#34;, { \u0026#34;id\u0026#34;: 6 } ] @JsonTypeIdResolver @JsonTypeIdResolver注释用于表示序列化和反序列化中的自定义类型标识处理程序。该处理程序负责Java类型和JSON文档中包含的类型id之间的转换。\n假设在处理以下类层次结构时，我们希望在JSON字符串中嵌入类型信息。\n@JsonTypeInfo( use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = \u0026#34;@type\u0026#34; ) @JsonTypeIdResolver(BeanIdResolver.class) public class AbstractBean { private int id; protected AbstractBean(int id) { this.id = id; } // no-arg constructor, getter and setter } public class FirstBean extends AbstractBean { String firstName; public FirstBean(int id, String name) { super(id); setFirstName(name); } // no-arg constructor, getter and setter } public class LastBean extends AbstractBean { String lastName; public LastBean(int id, String name) { super(id); setLastName(name); } // no-arg constructor, getter and setter } 这些类的实例用于填充BeanContainer对象：\npublic class BeanContainer { private List\u0026lt;AbstractBean\u0026gt; beans; // getter and setter } 我们可以看到，AbstractBean类用@JsonTypeIdResolver进行了注释，这表明它使用自定义TypeIdResorver来决定如何在序列化中包含子类型信息，以及如何反过来使用该元数据。\npublic class BeanIdResolver extends TypeIdResolverBase { private JavaType superType; @Override public void init(JavaType baseType) { superType = baseType; } @Override public Id getMechanism() { return Id.NAME; } @Override public String idFromValue(Object obj) { return idFromValueAndType(obj, obj.getClass()); } @Override public String idFromValueAndType(Object obj, Class\u0026lt;?\u0026gt; subType) { String typeId = null; switch (subType.getSimpleName()) { case \u0026#34;FirstBean\u0026#34;: typeId = \u0026#34;bean1\u0026#34;; break; case \u0026#34;LastBean\u0026#34;: typeId = \u0026#34;bean2\u0026#34;; } return typeId; } @Override public JavaType typeFromId(DatabindContext context, String id) { Class\u0026lt;?\u0026gt; subType = null; switch (id) { case \u0026#34;bean1\u0026#34;: subType = FirstBean.class; break; case \u0026#34;bean2\u0026#34;: subType = LastBean.class; } return context.constructSpecializedType(superType, subType); } } 最值得注意的两个方法是idFromValueAndType和typeFromId，前者告诉序列化POJO时如何包含类型信息，后者使用该元数据确定重新创建的对象的子类型。\n为了确保序列化和反序列化都能正常工作，让我们编写一个测试来验证完整的进度。\n首先，我们需要实例化一个bean容器和bean类，然后用bean实例填充该容器：\nFirstBean bean1 = new FirstBean(1, \u0026#34;Bean 1\u0026#34;); LastBean bean2 = new LastBean(2, \u0026#34;Bean 2\u0026#34;); List\u0026lt;AbstractBean\u0026gt; beans = new ArrayList\u0026lt;\u0026gt;(); beans.add(bean1); beans.add(bean2); BeanContainer serializedContainer = new BeanContainer(); serializedContainer.setBeans(beans); 接下来，BeanContainer对象被序列化，我们确认结果字符串包含类型信息：\nString jsonString = mapper.writeValueAsString(serializedContainer); assertThat(jsonString, containsString(\u0026#34;bean1\u0026#34;)); assertThat(jsonString, containsString(\u0026#34;bean2\u0026#34;)); { \u0026#34;beans\u0026#34;: [ { \u0026#34;@type\u0026#34;: \u0026#34;bean1\u0026#34;, \u0026#34;id\u0026#34;: 1, \u0026#34;firstName\u0026#34;: \u0026#34;Bean 1\u0026#34; }, { \u0026#34;@type\u0026#34;: \u0026#34;bean2\u0026#34;, \u0026#34;id\u0026#34;: 2, \u0026#34;lastName\u0026#34;: \u0026#34;Bean 2\u0026#34; } ] } 该JSON结构将用于重新创建与序列化之前相同子类型的对象。以下是反序列化的实现步骤：\nBeanContainer deserializedContainer = mapper.readValue(jsonString, BeanContainer.class); List\u0026lt;AbstractBean\u0026gt; beanList = deserializedContainer.getBeans(); assertThat(beanList.get(0), instanceOf(FirstBean.class)); assertThat(beanList.get(1), instanceOf(LastBean.class)); How To 编组时如何忽略属性？ @JsonIgnoreProperties ： 在类上指定忽略的属性 @JsonIgnore： 在字段上指定忽略的属性 @JsonIgnoreType：忽略类型的所有属性 @JsonFilter： 动态忽略属性 @JsonInclude(Include.NON_NULL)：忽略特定值类型的属性 参考： https://www.baeldung.com/jackson-ignore-properties-on-serialization\njackson处理Optional 字段 public class Book { String title; Optional\u0026lt;String\u0026gt; subTitle; // getters and setters omitted } 序列化该对象：\nBook book = new Book(); book.setTitle(\u0026#34;Oliver Twist\u0026#34;); book.setSubTitle(Optional.of(\u0026#34;The Parish Boy\u0026#39;s Progress\u0026#34;)); String result = mapper.writeValueAsString(book); {\u0026#34;title\u0026#34;:\u0026#34;Oliver Twist\u0026#34;,\u0026#34;subTitle\u0026#34;:{\u0026#34;present\u0026#34;:true}} 我们将看到，Optional字段的输出不包含其值，而是包含一个嵌套的JSON对象，该对象具有一个名为present的字段.\n在本例中，isPresent是Optional类上的公共getter。这意味着它将被序列化为true或false，具体取决于它是否为空。这是jackson的默认序列化行为。\n现在，让我们反转上一个示例，这次尝试将对象反序列化为可选对象。现在我们将看到JsonMappingException：\n@Test(expected = JsonMappingException.class) public void givenFieldWithValue_whenDeserializing_thenThrowException String bookJson = \u0026#34;{ \\\u0026#34;title\\\u0026#34;: \\\u0026#34;Oliver Twist\\\u0026#34;, \\\u0026#34;subTitle\\\u0026#34;: \\\u0026#34;foo\\\u0026#34; }\u0026#34;; Book result = mapper.readValue(bookJson, Book.class); } com.fasterxml.jackson.databind.JsonMappingException: Can not construct instance of java.util.Optional: no String-argument constructor/factory method to deserialize from String value (\u0026#39;The Parish Boy\u0026#39;s Progress\u0026#39;) 这种行为再次有意义。本质上，Jackson需要一个构造函数，它可以将subtitle 的值作为参数。我们的可选字段并非如此。\n如何解决呢？\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.datatype\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-datatype-jdk8\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.13.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; ObjectMapper mapper = new ObjectMapper(); mapper.registerModule(new Jdk8Module()); 反序列化集合类型？ 转换成数组 @Test public void givenJsonArray_whenDeserializingAsArray_thenCorrect() throws JsonParseException, JsonMappingException, IOException { ObjectMapper mapper = new ObjectMapper(); List\u0026lt;MyDto\u0026gt; listOfDtos = Lists.newArrayList( new MyDto(\u0026#34;a\u0026#34;, 1, true), new MyDto(\u0026#34;bc\u0026#34;, 3, false)); String jsonArray = mapper.writeValueAsString(listOfDtos); // [{\u0026#34;stringValue\u0026#34;:\u0026#34;a\u0026#34;,\u0026#34;intValue\u0026#34;:1,\u0026#34;booleanValue\u0026#34;:true}, // {\u0026#34;stringValue\u0026#34;:\u0026#34;bc\u0026#34;,\u0026#34;intValue\u0026#34;:3,\u0026#34;booleanValue\u0026#34;:false}] MyDto[] asArray = mapper.readValue(jsonArray, MyDto[].class); assertThat(asArray[0], instanceOf(MyDto.class)); } 转换成集合 将同一个JSON数组读入Java集合有点困难——默认情况下，Jackson将无法获得完整的泛型类型信息，而是创建一个LinkedHashMap实例集合：\n@Test public void givenJsonArray_whenDeserializingAsListWithNoTypeInfo_thenNotCorrect() throws JsonParseException, JsonMappingException, IOException { ObjectMapper mapper = new ObjectMapper(); List\u0026lt;MyDto\u0026gt; listOfDtos = Lists.newArrayList( new MyDto(\u0026#34;a\u0026#34;, 1, true), new MyDto(\u0026#34;bc\u0026#34;, 3, false)); String jsonArray = mapper.writeValueAsString(listOfDtos); List\u0026lt;MyDto\u0026gt; asList = mapper.readValue(jsonArray, List.class); assertThat((Object) asList.get(0), instanceOf(LinkedHashMap.class)); } 有两种方法可以帮助Jackson理解正确的类型信息——我们可以为此使用库提供的TypeReference：\n@Test public void givenJsonArray_whenDeserializingAsListWithTypeReferenceHelp_thenCorrect() throws JsonParseException, JsonMappingException, IOException { ObjectMapper mapper = new ObjectMapper(); List\u0026lt;MyDto\u0026gt; listOfDtos = Lists.newArrayList( new MyDto(\u0026#34;a\u0026#34;, 1, true), new MyDto(\u0026#34;bc\u0026#34;, 3, false)); String jsonArray = mapper.writeValueAsString(listOfDtos); List\u0026lt;MyDto\u0026gt; asList = mapper.readValue( jsonArray, new TypeReference\u0026lt;List\u0026lt;MyDto\u0026gt;\u0026gt;() { }); assertThat(asList.get(0), instanceOf(MyDto.class)); } 或者我们可以使用接受JavaType的重载readValue方法：\n@Test public void givenJsonArray_whenDeserializingAsListWithJavaTypeHelp_thenCorrect() throws JsonParseException, JsonMappingException, IOException { ObjectMapper mapper = new ObjectMapper(); List\u0026lt;MyDto\u0026gt; listOfDtos = Lists.newArrayList( new MyDto(\u0026#34;a\u0026#34;, 1, true), new MyDto(\u0026#34;bc\u0026#34;, 3, false)); String jsonArray = mapper.writeValueAsString(listOfDtos); CollectionType javaType = mapper.getTypeFactory() .constructCollectionType(List.class, MyDto.class); List\u0026lt;MyDto\u0026gt; asList = mapper.readValue(jsonArray, javaType); assertThat(asList.get(0), instanceOf(MyDto.class)); } 最后一个注意事项是，MyDto类需要有无参数的默认构造函数——如果没有，Jackson将无法实例化它：\ncom.fasterxml.jackson.databind.JsonMappingException: No suitable constructor found for type [simple type, class org.baeldung.jackson.ignore.MyDto]: can not instantiate from JSON object (need to add/enable type information?) 如何比较两个json对象是否相等？ 使用 JsonNode.equals 方法执行完全（深度）比较。\n假设我们有一个JSON字符串定义为s1变量：\n{ \u0026#34;employee\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;1212\u0026#34;, \u0026#34;fullName\u0026#34;: \u0026#34;John Miles\u0026#34;, \u0026#34;age\u0026#34;: 34 } } 我们有另一个JSON字符串定义为s2变量：\n{ \u0026#34;employee\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;1212\u0026#34;, \u0026#34;age\u0026#34;: 34, \u0026#34;fullName\u0026#34;: \u0026#34;John Miles\u0026#34; } } 让我们将输入JSON读取为JsonNode，并进行比较：\nassertEquals(mapper.readTree(s1), mapper.readTree(s2)); 需要注意的是，即使输入JSON变量s1和s2中属性的顺序不同，equals（）方法也会忽略顺序并将它们视为相等。\n如何对Map进行序列化和反序列化 序列化将Java对象转换为字节流，可以根据需要进行持久化或共享。Java Map是将键对象映射到值对象的集合，通常是最不直观的序列化对象。\nMap 序列化 对于一个简单的例子，让我们创建一个Map＜String，String＞并将其序列化为JSON：\nMap\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;); ObjectMapper mapper = new ObjectMapper(); String jsonResult = mapper.writerWithDefaultPrettyPrinter() .writeValueAsString(map); ObjectMapper是Jackson的序列化映射器。它允许我们序列化我们的Map，并使用String中的toString方法将其写成一个打印精美的JSON字符串：\n{ \u0026#34;key\u0026#34; : \u0026#34;value\u0026#34; } Map 序列化 ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/jackson/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":1669984867,"title":"Jackson"},{"authors":[],"categories":[{"title":"java","url":"/myblog/categories/java/"},{"title":"spring","url":"/myblog/categories/spring/"}],"content":"1.容器和 Bean 介绍 控制反转也叫依赖注入(DI)，这是一个过程。对象通过下面的方式，知道自己的依赖项：\n构造函数参数 工厂方法创建对象时的参数 对象的setter方法参数 然后容器在创建bean时，注入这些依赖。在这个过程中，bean控制着自身的创建，通过类上的构造函数等机制搜索所需的依赖，因此称为控制反转。\norg.springframework.beans 和 org.springframework.context 包是 Spring Framework 的 IoC 容器的基础。 BeanFactory 接口管理容器中的bean。 ApplicationContext 是 BeanFactory 的扩展子接口，扩展项如下：\n更容易与 Spring 的 AOP 特性集成 消息资源处理（用于国际化） 事件发布 应用层特定上下文，例如用于 Web 应用程序的 WebApplicationContext。 简而言之，BeanFactory 提供了配置框架和基本功能，ApplicationContext 增加了更多企业特定的功能。\n在 Spring 中，构成应用程序主干并由 Spring IoC 容器管理的对象称为 bean。 bean 是由 Spring IoC 容器实例化、组装和管理的对象。\n2.容器概览 org.springframework.context.ApplicationContext接口表示Spring IoC容器，并负责实例化，配置和组装Bean。 容器通过读取配置元数据获取有关要实例化，配置和组装哪些对象的指令。 配置元数据以XML，Java批注或Java代码表示。 它使您能够表达组成应用程序的对象以及这些对象之间的丰富相互依赖关系。\nSpring提供了ApplicationContext接口的几种实现。 在独立应用程序中，通常创建ClassPathXmlApplicationContext或FileSystemXmlApplicationContext的实例。 尽管XML是定义配置元数据的传统格式，但是您可以通过提供少量XML配置来声明性地启用对这些其他元数据格式的支持，从而指示容器将Java注释或代码用作元数据格式。\n在大多数应用场景中，不需要显式用户代码即可实例化一个Spring IoC容器的一个或多个实例。 例如，在Web应用程序场景中，应用程序的web.xml文件中配置简单八行样板XML就足够了（请参阅Web应用程序的便捷ApplicationContext实例化）。\n下图显示了Spring的工作原理的高级视图。 您的应用程序类与配置元数据结合在一起，以便在创建和初始化ApplicationContext之后，您将拥有一个完全配置且可执行的系统或应用程序。\n配置元数据 如上图所示，Spring IoC容器使用一种形式的配置元数据。 此配置元数据表示您作为应用程序开发人员如何告诉Spring容器实例化，配置和组装应用程序中的对象。\n传统上，配置元数据以简单直观的XML格式提供，这是本章大部分内容用来传达Spring IoC容器的关键概念和功能的内容。\n有关在Spring容器中使用其他形式的元数据的信息，请参见：\n基于注释的配置：Spring 2.5引入了对基于注释的配置元数据的支持。\n基于Java的配置：从Spring 3.0开始，Spring JavaConfig项目提供的许多功能成为核心Spring Framework的一部分。 因此，您可以使用Java而不是XML文件来定义应用程序类外部的bean。 要使用这些新功能，请参见@Configuration，@Bean，@Import和@DependsOn批注。\n基于XML的配置元数据将这些bean配置为内的元素。 Java配置通常在@Configuration类中使用@Bean注释的方法。\n这些bean定义对应于组成应用程序的实际对象。 通常，您定义服务层对象，数据访问对象（DAO），表示层对象（例如Struts Action实例），基础结构对象（例如JPA EntityManagerFactory，JMS队列）等等。 通常，不会在容器中配置细粒度的域对象，因为DAO和业务逻辑通常负责创建和加载域对象。 但是，您可以使用Spring与AspectJ的集成来配置在IoC容器控制之外创建的对象。 请参阅使用AspectJ与Spring依赖注入域对象。\n以下示例显示了基于XML的配置元数据的基本结构：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;...\u0026#34; class=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;!-- collaborators and configuration for this bean go here --\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;...\u0026#34; class=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;!-- collaborators and configuration for this bean go here --\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- more bean definitions go here --\u0026gt; \u0026lt;/beans\u0026gt; id属性是标识单个bean定义的字符串。\nclass属性定义bean的类型并使用完全限定类名称。\n实例化容器 提供给ApplicationContext构造函数的一个或多个位置路径是资源字符串，这些资源字符串使容器可以从各种外部资源（例如本地文件系统，Java CLASSPATH等）加载配置元数据。\nApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;services.xml\u0026#34;, \u0026#34;daos.xml\u0026#34;); 下面是services.xml文件的内容:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;!-- services --\u0026gt; \u0026lt;bean id=\u0026#34;petStore\u0026#34; class=\u0026#34;org.springframework.samples.jpetstore.services.PetStoreServiceImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;accountDao\u0026#34; ref=\u0026#34;accountDao\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;itemDao\u0026#34; ref=\u0026#34;itemDao\u0026#34;/\u0026gt; \u0026lt;!-- additional collaborators and configuration for this bean go here --\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- more bean definitions for services go here --\u0026gt; \u0026lt;/beans\u0026gt; 下面是daos.xml文件的内容：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;accountDao\u0026#34; class=\u0026#34;org.springframework.samples.jpetstore.dao.jpa.JpaAccountDao\u0026#34;\u0026gt; \u0026lt;!-- additional collaborators and configuration for this bean go here --\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;itemDao\u0026#34; class=\u0026#34;org.springframework.samples.jpetstore.dao.jpa.JpaItemDao\u0026#34;\u0026gt; \u0026lt;!-- additional collaborators and configuration for this bean go here --\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- more bean definitions for data access objects go here --\u0026gt; \u0026lt;/beans\u0026gt; 在前面的示例中，服务层由PetStoreServiceImpl类和两个JpaAccountDao和JpaItemDao类型的数据访问对象组成（基于JPA对象关系映射标准）。 property 标签的names属性引用JavaBean属性的名称，而ref元素引用另一个bean定义的名称。 id和ref元素之间的这种联系表达了协作对象之间的依赖性。 有关配置对象的依存关系的详细信息，请参阅依存关系。\n基于XML的配置元数据的组成 使bean定义跨越多个XML文件可能很有用。 通常，每个单独的XML配置文件都代表体系结构中的逻辑层或模块。\n您可以使用应用程序上下文构造函数从所有这些XML片段中加载bean定义。 如上一节中所示，此构造函数具有多个Resource位置。 或者，使用元素的一个或多个实例从另一个文件中加载bean定义。 以下示例显示了如何执行此操作：\n\u0026lt;beans\u0026gt; \u0026lt;import resource=\u0026#34;services.xml\u0026#34;/\u0026gt; \u0026lt;import resource=\u0026#34;resources/messageSource.xml\u0026#34;/\u0026gt; \u0026lt;import resource=\u0026#34;/resources/themeSource.xml\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;bean1\u0026#34; class=\u0026#34;...\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;bean2\u0026#34; class=\u0026#34;...\u0026#34;/\u0026gt; \u0026lt;/beans\u0026gt; 在前面的示例中，外部bean定义是从三个文件加载的：services.xml，messageSource.xml和themeSource.xml。 所有位置路径都相对于进行导入的定义文件，因此，services.xml必须与进行导入的文件位于同一目录或类路径位置，而messageSource.xml和themeSource.xml必须位于该位置下方的resource目录下 。 如您所见，斜杠被忽略。 但是，鉴于这些路径是相对的，最好不要使用任何斜线。 根据Spring Schema，导入的文件的内容（包括顶级元素）必须是有效的XML bean定义。\n可以但不建议使用相对的“ ../”路径引用父目录中的文件。 这样做会让当前应用程序依赖外部文件。 特别是，不建议使用classpath：URL（例如，classpath：../ services.xml）引用，在URL中，运行时解析过程会选择“最近”的classpath根目录，然后查看其父目录。 类路径配置的更改可能导致选择其他错误的目录。\n您始终可以使用标准资源位置而不是相对路径：例如，file:C:/config/services.xml或classpath:/config/services.xml。 但是请注意，您正在将应用程序的配置耦合到特定的绝对位置。 通常，最好为这样的绝对位置保留一个间接寻址，例如，通过在运行时针对JVM系统属性解析的“ $ {…}”占位符。\n使用容器 ApplicationContext是高级工厂的接口，该工厂能够维护不同bean及其依赖关系的注册表。 通过使用方法T getBean（String name，Class requiredType），可以检索bean的实例。\n通过ApplicationContext，您可以读取Bean并访问它们，如以下示例所示：\n// create and configure beans ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;services.xml\u0026#34;, \u0026#34;daos.xml\u0026#34;); // retrieve configured instance PetStoreService service = context.getBean(\u0026#34;petStore\u0026#34;, PetStoreService.class); // use configured instance List\u0026lt;String\u0026gt; userList = service.getUsernameList(); 最灵活的变体是GenericApplicationContext,与具体的reader委托结合使用，例如，与XML文件的XmlBeanDefinitionReader结合使用，如以下示例所示：\nGenericApplicationContext context = new GenericApplicationContext(); new XmlBeanDefinitionReader(context).loadBeanDefinitions(\u0026#34;services.xml\u0026#34;, \u0026#34;daos.xml\u0026#34;); context.refresh(); 然后可以使用getBean检索bean的实例。 ApplicationContext接口还有其他几种检索bean的方法，但是理想情况下，您的应用程序代码永远不要使用它们。 确实，您的应用程序代码应该不调用getBean（）方法，这样不会耦合Spring API。 例如，Spring与Web框架的集成为各种Web框架组件（例如控制器和JSF管理的Bean）提供了依赖项注入，使您可以通过元数据（例如自动装配注释）声明对特定Bean的依赖项。\n3.bean概览 在spring中，bean 定义表示为 BeanDefinition 对象，其中包含以下元数据：\n包限定的类名：通常是定义的 bean 的实际实现类。 Bean 行为配置元素，它说明 Bean 在容器中的行为方式（范围、生命周期回调等）。 对 bean 执行其工作所需的其他 bean 的引用。 这些引用也称为协作者或依赖项。 要在新创建的对象中设置的其他配置设置 — 例如，管理连接池的 bean ，池的大小限制或使用的连接数。 这些元数据由下面的属性描述：\nProperty Explained in… Class Instantiating Beans Name Naming Beans Scope Bean Scopes Constructor arguments Dependency Injection Properties Dependency Injection Autowiring mode Autowiring Collaborators Lazy initialization mode Lazy-initialized Beans Initialization method Initialization Callbacks Destruction method Destruction Callbacks 除了包含有关如何创建特定bean的定义信息之外，ApplicationContext实现还允许注册在容器外部（由用户）创建的现有对象。 这是通过ApplicationContext的getBeanFactory（）方法返回的BeanFactory来完成的，该方法返回BeanFactory DefaultListableBeanFactory实现。 DefaultListableBeanFactory通过registerSingleton（..）和registerBeanDefinition（..）方法支持此注册。 但是，典型的应用程序只能与通过常规bean定义元数据定义的bean一起使用。\nBean元数据和手动提供的单例实例需要尽早注册，以便容器在自动装配和其他自省步骤中正确地推理它们。 尽管在某种程度上支持覆盖现有元数据和现有单例实例，但官方不支持在运行时（与对工厂的实时访问同时）对新bean的注册，并且可能导致并发访问异常，bean容器中的状态不一致。\n3.1 bean命名 每个bean具有一个或多个标识符。 这些标识符在承载Bean的容器内必须唯一。 一个bean通常只有一个标识符。 但是，如果需要多个，则可以将多余的别名视为别名。\n在基于XML的配置元数据中，可以使用id属性和（或）name属性来指定Bean标识符。 id属性可让您精确指定一个id。 按照惯例，这些名称是字母加数字（“ myBean”，“ someService”等），但它们也可以包含特殊字符。 如果要为bean引入其他别名，则还可以在name属性中指定它们，并用逗号（，）分号（;）或空格分隔。 作为历史记录，在Spring 3.1之前的版本中，id属性定义为xsd：ID类型，该类型限制了可能的字符。 从3.1开始，它被定义为xsd：string类型。 请注意，bean ID唯一性仍由容器强制执行，尽管不再由XML解析器执行。\n您不需要提供bean的名称或ID。 如果未明确提供名称或ID，则容器将为该bean生成一个唯一的名称。 但是，如果要通过名称引用该bean，则必须通过使用ref元素或服务定位器样式查找，您必须提供一个名称。\n通过在类路径中进行组件扫描，Spring会按照前面描述的规则为未命名的组件生成Bean名称：从本质上讲，采用简单的类名称并将其初始字符转换为小写。 但是，在（不寻常的）特殊情况下，如果有多个字符并且第一个和第二个字符均为大写字母，则会保留原始大小写。 这些规则与java.beans.Introspector.decapitalize（Spring在此使用）定义的规则相同。\n3.1.1 在Bean定义之外别名Bean 在bean定义本身中，可以通过使用id属性指定的最多一个名称和name属性中任意数量的其他名称的组合来为bean提供多个名称。 这些名称可以是同一个bean的等效别名，并且在某些情况下很有用，例如，通过使用特定于该组件本身的bean名称，让应用程序中的每个组件都引用一个公共依赖项。\n但是，在实际定义bean的地方指定所有别名并不总是足够的。 有时需要为在别处定义的bean引入别名。 这在大型系统中通常是这种情况，在大型系统中，配置在每个子系统之间分配，每个子系统都有自己的对象定义集。 在基于XML的配置元数据中，可以使用元素来完成此操作。 以下示例显示了如何执行此操作：\n\u0026lt;alias name=\u0026#34;fromName\u0026#34; alias=\u0026#34;toName\u0026#34;/\u0026gt; 在这种情况下，在使用该别名定义之后，也可以将名为fromName的bean（在同一容器中）称为toName。\n例如，子系统A的配置元数据可以通过子系统A-dataSource的名称引用数据源。 子系统B的配置元数据可以通过子系统B-dataSource的名称引用数据源。 组成使用这两个子系统的主应用程序时，主应用程序通过myApp-dataSource的名称引用数据源。 要使所有三个名称都引用同一个对象，可以将以下别名定义添加到配置元数据中：\n\u0026lt;alias name=\u0026#34;myApp-dataSource\u0026#34; alias=\u0026#34;subsystemA-dataSource\u0026#34;/\u0026gt; \u0026lt;alias name=\u0026#34;myApp-dataSource\u0026#34; alias=\u0026#34;subsystemB-dataSource\u0026#34;/\u0026gt; 现在，每个组件和主应用程序都可以通过唯一的名称引用数据源，并且可以保证不与任何其他定义冲突（有效地创建名称空间），但是它们引用的是同一bean。\n如果使用Javaconfiguration，则@Bean批注可用于提供别名。 有关详细信息，请参见使用@Bean注释。\n3.2 实例化Bean Bean定义实质上是创建一个或多个对象的方法。 容器在被询问时会查看命名bean的配方，并使用该bean定义封装的配置元数据来创建（或获取）实际对象。\n如果使用基于XML的配置元数据，请在元素的class属性中指定要实例化的对象的类型（或类）。 这个类属性（在内部是BeanDefinition实例的Class属性）通常是必需的。 （有关异常，请参见使用实例工厂方法实例化和Bean定义继承。）可以通过以下两种方式之一使用Class属性：\n通常，在容器本身通过反射性地调用其构造函数直接创建Bean的情况下，指定要构造的Bean类，这在某种程度上等同于使用new运算符的Java代码。 要指定包含用于创建对象的静态工厂方法的实际类，在不太常见的情况下，容器将在类上调用静态工厂方法以创建Bean。 从静态工厂方法的调用返回的对象类型可以是同一类，也可以是完全不同的另一类。 如果要为静态嵌套类配置Bean定义，则必须使用嵌套类的二进制名称。\n例如，如果您在com.example包中有一个名为SomeThing的类，并且此SomeThing类具有一个名为OtherThing的静态嵌套类，则bean定义上的class属性的值为com.example.SomeThing $ OtherThing。\n请注意，名称中使用$字符将嵌套的类名与外部类名分开。\n使用构造函数创建 当通过构造方法创建一个bean时，所有普通类都可以被Spring使用并兼容。 也就是说，正在开发的类不需要实现任何特定的接口或以特定的方式进行编码。 只需指定bean类就足够了。 但是，根据您用于该特定bean的IoC的类型，您可能需要一个默认（空）构造函数。\nSpring IoC容器几乎可以管理您要管理的任何类。 它不仅限于管理真正的JavaBean。 大多数Spring用户更喜欢实际的JavaBean，它们仅具有默认的（无参数）构造函数，并具有根据容器中的属性建模的适当的setter和getter。 您还可以在容器中具有更多奇特的非Bean样式类。 例如，如果您需要使用绝对不符合JavaBean规范的旧式连接池，则Spring也可以对其进行管理。\n使用基于XML的配置元数据，您可以如下指定bean类：\n\u0026lt;bean id=\u0026#34;exampleBean\u0026#34; class=\u0026#34;examples.ExampleBean\u0026#34;/\u0026gt; \u0026lt;bean name=\u0026#34;anotherExample\u0026#34; class=\u0026#34;examples.ExampleBeanTwo\u0026#34;/\u0026gt; 有关向构造函数提供参数（如果需要）并在构造对象之后设置对象实例属性的机制的详细信息，请参见注入依赖项。\n使用静态工厂方法创建实例 定义使用静态工厂方法创建的bean时，请使用class属性指定包含静态工厂方法的类，并使用名为factory-method的属性指定工厂方法本身的名称。 您应该能够调用此方法（使用可选参数，如稍后所述）并返回一个活动对象，该对象随后将被视为已通过构造函数创建。 这种bean定义的一种用法是在旧版代码中调用静态工厂。\n以下bean定义指定通过调用工厂方法来创建bean。 该定义不指定返回对象的类型（类），而仅指定包含工厂方法的类。 在此示例中，createInstance（）方法必须是静态方法。 以下示例显示如何指定工厂方法：\n\u0026lt;bean id=\u0026#34;clientService\u0026#34; class=\u0026#34;examples.ClientService\u0026#34; factory-method=\u0026#34;createInstance\u0026#34;/\u0026gt; 以下示例显示了可与前面的bean定义一起使用的类：\npublic class ClientService { private static ClientService clientService = new ClientService(); private ClientService() {} public static ClientService createInstance() { return clientService; } } 有关为工厂方法提供（可选）参数并在从工厂返回对象后设置对象实例属性的机制的详细信息，请参阅详细信息中的依赖关系和配置。\n使用实例工厂方法创建对象 类似于通过静态工厂方法进行实例化，使用实例工厂方法进行实例化会从容器中调用现有bean的非静态方法来创建新bean。 要使用此机制，请将class属性保留为空，并在factory-bean属性中，在当前（或父或祖先）容器中指定包含要创建该对象的实例方法的bean的名称。 使用factory-method属性设置工厂方法本身的名称。 以下示例显示了如何配置此类Bean：\npublic class DefaultServiceLocator { private static ClientService clientService = new ClientServiceImpl(); public ClientService createClientServiceInstance() { return clientService; } } 一个工厂类也可以包含一个以上的工厂方法，如以下示例所示：\n\u0026lt;bean id=\u0026#34;serviceLocator\u0026#34; class=\u0026#34;examples.DefaultServiceLocator\u0026#34;\u0026gt; \u0026lt;!-- inject any dependencies required by this locator bean --\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;clientService\u0026#34; factory-bean=\u0026#34;serviceLocator\u0026#34; factory-method=\u0026#34;createClientServiceInstance\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;accountService\u0026#34; factory-bean=\u0026#34;serviceLocator\u0026#34; factory-method=\u0026#34;createAccountServiceInstance\u0026#34;/\u0026gt; public class DefaultServiceLocator { private static ClientService clientService = new ClientServiceImpl(); private static AccountService accountService = new AccountServiceImpl(); public ClientService createClientServiceInstance() { return clientService; } public AccountService createAccountServiceInstance() { return accountService; } } 这种方法表明，工厂Bean本身可以通过依赖项注入（DI）进行管理和配置。 详细信息，请参见依赖性和配置。\n在Spring文档中，“ factory bean”是指在Spring容器中配置并通过实例或静态工厂方法创建对象的bean。 相比之下，FactoryBean（注意大小写）是指特定于Spring的FactoryBean实现类。\n确定Bean的运行时类型 确定特定bean的运行时类型并非易事。 Bean元数据定义中的指定类只是初始类引用，可能与声明的工厂方法结合使用，或者是FactoryBean类，这可能导致Bean的运行时类型不同，或者在实例工厂方法的情况下根本不进行设置 （通过指定的factory-bean名称解析）。 此外，AOP代理可以使用基于接口的代理包装bean实例，而目标Bean的实际类型（仅是其实现的接口）的暴露程度有限。\n找出特定bean的实际运行时类型的推荐方法是对指定bean名称的BeanFactory.getType调用。 这考虑了上述所有情况，并返回了针对相同bean名称的BeanFactory.getBean调用将返回的对象的类型。\n依赖 典型的企业应用程序不包含单个对象（或Spring术语中的bean）。 即使是最简单的应用程序，也有一些对象可以协同工作，以呈现最终用户视为一致的应用程序。 下一部分将说明如何从定义多个独立的Bean定义到实现对象协作以实现目标的完全实现的应用程序。\nbean的命名 在基于 XML 的配置元数据中，您可以使用 id 属性（唯一）、name 属性（相当于别名，多个用逗号分隔）或两者来指定 bean 标识符。如果没有给bean指定id，会默认生成一个。通常我们建议bean的名称是小写开头的简单类名。\n此外alias标签也可以创建别名：\n\u0026lt;alias name=\u0026#34;myApp-dataSource\u0026#34; alias=\u0026#34;subsystemA-dataSource\u0026#34;/\u0026gt; \u0026lt;alias name=\u0026#34;myApp-dataSource\u0026#34; alias=\u0026#34;subsystemB-dataSource\u0026#34;/\u0026gt; bean实例化 构造函数方式：\n\u0026lt;bean id=\u0026#34;exampleBean\u0026#34; class=\u0026#34;examples.ExampleBean\u0026#34;/\u0026gt; 静态工厂：\n\u0026lt;bean id=\u0026#34;clientService\u0026#34; class=\u0026#34;examples.ClientService\u0026#34; factory-method=\u0026#34;createInstance\u0026#34;/\u0026gt; 实例工厂：\nbean定义继承 使用父子 bean 定义可以节省大量输入。 实际上，这是一种模板形式。\n\u0026lt;bean id=\u0026#34;inheritedTestBean\u0026#34; abstract=\u0026#34;true\u0026#34; class=\u0026#34;org.springframework.beans.TestBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;name\u0026#34; value=\u0026#34;parent\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;age\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;inheritsWithDifferentClass\u0026#34; class=\u0026#34;org.springframework.beans.DerivedTestBean\u0026#34; parent=\u0026#34;inheritedTestBean\u0026#34; init-method=\u0026#34;initialize\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;name\u0026#34; value=\u0026#34;override\u0026#34;/\u0026gt; \u0026lt;!-- the age property value of 1 will be inherited from parent --\u0026gt; \u0026lt;/bean\u0026gt; 子 bean 定义从父 bean 继承范围、构造函数参数值、属性值和方法覆盖，并可以选择添加新值。 您指定的任何范围、初始化方法、销毁方法或静态工厂方法设置都会覆盖相应的父设置。\n前面的示例使用抽象属性将父 bean 定义显式标记为抽象。 如果父定义未指定类，则需要将父 bean 定义显式标记为抽象。\n父 bean 不能单独实例化，因为它是不完整的，并且它也被显式标记为抽象。 当定义是抽象的时，它只能用作纯模板 bean 定义，作为子定义的父定义。 通过将其作为另一个 bean 的 ref 属性引用或使用父 bean ID 执行显式 getBean() 调用，尝试单独使用此类抽象父 bean 会返回错误。 类似地，容器的内部 preInstantiateSingletons() 方法忽略定义为抽象的 bean 定义。\n依赖 构造函数注入 多个构造参数的构造函数，默认的注入方式：\n\u0026lt;beans\u0026gt; \u0026lt;bean id=\u0026#34;beanOne\u0026#34; class=\u0026#34;x.y.ThingOne\u0026#34;\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;beanTwo\u0026#34;/\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;beanThree\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;beanTwo\u0026#34; class=\u0026#34;x.y.ThingTwo\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;beanThree\u0026#34; class=\u0026#34;x.y.ThingThree\u0026#34;/\u0026gt; \u0026lt;/beans\u0026gt; 类型匹配的注入方式：\n\u0026lt;bean id=\u0026#34;exampleBean\u0026#34; class=\u0026#34;examples.ExampleBean\u0026#34;\u0026gt; \u0026lt;constructor-arg type=\u0026#34;int\u0026#34; value=\u0026#34;7500000\u0026#34;/\u0026gt; \u0026lt;constructor-arg type=\u0026#34;java.lang.String\u0026#34; value=\u0026#34;42\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 索引匹配的注入方式：\n\u0026lt;bean id=\u0026#34;exampleBean\u0026#34; class=\u0026#34;examples.ExampleBean\u0026#34;\u0026gt; \u0026lt;constructor-arg index=\u0026#34;0\u0026#34; value=\u0026#34;7500000\u0026#34;/\u0026gt; \u0026lt;constructor-arg index=\u0026#34;1\u0026#34; value=\u0026#34;42\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 构造参数名称匹配的方式：\n\u0026lt;bean id=\u0026#34;exampleBean\u0026#34; class=\u0026#34;examples.ExampleBean\u0026#34;\u0026gt; \u0026lt;constructor-arg name=\u0026#34;years\u0026#34; value=\u0026#34;7500000\u0026#34;/\u0026gt; \u0026lt;constructor-arg name=\u0026#34;ultimateAnswer\u0026#34; value=\u0026#34;42\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 请记住，要使这项工作开箱即用，您的代码必须在启用调试标志的情况下进行编译，以便 Spring 可以从构造函数中查找参数名称。 如果您不能或不想使用调试标志编译代码，则可以使用 @ConstructorProperties JDK 注释显式命名构造函数参数。 示例类必须如下所示：\npublic class ExampleBean { @ConstructorProperties({\u0026#34;years\u0026#34;, \u0026#34;ultimateAnswer\u0026#34;}) public ExampleBean(int years, String ultimateAnswer) { this.years = years; this.ultimateAnswer = ultimateAnswer; } } setter注入 基于 Setter 的 DI 是容器在调用无参数构造函数或无参数静态工厂方法来实例化 bean 后调用 bean 上的 setter 方法来完成的。\n以下示例显示了一个只能使用纯 setter 注入进行依赖注入的类。 这个类是传统的Java。 它是一个不依赖于容器特定接口、基类或注解的 POJO。\npublic class SimpleMovieLister { // the SimpleMovieLister has a dependency on the MovieFinder private MovieFinder movieFinder; // a setter method so that the Spring container can inject a MovieFinder public void setMovieFinder(MovieFinder movieFinder) { this.movieFinder = movieFinder; } // business logic that actually uses the injected MovieFinder is omitted... } 由于您可以混合使用基于构造函数和基于 setter 的 DI，因此根据经验，对强制依赖项使用构造函数，对可选依赖项使用 setter 方法是一个很好的经验法则。 请注意，在 setter 方法上使用 @Required 注释可用于使属性成为必需的依赖项； 但是，最好使用构造函数注入。\nSpring 团队通常提倡构造函数注入，因为它可以让您将应用程序组件实现为不可变对象，并确保所需的依赖项不为空。 此外，构造函数注入的组件总是以完全初始化的状态返回给客户端（调用）代码。\n大量的构造函数参数是一种糟糕的代码，这意味着该类可能有太多的责任，应该重构以更好地解决适当的关注点分离问题。\n循环依赖 使用构造函数注入，则可能会出现循环依赖。例如：A类通过构造函数注入B类的实例，B类通过构造函数注入A类的实例。 如果您将类 A 和 B 的 bean 配置为相互注入，则 Spring IoC 容器在运行时检测到此循环引用，并抛出 BeanCurrentlyInCreationException。\n可能的解决方案是编辑一些类的源代码，以便由 setter 而不是构造函数来配置。\nSpring 在真正创建 bean 时尽可能晚地设置属性并解析依赖项。 这意味着，如果创建该对象或其依赖项之一时出现问题，spring 容器仍然正常启动，只在你调用改bean时，才会告诉你异常。\n在容器启动时就创建bean,虽然会花费启动时间和系统内存，但是可以提前发现配置文件中的错误。你可以覆盖此默认的early方式，以便bean延时初始化。\ndepends-on 如果一个 bean 是另一个 bean 的依赖项，这通常意味着一个 bean 被设置为另一个 bean 的属性。 但是，有时 bean 之间的依赖关系不那么直接。 例如，当需要触发类中的静态初始化程序时(数据库驱动程序注册)。 在初始化使用此元素的 bean 之前，depends-on 属性可以显式地强制初始化一个或多个 bean。 以下示例使用depends-on 属性来表达对bean 的依赖：\n\u0026lt;bean id=\u0026#34;beanOne\u0026#34; class=\u0026#34;ExampleBean\u0026#34; depends-on=\u0026#34;manager,accountDao\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;manager\u0026#34; ref=\u0026#34;manager\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;manager\u0026#34; class=\u0026#34;ManagerBean\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;accountDao\u0026#34; class=\u0026#34;x.y.jdbc.JdbcAccountDao\u0026#34; /\u0026gt; 配置细节 p标签方式：\n\u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;myDataSource\u0026#34; class=\u0026#34;org.apache.commons.dbcp.BasicDataSource\u0026#34; destroy-method=\u0026#34;close\u0026#34; p:driverClassName=\u0026#34;com.mysql.jdbc.Driver\u0026#34; p:url=\u0026#34;jdbc:mysql://localhost:3306/mydb\u0026#34; p:username=\u0026#34;root\u0026#34; p:password=\u0026#34;misterkaoli\u0026#34;/\u0026gt; \u0026lt;/beans\u0026gt; idref 元素\nidref 元素只是一种将容器中另一个 bean 的 id（字符串值 - 而不是引用）传递给元素的防错方式。 以下示例显示了如何使用它：\n\u0026lt;bean id=\u0026#34;theTargetBean\u0026#34; class=\u0026#34;...\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;theClientBean\u0026#34; class=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;targetName\u0026#34;\u0026gt; \u0026lt;idref bean=\u0026#34;theTargetBean\u0026#34;/\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 完全等同下面的代码：\n\u0026lt;bean id=\u0026#34;theTargetBean\u0026#34; class=\u0026#34;...\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;client\u0026#34; class=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;targetName\u0026#34; value=\u0026#34;theTargetBean\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; ref元素\nref等同与property标签上的ref属性，表示对bean的引用。但是ref更强大，支持引用父容器中的bean。例如：\n内部bean\n内部 bean 定义不需要定义的 ID 或name。 如果指定，容器不会使用这样的值作为标识符。 容器在创建时也会忽略范围标志，因为内部 bean 始终是匿名的，并且始终与外部 bean 一起创建。 不可能独立访问内部 bean 或将它们注入除封闭 bean 之外的协作 bean 中:\n\u0026lt;bean id=\u0026#34;outer\u0026#34; class=\u0026#34;...\u0026#34;\u0026gt; \u0026lt;!-- instead of using a reference to a target bean, simply define the target bean inline --\u0026gt; \u0026lt;property name=\u0026#34;target\u0026#34;\u0026gt; \u0026lt;bean class=\u0026#34;com.example.Person\u0026#34;\u0026gt; \u0026lt;!-- this is the inner bean --\u0026gt; \u0026lt;property name=\u0026#34;name\u0026#34; value=\u0026#34;Fiona Apple\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;age\u0026#34; value=\u0026#34;25\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 设置集合类型的属性\n, , , 和\n\u0026lt;bean id=\u0026#34;moreComplexObject\u0026#34; class=\u0026#34;example.ComplexObject\u0026#34;\u0026gt; \u0026lt;!-- results in a setAdminEmails(java.util.Properties) call --\u0026gt; \u0026lt;property name=\u0026#34;adminEmails\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;administrator\u0026#34;\u0026gt;administrator@example.org\u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;support\u0026#34;\u0026gt;support@example.org\u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;development\u0026#34;\u0026gt;development@example.org\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- results in a setSomeList(java.util.List) call --\u0026gt; \u0026lt;property name=\u0026#34;someList\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;a list element followed by a reference\u0026lt;/value\u0026gt; \u0026lt;ref bean=\u0026#34;myDataSource\u0026#34; /\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- results in a setSomeMap(java.util.Map) call --\u0026gt; \u0026lt;property name=\u0026#34;someMap\u0026#34;\u0026gt; \u0026lt;map\u0026gt; \u0026lt;entry key=\u0026#34;an entry\u0026#34; value=\u0026#34;just some string\u0026#34;/\u0026gt; \u0026lt;entry key=\u0026#34;a ref\u0026#34; value-ref=\u0026#34;myDataSource\u0026#34;/\u0026gt; \u0026lt;/map\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- results in a setSomeSet(java.util.Set) call --\u0026gt; \u0026lt;property name=\u0026#34;someSet\u0026#34;\u0026gt; \u0026lt;set\u0026gt; \u0026lt;value\u0026gt;just some string\u0026lt;/value\u0026gt; \u0026lt;ref bean=\u0026#34;myDataSource\u0026#34; /\u0026gt; \u0026lt;/set\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 集合合并\n子集合的值是合并父集合和子集合的元素的结果，子集合元素覆盖父集合中指定的值\n\u0026lt;beans\u0026gt; \u0026lt;bean id=\u0026#34;parent\u0026#34; abstract=\u0026#34;true\u0026#34; class=\u0026#34;example.ComplexObject\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;adminEmails\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;administrator\u0026#34;\u0026gt;administrator@example.com\u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;support\u0026#34;\u0026gt;support@example.com\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;child\u0026#34; parent=\u0026#34;parent\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;adminEmails\u0026#34;\u0026gt; \u0026lt;!-- the merge is specified on the child collection definition --\u0026gt; \u0026lt;props merge=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;prop key=\u0026#34;sales\u0026#34;\u0026gt;sales@example.com\u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;support\u0026#34;\u0026gt;support@example.co.uk\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;beans\u0026gt; 集合上的泛型\npublic class SomeClass { private Map\u0026lt;String, Float\u0026gt; accounts; public void setAccounts(Map\u0026lt;String, Float\u0026gt; accounts) { this.accounts = accounts; } } \u0026lt;beans\u0026gt; \u0026lt;bean id=\u0026#34;something\u0026#34; class=\u0026#34;x.y.SomeClass\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;accounts\u0026#34;\u0026gt; \u0026lt;map\u0026gt; \u0026lt;entry key=\u0026#34;one\u0026#34; value=\u0026#34;9.99\u0026#34;/\u0026gt; \u0026lt;entry key=\u0026#34;two\u0026#34; value=\u0026#34;2.75\u0026#34;/\u0026gt; \u0026lt;entry key=\u0026#34;six\u0026#34; value=\u0026#34;3.99\u0026#34;/\u0026gt; \u0026lt;/map\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 空值处理\n\u0026lt;bean class=\u0026#34;ExampleBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;email\u0026#34; value=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 等同于：\nexampleBean.setEmail(\u0026#34;\u0026#34;); \u0026lt;bean class=\u0026#34;ExampleBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;email\u0026#34;\u0026gt; \u0026lt;null/\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 等同于：\nexampleBean.setEmail(null); bean的懒加载机制 默认情况下，ApplicationContext 实现会在初始化过程中急切地创建和配置所有单例 bean。 因为可以立即发现配置或周围环境中的错误。 当这种行为不可取时，您可以通过将 bean 定义标记为延迟初始化。 一个延迟初始化的 bean 告诉 IoC 容器在它第一次被请求时创建一个 bean 实例，而不是在容器启动时。\n在 XML 中，此行为由 元素上的 lazy-init 属性控制，如以下示例所示：\n\u0026lt;bean id=\u0026#34;lazy\u0026#34; class=\u0026#34;com.something.ExpensiveToCreateBean\u0026#34; lazy-init=\u0026#34;true\u0026#34;/\u0026gt; 当延迟初始化的 bean 是未延迟初始化的单例 bean 的依赖项时，ApplicationContext 在启动时创建延迟初始化的 bean，因为它必须满足单例的依赖项。\n您还可以通过使用 元素上的 default-lazy-init 属性在容器级别控制延迟初始化，如以下示例所示：\n\u0026lt;beans default-lazy-init=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- no beans will be pre-instantiated... --\u0026gt; \u0026lt;/beans\u0026gt; 自动装配 使用基于 XML 的配置元数据时，您可以使用标签的 autowire 属性为 bean 定义指定自动装配模式。 自动装配功能有四种模：\nno:（默认）没有自动装配。 Bean 引用必须由 ref 元素定义。 对于较大的部署，不建议更改默认设置，因为明确指定协作者可以提供更好的控制和清晰度。 在某种程度上，它记录了系统的结构。 byName:按属性名称自动装配。 Spring 查找与需要自动装配的属性同名的 bean。 例如，如果一个 bean 定义被设置为按名称自动装配并且它包含一个master属性（即它有一个 setMaster(..) 方法），Spring 会查找一个名为 master 的 bean 定义并使用它来设置属性。 byType:如果容器中只存在一个属性类型的 bean，则让属性自动装配。 如果存在多个，则会引发致命异常，这表明您不能为该 bean 使用 byType 自动装配。 如果没有匹配的 bean，则不会发生任何事情（未设置属性）。 constructor:类似于 byType 但适用于构造函数参数。 如果容器中没有一个构造函数参数类型的 bean，则会引发致命错误。 方法注入 单例 bean A 需要使用非单例bean B时，容器只创建单例 bean A 一次，因此只有一次设置属性的机会，容器无法在每次需要时为bean A 提供 bean B 的新实例。\n一个解决方案是放弃一些控制反转。 您可以通过实现 ApplicationContextAware 接口使 bean A 了解容器，并在每次使用 bean A 时通过对容器进行 getBean(\u0026ldquo;B\u0026rdquo;) 调用来请求（通常是新的）bean B 实例。 以下示例显示了这种方法：\n// a class that uses a stateful Command-style class to perform some processing package fiona.apple; // Spring-API imports import org.springframework.beans.BeansException; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; public class CommandManager implements ApplicationContextAware { private ApplicationContext applicationContext; public Object process(Map commandState) { // grab a new instance of the appropriate Command Command command = createCommand(); // set the state on the (hopefully brand new) Command instance command.setState(commandState); return command.execute(); } protected Command createCommand() { // notice the Spring API dependency! return this.applicationContext.getBean(\u0026#34;command\u0026#34;, Command.class); } public void setApplicationContext( ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; } } 但是，这样的代码是不可取的，因为业务代码耦合到 Spring Framework。 方法注入是 Spring IoC 容器的高级的特性，可以让你干净地处理这个用例。\npackage fiona.apple; // no more Spring imports! public abstract class CommandManager { public Object process(Object commandState) { // grab a new instance of the appropriate Command interface Command command = createCommand(); // set the state on the (hopefully brand new) Command instance command.setState(commandState); return command.execute(); } // okay... but where is the implementation of this method? protected abstract Command createCommand(); } spring使用CGLIB 生成子类实现覆盖指定的方法。等同的注解方式：\npublic abstract class CommandManager { public Object process(Object commandState) { Command command = createCommand(); command.setState(commandState); return command.execute(); } @Lookup(\u0026#34;myCommand\u0026#34;) protected abstract Command createCommand(); } bean的scope Spring Framework 支持六个scope，其中四个仅在使用 web 时可用。 您还可以创建自定义scope。\nsingleton：同一容器容器有且只有一个bean。 prototype：容器会创建bean，但是不会添加到容器中管理，因此每次使用就会创建新的。也就说，只管创建，不管销毁，因此只会走初始化流程，销毁流程不会触发，例如销毁的回调机制。 request：将单个 bean 定义范围限定为单个 HTTP 请求的生命周期。 也就是说，每个 HTTP 请求都有自己的 bean 实例。 @RequestScope session：将单个 bean 定义范围限定为 HTTP 会话的生命周期。@SessionScope application：将单个 bean 定义范围限定为 ServletContext 的生命周期。 @ApplicationScope websocket：将单个 bean 定义范围限定为 WebSocket 的生命周期。 如果你想将一个 HTTP 请求范围的 bean 注入到另一个生命周期更长的 bean 中，可以使用AOP 代理来代替该范围的 bean。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:aop=\u0026#34;http://www.springframework.org/schema/aop\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop https://www.springframework.org/schema/aop/spring-aop.xsd\u0026#34;\u0026gt; \u0026lt;!-- an HTTP Session-scoped bean exposed as a proxy --\u0026gt; \u0026lt;bean id=\u0026#34;userPreferences\u0026#34; class=\u0026#34;com.something.UserPreferences\u0026#34; scope=\u0026#34;session\u0026#34;\u0026gt; \u0026lt;!-- instructs the container to proxy the surrounding bean --\u0026gt; \u0026lt;aop:scoped-proxy/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- a singleton-scoped bean injected with a proxy to the above bean --\u0026gt; \u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;com.something.SimpleUserService\u0026#34;\u0026gt; \u0026lt;!-- a reference to the proxied userPreferences bean --\u0026gt; \u0026lt;property name=\u0026#34;userPreferences\u0026#34; ref=\u0026#34;userPreferences\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 在这个例子中，当一个 UserManager 实例在依赖注入的 UserPreferences 对象上调用一个方法时，它实际上是在调用代理上的一个方法。然后代理从（在这种情况下）HTTP 会话中获取真实的 UserPreferences 对象，并将方法调用委托给检索到的真实 UserPreferences 对象。\n自定义scope 实现 org.springframework.beans.factory.config.Scope 接口： public interface Scope { Object get(String name, ObjectFactory\u0026lt;?\u0026gt; objectFactory); @Nullable Object remove(String name); void registerDestructionCallback(String name, Runnable callback); @Nullable Object resolveContextualObject(String key); @Nullable String getConversationId(); } 使用自定义scope: Scope threadScope = new SimpleThreadScope(); beanFactory.registerScope(\u0026#34;thread\u0026#34;, threadScope); \u0026lt;bean id=\u0026#34;...\u0026#34; class=\u0026#34;...\u0026#34; scope=\u0026#34;thread\u0026#34;\u0026gt; 自定义bean 生命周期回调 在内部，Spring 框架使用 BeanPostProcessor 实现来处理它可以找到的任何回调接口并调用适当的方法。\n初始化：\n实现org.springframework.beans.factory.InitializingBean接口：耦合spring，不建议 @PostConstruct 注解 指定init-method方法 销毁：\n实现 org.springframework.beans.factory.DisposableBean 接口：耦合spring，不建议 @PreDestroy 注解： 指定destroy-method方法： 如果没有指定生命周期方法，spring默认查找 init()、initialize()、dispose() 等名称的方法作为生命周期回调方法，你可以修改默认名称：\n为同一个 bean 配置的多个生命周期机制，具有不同的初始化方法，调用如下：\n用@PostConstruct 注释的方法 afterPropertiesSet() 由 InitializingBean 回调接口定义 自定义配置的 init() 方法 如果为一个 bean 配置了多个生命周期机制，并且每个机制都配置了不同的方法名称，那么每个配置的方法将按照上面列出的顺序运行。 但是，如果配置了相同的方法名称 ，则该方法将运行一次。\nLifecycle Lifecycle 接口为任何具有自己生命周期要求的对象定义了基本方法：\npublic interface Lifecycle { void start(); void stop(); boolean isRunning(); } 任何 Spring 管理的对象都可以实现 Lifecycle 接口。 然后，当 ApplicationContext 本身接收到启动和停止信号时（例如，对于运行时的停止/重启场景），它会将这些调用级联到该上下文中定义的所有 Lifecycle 实现。 它通过委托给 LifecycleProcessor 来做到这一点，如下面所示：\npublic interface LifecycleProcessor extends Lifecycle { void onRefresh(); void onClose(); } 启动和关闭调用的顺序可能很重要。 如果任何两个对象之间存在“依赖”关系，则依赖方在其依赖之后开始，并在其依赖之前停止。 然而，有时，直接依赖是未知的。 您可能只知道某种类型的对象应该在另一种类型的对象之前开始。 在这些情况下，SmartLifecycle 接口定义了另一个选项，即在其超级接口 Phased 上定义的 getPhase() 方法。 以下清单显示了 Phased 接口的定义：\npublic interface Phased { int getPhase(); } 以下清单显示了 SmartLifecycle 接口的定义：\npublic interface SmartLifecycle extends Lifecycle, Phased { boolean isAutoStartup(); void stop(Runnable callback); } 启动时，Phased最低的对象首先启动。 停止时，遵循相反的顺序。 因此，一个实现 SmartLifecycle 并且其 getPhase() 方法返回 Integer.MIN_VALUE 的对象将是最先启动和最后一个停止的对象。在考虑Phased值时，重要的是要知道任何未实现 SmartLifecycle 的“正常”生命周期对象的默认Phased是 0。因此，任何负Phased值表示对象应该在这些标准组件之前开始（ 在他们之后停止）。\nApplicationContextAware 和BeanNameAware 当 ApplicationContext 创建一个实现 org.springframework.context.ApplicationContextAware 接口的对象实例时，该实例提供了对该 ApplicationContext 的引用。 以下清单显示了 ApplicationContextAware 接口的定义：\npublic interface ApplicationContextAware { void setApplicationContext(ApplicationContext applicationContext) throws BeansException; } 当 ApplicationContext 创建一个实现 org.springframework.beans.factory.BeanNameAware 接口的类时，该类被提供了对在其关联对象定义中定义的名称的引用。 以下清单显示了 BeanNameAware 接口的定义：\npublic interface BeanNameAware { void setBeanName(String name) throws BeansException; } Name Injected Dependency Explained in… ApplicationContextAware Declaring ApplicationContext. ApplicationContextAware and BeanNameAware ApplicationEventPublisherAware Event publisher of the enclosing ApplicationContext. Additional Capabilities of the ApplicationContext BeanClassLoaderAware Class loader used to load the bean classes. Instantiating Beans BeanFactoryAware Declaring BeanFactory. The BeanFactory BeanNameAware Name of the declaring bean. ApplicationContextAware and BeanNameAware LoadTimeWeaverAware Defined weaver for processing class definition at load time. Load-time Weaving with AspectJ in the Spring Framework MessageSourceAware Configured strategy for resolving messages (with support for parametrization and internationalization). Additional Capabilities of the ApplicationContext NotificationPublisherAware Spring JMX notification publisher. Notifications ResourceLoaderAware Configured loader for low-level access to resources. Resources ServletConfigAware Current ServletConfig the container runs in. Valid only in a web-aware Spring ApplicationContext. Spring MVC ServletContextAware Current ServletContext the container runs in. Valid only in a web-aware Spring ApplicationContext. Spring MVC 容器扩展点 使用BeanPostProcessor自定义bean 实例化：new创建了对象\n配置: 完成了依赖解析\n初始化：执行了生命周期方法\npublic interface BeanPostProcessor { @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { return bean; } @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; } } BeanPostProcessor 接口定义了回调方法，您可以实现这些方法来提供您自己的（或覆盖容器的默认）实例化逻辑、依赖解析逻辑等。 如果要在 Spring 容器完成对 bean 的实例化、配置和初始化之后实现一些自定义逻辑，可以插入一个或多个自定义 BeanPostProcessor 实现。\n您可以配置多个 BeanPostProcessor 实例，并且可以通过实现 Ordered 接口控制这些 BeanPostProcessor 实例的运行顺序。\n拦截bean的init callback方法，postProcessBeforeInitialization在init方法之前执行，postProcessAfterInitialization在init方法之后执行。 后处理器可以对 bean 实例执行任何操作，包括完全忽略初始化回调。 bean 后处理器通常检查回调接口，或者用代理包装 bean。 一些 Spring AOP 基础设施类被实现为 bean 后处理器，以提供代理包装逻辑。\nApplicationContext 自动检测实现 BeanPostProcessor 接口的 bean，然后 注册，以便稍后在 bean 创建时调用它们。 Bean 后处理器可以以与任何其他 Bean 相同的方式部署在容器中。\n以编程方式注册 BeanPostProcessor 实例\n虽然推荐的 BeanPostProcessor 注册方法是通过 ApplicationContext 自动检测，但您可以使用 ConfigurableBeanFactory 的addBeanPostProcessor 方法以编程方式注册它们。 当您需要在注册之前评估条件逻辑时，甚至需要在层次结构中的上下文之间复制 bean 后处理器时，这会很有用。 但是请注意，以编程方式添加的 BeanPostProcessor 实例不遵守 Ordered 接口。 在这里，注册的顺序决定了执行的顺序。 另请注意，以编程方式注册的 BeanPostProcessor 实例始终在通过自动检测注册的实例之前处理，而不管任何显式排序。\nBeanPostProcessor 实例和 AOP 自动代理\n实现 BeanPostProcessor 接口的类是特殊的，容器会对其进行不同的处理。 所有 BeanPostProcessor 实例和它们直接引用的 bean 在启动时被实例化，作为 ApplicationContext 的特殊启动阶段的一部分。 接下来，所有 BeanPostProcessor 实例都以排序方式注册并应用于容器中的所有其他 bean。\n因为 AOP 自动代理是作为 BeanPostProcessor 本身实现的，所以 BeanPostProcessor 实例和它们直接引用的 bean 都没有资格进行自动代理，因此，它们没有编织切面。对于任何此类 bean，您应该看到一条信息性日志消息：Bean someBean is not eligible for getting processed by all BeanPostProcessor interfaces (for example: not eligible for auto-proxying)\n如果您使用自动装配或 @Resource将 bean 连接到 BeanPostProcessor，则 Spring 在搜索类型匹配依赖项时可能会访问意外的 bean（它们有可能还没有被自动代理或应用其他 bean后处理）。\n将回调接口或注解与自定义 BeanPostProcessor 实现结合使用是扩展 Spring IoC 容器的常用方法。 一个例子是 Spring 的 AutowiredAnnotationBeanPostProcessor\n使用 BeanFactoryPostProcessor 自定义配置元数据 @FunctionalInterface public interface BeanFactoryPostProcessor { void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException; } 我们要查看的下一个扩展点是 org.springframework.beans.factory.config.BeanFactoryPostProcessor。 此接口的语义与 BeanPostProcessor 的语义相似，但有一个主要区别：BeanFactoryPostProcessor 对 bean 配置元数据进行操作。 也就是说，Spring IoC 容器让 BeanFactoryPostProcessor 读取配置元数据，并可能在容器实例化除 BeanFactoryPostProcessor 实例之外的任何 bean 之前更改它。\n您可以配置多个 BeanFactoryPostProcessor 实例，您可以通过实现实现 Ordered 接口 来控制运行顺序。\nbean 工厂后处理器在 ApplicationContext 中声明时会自动运行，以便将更改应用于定义容器的配置元数据。 Spring 包含许多预定义的 bean 工厂后处理器，例如 PropertyOverrideConfigurer 和 PropertySourcesPlaceholderConfigurer。\n使用 FactoryBean 自定义实例化逻辑 您可以为本身是工厂的对象实现 org.springframework.beans.factory.FactoryBean 接口。\nFactoryBean 接口是 Spring IoC 容器实例化逻辑的可插入点。 如果您有复杂的初始化代码，可以用 Java 更好地表达，而不是（可能）冗长的 XML，您可以创建自己的 FactoryBean，在该类中编写复杂的初始化，然后将您的自定义 FactoryBean 插入到容器中。\nFactoryBean 接口提供了三种方法：\nT getObject()：返回此工厂创建的对象的实例。 实例可能会被共享，这取决于这个工厂是返回单例还是原型。 boolean isSingleton()： 如果此 FactoryBean 返回单例，则返回 true，否则返回 false。 此方法的默认实现返回 true。 Class getObjectType()： 返回 getObject() 方法返回的对象类型，如果类型事先未知，则返回 null。 FactoryBean 概念和接口在 Spring Framework 中的许多地方使用。 超过 50 种 FactoryBean 接口的实现与 Spring 本身一起提供。\n当您需要向容器请求实际的 FactoryBean 实例本身而不是它生成的 bean 时，请在调用 ApplicationContext 的 getBean() 方法时在 bean 的 id 前面加上与符号 (\u0026amp;)。 因此，对于具有 myBean id 的给定 FactoryBean，在容器上调用 getBean(\u0026ldquo;myBean\u0026rdquo;) 会返回 FactoryBean 的产品，而调用 getBean(\u0026quot;\u0026amp;myBean\u0026quot;) 会返回 FactoryBean 实例本身。\n基于注解的方式配置容器 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;context:annotation-config/\u0026gt; \u0026lt;/beans\u0026gt; context:annotation-config/ 元素隐式注册以下后处理器：\nConfigurationClassPostProcessor AutowiredAnnotationBeanPostProcessor CommonAnnotationBeanPostProcessor PersistenceAnnotationBeanPostProcessor EventListenerMethodProcessor @Required ,spring5.1以后废弃\n@Autowired 用在构造函数上：\npublic class MovieRecommender { private final CustomerPreferenceDao customerPreferenceDao; @Autowired public MovieRecommender(CustomerPreferenceDao customerPreferenceDao) { this.customerPreferenceDao = customerPreferenceDao; } // ... } 从 Spring Framework 4.3 开始，如果目标 bean 只定义了一个构造函数，则不再需要在此类构造函数上添加 @Autowired 注释。 但是，如果有多个构造函数可用并且没有默认构造函数，则必须至少用 @Autowired 注释构造函数之一，以便指示容器使用哪个构造函数。\n@Autowired 应用于 setter 方法\npublic class SimpleMovieLister { private MovieFinder movieFinder; @Autowired public void setMovieFinder(MovieFinder movieFinder) { this.movieFinder = movieFinder; } // ... } 应用在任意方法上\npublic class MovieRecommender { private MovieCatalog movieCatalog; private CustomerPreferenceDao customerPreferenceDao; @Autowired public void prepare(MovieCatalog movieCatalog, CustomerPreferenceDao customerPreferenceDao) { this.movieCatalog = movieCatalog; this.customerPreferenceDao = customerPreferenceDao; } // ... } 应用于字段，甚至将其与构造函数混合使用\npublic class MovieRecommender { private final CustomerPreferenceDao customerPreferenceDao; @Autowired private MovieCatalog movieCatalog; @Autowired public MovieRecommender(CustomerPreferenceDao customerPreferenceDao) { this.customerPreferenceDao = customerPreferenceDao; } // ... } 您还可以通过将 @Autowired 注释添加到需要该类型数组的字段或方法来指示 Spring 从 ApplicationContext 提供特定类型的所有 bean：\npublic class MovieRecommender { @Autowired private MovieCatalog[] movieCatalogs; // ... } 这同样适用于类型化集合，如以下示例所示：\npublic class MovieRecommender { private Set\u0026lt;MovieCatalog\u0026gt; movieCatalogs; @Autowired public void setMovieCatalogs(Set\u0026lt;MovieCatalog\u0026gt; movieCatalogs) { this.movieCatalogs = movieCatalogs; } // ... } 如果您希望数组或列表中的项目按特定顺序排序，您的目标 bean 可以实现 org.springframework.core.Ordered 接口或使用 @Order 或标准 @Priority 注释。 否则，它们的顺序遵循容器中相应目标 bean 定义的注册顺序。\n您可以在目标类级别和 @Bean 方法上声明 @Order 注释。\n请注意，标准 javax.annotation.Priority 注释在 @Bean 级别不可用，因为它不能在方法上声明。 它的语义可以通过@Order 值结合@Primary 在每个类型的单个bean 上建模。\n只要预期的键类型是字符串，即使是类型化的 Map 实例也可以自动装配。 映射值包含预期类型的所有 bean，键包含相应的 bean 名称，如以下示例所示：\npublic class MovieRecommender { private Map\u0026lt;String, MovieCatalog\u0026gt; movieCatalogs; @Autowired public void setMovieCatalogs(Map\u0026lt;String, MovieCatalog\u0026gt; movieCatalogs) { this.movieCatalogs = movieCatalogs; } // ... } 默认情况下，当给定注入点没有匹配的候选 bean 时，自动装配失败。 对于声明的数组、集合或映射，至少需要一个匹配元素。\n默认行为是将带注释的方法和字段视为指示所需的依赖项。 您可以更改此行为，如下例所示，通过将不可满足的注入点标记为非必需（即，通过将 @Autowired 中的 required 属性设置为 false），使框架能够跳过不可满足的注入点：\npublic class SimpleMovieLister { private MovieFinder movieFinder; @Autowired(required = false) public void setMovieFinder(MovieFinder movieFinder) { this.movieFinder = movieFinder; } } 如果非必需方法的依赖项（或其依赖项之一，如果有多个参数）不可用，则根本不会调用它。 在这种情况下，根本不会填充非必填字段，而是保留其默认值。\n注入的构造函数和工厂方法参数是一种特殊情况，因为由于 Spring 的构造函数解析算法可能潜在地处理多个构造函数，@Autowired 中的 required 属性具有一些不同的含义。 构造函数和工厂方法参数在默认情况下是有效的，但在单构造函数场景中有一些特殊规则，例如多元素注入点（数组、集合、映射）在没有匹配的 bean 可用时解析为空实例。 这允许一种通用的实现模式，其中所有依赖项都可以在唯一的多参数构造函数中声明——例如，声明为没有 @Autowired 注释的单个公共构造函数。\n或者，您可以通过 Java 8 的 java.util.Optional 表达特定依赖项的非必需性质，如以下示例所示：\npublic class SimpleMovieLister { @Autowired public void setMovieFinder(Optional\u0026lt;MovieFinder\u0026gt; movieFinder) { ... } } 从 Spring Framework 5.0 开始，您还可以使用 @Nullable 注释（任何包中的任何类型 — 例如，来自 JSR-305 的 javax.annotation.Nullable）或仅利用 Kotlin 内置的空安全支持：\npublic class SimpleMovieLister { @Autowired public void setMovieFinder(@Nullable MovieFinder movieFinder) { ... } } 您还可以将 @Autowired 用于众所周知的可解析依赖项的接口：BeanFactory、ApplicationContext、Environment、ResourceLoader、ApplicationEventPublisher 和 MessageSource。 这些接口及其扩展接口（例如 ConfigurableApplicationContext 或 ResourcePatternResolver）会自动解析，无需特殊设置。 以下示例自动装配 ApplicationContext 对象：\npublic class MovieRecommender { @Autowired private ApplicationContext context; public MovieRecommender() { } // ... } @Autowired、@Inject、@Value 和 @Resource 注释由 Spring BeanPostProcessor 实现处理。 这意味着您不能在自己的 BeanPostProcessor 或 BeanFactoryPostProcessor 类型（如果有）中应用这些注释。 这些类型必须使用 XML 或 Spring @Bean 方法显式“连接”。\n@Primary @Primary 表示当多个 bean 是自动装配到单值依赖项的候选者时，应优先考虑特定 bean。 如果候选中恰好存在一个主要 bean，则它成为自动装配的值。\n@Configuration public class MovieConfiguration { @Bean @Primary public MovieCatalog firstMovieCatalog() { ... } @Bean public MovieCatalog secondMovieCatalog() { ... } // ... } public class MovieRecommender { // MovieRecommender 自动装配到 firstMovieCatalog @Autowired private MovieCatalog movieCatalog; // ... } @Qualifier 自动注入时，发现多个候选项，会根据注入项的名称匹配候选bean的名称，如果相同，则注入，否则失败。@Qualifier可以指定这个名称，使两者一致：\npublic class MovieRecommender { @Autowired @Qualifier(\u0026#34;secondMovieCatalog\u0026#34;) private MovieCatalog movieCatalog; // ... } @Qualifier是元注解。\n@Value @Value 通常用于注入外化属性：\n@Configuration @PropertySource(\u0026#34;classpath:application.properties\u0026#34;) //引入属性文件 public class AppConfig { } @Component public class MovieRecommender { private final String catalog; public MovieRecommender(@Value(\u0026#34;${catalog.name}\u0026#34;) String catalog) { this.catalog = catalog; } } Spring 提供了一个默认的宽松嵌入值解析器。 它将尝试解析属性值，如果无法解析，则属性名称（例如 ${catalog.name}）将作为值注入。 如果你想对不存在的值保持严格的控制，你应该声明一个 PropertySourcesPlaceholderConfigurer bean，如下例所示：\n@Configuration public class AppConfig { @Bean public static PropertySourcesPlaceholderConfigurer propertyPlaceholderConfigurer() { return new PropertySourcesPlaceholderConfigurer(); } } 使用 JavaConfig 配置 PropertySourcesPlaceholderConfigurer 时，@Bean 方法必须是静态的。\n如果无法解析任何 ${} 占位符，则使用上述配置可确保 Spring 初始化失败。 也可以使用 setPlaceholderPrefix、setPlaceholderSuffix 或 setValueSeparator 等方法来自定义占位符。\nSpring Boot 默认配置一个 PropertySourcesPlaceholderConfigurer bean，它将从 application.properties 和 application.yml 文件中获取属性。\nSpring 提供的内置转换器支持允许自动处理简单的类型转换（例如到 Integer 或 int）。 多个逗号分隔的值可以自动转换为 String 数组，无需额外的努力。可以提供如下默认值：\n@Component public class MovieRecommender { private final String catalog; public MovieRecommender(@Value(\u0026#34;${catalog.name:defaultCatalog}\u0026#34;) String catalog) { this.catalog = catalog; } } Spring BeanPostProcessor 在幕后使用 ConversionService 来处理将 @Value 中的 String 值转换为目标类型的过程。 如果您想为您自己的自定义类型提供转换支持，您可以提供您自己的 ConversionService bean 实例，如下例所示：\n@Configuration public class AppConfig { @Bean public ConversionService conversionService() { DefaultFormattingConversionService conversionService = new DefaultFormattingConversionService(); conversionService.addConverter(new MyCustomConverter()); return conversionService; } } 当 @Value 包含 SpEL 表达式时，该值将在运行时动态计算，如下例所示：\n@Component public class MovieRecommender { private final String catalog; public MovieRecommender(@Value(\u0026#34;#{systemProperties[\u0026#39;user.catalog\u0026#39;] + \u0026#39;Catalog\u0026#39; }\u0026#34;) String catalog) { this.catalog = catalog; } } SpEL 还支持使用更复杂的数据结构：\n@Component public class MovieRecommender { private final Map\u0026lt;String, Integer\u0026gt; countOfMoviesPerCatalog; public MovieRecommender( @Value(\u0026#34;#{{\u0026#39;Thriller\u0026#39;: 100, \u0026#39;Comedy\u0026#39;: 300}}\u0026#34;) Map\u0026lt;String, Integer\u0026gt; countOfMoviesPerCatalog) { this.countOfMoviesPerCatalog = countOfMoviesPerCatalog; } } 扫描并注册bean 您可以使用注释（例如@Component）、AspectJ 类型表达式或您自己的自定义过滤条件来选择哪些类具有向容器注册的 bean 定义。\n@Component @Component是元注解，基于此派生了@Service 和 @Controller和 @Repository。被 @Component及其派生注解标注的类，都会被扫描，然后被spring注册成bean，则默认 bean 名称是开头小写的非限定类名称,开启扫描：\n@Configuration @ComponentScan(basePackages = \u0026#34;org.example\u0026#34;) public class AppConfig { // ... } xml替代：\n\u0026lt;context:component-scan base-package=\u0026#34;org.example\u0026#34;/\u0026gt; context:component-scan 的使用隐式启用了 context:annotation-config 的功能。 使用 context:component-scan 时，通常不需要包含 context:annotation-config 元素。\n此外，当您使用组件扫描元素时， AutowiredAnnotationBeanPostProcessor 和 CommonAnnotationBeanPostProcessor 都隐式包含在内。 您可以通过包含值为 false 的 annotation-config 属性来禁用 AutowiredAnnotationBeanPostProcessor 和 CommonAnnotationBeanPostProcessor 的注册。\n@ComponentScan 注释的 includeFilters 或 excludeFilters 属性定义扫描的范围（或作为 XML 配置中 context:component-scan 元素的 \u0026lt;context:include-filter /\u0026gt; 或 \u0026lt;context:exclude-filter /\u0026gt; 子元素）。 每个过滤器元素都需要 type 和 expression 属性。 下表描述了过滤选项：\nFilter Type Example Expression Description annotation (default) org.example.SomeAnnotation An annotation to be present or meta-present at the type level in target components. assignable org.example.SomeClass A class (or interface) that the target components are assignable to (extend or implement). aspectj org.example..*Service+ An AspectJ type expression to be matched by the target components. regex org\\.example\\.Default.* A regex expression to be matched by the target components\u0026rsquo; class names. custom org.example.MyTypeFilter A custom implementation of the org.springframework.core.type.TypeFilter interface. @Configuration @ComponentScan(basePackages = \u0026#34;org.example\u0026#34;, includeFilters = @Filter(type = FilterType.REGEX, pattern = \u0026#34;.*Stub.*Repository\u0026#34;), excludeFilters = @Filter(Repository.class)) public class AppConfig { // ... } 在组件中定义 Bean 元数据 可以在@Component标注的类中定义bean元数据：\n@Component public class FactoryMethodComponent { private static int i; @Bean @Qualifier(\u0026#34;public\u0026#34;) public TestBean publicInstance() { return new TestBean(\u0026#34;publicInstance\u0026#34;); } // use of a custom qualifier and autowiring of method parameters @Bean protected TestBean protectedInstance( @Qualifier(\u0026#34;public\u0026#34;) TestBean spouse, @Value(\u0026#34;#{privateInstance.age}\u0026#34;) String country) { TestBean tb = new TestBean(\u0026#34;protectedInstance\u0026#34;, 1); tb.setSpouse(spouse); tb.setCountry(country); return tb; } @Bean private TestBean privateInstance() { return new TestBean(\u0026#34;privateInstance\u0026#34;, i++); } @Bean @RequestScope public TestBean requestScopedInstance() { return new TestBean(\u0026#34;requestScopedInstance\u0026#34;, 3); } } 您可以将@Bean 方法声明为静态方法，允许在不将其包含的配置类创建为实例的情况下调用它们。 这在定义后处理器 bean（例如，BeanFactoryPostProcessor 或 BeanPostProcessor 类型）时特别有意义，因为此类 bean 在容器生命周期的早期被初始化，并且应避免在那时触发配置的其他部分。\n由于技术限制，对静态 @Bean 方法的调用永远不会被容器拦截，即使在 @Configuration 类中也不行：CGLIB 子类化只能覆盖非静态方法。\n@Bean 方法的 Java 语言可见性不会对 Spring 容器中生成的 bean 定义产生直接影响。 您可以在非@Configuration 类以及任何地方的静态方法中自由地声明您认为合适的工厂方法。 但是，@Configuration 类中的常规@Bean 方法需要是可覆盖的 — 也就是说，它们不能被声明为private 或final。\n@Bean 方法也可以在给定组件或配置类的基类上发现，以及在组件或配置类实现的接口中声明的 Java 8 默认方法上。 这为组合复杂的配置安排提供了很大的灵活性，甚至可以通过 Java 8 默认方法（从 Spring 4.2 开始）进行多重继承。\n最后，单个类可以为同一个 bean 保存多个 @Bean 方法，作为多个工厂方法的安排，根据运行时的可用依赖项使用。 这与在其他配置场景中选择“最贪婪”的构造函数或工厂方法的算法相同：在构造时选择具有最多可满足依赖项的变体，类似于容器如何在多个 @Autowired 构造函数之间进行选择。\n实现BeanNameGenerator接口，重新定义注册的bean名称 ：\n@Configuration @ComponentScan(basePackages = \u0026#34;org.example\u0026#34;, nameGenerator = MyNameGenerator.class) public class AppConfig { // ... } 由于bean名称是简单类名，可能出现重复的情况，您可能需要配置一个 BeanNameGenerator，该 BeanNameGenerator 默认为该类的完全限定类名，spring提供了FullyQualifiedAnnotationBeanNameGenerator。\n@Scope @Scope 用在类上或@Bean方法上，要为范围解析提供自定义策略而不是依赖基于注释的方法，您可以实现 ScopeMetadataResolver 接口：\n@Configuration @ComponentScan(basePackages = \u0026#34;org.example\u0026#34;, scopeResolver = MyScopeResolver.class) public class AppConfig { // ... } 虽然类路径扫描非常快，但可以通过在编译时创建一个静态候选列表来提高大型应用程序的启动性能。 需要添加依赖：\ndependencies { annotationProcessor \u0026#34;org.springframework:spring-context-indexer:5.3.10\u0026#34; } spring-context-indexer 生成一个 META-INF/spring.components 文件，该文件包含在 jar 文件中。当在类路径上找到 META-INF/spring.components 文件时，索引会自动启用。\n基于java代码配置bean 完整的@Configuration 与“轻量级”@Bean 模式？\n当 @Bean 方法在没有用 @Configuration 注释的类中声明时，它们被称为在“精简”模式下处理。 在@Component 声明的 Bean 方法被认为是“轻量级”的。 例如，@Component类上声明的@Bean 方法向容器公开管理视图。 在这种情况下，@Bean 方法是一种通用的工厂方法机制。\n与完整的@Configuration 不同，lite @Bean 方法不能声明 bean 间的依赖关系。 因此，这样的 @Bean 方法不应调用其他 @Bean 方法。 每个这样的方法实际上只是特定 bean 引用的工厂方法，没有任何特殊的运行时语义。 这样的好处是声明的bean不会被 CGLIB 代理。\n在常见情况下，@Bean 方法将在 @Configuration 类中声明，确保始终使用“完整”模式，多次调用bean方法，只会生成一个实例。\nSpring 3.0 中引入的 AnnotationConfigApplicationContext，不仅能够接受 @Configuration 类作为输入，还能够接受普通的 @Component 类和用 JSR-330 元数据注释的类。\n@Configuration 类本身被注册为一个 bean 定义，并且该类中所有声明的 @Bean 方法也被注册为 bean 定义。\npublic static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(AppConfig.class); MyService myService = ctx.getBean(MyService.class); myService.doStuff(); } @Configuration @Configuration 是一个类级别的注解，通过@Bean 注释的方法声明bean，对@Bean 方法的调用也可用于定义bean 间的依赖关系：\n@Configuration public class AppConfig { @Bean public BeanOne beanOne() { return new BeanOne(beanTwo()); } @Bean public BeanTwo beanTwo() { return new BeanTwo(); } } 这种声明 bean 间依赖关系的方法只有在 @Configuration 类中声明了 @Bean 方法时才有效。 您不能使用普通的 @Component 类来声明 bean 间的依赖关系。\n查找方法注入是一项您应该很少使用的高级功能。 在单例范围的 bean 依赖于原型范围的 bean 的情况下，它很有用。\npublic abstract class CommandManager { public Object process(Object commandState) { // grab a new instance of the appropriate Command interface Command command = createCommand(); // set the state on the (hopefully brand new) Command instance command.setState(commandState); return command.execute(); } // okay... but where is the implementation of this method? protected abstract Command createCommand(); } @Bean @Scope(\u0026#34;prototype\u0026#34;) public AsyncCommand asyncCommand() { AsyncCommand command = new AsyncCommand(); // inject dependencies here as required return command; } @Bean public CommandManager commandManager() { // return new anonymous implementation of CommandManager with createCommand() // overridden to return a new prototype Command object return new CommandManager() { protected Command createCommand() { return asyncCommand(); } } } @Configuration public class AppConfig { @Bean public ClientService clientService1() { ClientServiceImpl clientService = new ClientServiceImpl(); clientService.setClientDao(clientDao()); return clientService; } @Bean public ClientService clientService2() { ClientServiceImpl clientService = new ClientServiceImpl(); clientService.setClientDao(clientDao()); return clientService; } @Bean public ClientDao clientDao() { return new ClientDaoImpl(); } } clientDao()方法被调用了两次，但是返回了相同的实例。：所有@Configuration 类在启动时使用 CGLIB 进行子类化。 在子类中，子方法在调用父方法并创建新实例之前，首先检查容器中是否有任何缓存的（作用域）bean。\n@Import注解 @Import 注释允许从另一个配置类加载 @Bean 定义：\n@Configuration public class ConfigA { @Bean public A a() { return new A(); } } @Configuration @Import(ConfigA.class) public class ConfigB { @Bean public B b() { return new B(); } } 现在，无需在实例化上下文时同时指定 ConfigA.class 和 ConfigB.class，只需显式提供 ConfigB，如下例所示：\npublic static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(ConfigB.class); // now both beans A and B will be available... A a = ctx.getBean(A.class); B b = ctx.getBean(B.class); } 从 Spring Framework 4.2 开始，@Import 还支持对常规组件类的引用，类似于 AnnotationConfigApplicationContext.register 方法。 如果您想避免组件扫描，这将特别有用，通过使用一些配置类作为入口点来显式定义所有组件。\n跨类引用bean:\n@Configuration public class ServiceConfig { @Bean public TransferService transferService(AccountRepository accountRepository) { return new TransferServiceImpl(accountRepository); } } @Configuration public class RepositoryConfig { @Bean public AccountRepository accountRepository(DataSource dataSource) { return new JdbcAccountRepository(dataSource); } } @Configuration @Import({ServiceConfig.class, RepositoryConfig.class}) public class SystemTestConfig { @Bean public DataSource dataSource() { // return new DataSource } } public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SystemTestConfig.class); // everything wires up across configuration classes... TransferService transferService = ctx.getBean(TransferService.class); transferService.transfer(100.00, \u0026#34;A123\u0026#34;, \u0026#34;C456\u0026#34;); } 还有另一种方法可以达到相同的结果，@Configuration 类最终只是容器中的另一个 bean：这意味着它们可以利用 @Autowired 和 @Value 注入配置类，然后调用相关bean方法。\n确保您以这种方式注入的依赖项只是最简单的类型。 @Configuration 类在上下文的初始化过程中被处理得很早，并且强制以这种方式注入依赖项可能会导致意外的早期初始化。 尽可能使用基于参数的注入，如前面的示例所示。\n另外，通过@Bean 定义 BeanPostProcessor 和 BeanFactoryPostProcessor 时要特别小心。 这些通常应该声明为静态@Bean 方法，而不是触发包含它们的配置类的实例化。 否则，@Autowired 和@Value 可能不适用于配置类本身，因为可能在 AutowiredAnnotationBeanPostProcessor 之前将其创建为 bean 实例。\n以下示例显示了如何将一个 bean 自动装配到另一个 bean：\n@Configuration public class ServiceConfig { @Autowired private AccountRepository accountRepository; @Bean public TransferService transferService() { return new TransferServiceImpl(accountRepository); } } @Configuration public class RepositoryConfig { private final DataSource dataSource; public RepositoryConfig(DataSource dataSource) { this.dataSource = dataSource; } @Bean public AccountRepository accountRepository() { return new JdbcAccountRepository(dataSource); } } @Configuration @Import({ServiceConfig.class, RepositoryConfig.class}) public class SystemTestConfig { @Bean public DataSource dataSource() { // return new DataSource } } public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(SystemTestConfig.class); // everything wires up across configuration classes... TransferService transferService = ctx.getBean(TransferService.class); transferService.transfer(100.00, \u0026#34;A123\u0026#34;, \u0026#34;C456\u0026#34;); } 但是上面方式，开发人员无法直接看到AccountRepository注入的详情，可以通过下面的方式：\n@Configuration public class ServiceConfig { @Autowired private RepositoryConfig repositoryConfig; @Bean public TransferService transferService() { // navigate \u0026#39;through\u0026#39; the config class to the @Bean method! return new TransferServiceImpl(repositoryConfig.accountRepository()); } } java配置和xml配置混合使用 Spring 的 @Configuration 类支持并不旨在 100% 完全替代 Spring XML，大多数情况下，两者都是混合使用的。\nxml为主，@Configuration 类辅助：\n@Configuration public class AppConfig { @Autowired private DataSource dataSource; @Bean public AccountRepository accountRepository() { return new JdbcAccountRepository(dataSource); } @Bean public TransferService transferService() { return new TransferService(accountRepository()); } } \u0026lt;beans\u0026gt; \u0026lt;!-- enable processing of annotations such as @Autowired and @Configuration --\u0026gt; \u0026lt;context:annotation-config/\u0026gt; \u0026lt;context:property-placeholder location=\u0026#34;classpath:/com/acme/jdbc.properties\u0026#34;/\u0026gt; \u0026lt;bean class=\u0026#34;com.acme.AppConfig\u0026#34;/\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.jdbc.datasource.DriverManagerDataSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;${jdbc.url}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${jdbc.username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${jdbc.password}\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; @Configuration为主，xml为辅：\n@Configuration @ImportResource(\u0026#34;classpath:/com/acme/properties-config.xml\u0026#34;) public class AppConfig { @Value(\u0026#34;${jdbc.url}\u0026#34;) private String url; @Value(\u0026#34;${jdbc.username}\u0026#34;) private String username; @Value(\u0026#34;${jdbc.password}\u0026#34;) private String password; @Bean public DataSource dataSource() { return new DriverManagerDataSource(url, username, password); } } \u0026lt;beans\u0026gt; \u0026lt;context:property-placeholder location=\u0026#34;classpath:/com/acme/jdbc.properties\u0026#34;/\u0026gt; \u0026lt;/beans\u0026gt; 环境抽象 Environment 接口是集成在容器中的抽象，它对应用程序环境的两个关键方面进行建模：配置文件和属性。\n配置文件是一个命名的、逻辑的 bean 定义组，仅当给定的配置文件处于活动状态时才向容器注册。 Bean 可以分配给配置文件，无论是在 XML 中定义还是使用注释。 与配置文件相关的环境对象的作用是确定哪些配置文件（如果有）当前是活动的，以及默认情况下哪些配置文件（如果有）应该是活动的。 属性在几乎所有应用程序中都扮演着重要的角色，并且可能来自各种来源：属性文件、JVM 系统属性、系统环境变量、JNDI、servlet 上下文参数、ad-hoc Properties 对象、Map 对象等等。 与属性相关的 Environment 对象的作用是为用户提供方便的服务接口，用于配置属性源并从中解析属性。 @Profile @Profile（元注解） 注解实际上是通过@Conditional 来实现的:\n@Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { // Read the @Profile annotation attributes MultiValueMap\u0026lt;String, Object\u0026gt; attrs = metadata.getAllAnnotationAttributes(Profile.class.getName()); if (attrs != null) { for (Object value : attrs.get(\u0026#34;value\u0026#34;)) { if (context.getEnvironment().acceptsProfiles(((String[]) value))) { return true; } } return false; } return true; } 示例：\n@Configuration @Profile(\u0026#34;development\u0026#34;) public class StandaloneDataConfig { @Bean public DataSource dataSource() { return new EmbeddedDatabaseBuilder() .setType(EmbeddedDatabaseType.HSQL) .addScript(\u0026#34;classpath:com/bank/config/sql/schema.sql\u0026#34;) .addScript(\u0026#34;classpath:com/bank/config/sql/test-data.sql\u0026#34;) .build(); } } @Configuration @Profile(\u0026#34;production\u0026#34;) public class JndiDataConfig { @Bean(destroyMethod=\u0026#34;\u0026#34;) public DataSource dataSource() throws Exception { Context ctx = new InitialContext(); return (DataSource) ctx.lookup(\u0026#34;java:comp/env/jdbc/datasource\u0026#34;); } } @Profile支持一些简单的表达式：\n!: A logical “not” of the profile \u0026amp;: A logical “and” of the profiles |: A logical “or” of the profiles @Profile可以声明在方法级别上：\n@Configuration public class AppConfig { @Bean(\u0026#34;dataSource\u0026#34;) @Profile(\u0026#34;development\u0026#34;) public DataSource standaloneDataSource() { return new EmbeddedDatabaseBuilder() .setType(EmbeddedDatabaseType.HSQL) .addScript(\u0026#34;classpath:com/bank/config/sql/schema.sql\u0026#34;) .addScript(\u0026#34;classpath:com/bank/config/sql/test-data.sql\u0026#34;) .build(); } @Bean(\u0026#34;dataSource\u0026#34;) @Profile(\u0026#34;production\u0026#34;) public DataSource jndiDataSource() throws Exception { Context ctx = new InitialContext(); return (DataSource) ctx.lookup(\u0026#34;java:comp/env/jdbc/datasource\u0026#34;); } } 代码操作profile:\nctx.getEnvironment().setActiveProfiles(\u0026#34;profile1\u0026#34;, \u0026#34;profile2\u0026#34;); jvm参数指定profile:\n-Dspring.profiles.active=\u0026#34;profile1,profile2\u0026#34; 默认配置文件代表默认启用的配置文件。 考虑以下示例：\n@Configuration @Profile(\u0026#34;default\u0026#34;) public class DefaultDataConfig { @Bean public DataSource dataSource() { return new EmbeddedDatabaseBuilder() .setType(EmbeddedDatabaseType.HSQL) .addScript(\u0026#34;classpath:com/bank/config/sql/schema.sql\u0026#34;) .build(); } } 您可以通过在 Environment 上使用 setDefaultProfiles() 或声明性地使用 spring.profiles.default 属性来更改默认配置文件的名称。\nPropertySource 抽象 spring对属性操作是通过Environment接口实现的：\nApplicationContext ctx = new GenericApplicationContext(); Environment env = ctx.getEnvironment(); boolean containsMyProperty = env.containsProperty(\u0026#34;my-property\u0026#34;); System.out.println(\u0026#34;Does my environment contain the \u0026#39;my-property\u0026#39; property? \u0026#34; + containsMyProperty); Spring 的 StandardEnvironment 配置了两个 PropertySource 对象 : 一个表示 JVM 系统属性集（System.getProperties()）和一个表示系统环境变量集（ System.getenv())。\n执行的搜索是分层的。 默认情况下，系统属性优先于环境变量。 因此，如果在调用 env.getProperty(\u0026ldquo;my-property\u0026rdquo;) 期间碰巧在两个地方都设置了 my-property 属性，则系统属性值“获胜”并返回。 请注意，属性值不会合并，而是被前面的条目完全覆盖。\n对于常见的 StandardServletEnvironment，完整的层次结构如下，最高优先级的条目位于顶部：\nServletConfig 参数（如果适用 — 例如，在 DispatcherServlet 上下文的情况下） ServletContext 参数（web.xml 上下文参数条目） JNDI 环境变量（java:comp/env/ 条目） JVM 系统属性（-D 命令行参数） JVM系统环境（操作系统环境变量） 最重要的是，整个机制是可配置的。 也许您有想要集成到此搜索中的自定义属性源。 为此，请实现并实例化您自己的 PropertySource，并将其添加到当前环境的 PropertySource 集中。 以下示例显示了如何执行此操作：\nConfigurableApplicationContext ctx = new GenericApplicationContext(); MutablePropertySources sources = ctx.getEnvironment().getPropertySources(); sources.addFirst(new MyPropertySource()); @PropertySource 注解可以代替上面的代码：\n@Configuration @PropertySource(\u0026#34;classpath:/com/myco/app.properties\u0026#34;) public class AppConfig { @Autowired Environment env; @Bean public TestBean testBean() { TestBean testBean = new TestBean(); testBean.setName(env.getProperty(\u0026#34;testbean.name\u0026#34;)); return testBean; } } @PropertySource支持占位符：\n@Configuration @PropertySource(\u0026#34;classpath:/com/${my.placeholder:default/path}/app.properties\u0026#34;) public class AppConfig { @Autowired Environment env; @Bean public TestBean testBean() { TestBean testBean = new TestBean(); testBean.setName(env.getProperty(\u0026#34;testbean.name\u0026#34;)); return testBean; } } ApplicationContext其他功能 使用 MessageSource 进行国际化 ApplicationContext 接口扩展了一个名为 MessageSource 的接口，因此提供了国际化（“i18n”）功能。 Spring 还提供了 HierarchicalMessageSource 接口，可以分层解析消息。 这些接口一起提供了 Spring 影响消息解析的基础。 在这些接口上定义的方法包括：\nString getMessage(String code, Object[] args, String default, Locale loc)：用于从 MessageSource 检索消息的基本方法。 如果没有找到指定语言环境的消息，则使用默认消息。 使用标准库提供的 MessageFormat 功能，传入的任何参数都成为替换值。 String getMessage(String code, Object[] args, Locale loc)：与前面的方法基本相同，但有一个区别：不能指定默认消息。 如果找不到消息，则抛出 NoSuchMessageException。 String getMessage(MessageSourceResolvable resolvable, Locale locale)：上述方法中使用的所有属性也都封装在一个名为 MessageSourceResolvable 的类中，您可以在此方法中使用该类。 加载 ApplicationContext 时，它会自动搜索上下文中定义的 MessageSource bean。 bean 必须具有名称 messageSource。 如果找到这样的 bean，则对上述方法的所有调用都将委托给消息源。 如果未找到消息源，则 ApplicationContext 会尝试查找包含同名 bean 的父级。 如果是，则使用该 bean 作为 MessageSource。 如果 ApplicationContext 找不到任何消息源，则会实例化一个空的 DelegatingMessageSource，以便能够接受对上面定义的方法的调用。\nSpring 提供了三个 MessageSource 实现，ResourceBundleMessageSource、ReloadableResourceBundleMessageSource 和 StaticMessageSource。 它们都实现 HierarchicalMessageSource 以进行嵌套消息传递。 StaticMessageSource 很少使用，但提供了向源添加消息的编程方式。 以下示例显示了 ResourceBundleMessageSource：\n\u0026lt;beans\u0026gt; \u0026lt;bean id=\u0026#34;messageSource\u0026#34; class=\u0026#34;org.springframework.context.support.ResourceBundleMessageSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;basenames\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;format\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;exceptions\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;windows\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 该示例假设您在类路径中定义了三个名为 format、exceptions 和 windows 的资源包。 任何解析消息的请求都以 JDK 标准的方式通过 ResourceBundle 对象解析消息来处理。 出于示例的目的，假设上述两个资源包文件的内容如下：\n# in format.properties message=Alligators rock! # in exceptions.properties argument.required=The {0} argument is required. 下一个示例显示了一个运行 MessageSource 功能的程序。 请记住，所有 ApplicationContext 实现也是 MessageSource 实现，因此可以转换为 MessageSource 接口:\npublic static void main(String[] args) { MessageSource resources = new ClassPathXmlApplicationContext(\u0026#34;beans.xml\u0026#34;); String message = resources.getMessage(\u0026#34;message\u0026#34;, null, \u0026#34;Default\u0026#34;, Locale.ENGLISH); System.out.println(message); } 总而言之，MessageSource 是在名为 beans.xml 的文件中定义的，该文件位于类路径的根目录中。 messageSource bean 定义通过其 basenames 属性引用了许多资源包。 在列表中传递给 basenames 属性的三个文件作为文件存在于类路径的根目录中，分别称为 format.properties、exceptions.properties 和 windows.properties。\n下一个示例显示传递给消息查找的参数。 这些参数被转换为 String 对象并插入到查找消息中的占位符中。\n\u0026lt;beans\u0026gt; \u0026lt;!-- this MessageSource is being used in a web application --\u0026gt; \u0026lt;bean id=\u0026#34;messageSource\u0026#34; class=\u0026#34;org.springframework.context.support.ResourceBundleMessageSource\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;basename\u0026#34; value=\u0026#34;exceptions\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- lets inject the above MessageSource into this POJO --\u0026gt; \u0026lt;bean id=\u0026#34;example\u0026#34; class=\u0026#34;com.something.Example\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;messages\u0026#34; ref=\u0026#34;messageSource\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; public class Example { private MessageSource messages; public void setMessages(MessageSource messages) { this.messages = messages; } public void execute() { String message = this.messages.getMessage(\u0026#34;argument.required\u0026#34;, new Object [] {\u0026#34;userDao\u0026#34;}, \u0026#34;Required\u0026#34;, Locale.ENGLISH); System.out.println(message); } } 调用 execute() 方法的结果输出如下：\nThe userDao argument is required. 关于国际化（“i18n”），Spring 的各种 MessageSource 实现遵循与标准 JDK ResourceBundle 相同的区域设置解析和回退规则。 简而言之，并继续之前定义的示例 messageSource，如果您想根据英国 (en-GB) 语言环境解析消息，您将分别创建名为 format_en_GB.properties、exceptions_en_GB.properties 和 windows_en_GB.properties 的文件。\n通常，区域设置解析由应用程序的周围环境管理。 在以下示例中，手动指定解析（英国）消息所针对的区域设置：\n# in exceptions_en_GB.properties argument.required=Ebagum lad, the \u0026#39;\u0026#39;{0}\u0026#39;\u0026#39; argument is required, I say, required. public static void main(final String[] args) { MessageSource resources = new ClassPathXmlApplicationContext(\u0026#34;beans.xml\u0026#34;); String message = resources.getMessage(\u0026#34;argument.required\u0026#34;, new Object [] {\u0026#34;userDao\u0026#34;}, \u0026#34;Required\u0026#34;, Locale.UK); System.out.println(message); } 运行上述程序的结果如下：\nEbagum lad, the \u0026#39;userDao\u0026#39; argument is required, I say, required. 您还可以使用 MessageSourceAware 接口获取对已定义的任何 MessageSource 的引用。 创建和配置 bean 时，在实现 MessageSourceAware 接口的 ApplicationContext 中定义的任何 bean 都会注入应用程序上下文的 MessageSource。\n因为 Spring 的 MessageSource 基于 Java 的 ResourceBundle，所以它不会合并具有相同基名的 bundle，而只会使用找到的第一个 bundle。 具有相同基本名称的后续消息包将被忽略。\n作为 ResourceBundleMessageSource 的替代方案，Spring 提供了一个 ReloadableResourceBundleMessageSource 类。 此变体支持相同的包文件格式，但比基于标准 JDK 的 ResourceBundleMessageSource 实现更灵活。 特别是，它允许从任何 Spring 资源位置（不仅从类路径）读取文件，并支持包属性文件的热重载（同时在它们之间有效地缓存它们）。 有关详细信息，请参阅 ReloadableResourceBundleMessageSource javadoc。\n标准和自定义事件 ApplicationContext 中的事件处理是通过 ApplicationEvent 类和 ApplicationListener 接口提供的。 如果将实现 ApplicationListener 接口的 bean 部署到上下文中，则每次将 ApplicationEvent 发布到 ApplicationContext 时，都会通知该 bean。 本质上，这是标准的观察者设计模式。\nEvent Explanation ContextRefreshedEvent 在 ApplicationContext 初始化或刷新时发布（例如，通过使用 ConfigurableApplicationContext 接口上的 refresh() 方法）。 这里，“初始化”意味着所有 bean 都被加载，后处理器 bean 被检测并激活，单例被预实例化，ApplicationContext 对象准备好使用。 只要上下文尚未关闭，就可以多次触发刷新，前提是所选的 ApplicationContext 实际上支持这种“热”刷新。 例如，XmlWebApplicationContext 支持热刷新，但 GenericApplicationContext 不支持。 ContextStartedEvent 使用 ConfigurableApplicationContext 接口上的 start() 方法启动 ApplicationContext 时发布。 在这里，“已启动”意味着所有“Lifecycle”bean 都收到一个明确的启动信号。 通常，此信号用于在显式停止后重新启动 bean，但它也可用于启动尚未配置为自动启动的组件（例如，尚未在初始化时启动的组件）。 ContextStoppedEvent 使用 ConfigurableApplicationContext 接口上的 stop() 方法停止 ApplicationContext 时发布。 在这里，“停止”意味着所有“Lifecycle”bean 都收到一个明确的停止信号。 停止的上下文可以通过start() 调用重新启动。 ContextClosedEvent 当使用ConfigurableApplicationContext 接口上的close() 方法或通过JVM 关闭挂钩关闭ApplicationContext 时发布。 在这里，“关闭”意味着所有的单例 bean 都将被销毁。 一旦上下文关闭，它就会到达生命的尽头，无法刷新或重新启动。 RequestHandledEvent 一个网络特定的事件，告诉所有的bean一个HTTP请求已经被服务。请求完成后，该事件被发布。此事件仅适用于使用Spring的DispatcherServlet Web应用程序。 ServletRequestHandledEvent RequestHandledEvent 的子类，用于添加特定于 Servlet 的上下文信息。 您还可以创建和发布自己的自定义事件。 以下示例显示了一个扩展 Spring 的 ApplicationEvent 基类的简单类：\npublic class BlockedListEvent extends ApplicationEvent { private final String address; private final String content; public BlockedListEvent(Object source, String address, String content) { super(source); this.address = address; this.content = content; } // accessor and other methods... } 要发布自定义 ApplicationEvent，请在 ApplicationEventPublisher 上调用 publishEvent() 方法。 通常，这是通过创建一个实现 ApplicationEventPublisherAware 的类并将其注册为 Spring bean 来完成的。 以下示例显示了这样一个类：\npublic class EmailService implements ApplicationEventPublisherAware { private List\u0026lt;String\u0026gt; blockedList; private ApplicationEventPublisher publisher; public void setBlockedList(List\u0026lt;String\u0026gt; blockedList) { this.blockedList = blockedList; } public void setApplicationEventPublisher(ApplicationEventPublisher publisher) { this.publisher = publisher; } public void sendEmail(String address, String content) { if (blockedList.contains(address)) { publisher.publishEvent(new BlockedListEvent(this, address, content)); return; } // send email... } } 配置时，Spring容器检测到EmailService实现了ApplicationEventPublisherAware，并自动调用setApplicationEventPublisher()。 实际上，传入的参数是Spring容器本身。 您正在通过其 ApplicationEventPublisher 接口与应用程序上下文进行交互。\n要接收自定义 ApplicationEvent，您可以创建一个实现 ApplicationListener 的类并将其注册为 Spring bean。 以下示例显示了这样一个类：\npublic class BlockedListNotifier implements ApplicationListener\u0026lt;BlockedListEvent\u0026gt; { private String notificationAddress; public void setNotificationAddress(String notificationAddress) { this.notificationAddress = notificationAddress; } public void onApplicationEvent(BlockedListEvent event) { // notify appropriate parties via notificationAddress... } } 请注意，ApplicationListener 通常使用自定义事件的类型（在前面的示例中为 BlockedListEvent）进行参数化。 这意味着 onApplicationEvent() 方法可以保持类型安全，避免任何向下转换的需要。 您可以根据需要注册任意数量的事件侦听器，但请注意，默认情况下，事件侦听器会同步接收事件。 这意味着 publishEvent() 方法会阻塞，直到所有侦听器都完成对事件的处理。 这种同步和单线程方法的一个优点是，当侦听器接收到事件时，如果事务上下文可用，它就会在发布者的事务上下文中运行。 如果需要另一种事件发布策略，请参阅 Spring 的 ApplicationEventMulticaster 接口和 SimpleApplicationEventMulticaster 实现的 javadoc 以了解配置选项。\n以下示例显示了用于注册和配置上述每个类的 bean 定义：\n\u0026lt;bean id=\u0026#34;emailService\u0026#34; class=\u0026#34;example.EmailService\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;blockedList\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;known.spammer@example.org\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;known.hacker@example.org\u0026lt;/value\u0026gt; \u0026lt;value\u0026gt;john.doe@example.org\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;blockedListNotifier\u0026#34; class=\u0026#34;example.BlockedListNotifier\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;notificationAddress\u0026#34; value=\u0026#34;blockedlist@example.org\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 总而言之，当调用 emailService bean 的 sendEmail() 方法时，如果有任何电子邮件消息应该被阻止，则会发布一个 BlockedListEvent 类型的自定义事件。 BlockedListNotifier bean 注册为 ApplicationListener 并接收 BlockedListEvent，此时它可以通知适当的各方。\nSpring 的事件机制是为同一应用程序上下文中 Spring bean 之间的简单通信而设计的。 然而，对于更复杂的企业集成需求，单独维护的 Spring Integration 项目为构建基于众所周知的 Spring 编程模型的轻量级、面向模式、事件驱动的体系结构提供了完整的支持。\n基于注解的事件监听器 您可以使用 @EventListener 注释在托管 bean 的任何方法上注册事件侦听器。 BlockedListNotifier 可以重写如下：\n@Compoent public class BlockedListNotifier { private String notificationAddress; public void setNotificationAddress(String notificationAddress) { this.notificationAddress = notificationAddress; } @EventListener public void processBlockedListEvent(BlockedListEvent event) { // notify appropriate parties via notificationAddress... } } 方法签名再次声明了它侦听的事件类型，但这次使用了灵活的名称并且没有实现特定的侦听器接口。 只要实际事件类型在其实现层次结构中解析您的泛型参数，也可以通过泛型缩小事件类型。\n如果您的方法应该侦听多个事件，或者您想定义它时根本不带参数，则还可以在注释本身上指定事件类型。 以下示例显示了如何执行此操作：\n@EventListener({ContextStartedEvent.class, ContextRefreshedEvent.class}) public void handleContextStart() { // ... } 还可以通过使用定义 SpEL 表达式的注释的条件属性添加额外的运行时过滤，该表达式应该匹配以实际调用特定事件的方法。以下示例显示了如何重写我们的通知程序以仅在事件的内容属性等于 my-event 时才被调用：\n@EventListener(condition = \u0026#34;#blEvent.content == \u0026#39;my-event\u0026#39;\u0026#34;) public void processBlockedListEvent(BlockedListEvent blEvent) { // notify appropriate parties via notificationAddress... } 每个 SpEL 表达式都针对专用上下文进行评估。 下表列出了可用于上下文的项目，以便您可以将它们用于条件事件处理：\nName Location Description Example Event root object The actual ApplicationEvent. #root.event or event Arguments array root object The arguments (as an object array) used to invoke the method. #root.args or args; args[0] to access the first argument, etc. Argument name evaluation context The name of any of the method arguments. If, for some reason, the names are not available (for example, because there is no debug information in the compiled byte code), individual arguments are also available using the #a\u0026lt;#arg\u0026gt; syntax where \u0026lt;#arg\u0026gt; stands for the argument index (starting from 0). #blEvent or #a0 (you can also use #p0 or #p\u0026lt;#arg\u0026gt; parameter notation as an alias) 请注意，#root.event 可让您访问底层事件，即使您的方法签名实际上是指已发布的任意对象。\n如果您需要发布一个事件作为处理另一个事件的结果，您可以更改方法签名以返回应该发布的事件，如以下示例所示：\n@EventListener public ListUpdateEvent handleBlockedListEvent(BlockedListEvent event) { // notify appropriate parties via notificationAddress and // then publish a ListUpdateEvent... } handleBlockedListEvent() 方法为它处理的每个 BlockedListEvent 发布一个新的 ListUpdateEvent。 如果您需要发布多个事件，则可以返回一个集合或事件数组。\n异步监听 如果您希望特定的侦听器异步处理事件，则可以重用常规的 @Async 支持。 以下示例显示了如何执行此操作：\n@EventListener @Async public void processBlockedListEvent(BlockedListEvent event) { // BlockedListEvent is processed in a separate thread } 使用异步事件时请注意以下限制：\n如果异步事件侦听器抛出异常，则不会将其传播给调用者。 有关更多详细信息，请参阅 AsyncUncaughtExceptionHandler。\n异步事件侦听器方法无法通过返回值来发布后续事件。 如果您需要发布另一个事件作为处理结果，请注入 ApplicationEventPublisher 以手动发布事件。\n监听器的顺序 如果您需要在另一个侦听器之前调用一个侦听器，则可以在方法声明中添加 @Order 注释，如下例所示：\n@EventListener @Order(42) public void processBlockedListEvent(BlockedListEvent event) { // notify appropriate parties via notificationAddress... } 泛型事件 您还可以使用泛型进一步定义事件的结构。 考虑使用 EntityCreatedEvent ，其中 T 是创建的实际实体的类型。 例如，您可以创建以下侦听器定义以仅接收 Person 的 EntityCreatedEvent：\n@EventListener public void onPersonCreated(EntityCreatedEvent\u0026lt;Person\u0026gt; event) { // ... } 由于类型擦除，这仅在被触发的事件解析事件侦听器过滤的通用参数时才有效（即类 PersonCreatedEvent extends EntityCreatedEvent { \u0026hellip; }）。\n在某些情况下，如果所有事件都遵循相同的结构（如前面示例中的事件应该是这种情况），这可能会变得非常乏味。 在这种情况下，您可以实现 ResolvableTypeProvider 来指导框架超出运行时环境提供的范围。 以下事件显示了如何执行此操作：\npublic class EntityCreatedEvent\u0026lt;T\u0026gt; extends ApplicationEvent implements ResolvableTypeProvider { public EntityCreatedEvent(T entity) { super(entity); } @Override public ResolvableType getResolvableType() { return ResolvableType.forClassWithGenerics(getClass(), ResolvableType.forInstance(getSource())); } } 便捷访问底层资源 为了最佳地使用和理解应用程序上下文，您应该熟悉 Spring 的 Resource 抽象，如参考资料中所述。\n应用程序上下文是一个 ResourceLoader，可用于加载 Resource 对象。 资源本质上是 JDK java.net.URL 类的功能更丰富的版本。 事实上，Resource 的实现在适当的地方包装了一个 java.net.URL 的实例。 Resource 可以以透明的方式从几乎任何位置获取低级资源，包括从类路径、文件系统位置、用标准 URL 描述的任何位置以及其他一些变体。 如果资源位置字符串是一个没有任何特殊前缀的简单路径，那么这些资源的来源是特定的并且适合实际的应用程序上下文类型。\n您可以将部署到应用程序上下文中的 bean 配置为实现特殊的回调接口 ResourceLoaderAware，以在初始化时自动回调应用程序上下文本身作为 ResourceLoader 传入。 您还可以公开 Resource 类型的属性，用于访问静态资源。 它们像任何其他属性一样被注入其中。 您可以将这些 Resource 属性指定为简单的 String 路径，并在部署 bean 时依赖于从这些文本字符串到实际 Resource 对象的自动转换。\n提供给 ApplicationContext 构造函数的位置路径或路径实际上是资源字符串，并且以简单的形式根据特定的上下文实现进行适当处理。 例如 ClassPathXmlApplicationContext 将简单的位置路径视为类路径位置。 您还可以使用带有特殊前缀的位置路径（资源字符串）来强制从类路径或 URL 加载定义，而不管实际的上下文类型。\npackage cn.zhao.beans; import org.springframework.beans.BeansException; import org.springframework.beans.factory.InitializingBean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.context.SmartLifecycle; import org.springframework.stereotype.Service; @Service public class TestImpl implements ITest, ApplicationContextAware, InitializingBean, SmartLifecycle { private User user; public TestImpl() { System.err.println(\u0026#34;constructor \u0026#34;); } @Autowired public void setUser(User user) { System.err.println(\u0026#34;setter \u0026#34;); this.user = user; } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { System.err.println(\u0026#34;set context\u0026#34;); } @Override public void afterPropertiesSet() throws Exception { System.err.println(\u0026#34;init \u0026#34;); } @Override public void start() { System.err.println(\u0026#34;start ... \u0026#34;); } @Override public void stop() { System.err.println(\u0026#34;stop\u0026#34;); } @Override public boolean isRunning() { return true; } } public class ApplicationTest2 { public static void main(String[] args) throws InterruptedException { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(AppConfig.class); applicationContext.start(); applicationContext.getBean(ITest.class); System.err.println(\u0026#34;get bean end\u0026#34;); Thread.sleep(10000); applicationContext.stop(); System.err.println(\u0026#34;容器 stop\u0026#34;); applicationContext.start(); System.err.println(\u0026#34;容器 start2\u0026#34;); applicationContext.close(); System.err.println(\u0026#34;容器 close\u0026#34;); Thread.sleep(10000); } } appConfig before... appConfig after... constructor user before... user after... setter set context testImpl before... init testImpl after... get bean end stop 容器 stop 容器 start2 stop 容器 close ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring%E5%AE%B9%E5%99%A8/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"},{"title":"spring","url":"/myblog/tags/spring/"}],"timestamp":1669982550,"title":"Spring容器"},{"authors":[],"categories":[{"title":"java","url":"/myblog/categories/java/"},{"title":"spring-boot","url":"/myblog/categories/spring-boot/"}],"content":"Spring Boot Admin codecentric 的 Spring Boot Admin 是一个社区项目，用于管理和监控您的 Spring Boot ® 应用程序。 应用程序使用 Spring Boot Admin Client 向我们注册（通过 HTTP）或使用 Spring Cloud （例如 Eureka、Consul）被发现。\n使用 Pyctuator 可以支持 Python 应用程序。\n快速开始 安装Spring Boot Admin Server 首先，您需要设置您的服务器。 为此，只需设置一个简单的启动项目（使用 start.spring.io）。 Spring Boot Admin Server 能够作为 servlet 或 webflux 应用程序运行，你可以根据需要添加相应的 Spring Boot Starter。 在这个例子中，我们使用了 servlet web starter：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;de.codecentric\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-admin-starter-server\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.0-M3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 然后，在配置类上添加@EnableAdminServer注解\n@Configuration @EnableAutoConfiguration @EnableAdminServer public class SpringBootAdminApplication { public static void main(String[] args) { SpringApplication.run(SpringBootAdminApplication.class, args); } } 注册客户端 要在 SBA 服务器上注册您的应用程序，您可以包含 SBA 客户端或使用 Spring Cloud Discovery（例如 Eureka、Consul \u0026hellip;\u0026hellip;）。 还有一个在 SBA 服务器端使用静态配置的简单选项。\n客户端方式 每个想要注册的应用程序都必须包含 Spring Boot Admin Client。 为了保护端点，还要添加 spring-boot-starter-security。 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;de.codecentric\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-admin-starter-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.0-M3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 通过配置 Spring Boot Admin Server 的 URL 来启用 SBA Client： spring.boot.admin.client.url=http://localhost:8080 management.endpoints.web.exposure.include=* management.info.env.enabled=true 要注册的 Spring Boot 管理服务器的 URL。 与 Spring Boot 2 一样，默认情况下大多数端点都不会通过 http 公开，我们将它们全部公开。 对于生产，您应该仔细选择要公开的端点。 从 Spring Boot 2.6 开始，默认情况下禁用 env info 。 因此，我们必须启用它。 使执行器端点可访问： @Configuration public static class SecurityPermitAllConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests().anyRequest().permitAll() .and().csrf().disable(); } } 为简洁起见，我们现在禁用安全性。更适合生产的配置请参考安全配置部分。\n服务发现方式 如果您已经将 Spring Cloud Discovery 用于您的应用程序，则不需要 SBA 客户端。 只需在 Spring Boot Admin Server 中添加一个 DiscoveryClient，其余的由我们的 AutoConfiguration 完成。\n以下步骤使用 Eureka，但也支持其他 Spring Cloud Discovery 实现。\n添加依赖： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${eureka-client.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 启用服务发现配置 @Configuration @EnableAutoConfiguration @EnableDiscoveryClient @EnableScheduling @EnableAdminServer public class SpringBootAdminApplication { public static void main(String[] args) { SpringApplication.run(SpringBootAdminApplication.class, args); } @Configuration public static class SecurityPermitAllConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests().anyRequest().permitAll() .and().csrf().disable(); } } } 配置服务发现 eureka: instance: leaseRenewalIntervalInSeconds: 10 health-check-url-path: /actuator/health metadata-map: startup: ${random.int} #needed to trigger info and endpoint update after restart client: registryFetchIntervalSeconds: 5 serviceUrl: defaultZone: ${EUREKA_SERVICE_URL:http://localhost:8761}/eureka/ management: endpoints: web: exposure: include: \u0026#34;*\u0026#34; endpoint: health: show-details: ALWAYS 客户端 显示应用版本信息 对于 Spring Boot 应用程序，显示版本的最简单方法是使用 spring-boot-maven-plugin 中的 build-info 目标，该目标生成 META-INF/build-info.properties。 另请参阅 Spring Boot 参考指南。\n对于非 Spring Boot 应用程序，您可以将版本或 build.version 添加到注册元数据，版本将显示在应用程序列表中。\n\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;build-info\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; springBoot { buildInfo() } JMX-beans 管理 要在管理 UI 中与 JMX-bean 交互，您必须在应用程序中包含 Jolokia。 由于 Jolokia 是基于 servlet 的，因此不支持反应式应用程序。 如果您使用的是 spring-boot-admin-starter-client ，它将为您提取，如果没有将 Jolokia 添加到您的依赖项中。 对于 Spring Boot 2.2.0，如果您想通过 JMX 公开 Spring bean，您可能需要设置 spring.jmx.enabled=true。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.jolokia\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jolokia-core\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 日志文件查看器 默认情况下，日志文件无法通过执行器端点访问，因此在 Spring Boot Admin 中不可见。 为了启用日志文件执行器端点，您需要通过设置 logging.file.path 或 logging.file.name 来配置 Spring Boot 以写入日志文件。\nSpring Boot Admin 将检测所有看起来像 URL 的内容并将其呈现为超链接。\n还支持 ANSI 颜色转义。 您需要设置自定义文件日志模式，因为 Spring Boot 的默认模式不使用颜色。\n要强制使用 ANSI 彩色输出，请设置 spring.output.ansi.enabled=ALWAYS。 否则 Spring 会尝试检测 ANSI 彩色输出是否可用，并可能禁用它。\nlogging.file.name=/var/log/sample-boot-application.log logging.pattern.file=%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(%5p) %clr(${PID}){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n%wEx 显示标签 标签是为每个实例添加视觉标记的一种方式，它们将出现在应用程序列表以及实例视图中。 默认情况下，不会向实例添加标签，由客户端通过将信息添加到元数据或info端点来指定所需的标签。\n#using the metadata spring.boot.admin.client.instance.metadata.tags.environment=test #using the info endpoint info.tags.environment=test Spring Boot Admin Client Spring Boot Admin Client 在管理服务器上注册应用程序。 这是通过定期向 SBA 服务器发出 HTTP 发布请求来提供有关应用程序的信息来完成的。\nProperty name Description Default value spring.boot.admin.client.enabled 是否启用 Spring Boot Admin Client. true spring.boot.admin.client.url 逗号分隔的 要注册的 Spring Boot 管理服务器的 URL 的有序列表。 这会触发自动配置。 强制的。 spring.boot.admin.client.api-path 管理服务器上注册端点的 Http 路径。 \u0026ldquo;instances\u0026rdquo; spring.boot.admin.client.usernamespring.boot.admin.client.password 如果 SBA 服务器 api 受 HTTP 基本身份验证保护，则用户名和密码。 spring.boot.admin.client.period 重复注册的时间间隔（以毫秒为单位）。 10,000 spring.boot.admin.client.connect-timeout 注册连接超时（以毫秒为单位）。 5,000 spring.boot.admin.client.read-timeout 注册的读取超时（以毫秒为单位）。 5,000 spring.boot.admin.client.auto-registration 如果设置为 true，则在应用程序准备好后自动安排注册应用程序的定期任务。 true spring.boot.admin.client.auto-deregistration 当上下文关闭时，切换以在 Spring Boot 管理服务器上启用自动注销。 如果未设置该值，则如果检测到正在运行的 CloudPlatform，则该功能处于活动状态。 null spring.boot.admin.client.register-once 如果设置为 true，客户端将只注册一个管理服务器（按 spring.boot.admin.instance.url 定义的顺序）； 如果该管理服务器出现故障，将自动注册到下一个管理服务器。 如果为 false，将对所有管理服务器进行注册。 true spring.boot.admin.client.instance.health-url 注册的健康网址。 如果可访问的 URL 不同（例如 Docker），则可以覆盖。 在注册表中必须是唯一的。 根据 management-url 和 endpoints.health.id 猜测 spring.boot.admin.client.instance.management-base-url 用于计算要注册的管理 URL 的基本 URL。 该路径在运行时推断，并附加到基本 url。 根据 management.port、service-url 和 server.servlet-path 猜测。 spring.boot.admin.client.instance.management-url 要注册的管理网址。 如果可访问的 url 不同（例如 Docker），可以覆盖。 根据 management-base-url 和 management.context-path 猜测。 spring.boot.admin.client.instance.service-base-url 用于计算要注册的服务 url 的基本 url。 该路径在运行时推断，并附加到基本 url。 在 Cloudfoundry 环境中，您可以像这样切换到 https：spring.boot.admin.client.instance.service-base-url=https://${vcap.application.uris[0]} 根据主机名 server.port 猜测。 spring.boot.admin.client.instance.service-url 要注册的服务网址。 如果可访问的 url 不同（例如 Docker），可以覆盖。 根据 service-base-url 和 server.context-path 猜测。 spring.boot.admin.client.instance.service-path 注册的服务路径。 如果可达路径不同（例如，以编程方式设置的上下文路径），则可以覆盖。 / spring.boot.admin.client.instance.name 要注册的名称。 ${spring.application.name} 如果设置，否则为“spring-boot-application”。 spring.boot.admin.client.instance.service-host-type 选择发送服务主机时应考虑哪些信息：* IP：使用 InetAddress.getHostAddress() 返回的 IP* HOST_NAME：使用 InetAddress.getHostName() 返回的单台机器的主机名* CANONICAL_HOST_NAME：使用 InetAddress.geCanonicalHostName() 返回的 FQDN如果在服务中设置了 server.address 或 management.address，则该值将覆盖该属性。 CANONICAL_HOST_NAME spring.boot.admin.client.instance.metadata.* 要与此实例关联的元数据键值对。 spring.boot.admin.client.instance.metadata.tags.* 要与此实例关联的标签键值对。 服务端 在代理服务器后面运行 如果 Spring Boot Admin 服务器在反向代理后面运行，则可能需要配置 (spring.boot.admin.ui.public-url) 公共 url。 另外当反向代理终止https连接时，可能需要配置server.forward-headers-strategy=native（另见Spring Boot参考指南）。\n配置项 Property name Description Default value spring.boot.admin.server.enabled 启用Spring Boot Admin Server. true spring.boot.admin.context-path context-path 为应该提供 Admin Server 静态资产和 API 的路径添加前缀。 相对于 Dispatcher-Servlet。 spring.boot.admin.monitor.status-interval 检查实例状态的时间间隔。 10,000ms spring.boot.admin.monitor.status-lifetime 状态的生命周期。 只要最后一个状态没有过期，状态就不会更新。 10,000ms spring.boot.admin.monitor.info-interval 检查实例信息的时间间隔。 1m spring.boot.admin.monitor.info-lifetime 信息的生命周期。 只要最后一个信息没有过期，信息就不会更新。 1m spring.boot.admin.monitor.default-timeout 发出请求时的默认超时。 可以使用 spring.boot.admin.monitor.timeout.* 覆盖特定端点的各个值。 10,000 spring.boot.admin.monitor.timeout.* 每个 endpointId 具有超时的键值对。 默认为default-timeout。 spring.boot.admin.monitor.default-retries 失败请求的默认重试次数。 永远不会重试修改请求（PUT、POST、PATCH、DELETE）。 可以使用 spring.boot.admin.monitor.retries.* 覆盖特定端点的各个值。 0 spring.boot.admin.monitor.retries.* spring.boot.admin.metadata-keys-to-sanitize 匹配这些正则表达式模式的键的元数据值将在所有 json 输出中进行清理。 \u0026quot;.**password$\u0026quot;, \u0026quot;.*secret$\u0026quot;, \u0026quot;.*key$\u0026quot;, \u0026quot;.*token$\u0026quot;, \u0026quot;.*credentials.**\u0026quot;, \u0026quot;.*vcap_services$\u0026quot; spring.boot.admin.probed-endpoints 对于 Spring Boot 1.x 客户端应用程序，SBA 使用 OPTIONS 请求探测指定端点。 如果路径与 id 不同，您可以将其指定为 id:path (例如 health:ping).. \u0026ldquo;health\u0026rdquo;, \u0026ldquo;env\u0026rdquo;, \u0026ldquo;metrics\u0026rdquo;, \u0026ldquo;httptrace:trace\u0026rdquo;, \u0026ldquo;threaddump:dump\u0026rdquo;, \u0026ldquo;jolokia\u0026rdquo;, \u0026ldquo;info\u0026rdquo;, \u0026ldquo;logfile\u0026rdquo;, \u0026ldquo;refresh\u0026rdquo;, \u0026ldquo;flyway\u0026rdquo;, \u0026ldquo;liquibase\u0026rdquo;, \u0026ldquo;heapdump\u0026rdquo;, \u0026ldquo;loggers\u0026rdquo;, \u0026ldquo;auditevents\u0026rdquo; spring.boot.admin.instance-auth.enabled 启用从 spring 配置属性中提取凭据 true spring.boot.admin.instance-auth.default-user-name 用于对注册服务进行身份验证的默认用户名。 spring.boot.admin.instance-auth.enabled 属性必须为 true。 null spring.boot.admin.instance-auth.default-password 用于对注册服务进行身份验证的默认用户密码。 spring.boot.admin.instance-auth.enabled 属性必须为 true。 null spring.boot.admin.instance-auth.service-map.*.user-name 用于向具有指定名称的注册服务进行身份验证的用户名。 spring.boot.admin.instance-auth.enabled 属性必须为 true。 spring.boot.admin.instance-auth.service-map.*.user-password 用于向具有指定名称的注册服务进行身份验证的用户密码。 spring.boot.admin.instance-auth.enabled 属性必须为 true。 spring.boot.admin.instance-proxy.ignored-headers 向客户端发出请求时不转发标头。 \u0026ldquo;Cookie\u0026rdquo;, \u0026ldquo;Set-Cookie\u0026rdquo;, \u0026ldquo;Authorization\u0026rdquo; spring.boot.admin.ui.public-url 用于在 ui 中构建基本 href 的基本 url。 If running behind a reverse proxy (using path rewriting) this can be used to make correct self references. If the host/port is omitted it will be inferred from the request. spring.boot.admin.ui.brand 要在导航栏中显示的品牌。 \u0026ldquo;Spring Boot Admin\u0026rdquo; spring.boot.admin.ui.title 要显示的页面标题。 \u0026ldquo;Spring Boot Admin\u0026rdquo; spring.boot.admin.ui.login-icon 图标用作登录页面上的图像。 \u0026ldquo;assets/img/icon-spring-boot-admin.svg\u0026rdquo; spring.boot.admin.ui.favicon 用作桌面通知的默认图标。 \u0026ldquo;assets/img/favicon.png\u0026rdquo; spring.boot.admin.ui.favicon-danger 当一项或多项服务关闭时用作图标图标并用于桌面通知。 \u0026ldquo;assets/img/favicon-danger.png\u0026rdquo; spring.boot.admin.ui.remember-me-enabled 切换以显示/隐藏登录页面上的记住我复选框。 true spring.boot.admin.ui.poll-timer.cache 以毫秒为单位的轮询持续时间以获取新的缓存数据。 2500 spring.boot.admin.ui.poll-timer.datasource 以毫秒为单位的轮询持续时间以获取新的数据源数据。 2500 spring.boot.admin.ui.poll-timer.gc 以毫秒为单位的轮询持续时间以获取新的 gc 数据。 2500 spring.boot.admin.ui.poll-timer.process 以毫秒为单位的轮询持续时间以获取新的流程数据。 2500 spring.boot.admin.ui.poll-timer.memory 以毫秒为单位的轮询持续时间以获取新的内存数据。 2500 spring.boot.admin.ui.poll-timer.threads 以毫秒为单位的轮询持续时间以获取新的线程数据。 2500 Spring Cloud Discovery Spring Boot Admin Server 可以使用 Spring Clouds DiscoveryClient 来发现应用程序。 优点是客户端不必包含 spring-boot-admin-starter-client。 您只需将 DiscoveryClient 实现添加到您的管理服务器 - 其他一切都由 AutoConfiguration 完成。\n使用 SimpleDiscoveryClient 的静态配置 Spring Cloud 提供了一个 SimpleDiscoveryClient。 它允许您通过静态配置指定客户端应用程序：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; spring: cloud: discovery: client: simple: instances: test: - uri: http://instance1.intern:8080 metadata: management.context-path: /actuator - uri: http://instance2.intern:8080 metadata: management.context-path: /actuator 通知 邮件通知 邮件通知将作为使用 Thymeleaf 模板呈现的 HTML 电子邮件发送。 要启用邮件通知，请使用 spring-boot-starter-mail 配置 JavaMailSender 并设置收件人。\n添加依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-mail\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置JavaMailSender spring.mail.host=smtp.example.com spring.boot.admin.notify.mail.to=admin@example.com Property name Description Default value spring.boot.admin.notify.mail.enabled Enable mail notifications true spring.boot.admin.notify.mail.ignore-changes 要忽略的状态更改的逗号分隔列表。 格式： ”：”。 允许使用通配符。 \u0026ldquo;UNKNOWN:UP\u0026rdquo; spring.boot.admin.notify.mail.template 用于渲染的 Thymeleaf 模板的资源路径。 \u0026ldquo;classpath:/META-INF/spring-boot-admin-server/mail/status-changed.html\u0026rdquo; spring.boot.admin.notify.mail.to 以逗号分隔的邮件收件人列表 \u0026ldquo;root@localhost\u0026rdquo; spring.boot.admin.notify.mail.cc 以逗号分隔的抄送收件人列表 spring.boot.admin.notify.mail.from Mail sender \u0026ldquo;Spring Boot Admin noreply@localhost\u0026rdquo; spring.boot.admin.notify.mail.additional-properties 可以从模板访问的其他属性 安全 ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-boot-admin/","series":[],"smallImg":"","tags":[{"title":"spring-boot","url":"/myblog/tags/spring-boot/"},{"title":"spring-boot-admin","url":"/myblog/tags/spring-boot-admin/"}],"timestamp":1669982280,"title":"Spring-Boot-Admin"},{"authors":[],"categories":[{"title":"java","url":"/myblog/categories/java/"},{"title":"spring","url":"/myblog/categories/spring/"}],"content":"spring batch 核心概念 一个作业有一到多个步骤，每个步骤正好有一个ItemReader、一个ItemProcessor和一个ItemWriter。需要使用JobLauncher启动作业，JobRepository存储关于当前运行作业的元数据。\n作业（Job） 作业是封装整个批处理过程的实体。是整个层次结构的顶部，如下图所示：\n在SpringBatch中，作业只是步骤实例的容器。它将逻辑上属于一个流的多个步骤组合在一起，并允许配置所有步骤的全局属性，例如可重启性。作业配置包含：\n名称 步骤的顺序 作业是否需要重启 对于那些使用Java配置的人，SpringBatch以SimpleJob类的形式提供了作业接口的默认实现，它在作业之上创建了一些标准功能。使用基于java的配置时，可以使用构建器集合来实例化作业，如下例所示：\n@Bean public Job footballJob() { return this.jobBuilderFactory.get(\u0026#34;footballJob\u0026#34;) .start(playerLoad()) .next(gameLoad()) .next(playerSummarization()) .build(); } JobInstance JobInstance是job运行时的概念，这样说可能有些抽象。假如我们有个作业A，在每天快要结束的时候运行。那么一月一日运行该job就会创建一个JobInstance,一月二日则会创建一个新的JobInstance。\n但是，会有这样的情况，一月一日的JobInstance运行失败了，在一月二日会继续运行这个失败的JobInstance,同时一月二日的JobInstance照旧执行。\n因此，JobInstacen可能会多次执行（这是后面的JobExecution概念）。并且在给定时刻只能运行一个对应于特定作业和JobParameters的JobInstance。\nJobInstance的定义与要加载的数据完全没有关系。如何加载数据完全取决于ItemReader实现。使用新的JobInstance意味着“从头开始”，而使用现有实例通常意味着“从您停止的地方开始”。\nJobParameters 如何区分不同的JobInstance呢？答案：JobParameters。JobParameters对象包含一组用于启动批处理作业的参数。它们可用于识别，甚至在运行期间用作参考数据，如下图所示：\n并非所有作业参数都需要用于标识作业实例。默认情况下，它们会这样做。但是，该框架还允许提交带有不影响JobInstance标识的参数的作业。\nJobExecution JobExecution是指一次尝试运行作业的技术概念。执行可能以失败或成功结束，但对应的JobInstance不会被视为已完成，除非执行成功完成。假如任务A第一次执行失败，此时JobInstance会被标记会失败，当下次继续执行这个失败的JobInstance时，如果成功了，就会变更JobInstance为成功。\nJob定义了什么是作业以及如何执行作业，而JobInstance是一个纯粹的组织对象，用于将执行分组在一起，主要是为了实现正确的重启语义。然而，JobExecution是运行期间实际发生的事情的主要存储机制，它包含许多必须控制和持久化的属性，如下表所示：\n属性 定义 Status 指示执行状态的BatchStatus对象。运行时，状态为BatchStatus#STARTED。如果失败，则为BatchStatus#FAILED。如果成功完成，则为BatchStatus#COMPLETED startTime java.util.Date ,表示开始执行的时间，没有执行则为空 endTime java.util.Date,执行结束的时间 exitStatus 执行的结果，空代表还没有结束 createTime java.util.Date,创建的时间 lastUpdated java.util.Date executionContext 属性包，包含在执行之间需要的用户数据。 failureExceptions 作业执行期间遇到的异常列表 这些属性很重要，因为它们是持久化的，可用于完全确定执行状态。例如，如果01-01的EndOfDay作业在晚上9:00执行，但在9:30失败，则在批处理元数据表中创建以下条目：\n为了清晰和格式，列名可能已被缩写或删除。\n表：BATCH_JOB_INSTANCE\nJOB_INST_ID JOB_NAME 1 EndOfDayJob 表：BATCH_JOB_EXECUTION_PARAMS\nJOB_EXECUTION_ID TYPE_CD KEY_NAME DATE_VAL IDENTIFYING 1 DATE schedule.Date 2017-01-01 TRUE 表：BATCH_JOB_EXECUTION\nJOB_EXEC_ID JOB_INST_ID START_TIME END_TIME STATUS 1 1 2017-01-01 21:00 2017-01-01 21:30 FAILED 既然作业失败了，第二天从停止的位置开始，并在9:30成功完成。因为现在是第二天，01-02作业也必须运行，然后在9:31开始，并在10:30以正常的一小时时间完成。没有要求一个jobinstance一个接一个地启动，除非两个作业可能尝试访问相同的数据，从而导致数据库级别的锁定问题。作业何时运行完全取决于调度程序。由于它们是独立的JobInstance，SpringBatch不会试图阻止它们并发运行。（在另一个JobInstance已在运行时尝试运行同一个JobInstance会导致引发JobExecutionAlreadyRunningException）。现在，JobInstance和JobParameters表中都应该有一个新的条目，JobExecution表中应该有两个新的条目，如下表所示：\n表：BATCH_JOB_INSTANCE\nJOB_INST_ID JOB_NAME 1 EndOfDayJob 2 EndOfDayJob 表：BATCH_JOB_EXECUTION_PARAMS\nJOB_EXECUTION_ID TYPE_CD KEY_NAME DATE_VAL IDENTIFYING 1 DATE schedule.Date 2017-01-01 00:00:00 TRUE 2 DATE schedule.Date 2017-01-01 00:00:00 TRUE 3 DATE schedule.Date 2017-01-02 00:00:00 TRUE 表：BATCH_JOB_EXECUTION_PARAMS\nJOB_EXEC_ID JOB_INST_ID START_TIME END_TIME STATUS 1 1 2017-01-01 21:00 2017-01-01 21:30 FAILED 2 1 2017-01-02 21:00 2017-01-02 21:30 COMPLETED 3 2 2017-01-02 21:31 2017-01-02 22:29 Step步骤 步骤是封装批处理作业的独立、连续阶段的域对象。因此，每个作业都完全由一个或多个步骤组成。步骤包含定义和控制实际批处理所需的所有信息。这必然是一个模糊的描述，因为任何给定步骤的内容都由编写作业的开发人员自行决定。\nStepExecution StepExecution表示一次执行步骤的尝试。每次运行一个步骤时都会创建一个新的StepExecution，类似于JobExecution。但是，如果某个步骤由于之前的步骤失败而无法执行，则不会为其保留任何执行记录。步骤执行仅在其步骤实际启动时创建。\n每个执行对象都持有对应步骤和JobExecution的引用以及与事务相关的数据，例如提交和回滚计数以及开始和结束时间。此外，每个步骤执行都包含一个ExecutionContext，其中包含开发人员需要在批处理运行期间保留的任何数据，例如重新启动所需的统计信息或状态信息。下表列出了步骤执行的属性：\nProperty Definition Status 指示执行状态的BatchStatus对象。运行时，状态为BatchStatus#STARTED。如果失败，则为BatchStatus#FAILED。如果成功完成，则为BatchStatus#COMPLETED startTime java.util.Date ,表示开始执行的时间，没有执行则为空 endTime java.util.Date,执行结束的时间 exitStatus 执行的结果，空代表还没有结束 executionContext 属性包，包含在执行之间需要的用户数据。 readCount 成功读取的数量 writeCount 成功写入的数量 commitCount 成功提交的事务数 rollbackCount 步骤控制的业务事务已回滚的次数。 readSkipCount 读取失败的次数，导致跳过项。 processSkipCount 进程失败的次数，导致跳过项。 filterCount 已由ItemProcessor“筛选”的项目数。 writeSkipCount 写入失败的次数，导致跳过项。 ExecutionContext ExecutionContext表示一组键/值对，这些键/值对由框架持久化和控制，以允许开发人员在一个位置存储持久状态，该持久状态的作用域为StepExecution对象或JobExecution对象。对于那些熟悉Quartz的人来说，它与JobDataMap非常相似。最好的用法示例是方便重新启动。以平面文件输入为例，在处理单个行时，框架会定期在提交点持久化ExecutionContext。这样做允许ItemReader存储其状态，以防在运行期间发生致命错误，甚至断电。所需的只是将当前读取的行数放入上下文中，如以下示例所示，框架将完成其余工作：\nexecutionContext.putLong(getKey(LINES_READ_COUNT), reader.getPosition()); 假如作业EndOfDay有步骤loadData，读取文件数据到数据库。当其运行失败，表数据如下：\n表：BATCH_JOB_INSTANCE\nJOB_INST_ID JOB_NAME 1 EndOfDayJob 表：BATCH_JOB_EXECUTION_PARAMS\nJOB_INST_ID TYPE_CD KEY_NAME DATE_VAL 1 DATE schedule.Date 2017-01-01 表：BATCH_JOB_EXECUTION\nJOB_EXEC_ID JOB_INST_ID START_TIME END_TIME STATUS 1 1 2017-01-01 21:00 2017-01-01 21:30 FAILED 表：BATCH_STEP_EXECUTION\nSTEP_EXEC_ID JOB_EXEC_ID STEP_NAME START_TIME END_TIME STATUS 1 1 loadData 2017-01-01 21:00 2017-01-01 21:30 FAILED 表：BATCH_STEP_EXECUTION_CONTEXT\nSTEP_EXEC_ID SHORT_CONTEXT 1 {piece.count=40321} 在前面的例子中，该步骤运行了30分钟，处理了40321个“片段”，在这种情况下，这些片段表示文件中的行。该值在框架每次提交之前更新，可以包含多行与ExecutionContext对应的条目。在提交之前会通知StepListener实现（或ItemStream），本指南后面将详细讨论这些实现。\n与前面的示例一样，假定作业在第二天重新启动。重新启动时，将从数据库中读取上次运行的ExecutionContext中的值来重新构造。打开ItemReader时，它可以检查上下文中是否有任何存储状态，并从中初始化自身，如以下示例所示：\nif (executionContext.containsKey(getKey(LINES_READ_COUNT))) { log.debug(\u0026#34;Initializing for restart. Restart data is: \u0026#34; + executionContext); long lineCount = executionContext.getLong(getKey(LINES_READ_COUNT)); LineReader reader = getReader(); Object record = \u0026#34;\u0026#34;; while (reader.getPosition() \u0026lt; lineCount \u0026amp;\u0026amp; record != null) { record = readLine(); } } 上面的例子中，代码会从文件的40,322行继续读取数据。ExecutionContext 还可以存储自身运行的统计数据。例如，文件中存储的订单信息可能横跨多行，很有必要存储已经处理了多少个订单，当所有数据处理完成之后，发布通知邮件告诉相关人员处理了多少订单。\n还需要注意的是，每个作业执行至少有一个ExecutionContext，每个步骤执行至少有一个ExecutionContext。例如，考虑下面的代码片段：\nExecutionContext ecStep = stepExecution.getExecutionContext(); ExecutionContext ecJob = jobExecution.getExecutionContext(); //ecStep does not equal ecJob JobRepository JobRepository是上述所有原型的持久化机制。它为JobLauncher、Job和Step实现提供CRUD操作。首次启动作业时，将从存储库获取作业执行，并且在执行过程中，通过将步骤执行和作业执行实现传递到存储库来持久化它们。\nSpring批处理XML命名空间支持使用标记配置JobRepository实例，如下例所示：\n\u0026lt;job-repository id=\u0026#34;jobRepository\u0026#34;/\u0026gt; 在使用Java配置时，@EnableBatchProcessing注释提供了一个JobRepository，作为自动配置的现成组件之一。\nJobLauncher JobLauncher表示一个简单的接口，用于启动具有给定JobParameters集的作业，如以下示例所示：\npublic interface JobLauncher { public JobExecution run(Job job, JobParameters jobParameters) throws JobExecutionAlreadyRunningException, JobRestartException, JobInstanceAlreadyCompleteException, JobParametersInvalidException; } Item Reader 和 Item Writer ItemReader是一个抽象，表示一个步骤的输入，一次一个项目。当ItemReader读取到末尾时，它通过返回null来表示这一点。\nItemWriter 表示步骤的输出，一次一批。通常情况下，writer不知道自己下次接受的数据有多少条，只知道在其当前调用中传递的项。\n各种实现的更多详细信息可以在Reader和Writer中找到。\nItem Processor ItemProcessor 用来处理的输入数据。处理项目时，确定该项目无效，返回null表示不应写出该项目。\nBatch Namespace 前面列出的许多域概念都需要在Spring ApplicationContext中配置。虽然上述接口的实现可以在标准bean定义中使用，但为了便于配置，提供了一个名称空间，如下例所示：\n\u0026lt;beans:beans xmlns=\u0026#34;http://www.springframework.org/schema/batch\u0026#34; xmlns:beans=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34; http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/batch https://www.springframework.org/schema/batch/spring-batch.xsd\u0026#34;\u0026gt; \u0026lt;job id=\u0026#34;ioSampleJob\u0026#34;\u0026gt; \u0026lt;step id=\u0026#34;step1\u0026#34;\u0026gt; \u0026lt;tasklet\u0026gt; \u0026lt;chunk reader=\u0026#34;itemReader\u0026#34; writer=\u0026#34;itemWriter\u0026#34; commit-interval=\u0026#34;2\u0026#34;/\u0026gt; \u0026lt;/tasklet\u0026gt; \u0026lt;/step\u0026gt; \u0026lt;/job\u0026gt; \u0026lt;/beans:beans\u0026gt; 作业 配置作业 job接口有多种实现，但我们不建议直接创建实体类，而是通过建造者创建：\n@Bean public Job footballJob() { return this.jobBuilderFactory.get(\u0026#34;footballJob\u0026#34;) .start(playerLoad()) .next(gameLoad()) .next(playerSummarization()) .build(); } 作业依赖JobRepository，使用BatchConfigurer配置。\n上面的例子中，配置了三个步骤。和作业相关的builder还可以配置并行（Split）、声明式流程控制（Decision）、外部流程定义（Flow）.\n可重启 执行批处理作业时的一个关键问题是作业重新启动时的行为。如果特定JobInstance已存在JobExecution，则启动作业被视为“重新启动”。理想情况下，所有工作都应该能够在结束后重新启动，但在某些情况下这是不可能的。开发人员完全可以确保在此场景中创建新的JobInstance。然而，SpringBatch确实提供了一些帮助。如果作业永远不应重新启动，但应始终作为新作业实例的一部分运行，则restartable属性可能设置为“false”：\n@Bean public Job footballJob() { return this.jobBuilderFactory.get(\u0026#34;footballJob\u0026#34;) .preventRestart() ... .build(); } 换句话说，将restartable设置为false意味着“此作业不支持再次启动”。重新启动不可重启的作业会引发JobRestartException:\nJob job = new SimpleJob(); job.setRestartable(false); JobParameters jobParameters = new JobParameters(); JobExecution firstExecution = jobRepository.createJobExecution(job, jobParameters); jobRepository.saveOrUpdate(firstExecution); try { jobRepository.createJobExecution(job, jobParameters); fail(); } catch (JobRestartException e) { // expected } 拦截作业的执行 在作业的执行过程中，通知其生命周期中的各种事件可能很有用，以便可以执行自定义代码。SimpleJob通过在适当的时间调用JobListener来实现这一点：\npublic interface JobExecutionListener { void beforeJob(JobExecution jobExecution); void afterJob(JobExecution jobExecution); } 通过在作业上设置侦听器，可以将作业侦听器添加到SimpleJob:\n@Bean public Job footballJob() { return this.jobBuilderFactory.get(\u0026#34;footballJob\u0026#34;) .listener(sampleListener()) ... .build(); } 应该注意的是，不管作业成功与否，都会调用afterJob方法。如果需要确定成功或失败，可以从JobExecution中获得，如下所示：\npublic void afterJob(JobExecution jobExecution){ if (jobExecution.getStatus() == BatchStatus.COMPLETED ) { //job success } else if (jobExecution.getStatus() == BatchStatus.FAILED) { //job failure } } 与此接口对应的注解包括：\n@BeforeJob @AfterJob job参数验证 你可以验证作业的参数信息，有一个DefaultJobParametersValidator，可用于约束简单强制参数和可选参数的组合，对于更复杂的约束，您可以自己实现接口。\n@Bean public Job job1() { return this.jobBuilderFactory.get(\u0026#34;job1\u0026#34;) .validator(parametersValidator()) ... .build(); } @EnableBatchProcessing @EnableBatchProcessing为构建批处理作业提供基本配置，创建以下bean：\nJobRepository: bean name \u0026ldquo;jobRepository\u0026rdquo; JobLauncher: bean name \u0026ldquo;jobLauncher\u0026rdquo; JobRegistry: bean name \u0026ldquo;jobRegistry\u0026rdquo; PlatformTransactionManager: bean name \u0026ldquo;transactionManager\u0026rdquo; JobBuilderFactory: bean name \u0026ldquo;jobBuilders\u0026rdquo; StepBuilderFactory: bean name \u0026ldquo;stepBuilders\u0026rdquo; 此配置的核心接口是BatchConfigurer。默认实现提供了上面提到的bean，并且需要一个数据源作为要提供的上下文中的bean。该数据源被JobRepository使用。您可以通过创建BatchConfigurer接口的自定义实现来自定义这些bean中的任何一个。通常，扩展DefaultBatchConfigurer（在找不到BatchConfigurer时提供）并覆盖所需的getter就足够了。下面是一个示例： @Bean public BatchConfigurer batchConfigurer(DataSource dataSource) { return new DefaultBatchConfigurer(dataSource) { @Override public PlatformTransactionManager getTransactionManager() { return new MyTransactionManager(); } }; } 一旦配置了@EnableBatchProcessing注解，你就可以使用JobBuilderFactory和StepBuilderFactory：\n@Configuration @EnableBatchProcessing @Import(DataSourceConfiguration.class) public class AppConfig { @Autowired private JobBuilderFactory jobs; @Autowired private StepBuilderFactory steps; @Bean public Job job(@Qualifier(\u0026#34;step1\u0026#34;) Step step1, @Qualifier(\u0026#34;step2\u0026#34;) Step step2) { return jobs.get(\u0026#34;myJob\u0026#34;).start(step1).next(step2).build(); } @Bean protected Step step1(ItemReader\u0026lt;Person\u0026gt; reader, ItemProcessor\u0026lt;Person, Person\u0026gt; processor, ItemWriter\u0026lt;Person\u0026gt; writer) { return steps.get(\u0026#34;step1\u0026#34;) .\u0026lt;Person, Person\u0026gt; chunk(10) .reader(reader) .processor(processor) .writer(writer) .build(); } @Bean protected Step step2(Tasklet tasklet) { return steps.get(\u0026#34;step2\u0026#34;) .tasklet(tasklet) .build(); } } 配置JobRepository 使用了@EnableBatchProcessing注解之后，会帮我们自动配置JobRepository。\n如前所述，JobRepository用于Spring批处理中各种持久化域对象的基本CRUD操作，如JobExecution和StepExecution。许多主要框架功能都需要它，例如JobLauncher、Job和Step。\n如果提供了数据源，则提供现成的基于JDBC的数据源，如果没有，则提供基于map的数据源。但是，您可以通过实现BatchConfigurer接口自定义JobRepository的配置:\n... // This would reside in your BatchConfigurer implementation @Override protected JobRepository createJobRepository() throws Exception { JobRepositoryFactoryBean factory = new JobRepositoryFactoryBean(); factory.setDataSource(dataSource); factory.setTransactionManager(transactionManager); factory.setIsolationLevelForCreate(\u0026#34;ISOLATION_SERIALIZABLE\u0026#34;); factory.setTablePrefix(\u0026#34;BATCH_\u0026#34;); factory.setMaxVarCharLength(1000); return factory.getObject(); } ... 除了dataSource和transactionManager之外，上面列出的配置选项都不是必需的。如果未设置，将使用上面显示的默认值。以上所示为了解目的。max varchar length默认为2500，这是示例架构脚本中长varchar列的长度。\n事务配置 如果使用了名称空间或提供的FactoryBean，则会在存储库事务切面。这是为了确保批处理元数据（包括故障后重新启动所需的状态）正确持久化。\ncreate*方法属性中的隔离级别是单独指定的，以确保在启动作业时，如果两个进程试图同时启动同一作业，则只有一个成功。该方法的默认隔离级别是SERIALIZABLE，这是非常激进的。READ_COMMITTED也可以。如果两个进程不太可能以这种方式发生冲突，READ_UNCOMMITTED就可以了。但是，由于对create*方法的调用非常短，只要数据库平台支持，序列化就不太可能导致问题。但是，这可以被覆盖。\n@Override protected JobRepository createJobRepository() throws Exception { JobRepositoryFactoryBean factory = new JobRepositoryFactoryBean(); factory.setDataSource(dataSource); factory.setTransactionManager(transactionManager); factory.setIsolationLevelForCreate(\u0026#34;ISOLATION_REPEATABLE_READ\u0026#34;); return factory.getObject(); } 如果未使用名称空间或工厂bean，那么使用AOP配置存储库的事务行为也很重要。\n@Bean public TransactionProxyFactoryBean baseProxy() { TransactionProxyFactoryBean transactionProxyFactoryBean = new TransactionProxyFactoryBean(); Properties transactionAttributes = new Properties(); transactionAttributes.setProperty(\u0026#34;*\u0026#34;, \u0026#34;PROPAGATION_REQUIRED\u0026#34;); transactionProxyFactoryBean.setTransactionAttributes(transactionAttributes); transactionProxyFactoryBean.setTarget(jobRepository()); transactionProxyFactoryBean.setTransactionManager(transactionManager()); return transactionProxyFactoryBean; } 更改表的前缀 JobRepository的另一个可修改属性是元数据表的前缀。默认情况下，它们都以BATCH_开头。更改表前缀：\n@Override protected JobRepository createJobRepository() throws Exception { JobRepositoryFactoryBean factory = new JobRepositoryFactoryBean(); factory.setDataSource(dataSource); factory.setTransactionManager(transactionManager); factory.setTablePrefix(\u0026#34;SYSTEM.TEST_\u0026#34;); return factory.getObject(); } 基于内存的Repository 在某些情况下，您可能不希望将域对象持久化到数据库。一个原因可能是速度；在每个提交点存储域对象需要额外的时间。另一个原因可能是您不需要为特定的工作保持状态。因此，SpringBatch提供了作业存储库的内存map版本。\n// This would reside in your BatchConfigurer implementation @Override protected JobRepository createJobRepository() throws Exception { MapJobRepositoryFactoryBean factory = new MapJobRepositoryFactoryBean(); factory.setTransactionManager(transactionManager); return factory.getObject(); } 请注意，内存中的存储库是易失性的，因此不允许在JVM实例之间重新启动。它也不能保证同时启动具有相同参数的两个作业实例，并且不适合在多线程作业或本地分区步骤中使用。\n但是，它确实需要定义事务管理器，因为存储库中有回滚语义，而且业务逻辑可能仍然是事务性的（例如RDBMS访问）。出于测试目的，许多人认为ResourceleStransActionManager很有用。\n配置JobLauncher 配置@EnableBatchProcessing后，JobRegistry 开箱即用。JobLauncher接口的最基本实现是SimpleJobLauncher。它唯一需要的依赖项是JobRepository。\n... // This would reside in your BatchConfigurer implementation @Override protected JobLauncher createJobLauncher() throws Exception { SimpleJobLauncher jobLauncher = new SimpleJobLauncher(); jobLauncher.setJobRepository(jobRepository); jobLauncher.afterPropertiesSet(); return jobLauncher; } ... 获得JobLauncher后，它将传递给Job的execute方法，最终将JobExecution返回给调用方，如下图所示：\n该序列非常简单，从调度器启动时效果良好。但是，尝试从HTTP请求启动时会出现问题。在这种情况下，启动需要异步完成，以便SimpleZoblancher立即返回到其调用者：\n通过配置TaskExecutor，可以将SimpleJobLauncher配置为允许此场景：\n@Bean public JobLauncher jobLauncher() { SimpleJobLauncher jobLauncher = new SimpleJobLauncher(); jobLauncher.setJobRepository(jobRepository()); jobLauncher.setTaskExecutor(new SimpleAsyncTaskExecutor()); jobLauncher.afterPropertiesSet(); return jobLauncher; } spring TaskExecutor接口的任何实现都可以用来控制如何异步执行作业。\n运行作业 启动批处理作业至少需要两件事：要启动的作业和JobLauncher。两者可以包含在相同的上下文或不同的上下文中。例如，如果从命令行启动作业，将为每个作业实例化一个新的JVM，因此每个作业都有自己的JobLauncher。但是，如果在HttpRequest范围内的web容器中运行，通常会有一个配置为异步作业启动的JobLauncher，多个请求将调用同一个JobLauncher来启动它们的作业。\n命令行启动 对于希望从企业级调度程序运行作业的用户，命令行是主要界面。这是因为大多数调度器（Quartz除外，除非使用NativeJob）直接与操作系统进程一起工作，主要由shell脚本启动。除了shell脚本（如Perl、Ruby）之外，还有许多方法可以启动Java进程，甚至还有“构建工具”（如ant或maven）。但是，因为大多数人都熟悉shell脚本，所以本例将重点介绍它们。\nCommandLineJobRunner 因为启动作业的脚本必须启动Java虚拟机，所以需要有一个具有main方法的类作为主要入口点。Spring批处理提供了一个实现，它正好满足这个目的：CommandLineJobRunner。CommandLineJobRunner执行四项任务：\n加载适当的ApplicationContext\n将命令行参数解析为JobParameters\n根据参数找到适当的作业\n使用应用程序上下文中提供的JobLauncher启动作业。\n所有这些任务都只使用传入的参数来完成。以下是必需的参数：\njobPath 将用于创建ApplicationContext的XML文件的位置。此文件应包含运行完整作业所需的所有内容 jobName 要运行的作业的名称。 这些参数之后的所有参数都被视为作业参数，将转换为JobParameters对象，并且必须采用“name=value”格式。\njava CommandLineJobRunner io.spring.EndOfDayJobConfiguration endOfDay schedule.date(date)=2007/05/05 默认情况下，CommandLineJobRunner使用DefaultJobParametersConverter，它隐式地将键/值对转换为作业参数。但是，可以通过分别在作业参数前面加上+或-来明确指定哪些是作业参数，哪些不是作业参数。可以使用自定义JobParametersConverter覆盖此行为。\njava CommandLineJobRunner io.spring.EndOfDayJobConfiguration endOfDay \\ +schedule.date(date)=2007/05/05 -vendor.id=123 大多数情况下，你希望使用jar包中的manifest申明你的main class.\n上面的例子中：\n第一个参数：io.spring.EndOfDayJobConfiguration 它是包含作业的配置类的完全限定类名 第二个参数：endOfDay，表示job的名称 最后一个参数： schedule.date(date)=2007/05/05，被转换成JobParameters 配置类的内容：\n@Configuration @EnableBatchProcessing public class EndOfDayJobConfiguration { @Autowired private JobBuilderFactory jobBuilderFactory; @Autowired private StepBuilderFactory stepBuilderFactory; @Bean public Job endOfDay() { return this.jobBuilderFactory.get(\u0026#34;endOfDay\u0026#34;) .start(step1()) .build(); } @Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .tasklet((contribution, chunkContext) -\u0026gt; null) .build(); } } ExitCodes 从命令行启动批处理作业时，通常使用企业级调度程序。大多数调度程序相当愚蠢，只在流程级别工作。这意味着他们只知道一些操作系统进程，比如他们正在调用的shell脚本。在这种情况下，向调度程序反馈作业成功或失败的唯一方法是通过返回代码。返回代码是进程返回给调度程序的数字，指示运行的结果。\n在最简单的情况下：0表示成功，1表示失败。但是，可能存在更复杂的情况：如果作业A返回4开始作业B,作业B返回5开始作业C.这种类型的行为是在调度程序级别配置的。在Spring批处理中，这被封装在ExitStatus中。ExitStatus有一个exit code属性，该属性由框架（或开发人员）设置，并作为JobLauncher返回的JobExecution的一部分返回。CommandLineJobRunner使用ExitCodeMapper接口将此字符串值转换为数字：\npublic interface ExitCodeMapper { public int intValue(String exitCode); } ExitCodeMapper的默认实现是SimpleJvmExitCodeMapper，它返回0表示完成，1表示一般错误，2表示任何作业运行程序错误，例如无法在提供的上下文中找到作业。如果需要比上述3个值更复杂的内容，则必须提供ExitCodeMapper接口的自定义实现。由于CommandLineJobRunner是创建ApplicationContext的类，因此不能自动发现定义的ExitCodeMapper ，需要你将其绑定到CommandLineJobRunner的上下文中。\nweb容器运行作业 过去，脱机处理（如批处理作业）是从命令行启动的，如上所述。然而，在许多情况下，从HttpRequest启动是一个更好的选择。许多这样的用例包括报告、临时作业运行和web应用程序支持。由于批处理作业定义为长时间运行，因此最重要的问题是确保异步启动作业：\n控制器使用配置为异步启动的JobLauncher启动作业，该程序立即返回JobExecution。作业可能仍在运行，但是，这种非阻塞行为允许控制器立即返回，这是处理HttpRequest时所必需的。一个例子如下：\n@Controller public class JobLauncherController { @Autowired JobLauncher jobLauncher; @Autowired Job job; @RequestMapping(\u0026#34;/jobLauncher.html\u0026#34;) public void handle() throws Exception{ jobLauncher.run(job, new JobParameters()); } } 高级元数据使用 到目前为止，已经讨论了JobLauncher和JobRepository接口。它们一起表示作业的简单启动，以及批处理域对象的基本CRUD操作：\nJobLauncher使用JobRepository创建新的JobExecution对象并运行它们。作业和步骤实现稍后将使用相同的作业存储库在作业运行期间对相同的执行进行基本更新。基本操作仅适用于简单场景，但在具有数百个批处理作业和复杂调度要求的大型批处理环境中，需要更高级的元数据访问：\nJobExplorer和JobOperator接口（将在下面讨论）添加了用于查询和控制元数据的附加功能。\n查询存储库 在使用任何高级功能之前，最基本的需求是能够查询存储库中现有的执行情况。此功能由JobExplorer接口提供：\npublic interface JobExplorer { List\u0026lt;JobInstance\u0026gt; getJobInstances(String jobName, int start, int count); JobExecution getJobExecution(Long executionId); StepExecution getStepExecution(Long jobExecutionId, Long stepExecutionId); JobInstance getJobInstance(Long instanceId); List\u0026lt;JobExecution\u0026gt; getJobExecutions(JobInstance jobInstance); Set\u0026lt;JobExecution\u0026gt; findRunningJobExecutions(String jobName); } 从上面的方法签名可以明显看出，JobExplorer是JobRepository的只读版本，与JobRepository一样，它可以通过使用factory bean轻松配置：\n... // This would reside in your BatchConfigurer implementation @Override public JobExplorer getJobExplorer() throws Exception { JobExplorerFactoryBean factoryBean = new JobExplorerFactoryBean(); factoryBean.setDataSource(this.dataSource); return factoryBean.getObject(); } ... 在本章前面，我们注意到可以修改JobRepository的表前缀，以允许不同的版本或模式。因为JobExplorer使用相同的表，所以它也需要设置前缀的功能。\n... // This would reside in your BatchConfigurer implementation @Override public JobExplorer getJobExplorer() throws Exception { JobExplorerFactoryBean factoryBean = new JobExplorerFactoryBean(); factoryBean.setDataSource(this.dataSource); factoryBean.setTablePrefix(\u0026#34;SYSTEM.\u0026#34;); return factoryBean.getObject(); } ... JobRegistry JobRegistry（及其父接口JobLocator）不是必需的，但如果您想跟踪上下文中有哪些作业，它可能很有用。自定义JobRegistry实现还可用于操作已注册作业的名称和其他属性。该框架只提供了一个实现，它基于从作业名称到作业实例的简单映射。\n... // This is already provided via the @EnableBatchProcessing but can be customized via // overriding the getter in the SimpleBatchConfiguration @Override @Bean public JobRegistry jobRegistry() throws Exception { return new MapJobRegistry(); } ... 有两种方法可以自动填充JobRegistry：使用bean后处理器和注册器生命周期组件。以下章节将介绍这两种机制。\nJobRegistryBeanPostProcessor 这是一个bean后处理器，可以在创建作业时注册所有作业。以下示例显示如何为Java中定义的作业包含JobRegistryBeanPostProcessor：\n@Bean public JobRegistryBeanPostProcessor jobRegistryBeanPostProcessor() { JobRegistryBeanPostProcessor postProcessor = new JobRegistryBeanPostProcessor(); postProcessor.setJobRegistry(jobRegistry()); return postProcessor; } 虽然这不是严格必需的，但示例中的后处理器已被赋予一个id，以便它可以包含在子上下文中（例如，作为父bean定义），并使在那里创建的所有作业也自动注册。\nAutomaticJobRegistrar 这是一个生命周期组件，用于创建子上下文，并在创建作业时从这些上下文中注册作业。这样做的一个优点是，虽然子上下文中的作业名称在注册表中仍然必须是全局唯一的，但它们的依赖项可以具有“自然”名称。例如，您可以创建一组XML配置文件，每个文件只有一个作业，但所有文件都具有相同bean名称的ItemReader的不同定义，例如“reader”。如果所有这些文件都导入到同一上下文中，读取器定义将发生冲突并相互覆盖，但使用自动注册器可以避免这种情况。这使得集成从应用程序的不同模块提供的作业变得更容易。\n@Bean public AutomaticJobRegistrar registrar() { AutomaticJobRegistrar registrar = new AutomaticJobRegistrar(); registrar.setJobLoader(jobLoader()); registrar.setApplicationContextFactories(applicationContextFactories()); registrar.afterPropertiesSet(); return registrar; } 注册器有两个必需属性，一个是ApplicationContextFactory数组（这里是从方便的工厂bean创建的），另一个是JobLoader。JobLoader负责管理子上下文的生命周期，并在JobRegistry中注册作业。\nApplicationContextFactory负责创建子上下文，最常见的用法是如上所述使用ClassPathXmlApplicationContextFactory。此工厂的一个特性是，默认情况下，它将一些配置从父上下文向下复制到子上下文。例如，如果属性PlaceHolderConfigure或AOP配置应与父级相同，则不必在子级中重新定义属性PlaceHolderConfigure或AOP配置。\n如果需要，AutomaticObjRegister可以与JobRegistryBeanPostProcessor结合使用（只要同时使用DefaultJobLoader）。例如，如果在主父上下文以及子位置中定义了作业，则这可能是可取的。\nJobOperator 如前所述，JobRepository对元数据提供CRUD操作，而JobExplorer对元数据提供只读操作。但是，这些操作在一起用于执行常见的监视任务（如停止、重新启动或汇总作业）时最有用，这通常是由JobOperator完成的。Spring Batch通过JobOperator界面提供以下类型的操作：\npublic interface JobOperator { List\u0026lt;Long\u0026gt; getExecutions(long instanceId) throws NoSuchJobInstanceException; List\u0026lt;Long\u0026gt; getJobInstances(String jobName, int start, int count) throws NoSuchJobException; Set\u0026lt;Long\u0026gt; getRunningExecutions(String jobName) throws NoSuchJobException; String getParameters(long executionId) throws NoSuchJobExecutionException; Long start(String jobName, String parameters) throws NoSuchJobException, JobInstanceAlreadyExistsException; Long restart(long executionId) throws JobInstanceAlreadyCompleteException, NoSuchJobExecutionException, NoSuchJobException, JobRestartException; Long startNextInstance(String jobName) throws NoSuchJobException, JobParametersNotFoundException, JobRestartException, JobExecutionAlreadyRunningException, JobInstanceAlreadyCompleteException; boolean stop(long executionId) throws NoSuchJobExecutionException, JobExecutionNotRunningException; String getSummary(long executionId) throws NoSuchJobExecutionException; Map\u0026lt;Long, String\u0026gt; getStepExecutionSummaries(long executionId) throws NoSuchJobExecutionException; Set\u0026lt;String\u0026gt; getJobNames(); } 上述操作表示来自许多不同接口的方法，如JobLauncher、JobRepository、JobExplorer和JobRegistry。因此，提供的JobOperator实现SimpleJobOperator具有许多依赖性。\n以下示例显示了Java中SimpleJoboOperator的典型bean定义：\n/** * All injected dependencies for this bean are provided by the @EnableBatchProcessing * infrastructure out of the box. */ @Bean public SimpleJobOperator jobOperator(JobExplorer jobExplorer, JobRepository jobRepository, JobRegistry jobRegistry) { SimpleJobOperator jobOperator = new SimpleJobOperator(); jobOperator.setJobExplorer(jobExplorer); jobOperator.setJobRepository(jobRepository); jobOperator.setJobRegistry(jobRegistry); jobOperator.setJobLauncher(jobLauncher); return jobOperator; } JobParametersIncrementer JobOperator上的大多数方法都是自解释的。然而，startnexistance方法值得注意。此方法将始终启动作业的新实例。如果作业执行中存在严重问题，并且需要从头开始重新启动作业，则此功能非常有用。不过，与JobLauncher不同，JobLauncher需要一个新的JobParameters对象，如果参数与以前的任何一组参数不同，该对象将触发一个新的JobInstance，StartEndistance方法将使用绑定到作业的JobParametersIncrementer强制作业到一个新实例：\npublic interface JobParametersIncrementer { JobParameters getNext(JobParameters parameters); } JobParametersIncrementer的约定是，给定一个JobParameters对象，它将通过递增可能包含的任何必要值来返回“下一个”JobParameters对象。此策略很有用，因为框架无法知道对JobParameters的哪些更改使其成为“下一个”实例。例如，如果JobParameters中的唯一值是日期，并且应该创建下一个实例，那么该值是否应该增加一天？或者一周（例如，如果工作是每周的）？对于有助于识别作业的任何数值也可以这样说，如下所示：\npublic class SampleIncrementer implements JobParametersIncrementer { public JobParameters getNext(JobParameters parameters) { if (parameters==null || parameters.isEmpty()) { return new JobParametersBuilder().addLong(\u0026#34;run.id\u0026#34;, 1L).toJobParameters(); } long id = parameters.getLong(\u0026#34;run.id\u0026#34;,1L) + 1; return new JobParametersBuilder().addLong(\u0026#34;run.id\u0026#34;, id).toJobParameters(); } } 在本例中，键为“run”的值。“id”用于区分作业实例。如果传入的JobParameters为null，则可以假定该作业以前从未运行过，因此可以返回其初始状态。但是，如果没有，则获取旧值，并将其递增1，然后返回。\n对于Java中定义的作业，可以通过构建器中提供的incrementer方法将incrementer与“作业”关联，如下所示：\n@Bean public Job footballJob() { return this.jobBuilderFactory.get(\u0026#34;footballJob\u0026#34;) .incrementer(sampleIncrementer()) ... .build(); } stop作业 JobOperator最常见的用例之一是优雅地停止作业：\nSet\u0026lt;Long\u0026gt; executions = jobOperator.getRunningExecutions(\u0026#34;sampleJob\u0026#34;); jobOperator.stop(executions.iterator().next()); 关闭不是立即的，因为没有办法强制立即关闭，特别是如果当前在框架无法控制的开发人员代码中执行，例如业务服务。但是，一旦控制权返回框架，它就会将当前StepExecution的状态设置为BatchStatus.STOPPED，保存它，然后在完成之前对JobExecution执行相同的操作。\n中断作业 失败的作业执行可以重新启动（如果作业可重新启动）。状态为ABANDONED的作业执行不会被框架重新启动。ABANDONED状态还用于步骤执行，以在重新启动的作业执行中将其标记为可跳过：如果作业正在执行，并且遇到在上一次失败的作业执行中已标记为ABANDONED的步骤，则它将继续执行下一步（由作业流定义和步骤执行退出状态确定）。\n如果进程死亡（“kill-9”或服务器故障），作业当然不会运行，但JobRepository无法知道，因为在进程死亡之前没有人告诉它。您必须手动告诉它，您知道执行失败或应被视为中止（将其状态更改为失败或放弃）-这是一个业务决策，无法实现自动化。仅当无法重新启动或知道重新启动数据有效时，才将状态更改为“失败”。Spring Batch Admin JobService中有一个用于中止作业执行的实用程序。\n步骤 面向块的批处理 SpringBatch在其最常见的实现中使用“面向块”的处理风格。面向块的处理是指一次读取一个数据并创建在事务边界内写出的“块”。一旦读取的项目数等于提交间隔，ItemWriter就会写出整个区块，然后提交事务。下图显示了该过程：\n下面是对应的伪代码：\nList items = new Arraylist(); for(int i = 0; i \u0026lt; commitInterval; i++){ Object item = itemReader.read(); if (item != null) { items.add(item); } } itemWriter.write(items); 面向块的步骤还可以配置可选的ItemProcessor，以便在将项目传递给ItemWriter之前对其进行处理。下图显示了在步骤中注册ItemProcessor时的过程：\n下面是对应的伪代码：\nList items = new Arraylist(); for(int i = 0; i \u0026lt; commitInterval; i++){ Object item = itemReader.read(); if (item != null) { items.add(item); } } List processedItems = new Arraylist(); for(Object item: items){ Object processedItem = itemProcessor.process(item); if (processedItem != null) { processedItems.add(processedItem); } } itemWriter.write(processedItems); 配置步骤 /** * Note the JobRepository is typically autowired in and not needed to be explicitly * configured */ @Bean public Job sampleJob(JobRepository jobRepository, Step sampleStep) { return this.jobBuilderFactory.get(\u0026#34;sampleJob\u0026#34;) .repository(jobRepository) .start(sampleStep) .build(); } /** * Note the TransactionManager is typically autowired in and not needed to be explicitly * configured */ @Bean public Step sampleStep(PlatformTransactionManager transactionManager) { return this.stepBuilderFactory.get(\u0026#34;sampleStep\u0026#34;) .transactionManager(transactionManager) .\u0026lt;String, String\u0026gt;chunk(10) .reader(itemReader()) .writer(itemWriter()) .build(); } 步骤读取和写入项，使用提供的PlatformTransactionManager定期提交。提交间隔为1时，它会在写入每个单独的项后提交。这在许多情况下都不太理想，因为开始和提交事务的成本很高。我们建议批量提交。例如上面的例子中，每次处理10条数据后提交。\n配置可重启 @Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(10) .reader(itemReader()) .writer(itemWriter()) .startLimit(1) .build(); } 上面的例子配置只运行一次，再次运行会抛出StartLimitExceededException。 注意，默认值是Integer.MAX_VALUE\n重启对步骤有很多影响，因此可能需要一些特定的配置。\n在许多情况下，您可能希望控制步骤的启动次数。例如，可能需要对特定步骤进行配置，使其只运行一次，因为它会使某些资源失效，而在重新运行之前，必须手动修复这些资源。这在步骤级别上是可配置的，因为不同的步骤可能有不同的要求。只能执行一次的步骤可以与可以无限运行的步骤作为同一作业的一部分存在。\n在可重启作业的情况下，可能有一个或多个步骤应该始终运行，无论它们第一次是否成功。例如，验证步骤或在处理之前清理资源的步骤。在重新启动作业的正常处理过程中，将跳过状态为“COMPLETED”的任何步骤，即该步骤已成功完成。将allow-start-if-complete设置为“true”将覆盖此设置，以便该步骤始终运行：\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(10) .reader(itemReader()) .writer(itemWriter()) .allowStartIfComplete(true) .build(); } 配置跳过逻辑 在许多情况下，处理过程中遇到的错误不应导致步骤失败，而应跳过。这通常是必须由了解数据本身及其含义的人做出的决定。例如，财务数据可能不可跳过，因为它会导致资金转移，这需要完全准确。另一方面，加载供应商列表可能会允许跳过。如果供应商由于格式不正确或缺少必要信息而未加载，则可能没有问题。通常，这些不良记录也会被记录下来，这将在以后讨论。\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(10) .reader(flatFileItemReader()) .writer(itemWriter()) .faultTolerant() .skipLimit(10) .skip(FlatFileParseException.class) .build(); } 在前面的示例中，使用了FlatFileItemReader。如果在任何时候抛出FlatFileParseException，则跳过该项并根据总跳过限制10进行计数。声明的异常（及其子类）可能会在块处理的任何阶段（读、处理、写）抛出，但在步骤执行过程中，对读、处理和写的跳过进行单独计数，但限制适用于所有跳过。一旦达到跳过限制，发现的下一个异常将导致步骤失败。换句话说，第十一次跳过触发异常，而不是第十次.\n前面示例的一个问题是，除了FlatFileParseException之外的任何其他异常都会导致作业失败。在某些情况下，这可能是正确的行为。但是，在其他场景中，可能更容易确定哪些异常会导致失败，并跳过其他所有其他异常：\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(10) .reader(flatFileItemReader()) .writer(itemWriter()) .faultTolerant() .skipLimit(10) .skip(Exception.class) .noSkip(FileNotFoundException.class) .build(); } 配置重试逻辑 有些时候，某些异常重试一下，可能就不存在了，例如DeadlockLoserDataAccessException，这表示当前进程试图更新另一进程持有锁定的记录。等待再尝试可能会成功。\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(2) .reader(itemReader()) .writer(itemWriter()) .faultTolerant() .retryLimit(3) .retry(DeadlockLoserDataAccessException.class) .build(); } 控制回滚 默认情况下，无论重试还是跳过，ItemWriter引发的任何异常都会导致该步骤控制的事务回滚。如果按前面所述配置skip，则ItemReader引发的异常不会导致回滚。但是，在许多情况下，ItemWriter引发的异常不应导致回滚，因为没有执行使事务无效的操作。因此，可以使用不应导致回滚的异常列表配置该步骤：\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(2) .reader(itemReader()) .writer(itemWriter()) .faultTolerant() .noRollback(ValidationException.class) .build(); } 事务读 ItemReader的基本约定是它只向前。该步骤缓冲读取器输入，以便在回滚的情况下，不需要从读取器重新读取项目。但是，在某些场景中，读取器构建在事务资源（如JMS队列）之上。在这种情况下，由于队列绑定到回滚的事务，因此从队列中提取的消息将被放回。因此，可以将步骤配置为不缓冲项目。\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(2) .reader(itemReader()) .writer(itemWriter()) .readerIsTransactionalQueue() .build(); } 事务属性 事务属性可用于控制隔离、传播和超时设置。关于设置事务属性的更多信息可以在Spring核心文档中找到。\n@Bean public Step step1() { DefaultTransactionAttribute attribute = new DefaultTransactionAttribute(); attribute.setPropagationBehavior(Propagation.REQUIRED.value()); attribute.setIsolationLevel(Isolation.DEFAULT.value()); attribute.setTimeout(30); return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(2) .reader(itemReader()) .writer(itemWriter()) .transactionAttribute(attribute) .build(); } 使用步骤注册ItemStream 步骤必须在其生命周期中的必要点处理ItemStream回调。如果一个步骤失败并且可能需要重新启动，这一点至关重要，因为ItemStream接口是步骤获取持久状态的地方。\n如果ItemReader、ItemProcessor或ItemWriter本身实现了ItemStream接口，则会自动注册这些接口。任何其他流都需要单独注册。这通常是将间接依赖项（如委托）注入读写器的情况。可以通过“stream”元素在步骤上注册流。\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(2) .reader(itemReader()) .writer(compositeItemWriter()) .stream(fileItemWriter1()) .stream(fileItemWriter2()) .build(); } /** * In Spring Batch 4, the CompositeItemWriter implements ItemStream so this isn\u0026#39;t * necessary, but used for an example. */ @Bean public CompositeItemWriter compositeItemWriter() { List\u0026lt;ItemWriter\u0026gt; writers = new ArrayList\u0026lt;\u0026gt;(2); writers.add(fileItemWriter1()); writers.add(fileItemWriter2()); CompositeItemWriter itemWriter = new CompositeItemWriter(); itemWriter.setDelegates(writers); return itemWriter; } 在上面的示例中，CompositeItemWriter不是ItemStream，但它的两个委托都是。因此，两个委托编写器都必须显式注册为流，以便框架正确处理它们。ItemReader不需要显式注册为流，因为它是步骤的直接属性。该步骤现在可以重新启动，并且读写器的状态在发生故障时正确保持。\n拦截步骤的执行 实现StepListener 接口监听事件：\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .\u0026lt;String, String\u0026gt;chunk(10) .reader(reader()) .writer(writer()) .listener(chunkListener()) .build(); } 除了StepListener接口之外，还提供了注解来解决同样的问题。\nStepExecutionListener StepExecutionListener表示步骤执行的最通用侦听器。它允许在步骤开始之前和结束之后发出通知，无论是正常结束还是失败，如以下示例所示：\npublic interface StepExecutionListener extends StepListener { void beforeStep(StepExecution stepExecution); ExitStatus afterStep(StepExecution stepExecution); } ExitStatus是afterStep的返回类型，以便侦听器有机会修改执行结果的状态。\n对应的注解：\n@BeforeStep\n@AfterStep\nChunkListener 提交事务时，在每个提交间隔提交一个“块”。ChunkListener可用于在区块开始处理之前或区块成功完成之后执行逻辑，如以下接口定义所示：\npublic interface ChunkListener extends StepListener { void beforeChunk(ChunkContext context); void afterChunk(ChunkContext context); void afterChunkError(ChunkContext context); } beforeChunk方法在事务启动后调用，但在ItemReader上调用read之前调用。相反，afterChunk在提交块后调用（如果存在回滚，则根本不调用）。对应的注解：\n@BeforeChunk @AfterChunk @AfterChunkError ItemReadListener 在前面讨论跳过逻辑时，提到跳过的记录以后处理。在读取错误的情况下，可以使用ItemReaderListener执行此操作，如以下接口定义所示：\npublic interface ItemReadListener\u0026lt;T\u0026gt; extends StepListener { void beforeRead(); void afterRead(T item); void onReadError(Exception ex); } 每次调用ItemReader读取之前，都会调用beforeRead方法。每次成功调用read后都会调用afterRead方法，并将读取的项传递给它。如果读取时出错，则调用onReadError方法。提供遇到的异常，以便记录它。对应的注解：\n@BeforeRead @AfterRead @OnReadError ItemProcessListener 与ItemReadListener一样，可以“侦听”项的处理，如以下接口定义所示：\npublic interface ItemProcessListener\u0026lt;T, S\u0026gt; extends StepListener { void beforeProcess(T item); void afterProcess(T item, S result); void onProcessError(T item, Exception e); } beforeProcess方法在ItemProcessor上的处理前调用，并将要处理的项传递给它。成功处理项目后，将调用afterProcess方法。如果处理时出错，则调用onProcessError方法。将提供遇到的异常和尝试处理的项目，以便记录它们。对应的注解：\n@BeforeProcess @AfterProcess @OnProcessError ItemWriteListener 可以使用ItemWriteListener“监听”项的写入，如以下接口定义所示：\npublic interface ItemWriteListener\u0026lt;S\u0026gt; extends StepListener { void beforeWrite(List\u0026lt;? extends S\u0026gt; items); void afterWrite(List\u0026lt;? extends S\u0026gt; items); void onWriteError(Exception exception, List\u0026lt;? extends S\u0026gt; items); } 在ItemWriter上写入之前调用beforeWrite方法，并向其传递已写入的项列表。成功写入项目后，将调用afterWrite方法。如果写入时出错，则调用onWriteError方法。将提供遇到的异常和尝试写入的项目，以便记录它们。对应的注解：\n@BeforeWrite\n@AfterWrite\n@OnWriteError\nSkipListener ItemReadListener、ItemProcessListener和ItemWriteListener都提供了接收错误通知的机制，但没有任何机制通知您记录实际上已被跳过。例如，即使项目重试并成功，也会调用onWriteError。因此，有一个单独的接口用于跟踪跳过的项，如以下接口定义所示：\npublic interface SkipListener\u0026lt;T,S\u0026gt; extends StepListener { void onSkipInRead(Throwable t); void onSkipInProcess(T item, Throwable t); void onSkipInWrite(S item, Throwable t); } 每当在读取时跳过项时，都会调用onSkipInRead。应该注意，回滚可能会导致同一项注册为跳过多次。在写入时跳过项时调用onSkipInWrite。由于已成功读取（且未跳过）该项，因此还将该项本身作为参数提供。对应的注解：\n@OnSkipInRead\n@OnSkipInWrite\n@OnSkipInProcess\nSkipListener最常见的用例之一是注销跳过的项目，以便使用另一个批处理过程甚至人工过程来评估和修复导致跳过的问题。因为在许多情况下原始事务可能会回滚，Spring Batch提供了两个保证：\n每个项只调用一次相应的跳过方法（取决于错误发生的时间）。 始终在提交事务之前调用SkipListener。这是为了确保侦听器的任何事务性资源调用不会因ItemWriter中的故障而回滚。 TaskletStep 面向块的处理不是在一个步骤中处理的唯一方法。如果一个步骤必须由一个简单的存储过程调用组成，该怎么办？您可以将调用实现为ItemReader，并在过程完成后返回null。然而，这样做有点不自然，因为需要一个无操作的ItemWriter。SpringBatch为此场景提供了TaskletStep。\nTasklet是一个简单的接口，它有一个方法execute，TaskletStep会重复调用该方法，直到返回RepeatStatus。已完成或引发异常。对Tasklet的每次调用都包装在一个事务中。Tasklet实现者可以调用存储过程、脚本或简单的SQL update语句。\n要在Java中创建TaskletStep，传递给构建器tasklet方法的bean应该实现tasklet接口。构建TaskletStep时不应调用chunk。以下示例显示了一个简单的tasklet：\n@Bean public Step step1() { return this.stepBuilderFactory.get(\u0026#34;step1\u0026#34;) .tasklet(myTasklet()) .build(); } 与ItemReader和ItemWriter接口的其他适配器一样，Tasklet接口包含一个实现，TaskletAdapter:\n@Bean public MethodInvokingTaskletAdapter myTasklet() { MethodInvokingTaskletAdapter adapter = new MethodInvokingTaskletAdapter(); adapter.setTargetObject(fooDao()); adapter.setTargetMethod(\u0026#34;updateFoo\u0026#34;); return adapter; } 许多批处理作业包含必须在主处理开始前完成的步骤，以便设置各种资源，或在处理完成后清理这些资源。对于大量处理文件的作业，通常需要在将某些文件成功上载到其他位置后在本地删除这些文件。以下示例（取自Spring Batch samples项目）是一个Tasklet实现，具有这样的职责：\npublic class FileDeletingTasklet implements Tasklet, InitializingBean { private Resource directory; public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception { File dir = directory.getFile(); Assert.state(dir.isDirectory()); File[] files = dir.listFiles(); for (int i = 0; i \u0026lt; files.length; i++) { boolean deleted = files[i].delete(); if (!deleted) { throw new UnexpectedJobExecutionException(\u0026#34;Could not delete file \u0026#34; + files[i].getPath()); } } return RepeatStatus.FINISHED; } public void setDirectoryResource(Resource directory) { this.directory = directory; } public void afterPropertiesSet() throws Exception { Assert.notNull(directory, \u0026#34;directory must be set\u0026#34;); } } 前面的tasklet实现删除给定目录中的所有文件。应该注意，execute方法只调用一次。剩下的就是引用步骤中的tasklet。\n@Bean public Job taskletJob() { return this.jobBuilderFactory.get(\u0026#34;taskletJob\u0026#34;) .start(deleteFilesInDir()) .build(); } @Bean public Step deleteFilesInDir() { return this.stepBuilderFactory.get(\u0026#34;deleteFilesInDir\u0026#34;) .tasklet(fileDeletingTasklet()) .build(); } @Bean public FileDeletingTasklet fileDeletingTasklet() { FileDeletingTasklet tasklet = new FileDeletingTasklet(); tasklet.setDirectoryResource(new FileSystemResource(\u0026#34;target/test-outputs/test-dir\u0026#34;)); return tasklet; } 控制步骤执行流程 顺序流程 使用next方法：\n@Bean public Job job() { return this.jobBuilderFactory.get(\u0026#34;job\u0026#34;) .start(stepA()) .next(stepB()) .next(stepC()) .build(); } 在上面的场景中，“步骤A”首先运行，因为它是列出的第一个步骤。如果“步骤A”正常完成，则“步骤B”运行，依此类推。但是，如果“步骤A”失败，则整个作业失败，“步骤B”不会执行。\n条件流程 JavaAPI提供了一组流畅的方法，允许您指定流程以及在步骤失败时执行的操作。以下示例显示了如何指定一个步骤（步骤A），然后根据步骤A是否成功，继续执行两个不同步骤（步骤B和步骤C）中的任何一个：\n@Bean public Job job() { return this.jobBuilderFactory.get(\u0026#34;job\u0026#34;) .start(stepA()) .on(\u0026#34;*\u0026#34;).to(stepB()) .from(stepA()).on(\u0026#34;FAILED\u0026#34;).to(stepC()) .end() .build(); } 当使用java配置时，on（）方法使用一个简单的模式匹配方案来匹配执行步骤所产生的ExitStatus。\n模式中只允许使用两个特殊字符：\n“*”匹配零个或多个字符 \u0026ldquo;?\u0026rdquo; 正好匹配一个字符 虽然步骤上的转换元素数量没有限制，但如果步骤执行导致元素未覆盖的ExitStatus，那么框架将抛出异常，作业将失败。框架会自动对从最特定到最不特定的转换进行排序。这意味着，即使在上面的示例中，排序被替换为“stepA”，ExitStatus“FAILED”仍将转到“stepC”。\n批处理状态与退出状态 ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-batch/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"},{"title":"spring-batch","url":"/myblog/tags/spring-batch/"}],"timestamp":1669981883,"title":"Spring-Batch"},{"authors":[],"categories":[{"title":"java","url":"/myblog/categories/java/"},{"title":"spring","url":"/myblog/categories/spring/"},{"title":"spring-cloud","url":"/myblog/categories/spring-cloud/"}],"content":"spring cloud gateway 概述 基于版本3.1.1\n该项目提供了一个建立在Spring生态系统之上的API网关，包括：Spring 5，Spring Boot 2和Project Reactor。Spring Cloud Gateway旨在提供一种简单而有效的方法来路由到API，并为它们提供跨领域的关注点，例如：安全性，监控/指标和可伸缩性。\norg.springframework.cloud:spring-cloud-starter-gateway\n路由：网关的基本构建基块。它由 ID、目标 URI、谓词集合和筛选器集合定义。如果聚合谓词为 true，则匹配路由。 谓词：这是一个 Java 8 函数谓词。输入类型是Spring Framework ServerWebExchange。这使您可以匹配 HTTP 请求中的任何内容，例如标头或参数。 过滤器：这些是使用特定工厂构建的网关过滤器实例。在这里，您可以修改发送下游请求之前或之后的请求和响应。 如何工作 客户端向 Spring Cloud Gateway 发出请求。 如果Gateway Handler Mapping确定请求与路由匹配，则将其发送到Gateway Web Handler。 此处理程序通过特定于请求的过滤器链运行请求。 过滤器被虚线分隔的原因是过滤器可以在发送代理请求之前和之后运行逻辑。 执行所有“pre”过滤器逻辑。 然后进行代理请求。 发出代理请求后，将运行“post”过滤器逻辑。\n如何配置 有两种方法可以配置谓词和过滤器：简洁方式和完全模式。\n简洁方式\nspring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - Cookie=mycookie,mycookievalue 定义了 路由谓词工厂（Cookie ），cookie 名称(mycookie) 和匹配值(mycookievalue)。\n完全模式\nspring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - name: Cookie args: name: mycookie regexp: mycookievalue 可以看出，完全模式，需要指定 name 和 args 参数。\n路由谓词工厂 Spring Cloud Gateway 匹配路由作为 Spring WebFlux HandlerMapping 基础结构的一部分。 Spring Cloud Gateway 包含许多内置的路由谓词工厂。 所有这些谓词都匹配 HTTP 请求的不同属性。 您可以将多个路由谓词工厂组合在一起。\nAfter 路由谓词 After 路由谓词工厂接受一个参数（datetime ,这是一个 java ZonedDateTime）。 此谓词匹配在指定日期时间之后发生的请求。 以下示例配置了一个 after 路由谓词：\nspring: cloud: gateway: routes: - id: after_route uri: https://example.org predicates: - After=2017-01-20T17:42:47.789-07:00[America/Denver] Before 路由谓词 After 路由谓词工厂接受一个参数（datetime ,这是一个 java ZonedDateTime）。 此谓词匹配在指定日期时间之前发生的请求。 以下示例配置了一个 before 路由谓词：\nspring: cloud: gateway: routes: - id: before_route uri: https://example.org predicates: - Before=2017-01-20T17:42:47.789-07:00[America/Denver] Between 路由谓词 路由谓词工厂之间有两个参数，datetime1 和 datetime2，它们是 java ZonedDateTime 对象。 此谓词匹配发生在 datetime1 之后和 datetime2 之前的请求。 datetime2 参数必须在 datetime1 之后。 以下示例配置了一个 between 路由谓词：\nspring: cloud: gateway: routes: - id: between_route uri: https://example.org predicates: - Between=2017-01-20T17:42:47.789-07:00[America/Denver], 2017-01-21T17:42:47.789-07:00[America/Denver] Cookie 路由谓词 Cookie 路由谓词工厂有两个参数，即 cookie 名称和一个 regexp（这是一个 Java 正则表达式）。 此谓词匹配具有给定名称且其值与正则表达式匹配的 cookie。 以下示例配置 cookie 路由谓词工厂：\nspring: cloud: gateway: routes: - id: cookie_route uri: https://example.org predicates: - Cookie=chocolate, ch.p Header 路由谓词 Header 路由谓词工厂接受两个参数，标题名称和一个 regexp（这是一个 Java 正则表达式）。 此谓词与具有给定名称的标头匹配，其值与正则表达式匹配。 以下示例配置标头路由谓词：\nspring: cloud: gateway: routes: - id: header_route uri: https://example.org predicates: - Header=X-Request-Id, \\d+ Host 路由谓词 主机路由谓词工厂采用一个参数：主机名模式列表。 该模式是 Ant 风格的模式。 此谓词匹配的 Host 标头。 以下示例配置主机路由谓词：\nspring: cloud: gateway: routes: - id: host_route uri: https://example.org predicates: - Host=**.somehost.org,**.anotherhost.org 还支持 URI 模板变量（例如 {sub}.myhost.org）。\n此谓词提取 URI 模板变量（例如 sub，在前面的示例中定义）作为名称和值的映射，并将其放置在 ServerWebExchange.getAttributes() 中，并使用 ServerWebExchangeUtils.URI_TEMPLATE_VARIABLES_ATTRIBUTE 中定义的键。 然后这些值可供 GatewayFilter 工厂使用\nMethod 路由谓词 方法路由谓词工厂采用一个方法参数：要匹配的 HTTP 方法。 以下示例配置方法路由谓词：\nspring: cloud: gateway: routes: - id: method_route uri: https://example.org predicates: - Method=GET,POST Path 路由谓词 Path Route Predicate Factory 接受两个参数：一个 Spring PathMatcher 模式列表和一个名为 matchTrailingSlash 的可选标志（默认为 true）。 以下示例配置路径路由谓词：\nspring: cloud: gateway: routes: - id: path_route uri: https://example.org predicates: - Path=/red/{segment},/blue/{segment} 如果 matchTrailingSlash 设置为 false，则不会匹配请求路径 /red/1/。\n此谓词提取 URI 模板变量（例如在前面的示例中定义的segment）作为名称和值的映射，并将其放置在 ServerWebExchange.getAttributes() 中，并使用在 ServerWebExchangeUtils.URI_TEMPLATE_VARIABLES_ATTRIBUTE 中定义的键。 然后这些值可供 GatewayFilter 工厂使用\n可以使用实用方法（称为 get）来更轻松地访问这些变量。 以下示例显示了如何使用 get 方法：\nMap\u0026lt;String, String\u0026gt; uriVariables = ServerWebExchangeUtils.getPathPredicateVariables(exchange); String segment = uriVariables.get(\u0026#34;segment\u0026#34;); Query 路由谓词 查询路由谓词工厂有两个参数：一个必需的参数和一个可选的正则表达式（这是一个 Java 正则表达式）。 以下示例配置查询路由谓词：\nspring: cloud: gateway: routes: - id: query_route uri: https://example.org predicates: - Query=red, gree. RemoteAddr 路由谓词 RemoteAddr 路由谓词工厂采用源列表（最小大小 1），这些源是 CIDR 表示法（IPv4 或 IPv6）字符串，例如 192.168.0.1/16（其中 192.168.0.1 是 IP 地址，16 是子网掩码 ）。 以下示例配置 RemoteAddr 路由谓词：\nspring: cloud: gateway: routes: - id: remoteaddr_route uri: https://example.org predicates: - RemoteAddr=192.168.1.1/24 默认情况下，RemoteAddr 路由谓词工厂使用来自传入请求的远程地址。 如果 Spring Cloud Gateway 位于代理层之后，这可能与实际客户端 IP 地址不匹配。\n您可以通过设置自定义的RemoteAddressResolver 来解析远程地址。 Spring Cloud Gateway 带有一个基于 X-Forwarded-For 标头 的XForwardedRemoteAddressResolver (非默认)RemoteAddr 解析器。\nXForwardedRemoteAddressResolver 有两个静态构造函数方法，它们采取不同的安全方法：\nXForwardedRemoteAddressResolver::trustAll 返回一个 RemoteAddressResolver，它总是采用在 X-Forwarded-For 标头中找到的第一个 IP 地址。 这种方法容易受到欺骗，因为恶意客户端可以为 X-Forwarded-For 设置一个初始值，该值将被解析器接受。 XForwardedRemoteAddressResolver::maxTrustedIndex 采用一个索引，该索引与运行在 Spring Cloud Gateway 前面的受信任基础设施的数量相关。 例如，如果 Spring Cloud Gateway 只能通过 HAProxy 访问，则应使用值 1。 如果在访问 Spring Cloud Gateway 之前需要两跳可信基础设施，则应使用值 2。 假如有如下：\nX-Forwarded-For: 0.0.0.1, 0.0.0.2, 0.0.0.3 根据设置的maxTrustedIndex，具体的取值如下表：\nmaxTrustedIndex result [Integer.MIN_VALUE,0] 无效, 初始化时抛出IllegalArgumentException 1 0.0.0.3 2 0.0.0.2 3 0.0.0.1 [4, Integer.MAX_VALUE] 0.0.0.1 使用java配置XForwardedRemoteAddressResolver ：\nRemoteAddressResolver resolver = XForwardedRemoteAddressResolver .maxTrustedIndex(1); ... .route(\u0026#34;direct-route\u0026#34;, r -\u0026gt; r.remoteAddr(\u0026#34;10.1.1.1\u0026#34;, \u0026#34;10.10.1.1/24\u0026#34;) .uri(\u0026#34;https://downstream1\u0026#34;) .route(\u0026#34;proxied-route\u0026#34;, r -\u0026gt; r.remoteAddr(resolver, \u0026#34;10.10.1.1\u0026#34;, \u0026#34;10.10.1.1/24\u0026#34;) .uri(\u0026#34;https://downstream2\u0026#34;) ) Weight 路由谓词 Weight 路由谓词工厂采用两个参数：group 和 weight（一个 int）。 权重是按组计算的。 以下示例配置权重路由谓词：\nspring: cloud: gateway: routes: - id: weight_high uri: https://weighthigh.org predicates: - Weight=group1, 8 - id: weight_low uri: https://weightlow.org predicates: - Weight=group1, 2 该路由会将约 80% 的流量转发到 weighthigh.org，将约 20% 的流量转发到 weightlow.org\nXForear????\nfilter工厂 路由过滤器允许以某种方式修改传入的 HTTP 请求或传出的 HTTP 响应。 Spring Cloud Gateway 包括许多内置的 GatewayFilter 工厂。\n添加类型 AddRequestHeader AddRequestHeader 有两个参数：name和value。 以下示例配置 AddRequestHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org filters: - AddRequestHeader=X-Request-red, blue 将 X-Request-red:blue 标头添加到所有匹配请求的下游请求标头中。\nAddRequestHeader 知道用于匹配路径或主机的 URI 变量。 URI 变量可以在值中使用并在运行时扩展。 以下示例配置使用变量的 AddRequestHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: add_request_header_route uri: https://example.org predicates: - Path=/red/{segment} filters: - AddRequestHeader=X-Request-Red, Blue-{segment} AddRequestParameter AddRequestParameter 两个参数：name和value:\nspring: cloud: gateway: routes: - id: add_request_parameter_route uri: https://example.org filters: - AddRequestParameter=red, blue 同理，也可以使用URI变量：\nspring: cloud: gateway: routes: - id: add_request_parameter_route uri: https://example.org predicates: - Host: {segment}.myhost.org filters: - AddRequestParameter=foo, bar-{segment} AddResponseHeader AddResponseHeader 两个参数：name和value:\nspring: cloud: gateway: routes: - id: add_response_header_route uri: https://example.org filters: - AddResponseHeader=X-Response-Red, Blue 同理，也可以使用URI变量：\nspring: cloud: gateway: routes: - id: add_response_header_route uri: https://example.org predicates: - Host: {segment}.myhost.org filters: - AddResponseHeader=foo, bar-{segment} 删除类型 RemoveRequestHeader RemoveRequestHeader GatewayFilter 工厂采用 name 参数。 它是要删除的标题的名称。 以下清单配置了 RemoveRequestHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: removerequestheader_route uri: https://example.org filters: - RemoveRequestHeader=X-Request-Foo 这会在向下游发送之前删除 X-Request-Foo 标头。\nRemoveResponseHeader RemoveResponseHeader GatewayFilter 工厂采用 name 参数。 它是要删除的标题的名称。 以下清单配置了 RemoveResponseHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: removeresponseheader_route uri: https://example.org filters: - RemoveResponseHeader=X-Response-Foo 要删除任何类型的敏感标头，您应该为您可能想要这样做的任何路由配置此过滤器。 此外，您可以使用 spring.cloud.gateway.default-filters 配置一次此过滤器，并将其应用于所有路由。\nRemoveRequestParameter RemoveRequestParameter 传入name参数。 它是要删除的查询参数的名称。 以下示例配置 RemoveRequestParameter GatewayFilter：\nspring: cloud: gateway: routes: - id: removerequestparameter_route uri: https://example.org filters: - RemoveRequestParameter=red 修改请求头类型 SetRequestHeader 传入name和value参数：\nspring: cloud: gateway: routes: - id: setrequestheader_route uri: https://example.org filters: - SetRequestHeader=X-Request-Red, Blue 此 GatewayFilter 替换（而不是添加）具有给定名称的所有标头。 因此，如果下游服务器以 X-Request-Red:1234 响应，这将替换为 X-Request-Red:Blue，这是下游服务将收到的(确定不是网关收到的？？？)。\nSetRequestHeader 知道用于匹配路径或主机的 URI 变量。 URI 变量可以在值中使用并在运行时扩展。 以下示例配置使用变量的 SetRequestHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: setrequestheader_route uri: https://example.org predicates: - Host: {segment}.myhost.org filters: - SetRequestHeader=foo, bar-{segment} SetResponseHeader 传入name和value参数：\nspring: cloud: gateway: routes: - id: setresponseheader_route uri: https://example.org filters: - SetResponseHeader=X-Response-Red, Blue 此 GatewayFilter 替换（而不是添加）具有给定名称的所有标头。 因此，如果下游服务器以 X-Response-Red:1234 响应，这将替换为 X-Response-Red:Blue，这是网关客户端将收到的。\nSetResponseHeader 知道用于匹配路径或主机的 URI 变量。 URI 变量可以在值中使用，并将在运行时扩展。 以下示例配置使用变量的 SetResponseHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: setresponseheader_route uri: https://example.org predicates: - Host: {segment}.myhost.org filters: - SetResponseHeader=foo, bar-{segment} SetStatus SetStatus GatewayFilter 工厂采用单个参数 status。 它必须是有效的 Spring HttpStatus。 它可能是整数值 404 或枚举的字符串表示形式：NOT_FOUND。 以下清单配置了 SetStatus GatewayFilter：\nspring: cloud: gateway: routes: - id: setstatusstring_route uri: https://example.org filters: - SetStatus=BAD_REQUEST - id: setstatusint_route uri: https://example.org filters: - SetStatus=401 无论哪种情况，响应的 HTTP 状态都设置为 401。\n您可以配置 SetStatus GatewayFilter 以在响应的标头中返回来自代理请求的原始 HTTP 状态代码。 如果配置了以下属性，则将标头添加到响应中：\nspring: cloud: gateway: set-status: original-status-header-name: original-http-status RewriteResponseHeader RewriteResponseHeader GatewayFilter 工厂采用name、regexp和replacement 。 它使用 Java 正则表达式来灵活地重写响应头值。 以下示例配置 RewriteResponseHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: rewriteresponseheader_route uri: https://example.org filters: - RewriteResponseHeader=X-Response-Red, , password=[^\u0026amp;]+, password=*** 对于 /42?user=ford\u0026amp;password=omg!what\u0026amp;flag=true 的 header 值，在发出下游请求后设置为 /42?user=ford\u0026amp;password=***\u0026amp;flag=true。 由于 YAML 规范，您必须使用 $\\ 来表示 $。\nSetRequestHostHeader 在某些情况下，可能需要覆盖主机标头。 在这种情况下， SetRequestHostHeader GatewayFilter 工厂可以用指定的值替换现有的主机头。 过滤器采用主机参数。 以下清单配置了 SetRequestHostHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: set_request_host_header_route uri: http://localhost:8080/headers predicates: - Path=/headers filters: - name: SetRequestHostHeader args: host: example.org DedupeResponseHeader DedupeResponseHeader GatewayFilter 工厂采用name参数和可选的strategy 参数。 name 可以包含以空格分隔的标题名称列表。 以下示例配置 DedupeResponseHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: dedupe_response_header_route uri: https://example.org filters: - DedupeResponseHeader=Access-Control-Allow-Credentials Access-Control-Allow-Origin 在网关 CORS 逻辑和下游逻辑都添加它们的情况下，删除 Access-Control-Allow-Credentials 和 Access-Control-Allow-Origin 响应标头的重复值。\nDedupeResponseHeader 过滤器还接受一个可选的strategy 参数。 接受的值为 RETAIN_FIRST（默认）、RETAIN_LAST 和 RETAIN_UNIQUE。\nPreserveHostHeader PreserveHostHeader GatewayFilter 工厂没有参数。 此过滤器设置在请求的attribute设置值，然后 路由过滤器查看该请求属性是否为true，以确定是否应发送原始host标头，而不是由 HTTP 客户端确定的主机标头。 以下示例配置 PreserveHostHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: preserve_host_route uri: https://example.org filters: - PreserveHostHeader MapRequestHeader MapRequestHeader GatewayFilter 工厂采用 fromHeader 和 toHeader 参数。 它创建一个新的命名标头 (toHeader)，并从传入的 http 请求提取命名标头 (fromHeader) 中的值。 如果输入标头不存在，则过滤器没有影响。 如果新命名的标头已存在，则其值将使用新值进行扩充。 以下示例配置 MapRequestHeader：\nspring: cloud: gateway: routes: - id: map_request_header_route uri: https://example.org filters: - MapRequestHeader=Blue, X-Request-Red 传入的http请求携带Blue请求头，该过滤器将该请求头的值添加到X-Request-Red请求头中，然后传递给下游\n修改请求体或响应体 ModifyRequestBody 您可以使用 ModifyRequestBody 过滤器,在请求正文被网关发送到下游之前对其进行修改。\n此过滤器只能通过使用 Java DSL 进行配置。\n@Bean public RouteLocator routes(RouteLocatorBuilder builder) { return builder.routes() .route(\u0026#34;rewrite_request_obj\u0026#34;, r -\u0026gt; r.host(\u0026#34;*.rewriterequestobj.org\u0026#34;) .filters(f -\u0026gt; f.prefixPath(\u0026#34;/httpbin\u0026#34;) .modifyRequestBody(String.class, Hello.class, MediaType.APPLICATION_JSON_VALUE, (exchange, s) -\u0026gt; return Mono.just(new Hello(s.toUpperCase())))).uri(uri)) .build(); } static class Hello { String message; public Hello() { } public Hello(String message) { this.message = message; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } } ModifyResponseBody 您可以使用 ModifyResponseBody 过滤器在响应正文发送回客户端之前对其进行修改。\n此过滤器只能通过使用 Java DSL 进行配置。\n@Bean public RouteLocator routes(RouteLocatorBuilder builder) { return builder.routes() .route(\u0026#34;rewrite_response_upper\u0026#34;, r -\u0026gt; r.host(\u0026#34;*.rewriteresponseupper.org\u0026#34;) .filters(f -\u0026gt; f.prefixPath(\u0026#34;/httpbin\u0026#34;) .modifyResponseBody(String.class, String.class, (exchange, s) -\u0026gt; Mono.just(s.toUpperCase()))).uri(uri)) .build(); } 如果响应没有正文，则 RewriteFilter 将传递 null。 应返回 Mono.empty() 以在响应中分配缺失的主体。\n修改路径 PrefixPath PrefixPath GatewayFilter 工厂采用单个prefix 参数。 以下示例配置 PrefixPath GatewayFilter：\nspring: cloud: gateway: routes: - id: prefixpath_route uri: https://example.org filters: - PrefixPath=/mypath 这会将 /mypath 前缀添加到所有匹配请求的路径之前。 因此，对 /hello 的请求将被发送到 /mypath/hello。\nRewritePath RewritePath GatewayFilter 传入regexp 参数和replacement参数。 这使用 Java 正则表达式来灵活地重写请求路径。 以下清单配置了 RewritePath GatewayFilter：\nspring: cloud: gateway: routes: - id: rewritepath_route uri: https://example.org predicates: - Path=/red/** filters: - RewritePath=/red/?(?\u0026lt;segment\u0026gt;.*), /$\\{segment} 对于 /red/blue 的请求路径，这会在发出下游请求之前将路径设置为 /blue。 请注意，由于 YAML 规范，$ 应替换为 $\\。\nSetPath SetPath GatewayFilter 工厂采用路径模板参数。 它提供了一种通过允许路径的模板化段来操作请求路径的简单方法。 这使用了 Spring Framework 中的 URI 模板。 允许多个匹配段。 以下示例配置 SetPath GatewayFilter：\nspring: cloud: gateway: routes: - id: setpath_route uri: https://example.org predicates: - Path=/red/{segment} filters: - SetPath=/{segment} 对于 /red/blue 的请求路径，这会在发出下游请求之前将路径设置为 /blue。\nStripPrefix StripPrefix GatewayFilter 工厂采用一个参数，parts。 该参数指示在将请求发送到下游之前要从请求中剥离的路径中的部分数。 以下清单配置了 StripPrefix GatewayFilter：\nspring: cloud: gateway: routes: - id: nameRoot uri: https://nameservice predicates: - Path=/name/** filters: - StripPrefix=2 当通过网关向 /name/blue/red 发出请求时，对 nameservice 发出的请求看起来像 nameservice/red。\n重定向 RedirectTo RedirectTo GatewayFilter 工厂接受两个参数，status 和 url。 status 参数应该是一个 300 系列的重定向 HTTP 代码，比如 301。url 参数应该是一个有效的 URL。 这是 Location 标头的值。 对于相对重定向，您应该使用 uri: no://op 作为路由定义的 uri。 以下清单配置了一个 RedirectTo GatewayFilter：\nspring: cloud: gateway: routes: - id: prefixpath_route uri: https://example.org filters: - RedirectTo=302, https://acme.org 这将发送带有 Location:https://acme.org 标头的状态 302 以执行重定向。\nRewriteLocationResponseHeader RewriteLocationResponseHeader GatewayFilter 工厂修改 Location 响应头的值，通常是为了摆脱后端特定的细节。 它采用 stripVersionMode、locationHeaderName、hostValue 和 protocolsRegex 参数。 以下清单配置了 RewriteLocationResponseHeader GatewayFilter：\nspring: cloud: gateway: routes: - id: rewritelocationresponseheader_route uri: http://example.org filters: - RewriteLocationResponseHeader=AS_IN_REQUEST, Location, , 例如，对于POST api.example.com/some/object/name的请求，将Location响应头的值 o``bject-service.prod.example.net/v2/some/object/id 改写为api.example.com/some/object/id。\nstripVersionMode 参数具有以下可能的值：NEVER_STRIP、AS_IN_REQUEST（默认）和 ALWAYS_STRIP。\nNEVER_STRIP: 即使原始请求路径不包含版本，也不会剥离版本。 AS_IN_REQUEST : 仅当原始请求路径不包含版本时才会剥离版本。 ALWAYS_STRIP : 版本总是被剥离，即使原始请求路径包含版本。 hostValue 参数（如果提供）用于替换响应 Location 标头的 host:port 部分。 如果未提供，则使用 Host 请求标头的值。\nprotocolRegex 参数必须是有效的正则表达式字符串，与协议名称匹配。 如果不匹配，则过滤器不执行任何操作。 默认为 http|https|ftp|ftps。\n对请求进行限制 RequestSize 当请求大小大于允许的限制时，RequestSize GatewayFilter 工厂可以限制请求到达下游服务。 过滤器采用 maxSize 参数。 maxSize 是一个 `DataSize 类型，因此值可以定义为一个数字，后跟一个可选的 DataUnit 后缀，例如 \u0026lsquo;KB\u0026rsquo; 或 \u0026lsquo;MB\u0026rsquo;。 字节的默认值为“B”。 它是以字节为单位定义的请求的允许大小限制。 以下清单配置了 RequestSize GatewayFilter：\nspring: cloud: gateway: routes: - id: request_size_route uri: http://localhost:8080/upload predicates: - Path=/upload filters: - name: RequestSize args: maxSize: 5000000 当请求因大小而被拒绝时，RequestSize GatewayFilter 工厂将响应状态设置为 413 Payload Too Large 并带有一个额外的标头 errorMessage。 以下示例显示了这样的错误消息：\nerrorMessage` : `Request size is larger than permissible limit. Request size is 6.0 MB where permissible limit is 5.0 MB 如果未在路由定义中作为过滤器参数提供，则默认请求大小设置为 5 MB。\nRequestRateLimiter RequestRateLimiter GatewayFilter 工厂使用 RateLimiter 实现来确定是否允许继续处理当前请求。 如果不是，则返回 HTTP 429 - Too Many Requests（默认情况下）状态。\n此过滤器采用可选的 keyResolver 参数和特定于速率限制器的参数（本节稍后介绍）。\nkeyResolver 是一个实现 KeyResolver 接口的 bean。 在配置中，使用 SpEL 按名称引用 bean。 #{@myKeyResolver} 是一个 SpEL 表达式，它引用名为 myKeyResolver 的 bean。 以下清单显示了 KeyResolver 接口：\npublic interface KeyResolver { Mono\u0026lt;String\u0026gt; resolve(ServerWebExchange exchange); } KeyResolver 接口让可插拔策略派生出限制请求的key。 在未来的里程碑版本中，将有一些 KeyResolver 实现。\nKeyResolver 的默认实现是 PrincipalNameKeyResolver，它从 ServerWebExchange 检索 Principal 并调用 Principal.getName()。\n默认情况下，如果 KeyResolver 未找到key，则拒绝请求。 您可以通过设置 spring.cloud.gateway.filter.request-rate-limiter.deny-empty-key（true 或 false）和 spring.cloud.gateway.filter.request-rate-limiter.empty-key-status-code来调整此行为\nRedis 实现基于在 Stripe 完成的工作。 它需要使用 spring-boot-starter-data-redis-reactive Spring Boot starter。\n使用的算法是令牌桶算法。\nredis-rate-limiter.replenishRate 属性是您希望允许用户每秒执行多少请求。 这是令牌桶填充的速率。\nredis-rate-limiter.burstCapacity 属性是允许用户在一秒内执行的最大请求数。 这是令牌桶可以容纳的令牌数量。 将此值设置为零会阻止所有请求。\nredis-rate-limiter.requestedTokens 属性是请求花费多少令牌。 这是每个请求从存储桶中获取的令牌数量，默认为 1。\n稳定的速率是通过在replyRate 和burstCapacity 中设置相同的值来实现的。 通过将burstCapacity 设置为高于replyRate，可以允许临时突发。 在这种情况下，需要允许速率限制器在突发之间有一段时间（根据replyRate），因为两个连续的突发将导致请求丢失（HTTP 429 - Too Many Requests）。 以下清单配置了 redis-rate-limiter：\nspring: cloud: gateway: routes: - id: requestratelimiter_route uri: https://example.org filters: - name: RequestRateLimiter args: redis-rate-limiter.replenishRate: 10 redis-rate-limiter.burstCapacity: 20 redis-rate-limiter.requestedTokens: 1 java代码\n@Bean KeyResolver userKeyResolver() { return exchange -\u0026gt; Mono.just(exchange.getRequest().getQueryParams().getFirst(\u0026#34;user\u0026#34;)); } 这将每个用户的请求速率限制定义为 10。 允许突发 20 个，但在下一秒，只有 10 个请求可用。 KeyResolver 是一个简单的获取用户请求参数的方法（注意，不推荐用于生产）。\n您还可以将速率限制器定义为实现 RateLimiter 接口的 bean。 在配置中，您可以使用 SpEL 按名称引用 bean。 #{@myRateLimiter} 是一个 SpEL 表达式，它引用名为 myRateLimiter 的 bean。 下面的清单定义了一个速率限制器，它使用在前面的清单中定义的 KeyResolver：\nspring: cloud: gateway: routes: - id: requestratelimiter_route uri: https://example.org filters: - name: RequestRateLimiter args: rate-limiter: \u0026#34;#{@myRateLimiter}\u0026#34; key-resolver: \u0026#34;#{@userKeyResolver}\u0026#34; 安全相关 Token Relay 令牌中继是 OAuth2 消费者充当客户端并将传入令牌转发到传出资源请求的地方。 消费者可以是纯客户端（如 SSO 应用程序）或资源服务器。\nSpring Cloud Gateway 可以将 OAuth2 访问令牌下游转发到它正在代理的服务。 要将此功能添加到网关，您需要像这样添加 TokenRelayGatewayFilterFactory：\n@Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\u0026#34;resource\u0026#34;, r -\u0026gt; r.path(\u0026#34;/resource\u0026#34;) .filters(f -\u0026gt; f.tokenRelay()) .uri(\u0026#34;http://localhost:9000\u0026#34;)) .build(); } spring: cloud: gateway: routes: - id: resource uri: http://localhost:9000 predicates: - Path=/resource filters: - TokenRelay= 并且它将（除了登录用户并获取令牌之外）将身份验证令牌下游传递给服务（在本例中为 /resource）。\n要为 Spring Cloud Gateway 启用此功能，请添加以下依赖项:\norg.springframework.boot:spring-boot-starter-oauth2-client {githubmaster}/src/main/java/org/springframework/cloud/gateway/security/TokenRelayGatewayFilterFactory.java[filter] 从当前已验证的用户中提取访问令牌，并将其放入下游请求的请求头中。\n只有在设置了正确的 spring.security.oauth2.client.* 属性时才会创建 TokenRelayGatewayFilterFactory bean，这将触发 ReactiveClientRegistrationRepository bean 的创建。\nTokenRelayGatewayFilterFactory 使用的 ReactiveOAuth2AuthorizedClientService 的默认实现使用内存数据存储。 如果您需要更强大的解决方案，您将需要提供自己的实现 ReactiveOAuth2AuthorizedClientService。\nSecureHeaders 根据本博客文章中提出的建议，SecureHeaders GatewayFilter 工厂向响应添加了许多标头。\nX-Xss-Protection:1 (mode=block) Strict-Transport-Security (max-age=631138519) X-Frame-Options (DENY) X-Content-Type-Options (nosniff) Referrer-Policy (no-referrer) Content-Security-Policy (default-src \u0026#39;self\u0026#39; https:; font-src \u0026#39;self\u0026#39; https: data:; img-src \u0026#39;self\u0026#39; https: data:; object-src \u0026#39;none\u0026#39;; script-src https:; style-src \u0026#39;self\u0026#39; https: \u0026#39;unsafe-inline)\u0026#39; X-Download-Options (noopen) X-Permitted-Cross-Domain-Policies (none) 要更改默认值，请在 spring.cloud.gateway.filter.secure-headers 命名空间中设置适当的属性。 以下属性可用：\nxss-protection-header strict-transport-security x-frame-options x-content-type-options referrer-policy content-security-policy x-download-options x-permitted-cross-domain-policies 要禁用默认值，请使用逗号分隔值设置 spring.cloud.gateway.filter.secure-headers.disable 属性。 以下示例显示了如何执行此操作：\nspring.cloud.gateway.filter.secure-headers.disable=x-frame-options,strict-transport-security 服务降级相关 CircuitBreaker Spring Cloud CircuitBreaker GatewayFilter 工厂使用 Spring Cloud CircuitBreaker API 将网关路由包装在断路器中。 Spring Cloud CircuitBreaker 可与 Spring Cloud Gateway 一起使用。 Spring Cloud 支持开箱即用的 Resilience4J。\n要启用 Spring Cloud CircuitBreaker 过滤器，您需要将 spring-cloud-starter-circuitbreaker-reactor-resilience4j 放在类路径上。 以下示例配置 Spring Cloud CircuitBreaker GatewayFilter：\nspring: cloud: gateway: routes: - id: circuitbreaker_route uri: https://example.org filters: - CircuitBreaker=myCircuitBreaker Spring Cloud CircuitBreaker 过滤器还可以接受可选的 fallbackUri 参数。 目前，仅支持转发。 如果调用回退，则请求将转发到与 URI 匹配的控制器。 以下示例配置了这样的回退：\nspring: cloud: gateway: routes: - id: circuitbreaker_route uri: lb://backing-service:8088 predicates: - Path=/consumingServiceEndpoint filters: - name: CircuitBreaker args: name: myCircuitBreaker fallbackUri: forward:/inCaseOfFailureUseThis - RewritePath=/consumingServiceEndpoint, /backingServiceEndpoint 同样的java配置如下：\n@Bean public RouteLocator routes(RouteLocatorBuilder builder) { return builder.routes() .route(\u0026#34;circuitbreaker_route\u0026#34;, r -\u0026gt; r.path(\u0026#34;/consumingServiceEndpoint\u0026#34;) .filters(f -\u0026gt; f.circuitBreaker(c -\u0026gt; c.name(\u0026#34;myCircuitBreaker\u0026#34;).fallbackUri(\u0026#34;forward:/inCaseOfFailureUseThis\u0026#34;)) .rewritePath(\u0026#34;/consumingServiceEndpoint\u0026#34;, \u0026#34;/backingServiceEndpoint\u0026#34;)).uri(\u0026#34;lb://backing-service:8088\u0026#34;) .build(); } 当调用断路器回退时，此示例转发到 /inCaseofFailureUseThis URI。 请注意，此示例还演示了（可选）Spring Cloud LoadBalancer 负载平衡（由目标 URI 上的 lb 前缀定义）。\n主要场景是使用 fallbackUri 在网关应用程序中定义内部controller 或handler。 但是，您也可以将请求重新路由到外部应用程序中的controller 或handler，如下所示：\nspring: cloud: gateway: routes: - id: ingredients uri: lb://ingredients predicates: - Path=//ingredients/** filters: - name: CircuitBreaker args: name: fetchIngredients fallbackUri: forward:/fallback - id: ingredients-fallback uri: http://localhost:9994 predicates: - Path=/fallback 在此示例中，网关应用程序中没有回退端点或处理程序。 但是，在另一个应用程序中有一个，在 localhost:9994 下注册。\n如果请求被转发到回退，Spring Cloud CircuitBreaker Gateway 过滤器还提供导致它的 Throwable。 它作为 ServerWebExchangeUtils.CIRCUITBREAKER_EXECUTION_EXCEPTION_ATTR 属性添加到 ServerWebExchange 中，可在网关应用程序中处理回退时使用。\n对于外部控制器/处理程序场景，可以添加带有异常详细信息的标头。 您可以在 FallbackHeaders GatewayFilter Factory 部分找到有关这样做的更多信息。\n在某些情况下，您可能希望根据从其环绕的路由返回的状态代码来触发断路器。 断路器配置对象采用状态代码列表，如果返回这些状态代码，将导致断路器跳闸。 在设置要使断路器跳闸的状态代码时，您可以使用带有状态代码值的整数或 HttpStatus 枚举的字符串表示形式。\nspring: cloud: gateway: routes: - id: circuitbreaker_route uri: lb://backing-service:8088 predicates: - Path=/consumingServiceEndpoint filters: - name: CircuitBreaker args: name: myCircuitBreaker fallbackUri: forward:/inCaseOfFailureUseThis statusCodes: - 500 - \u0026#34;NOT_FOUND\u0026#34; 等效的java配置\n@Bean public RouteLocator routes(RouteLocatorBuilder builder) { return builder.routes() .route(\u0026#34;circuitbreaker_route\u0026#34;, r -\u0026gt; r.path(\u0026#34;/consumingServiceEndpoint\u0026#34;) .filters(f -\u0026gt; f.circuitBreaker(c -\u0026gt; c.name(\u0026#34;myCircuitBreaker\u0026#34;).fallbackUri(\u0026#34;forward:/inCaseOfFailureUseThis\u0026#34;).addStatusCode(\u0026#34;INTERNAL_SERVER_ERROR\u0026#34;)) .rewritePath(\u0026#34;/consumingServiceEndpoint\u0026#34;, \u0026#34;/backingServiceEndpoint\u0026#34;)).uri(\u0026#34;lb://backing-service:8088\u0026#34;) .build(); } FallbackHeaders FallbackHeaders 工厂允许您在转发到外部应用程序中的 fallbackUri 的请求的标头中添加 Spring Cloud CircuitBreaker 执行异常详细信息，如下面的场景：\nspring: cloud: gateway: routes: - id: ingredients uri: lb://ingredients predicates: - Path=//ingredients/** filters: - name: CircuitBreaker args: name: fetchIngredients fallbackUri: forward:/fallback - id: ingredients-fallback uri: http://localhost:9994 predicates: - Path=/fallback filters: - name: FallbackHeaders args: executionExceptionTypeHeaderName: Test-Header 在此示例中，在运行断路器时发生执行异常后，请求将转发到在 localhost:9994 上运行的应用程序中的回退端点或处理程序。 FallbackHeaders 过滤器将带有异常类型、消息和（如果可用）根本原因异常类型和消息的标头添加到该请求中。\n您可以通过设置以下参数的值（显示为它们的默认值）来覆盖配置中标头的名称：\nexecutionExceptionTypeHeaderName (\u0026quot;Execution-Exception-Type\u0026quot;) executionExceptionMessageHeaderName (\u0026quot;Execution-Exception-Message\u0026quot;) rootCauseExceptionTypeHeaderName (\u0026quot;Root-Cause-Exception-Type\u0026quot;) rootCauseExceptionMessageHeaderName (\u0026quot;Root-Cause-Exception-Message\u0026quot;) Retry 支持以下参数:\nretries : 重试的次数，默认3 statuses： 应该重试的 HTTP 状态码，用 org.springframework.http.HttpStatus 表示。 methods：应该重试的 HTTP 方法，使用 org.springframework.http.HttpMethod 表示。默认GET series：要重试的状态码系列，用org.springframework.http.HttpStatus.Series表示。默认5XX exceptions： 应该重试的抛出异常的列表。默认IOException and TimeoutException backoff： 为重试配置的指数退避。 在 firstBackoff * (factor ^ n) 的退避间隔后执行重试，其中 n 是迭代。 如果配置了 maxBackoff，则应用的最大退避限制为 maxBackoff。 如果 basedOnPreviousValue 为真，则使用 prevBackoff * 因子计算回退。默认disabled spring: cloud: gateway: routes: - id: retry_test uri: http://localhost:8080/flakey predicates: - Host=*.retry.com filters: - name: Retry args: retries: 3 statuses: BAD_GATEWAY methods: GET,POST backoff: firstBackoff: 10ms maxBackoff: 50ms factor: 2 basedOnPreviousValue: false 使用带有 forward: 前缀的重试过滤器时，应仔细编写目标端点，以便在出现错误时不会执行任何可能导致响应被发送到客户端并提交的操作。 例如，如果目标端点是带注释的控制器，则目标控制器方法不应返回带有错误状态代码的 ResponseEntity。 相反，它应该抛出异常或发出错误信号（例如，通过 Mono.error(ex) 返回值），重试过滤器可以配置为通过重试来处理。\n将重试过滤器与任何带有正文的 HTTP 方法一起使用时，正文将被缓存，网关将受到内存限制。 正文缓存在由 ServerWebExchangeUtils.CACHED_REQUEST_BODY_ATTR 定义的请求属性中。 对象的类型是 org.springframework.core.io.buffer.DataBuffer。\n其他 SaveSession SaveSession GatewayFilter 工厂在向下游转发调用之前强制执行 WebSession::save 操作。 这在将 Spring Session 之类的东西与惰性数据存储一起使用时特别有用，并且您需要确保在进行转发调用之前已保存会话状态。 以下示例配置 SaveSession GatewayFilter：\nspring: cloud: gateway: routes: - id: save_session uri: https://example.org predicates: - Path=/foo/** filters: - SaveSession 如果您将 Spring Security 与 Spring Session 集成并希望确保安全详细信息已转发到远程进程，那么这很关键。\n全局过滤器 GlobalFilter 接口与 GatewayFilter 具有相同的签名。 这些是有条件地应用于所有路由的特殊过滤器。\n组合全局过滤器以及GatewayFilter 排序 当请求与路由匹配时， filtering web handler 会将 GlobalFilter 的所有实例和 GatewayFilter 的所有特定于路由的实例添加到过滤器链中。 这个组合过滤器链由 org.springframework.core.Ordered 接口排序，您可以通过实现 getOrder() 方法设置该接口。\n由于 Spring Cloud Gateway 区分过滤器逻辑执行的“pre”和“post”阶段（参见 How it Works），具有最高优先级的过滤器是“pre”阶段的第一个，“post”阶段的最后一个阶段。\n@Bean public GlobalFilter customFilter() { return new CustomGlobalFilter(); } public class CustomGlobalFilter implements GlobalFilter, Ordered { @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { log.info(\u0026#34;custom global filter\u0026#34;); return chain.filter(exchange); } @Override public int getOrder() { return -1; } } ForwardRoutingFilter ForwardRoutingFilter 在交换属性 ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR 中查找 URI。 如果 URL 有转发方案（例如 forward:///localendpoint），它会使用 Spring DispatcherHandler 来处理请求。 请求 URL 的路径部分被转发 URL 中的路径覆盖。 未修改的原始 URL 将附加到 ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR 属性中的列表中。\nReactiveLoadBalancerClientFilter ReactiveLoadBalancerClientFilter 在名为 ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR 的交换属性中查找 URI。 如果 URL 具有 lb 方案（例如 lb://myservice），则它使用 Spring Cloud ReactorLoadBalancer 将名称（在此示例中为 myservice）解析为实际主机和端口，并替换同一属性中的 URI。 未修改的原始 URL 将附加到 ServerWebExchangeUtils.GATEWAY_ORIGINAL_REQUEST_URL_ATTR 属性中的列表中。 过滤器还会查看 ServerWebExchangeUtils.GATEWAY_SCHEME_PREFIX_ATTR 属性以查看它是否等于 lb。如果是，则应用相同的规则。 以下清单配置了一个 ReactiveLoadBalancerClientFilter：\nspring: cloud: gateway: routes: - id: myRoute uri: lb://service predicates: - Path=/service/** 默认情况下，当 ReactorLoadBalancer 找不到服务实例时，会返回 503。 您可以通过设置 spring.cloud.gateway.loadbalancer.use404=true 将网关配置为返回 404。\n从 ReactiveLoadBalancerClientFilter 返回的 ServiceInstance 的 isSecure 值会覆盖向网关发出的请求中指定的方案。 例如，如果请求通过 HTTPS 进入网关，但 ServiceInstance 指示它不安全，则通过 HTTP 发出下游请求。 相反的情况也可以适用。 但是，如果在网关配置中为路由指定了 GATEWAY_SCHEME_PREFIX_ATTR，则前缀将被剥离，并且来自路由 URL 的结果方案将覆盖 ServiceInstance 配置。\nNetty 路由过滤器 如果位于 ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR 交换属性中的 URL 具有 http 或 https 方案，则 Netty 路由过滤器运行。 它使用 Netty HttpClient 发出下游代理请求。 响应放在 ServerWebExchangeUtils.CLIENT_RESPONSE_ATTR 交换属性中，以供稍后过滤器使用。 （还有一个实验性的 WebClientHttpRoutingFilter 执行相同的功能但不需要 Netty。）\nNettyWriteResponseFilter 如果 ServerWebExchangeUtils.CLIENT_RESPONSE_ATTR 交换属性中存在 Netty HttpClientResponse，则 NettyWriteResponseFilter 运行。 它在所有其他过滤器完成后运行，并将代理响应写回网关客户端响应。 （还有一个实验性的 WebClientWriteResponseFilter 可以执行相同的功能，但不需要 Netty。）\nRouteToRequestUrlFilter 如果 ServerWebExchangeUtils.GATEWAY_ROUTE_ATTR 交换属性中有 Route 对象，则 RouteToRequestUrlFilter 运行。 它基于请求 URI 创建一个新的 URI，但使用 Route 对象的 URI 属性进行更新。 新 URI 放置在 ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR 交换属性中。\n如果 URI 具有方案前缀，例如 lb:ws://serviceid，则 lb 方案将从 URI 中剥离并放置在 ServerWebExchangeUtils.GATEWAY_SCHEME_PREFIX_ATTR 中，以便稍后在过滤器链中使用。\nwebsocket 路由过滤器 如果位于 ServerWebExchangeUtils.GATEWAY_REQUEST_URL_ATTR 交换属性中的 URL 具有 ws 或 wss 方案，则 websocket 路由过滤器运行。 它使用 Spring WebSocket 基础结构向下游转发 websocket 请求。\n您可以通过在 URI 前加上 lb 来对 websockets 进行负载平衡，例如 lb:ws://serviceid。\nspring: cloud: gateway: routes: # SockJS route - id: websocket_sockjs_route uri: http://localhost:3001 predicates: - Path=/websocket/info/** # Normal Websocket route - id: websocket_route uri: ws://localhost:3001 predicates: - Path=/websocket/** metrics过滤器 要启用网关指标，请将 spring-boot-starter-actuator 添加为项目依赖项。 然后，默认情况下，只要属性 spring.cloud.gateway.metrics.enabled 未设置为 false，网关指标过滤器就会运行。 此过滤器添加了一个名为 gateway.requests 的计时器指标，并带有以下标签：\nrouteId：路由ID routeUri：API 路由到的 URI。 outcome：结果，由 HttpStatus.Series 分类。 status：返回给客户端的请求的 HTTP 状态 httpStatusCode：返回给客户端的请求的 HTTP 状态。 httpMethod：用于请求的 HTTP 方法。 然后可以从 /actuator/metrics/gateway.requests 抓取这些指标，并且可以轻松地与 Prometheus 集成以创建 Grafana 仪表板。\n要启用 prometheus 端点，请将 micrometer-registry-prometheus 添加为项目依赖项。\n将交换标记为已路由 网关路由 ServerWebExchange 后，它通过将 gatewayAlreadyRouted 添加到交换属性来将该交换标记为“已路由”。 一旦请求被标记为路由，其他路由过滤器将不会再次路由该请求，实质上是跳过过滤器。 有一些方便的方法可用于将交换标记为已路由或检查交换是否已被路由。\nServerWebExchangeUtils.isAlreadyRouted 接受一个 ServerWebExchange 对象并检查它是否已被“路由”。\nServerWebExchangeUtils.setAlreadyRouted 接受一个 ServerWebExchange 对象并将其标记为“已路由”。\nHttpHeadersFilters HttpHeadersFilters 在向下游发送请求之前应用于请求，例如在 NettyRoutingFilter 中。\n转发headers的过滤器 转发头过滤器创建转发头以发送到下游服务。 它将当前请求的 Host 标头、方案和端口添加到任何现有的 Forwarded 标头中。\nRemoveHopByHop RemoveHopByHop 标头过滤器从转发的请求中删除标头。 删除的默认标头列表来自 IETF。\n默认一出的标头：\nConnection Keep-Alive Proxy-Authenticate Proxy-Authorization TE Trailer Transfer-Encoding Upgrade 要更改此设置，请将 spring.cloud.gateway.filter.remove-hop-by-hop.headers 属性设置为要删除的标头名称列表。\nXForwarded XForwarded 标头过滤器创建各种 X-Forwarded-* 标头以发送到下游服务。 它使用当前请求的主机头、方案、端口和路径来创建各种头。\n可以通过以下布尔属性（默认为 true）控制单个标题的创建：\nspring.cloud.gateway.x-forwarded.for-enabled spring.cloud.gateway.x-forwarded.host-enabled spring.cloud.gateway.x-forwarded.port-enabled spring.cloud.gateway.x-forwarded.proto-enabled spring.cloud.gateway.x-forwarded.prefix-enabled 附加多个标题可以由以下布尔属性控制（默认为 true）：\nspring.cloud.gateway.x-forwarded.for-append spring.cloud.gateway.x-forwarded.host-append spring.cloud.gateway.x-forwarded.port-append spring.cloud.gateway.x-forwarded.proto-append spring.cloud.gateway.x-forwarded.prefix-append TLS和SSL 网关可以通过遵循通常的 Spring 服务器配置来侦听 HTTPS 上的请求。 以下示例显示了如何执行此操作：\nserver: ssl: enabled: true key-alias: scg key-store-password: scg1234 key-store: classpath:scg-keystore.p12 key-store-type: PKCS12 您可以将网关路由路由到 HTTP 和 HTTPS 后端。 如果您要路由到 HTTPS 后端，则可以使用以下配置将网关配置为信任所有下游证书：\nspring: cloud: gateway: httpclient: ssl: useInsecureTrustManager: true 使用不安全的信任管理器不适合生产。 对于生产部署，您可以使用一组可以信任的已知证书配置网关，并使用以下配置：\nspring: cloud: gateway: httpclient: ssl: trustedX509Certificates: - cert1.pem - cert2.pem 如果 Spring Cloud Gateway 未提供受信任的证书，则使用默认信任存储（您可以通过设置 javax.net.ssl.trustStore 系统属性来覆盖）。\nTLS握手 网关维护一个客户端池，用于路由到后端。 通过 HTTPS 通信时，客户端会发起 TLS 握手。 许多超时与此握手相关联。 您可以配置这些超时可以配置（默认显示）如下：\nspring: cloud: gateway: httpclient: ssl: handshake-timeout-millis: 10000 close-notify-flush-timeout-millis: 3000 close-notify-read-timeout-millis: 0 配置 Spring Cloud Gateway 的配置由一组 RouteDefinitionLocator 实例驱动。 以下清单显示了 RouteDefinitionLocator 接口的定义：\npublic interface RouteDefinitionLocator { Flux\u0026lt;RouteDefinition\u0026gt; getRouteDefinitions(); } 默认情况下，PropertiesRouteDefinitionLocator 使用 Spring Boot 的 @ConfigurationProperties 机制加载属性。\n较早的配置示例都使用使用位置参数而不是命名参数的快捷表示法。 下面两个例子是等价的：\nspring: cloud: gateway: routes: - id: setstatus_route uri: https://example.org filters: - name: SetStatus args: status: 401 - id: setstatusshortcut_route uri: https://example.org filters: - SetStatus=401 对于网关的某些用途，属性就足够了，但某些生产用例受益于从外部源（例如数据库）加载配置。 未来的里程碑版本将具有基于 Spring Data Repositories 的 RouteDefinitionLocator 实现，例如 Redis、MongoDB 和 Cassandra。\n路由元数据配置 您可以使用元数据为每个路由配置附加参数，如下所示：\nspring: cloud: gateway: routes: - id: route_with_metadata uri: https://example.org metadata: optionName: \u0026#34;OptionValue\u0026#34; compositeObject: name: \u0026#34;value\u0026#34; iAmNumber: 1 您可以从交换中获取所有元数据属性，如下所示：\nRoute route = exchange.getAttribute(GATEWAY_ROUTE_ATTR); // get all metadata properties route.getMetadata(); // get a single metadata property route.getMetadata(someKey); http超时配置 可以为所有路由配置 Http 超时（响应和连接），并为每个特定路由覆盖。\n全局配置 要配置全局 http 超时：\n连接超时必须以毫秒为单位指定。\n响应超时必须指定为 java.time.Duration\nspring: cloud: gateway: httpclient: connect-timeout: 1000 response-timeout: 5s 单路由配置 要配置每条路由超时：\n连接超时必须以毫秒为单位指定。\n响应超时必须以毫秒为单位指定。\n- id: per_route_timeouts uri: https://example.org predicates: - name: Path args: pattern: /delay/{timeout} metadata: response-timeout: 200 connect-timeout: 200 java配置\nimport static org.springframework.cloud.gateway.support.RouteMetadataUtils.CONNECT_TIMEOUT_ATTR; import static org.springframework.cloud.gateway.support.RouteMetadataUtils.RESPONSE_TIMEOUT_ATTR; @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeBuilder){ return routeBuilder.routes() .route(\u0026#34;test1\u0026#34;, r -\u0026gt; { return r.host(\u0026#34;*.somehost.org\u0026#34;).and().path(\u0026#34;/somepath\u0026#34;) .filters(f -\u0026gt; f.addRequestHeader(\u0026#34;header1\u0026#34;, \u0026#34;header-value-1\u0026#34;)) .uri(\u0026#34;http://someuri\u0026#34;) .metadata(RESPONSE_TIMEOUT_ATTR, 200) .metadata(CONNECT_TIMEOUT_ATTR, 200); }) .build(); } java路由API 为了允许在 Java 中进行简单的配置，RouteLocatorBuilder bean 包含一个流畅的 API。 以下清单显示了它的工作原理：\n// static imports from GatewayFilters and RoutePredicates @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder, ThrottleGatewayFilterFactory throttle) { return builder.routes() .route(r -\u0026gt; r.host(\u0026#34;**.abc.org\u0026#34;).and().path(\u0026#34;/image/png\u0026#34;) .filters(f -\u0026gt; f.addResponseHeader(\u0026#34;X-TestHeader\u0026#34;, \u0026#34;foobar\u0026#34;)) .uri(\u0026#34;http://httpbin.org:80\u0026#34;) ) .route(r -\u0026gt; r.path(\u0026#34;/image/webp\u0026#34;) .filters(f -\u0026gt; f.addResponseHeader(\u0026#34;X-AnotherHeader\u0026#34;, \u0026#34;baz\u0026#34;)) .uri(\u0026#34;http://httpbin.org:80\u0026#34;) .metadata(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) ) .route(r -\u0026gt; r.order(-1) .host(\u0026#34;**.throttle.org\u0026#34;).and().path(\u0026#34;/get\u0026#34;) .filters(f -\u0026gt; f.filter(throttle.apply(1, 1, 10, TimeUnit.SECONDS))) .uri(\u0026#34;http://httpbin.org:80\u0026#34;) .metadata(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) ) .build(); } 这种风格还允许更多的自定义谓词断言。 RouteDefinitionLocator bean 定义的谓词使用逻辑和组合。 通过使用 fluent Java API，您可以在 Predicate 类上使用 and()、or() 和 negate() 运算符。\nDiscoveryClient 路由配置 您可以将网关配置为基于向 DiscoveryClient 兼容服务注册表注册的服务创建路由。\n要启用此功能，请设置 spring.cloud.gateway.discovery.locator.enabled=true 并确保 DiscoveryClient 实现（例如 Netflix Eureka、Consul 或 Zookeeper）在类路径上并已启用。\n为 DiscoveryClient 路由配置谓词和过滤器 默认情况下，网关为使用 DiscoveryClient 创建的路由定义单个谓词和过滤器。\n默认谓词是使用模式 /serviceId/** 定义的路径谓词，其中 serviceId 是来自 DiscoveryClient 的服务的 ID。\n默认过滤器是带有正则表达式 /serviceId/?(?.*) 和替换 /${remaining} 的重写路径过滤器。 这会在向下游发送请求之前从路径中剥离服务 ID。\n如果要自定义 DiscoveryClient 路由使用的谓词或过滤器，请设置 spring.cloud.gateway.discovery.locator.predicates[x] 和 spring.cloud.gateway.discovery.locator.filters[y]。 这样做时，如果您想保留该功能，您需要确保包含前面显示的默认谓词和过滤器。 以下示例显示了它的样子：\nspring.cloud.gateway.discovery.locator.predicates[0].name: Path spring.cloud.gateway.discovery.locator.predicates[0].args[pattern]: \u0026#34;\u0026#39;/\u0026#39;+serviceId+\u0026#39;/**\u0026#39;\u0026#34; spring.cloud.gateway.discovery.locator.predicates[1].name: Host spring.cloud.gateway.discovery.locator.predicates[1].args[pattern]: \u0026#34;\u0026#39;**.foo.com\u0026#39;\u0026#34; spring.cloud.gateway.discovery.locator.filters[0].name: CircuitBreaker spring.cloud.gateway.discovery.locator.filters[0].args[name]: serviceId spring.cloud.gateway.discovery.locator.filters[1].name: RewritePath spring.cloud.gateway.discovery.locator.filters[1].args[regexp]: \u0026#34;\u0026#39;/\u0026#39; + serviceId + \u0026#39;/?(?\u0026lt;remaining\u0026gt;.*)\u0026#39;\u0026#34; spring.cloud.gateway.discovery.locator.filters[1].args[replacement]: \u0026#34;\u0026#39;/${remaining}\u0026#39;\u0026#34; Reactor Netty 访问日志 要启用 Reactor Netty 访问日志，请设置 -Dreactor.netty.http.server.accessLogEnabled=true。它必须是 Java 系统属性，而不是 Spring Boot 属性。\n您可以将日志记录系统配置为具有单独的访问日志文件。 以下示例创建一个 Logback 配置：\n\u0026lt;appender name=\u0026#34;accessLog\u0026#34; class=\u0026#34;ch.qos.logback.core.FileAppender\u0026#34;\u0026gt; \u0026lt;file\u0026gt;access_log.log\u0026lt;/file\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;async\u0026#34; class=\u0026#34;ch.qos.logback.classic.AsyncAppender\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;accessLog\u0026#34; /\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;reactor.netty.http.server.AccessLog\u0026#34; level=\u0026#34;INFO\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;async\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; CORS 配置 您可以配置网关以控制 CORS 行为。 “全局” CORS 配置是 URL 模式到 Spring Framework CorsConfiguration 的映射。 以下示例配置 CORS：\nspring: cloud: gateway: globalcors: cors-configurations: \u0026#39;[/**]\u0026#39;: allowedOrigins: \u0026#34;https://docs.spring.io\u0026#34; allowedMethods: - GET 在前面的示例中，对于所有 GET 请求路径，都允许来自 docs.spring.io 的请求发出 CORS 请求。\n要为某些网关路由谓词未处理的请求提供相同的 CORS 配置，请将 spring.cloud.gateway.globalcors.add-to-simple-url-handler-mapping 属性设置为 true。 当您尝试支持 CORS 预检请求并且您的路由谓词由于 HTTP 方法是选项而未评估为 true 时，这很有用。\nActuator API /gateway 执行器端点允许您监视 Spring Cloud Gateway 应用程序并与之交互。 要远程访问，必须在应用程序属性中启用并通过 HTTP 或 JMX 公开端点。 以下清单显示了如何执行此操作：\nmanagement.endpoint.gateway.enabled=true # default value management.endpoints.web.exposure.include=gateway Spring Cloud Gateway 中添加了一种新的、更详细的格式。 它为每个路由添加了更多详细信息，让您可以查看与每个路由关联的谓词和过滤器以及任何可用的配置。 以下示例配置 /actuator/gateway/routes：\n[ { \u0026#34;predicate\u0026#34;: \u0026#34;(Hosts: [**.addrequestheader.org] \u0026amp;\u0026amp; Paths: [/headers], match trailing slash: true)\u0026#34;, \u0026#34;route_id\u0026#34;: \u0026#34;add_request_header_test\u0026#34;, \u0026#34;filters\u0026#34;: [ \u0026#34;[[AddResponseHeader X-Response-Default-Foo = \u0026#39;Default-Bar\u0026#39;], order = 1]\u0026#34;, \u0026#34;[[AddRequestHeader X-Request-Foo = \u0026#39;Bar\u0026#39;], order = 1]\u0026#34;, \u0026#34;[[PrefixPath prefix = \u0026#39;/httpbin\u0026#39;], order = 2]\u0026#34; ], \u0026#34;uri\u0026#34;: \u0026#34;lb://testservice\u0026#34;, \u0026#34;order\u0026#34;: 0 } ] 默认情况下启用此功能。 要禁用它，请设置以下属性：\nspring.cloud.gateway.actuator.verbose.enabled=false 检索路由过滤器 要检索应用于所有路由的全局过滤器，请向 /actuator/gateway/globalfilters 发出 GET 请求。 得到的响应类似于以下内容：\n{ \u0026#34;org.springframework.cloud.gateway.filter.ReactiveLoadBalancerClientFilter@77856cc5\u0026#34;: 10100, \u0026#34;org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@4f6fd101\u0026#34;: 10000, \u0026#34;org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@32d22650\u0026#34;: -1, \u0026#34;org.springframework.cloud.gateway.filter.ForwardRoutingFilter@106459d9\u0026#34;: 2147483647, \u0026#34;org.springframework.cloud.gateway.filter.NettyRoutingFilter@1fbd5e0\u0026#34;: 2147483647, \u0026#34;org.springframework.cloud.gateway.filter.ForwardPathFilter@33a71d23\u0026#34;: 0, \u0026#34;org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@135064ea\u0026#34;: 2147483637, \u0026#34;org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@23c05889\u0026#34;: 2147483646 } 响应包含现有全局过滤器的详细信息。 对于每个全局过滤器，都有过滤器对象的字符串表示（例如，org.springframework.cloud.gateway.filter.ReactiveLoadBalancerClientFilter@77856cc5）和过滤器链中的对应顺序。}\n要检索应用于路由的 GatewayFilter 工厂，请向 /actuator/gateway/routefilters 发出 GET 请求。 得到的响应类似于以下内容：\n{ \u0026#34;[AddRequestHeaderGatewayFilterFactory@570ed9c configClass = AbstractNameValueGatewayFilterFactory.NameValueConfig]\u0026#34;: null, \u0026#34;[SecureHeadersGatewayFilterFactory@fceab5d configClass = Object]\u0026#34;: null, \u0026#34;[SaveSessionGatewayFilterFactory@4449b273 configClass = Object]\u0026#34;: null } 响应包含应用于任何特定路由的 GatewayFilter 工厂的详细信息。 对于每个工厂，都有对应对象的字符串表示（例如，[SecureHeadersGatewayFilterFactory@fceab5d configClass = Object]）。 请注意，空值是由于端点控制器的实现不完整，因为它尝试设置过滤器链中对象的顺序，这不适用于 GatewayFilter 工厂对象。\n刷新路由缓存 要清除路由缓存，请向 /actuator/gateway/refresh 发出 POST 请求。 请求返回 200 没有响应正文。\n检索网关定义的路由 要检索网关中定义的路由，请向 /actuator/gateway/routes 发出 GET 请求。 得到的响应类似于以下内容：\n[{ \u0026#34;route_id\u0026#34;: \u0026#34;first_route\u0026#34;, \u0026#34;route_object\u0026#34;: { \u0026#34;predicate\u0026#34;: \u0026#34;org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$432/1736826640@1e9d7e7d\u0026#34;, \u0026#34;filters\u0026#34;: [ \u0026#34;OrderedGatewayFilter{delegate=org.springframework.cloud.gateway.filter.factory.PreserveHostHeaderGatewayFilterFactory$$Lambda$436/674480275@6631ef72, order=0}\u0026#34; ] }, \u0026#34;order\u0026#34;: 0 }, { \u0026#34;route_id\u0026#34;: \u0026#34;second_route\u0026#34;, \u0026#34;route_object\u0026#34;: { \u0026#34;predicate\u0026#34;: \u0026#34;org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory$$Lambda$432/1736826640@cd8d298\u0026#34;, \u0026#34;filters\u0026#34;: [] }, \u0026#34;order\u0026#34;: 0 }] 响应包含网关中定义的所有路由的详细信息。 下表描述了响应的每个元素（每个元素都是一个路由）的结构：\nPath Type Description route_id String The route ID. route_object.predicate Object The route predicate. route_object.filters Array The [GatewayFilter](https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gatewayfilter-factories) factories applied to the route. order Number The route order. 要检索有关单个路由的信息，请向 /actuator/gateway/routes/{id}（例如，/actuator/gateway/routes/first_route）发出 GET 请求。 得到的响应类似于以下内容：\n{ \u0026#34;id\u0026#34;: \u0026#34;first_route\u0026#34;, \u0026#34;predicates\u0026#34;: [{ \u0026#34;name\u0026#34;: \u0026#34;Path\u0026#34;, \u0026#34;args\u0026#34;: {\u0026#34;_genkey_0\u0026#34;:\u0026#34;/first\u0026#34;} }], \u0026#34;filters\u0026#34;: [], \u0026#34;uri\u0026#34;: \u0026#34;https://www.uri-destination.org\u0026#34;, \u0026#34;order\u0026#34;: 0 }] 下表描述了响应的结构：\nPath Type Description id String The route ID. predicates Array The collection of route predicates. Each item defines the name and the arguments of a given predicate. filters Array The collection of filters applied to the route. uri String The destination URI of the route. order Number The route order. 要创建路由，请使用指定路由字段的 JSON 正文向 /gateway/routes/{id_route_to_create} 发出 POST 请求（请参阅检索有关特定路由的信息）。\n要删除路由，请向 /gateway/routes/{id_route_to_delete} 发出 DELETE 请求。\n回顾：所有端点的列表\nID HTTP Method Description globalfilters GET Displays the list of global filters applied to the routes. routefilters GET Displays the list of GatewayFilter factories applied to a particular route. refresh POST Clears the routes cache. routes GET Displays the list of routes defined in the gateway. routes/{id} GET Displays information about a particular route. routes/{id} POST Adds a new route to the gateway. routes/{id} DELETE Removes an existing route from the gateway. 日志 以下记录器可能包含 DEBUG 和 TRACE 级别的有价值的故障排除信息：\norg.springframework.cloud.gateway org.springframework.http.server.reactive org.springframework.web.reactive org.springframework.boot.autoconfigure.web reactor.netty redisratelimiter Reactor Netty HttpClient 和 HttpServer 可以启用窃听。 当与将 reactor.netty 日志级别设置为 DEBUG 或 TRACE 结合使用时，它可以记录信息，例如通过线路发送和接收的标头和正文。 要启用窃听，请分别为 HttpServer 和 HttpClient 设置 spring.cloud.gateway.httpserver.wiretap=true 或 spring.cloud.gateway.httpclient.wiretap=true。\n自定义过滤器 自己编写谓词 为了编写路由谓词，您需要实现 RoutePredicateFactory。 有一个名为 AbstractRoutePredicateFactory 的抽象类，您可以对其进行扩展。\npublic class MyRoutePredicateFactory extends AbstractRoutePredicateFactory\u0026lt;HeaderRoutePredicateFactory.Config\u0026gt; { public MyRoutePredicateFactory() { super(Config.class); } @Override public Predicate\u0026lt;ServerWebExchange\u0026gt; apply(Config config) { // grab configuration from Config object return exchange -\u0026gt; { //grab the request ServerHttpRequest request = exchange.getRequest(); //take information from the request to see if it //matches configuration. return matches(config, request); }; } public static class Config { //Put the configuration properties for your filter here } } 自己编写GatewayFilter 要编写 GatewayFilter，您必须实现 GatewayFilterFactory。 您可以扩展名为 AbstractGatewayFilterFactory 的抽象类。 以下示例显示了如何执行此操作：\npublic class PreGatewayFilterFactory extends AbstractGatewayFilterFactory\u0026lt;PreGatewayFilterFactory.Config\u0026gt; { public PreGatewayFilterFactory() { super(Config.class); } @Override public GatewayFilter apply(Config config) { // grab configuration from Config object return (exchange, chain) -\u0026gt; { //If you want to build a \u0026#34;pre\u0026#34; filter you need to manipulate the //request before calling chain.filter ServerHttpRequest.Builder builder = exchange.getRequest().mutate(); //use builder to manipulate the request return chain.filter(exchange.mutate().request(builder.build()).build()); }; } public static class Config { //Put the configuration properties for your filter here } } public class PostGatewayFilterFactory extends AbstractGatewayFilterFactory\u0026lt;PostGatewayFilterFactory.Config\u0026gt; { public PostGatewayFilterFactory() { super(Config.class); } @Override public GatewayFilter apply(Config config) { // grab configuration from Config object return (exchange, chain) -\u0026gt; { return chain.filter(exchange).then(Mono.fromRunnable(() -\u0026gt; { ServerHttpResponse response = exchange.getResponse(); //Manipulate the response in some way })); }; } public static class Config { //Put the configuration properties for your filter here } } 在配置中命名自定义过滤器和引用 自定义过滤器类名称应以 GatewayFilterFactory 结尾。\n例如，要在配置文件中引用名为Something 的过滤器，该过滤器必须位于名为SomethingGatewayFilterFactory 的类中。\n可以创建一个没有 GatewayFilterFactory 后缀命名的网关过滤器，例如类 AnotherThing。 此过滤器可以在配置文件中作为 AnotherThing 引用。 这不是受支持的命名约定，并且可能会在未来版本中删除此语法。 请更新过滤器名称以符合要求。\n自定义全局过滤器 要编写自定义全局过滤器，您必须实现 GlobalFilter 接口。 这将过滤器应用于所有请求。\n以下示例分别显示了如何设置全局前置过滤器和后置过滤器：\n@Bean public GlobalFilter customGlobalFilter() { return (exchange, chain) -\u0026gt; exchange.getPrincipal() .map(Principal::getName) .defaultIfEmpty(\u0026#34;Default User\u0026#34;) .map(userName -\u0026gt; { //adds header to proxied request exchange.getRequest().mutate().header(\u0026#34;CUSTOM-REQUEST-HEADER\u0026#34;, userName).build(); return exchange; }) .flatMap(chain::filter); } @Bean public GlobalFilter customGlobalPostFilter() { return (exchange, chain) -\u0026gt; chain.filter(exchange) .then(Mono.just(exchange)) .map(serverWebExchange -\u0026gt; { //adds header to response serverWebExchange.getResponse().getHeaders().set(\u0026#34;CUSTOM-RESPONSE-HEADER\u0026#34;, HttpStatus.OK.equals(serverWebExchange.getResponse().getStatusCode()) ? \u0026#34;It worked\u0026#34;: \u0026#34;It did not work\u0026#34;); return serverWebExchange; }) .then(); } 使用 Spring MVC 或 Webflux 构建简单网关 Spring Cloud Gateway 提供了一个名为 ProxyExchange 的实用程序对象。 您可以在常规 Spring Web 处理程序中使用它作为方法参数。 它通过反映 HTTP 动词的方法支持基本的下游 HTTP 交换。 对于 MVC，它还支持通过 forward() 方法转发到本地处理程序。 要使用 ProxyExchange，请在类路径中包含正确的模块（spring-cloud-gateway-mvc 或 spring-cloud-gateway-webflux）。\n以下 MVC 示例将向 /test 下游的请求代理到远程服务器：\n@RestController @SpringBootApplication public class GatewaySampleApplication { @Value(\u0026#34;${remote.home}\u0026#34;) private URI home; @GetMapping(\u0026#34;/test\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; proxy(ProxyExchange\u0026lt;byte[]\u0026gt; proxy) throws Exception { return proxy.uri(home.toString() + \u0026#34;/image/png\u0026#34;).get(); } } 以下示例对 Webflux 执行相同的操作：\n@RestController @SpringBootApplication public class GatewaySampleApplication { @Value(\u0026#34;${remote.home}\u0026#34;) private URI home; @GetMapping(\u0026#34;/test\u0026#34;) public Mono\u0026lt;ResponseEntity\u0026lt;?\u0026gt;\u0026gt; proxy(ProxyExchange\u0026lt;byte[]\u0026gt; proxy) throws Exception { return proxy.uri(home.toString() + \u0026#34;/image/png\u0026#34;).get(); } } ProxyExchange 上的便捷方法使处理程序方法能够发现和增强传入请求的 URI 路径。 例如，您可能希望提取路径的尾随元素以将它们传递到下游：\n@GetMapping(\u0026#34;/proxy/path/**\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; proxyPath(ProxyExchange\u0026lt;byte[]\u0026gt; proxy) throws Exception { String path = proxy.path(\u0026#34;/proxy/path/\u0026#34;); return proxy.uri(home.toString() + \u0026#34;/foos/\u0026#34; + path).get(); } Spring MVC 和 Webflux 的所有功能都可用于网关处理程序方法。 因此，您可以注入请求标头和查询参数，例如，您可以使用映射注释中的声明来约束传入的请求。 有关这些功能的更多详细信息，请参阅 Spring MVC 中 @RequestMapping 的文档。\n您可以使用 ProxyExchange 上的 header() 方法向下游响应添加标头。\n您还可以通过向 get() 方法（和其他方法）添加映射器来操作响应标头（以及响应中您喜欢的任何其他内容）。 映射器是一个函数，它接受传入的 ResponseEntity 并将其转换为传出的。\n为不向下游传递的“敏感”标头（默认情况下，cookie 和授权）和“代理”（x-forwarded-*）标头提供一流的支持。\n属性列表 https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/appendix.html\n源码 ServerWebExchange: HTTP 请求-响应交互的契约。 提供对 HTTP 请求和响应的访问，还公开其他与服务器端处理相关的属性和功能，例如请求属性。\npublic interface ServerWebExchange { String LOG_ID_ATTRIBUTE = ServerWebExchange.class.getName() + \u0026#34;.LOG_ID\u0026#34;; ServerHttpRequest getRequest(); ServerHttpResponse getResponse(); Map\u0026lt;String, Object\u0026gt; getAttributes(); @Nullable default \u0026lt;T\u0026gt; T getAttribute(String name) { return this.getAttributes().get(name); } default \u0026lt;T\u0026gt; T getRequiredAttribute(String name) { T value = this.getAttribute(name); Assert.notNull(value, () -\u0026gt; { return \u0026#34;Required attribute \u0026#39;\u0026#34; + name + \u0026#34;\u0026#39; is missing\u0026#34;; }); return value; } default \u0026lt;T\u0026gt; T getAttributeOrDefault(String name, T defaultValue) { return this.getAttributes().getOrDefault(name, defaultValue); } Mono\u0026lt;WebSession\u0026gt; getSession(); \u0026lt;T extends Principal\u0026gt; Mono\u0026lt;T\u0026gt; getPrincipal(); Mono\u0026lt;MultiValueMap\u0026lt;String, String\u0026gt;\u0026gt; getFormData(); Mono\u0026lt;MultiValueMap\u0026lt;String, Part\u0026gt;\u0026gt; getMultipartData(); LocaleContext getLocaleContext(); @Nullable ApplicationContext getApplicationContext(); boolean isNotModified(); boolean checkNotModified(Instant var1); boolean checkNotModified(String var1); boolean checkNotModified(@Nullable String var1, Instant var2); String transformUrl(String var1); void addUrlTransformer(Function\u0026lt;String, String\u0026gt; var1); String getLogPrefix(); default ServerWebExchange.Builder mutate() { return new DefaultServerWebExchangeBuilder(this); } public interface Builder { ServerWebExchange.Builder request(Consumer\u0026lt;org.springframework.http.server.reactive.ServerHttpRequest.Builder\u0026gt; var1); ServerWebExchange.Builder request(ServerHttpRequest var1); ServerWebExchange.Builder response(ServerHttpResponse var1); ServerWebExchange.Builder principal(Mono\u0026lt;Principal\u0026gt; var1); ServerWebExchange build(); } } ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/spring-cloud-gateway/","series":[],"smallImg":"","tags":[{"title":"spring-cloud-gateway","url":"/myblog/tags/spring-cloud-gateway/"}],"timestamp":1669981570,"title":"Spring-Cloud-Gateway"},{"authors":[],"categories":[{"title":"容器技术","url":"/myblog/categories/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"title":"docker","url":"/myblog/categories/docker/"}],"content":"docker安装 ubuntu # 卸载已安装的docker sudo apt-get remove docker docker-engine docker.io containerd runc # 更新apt软件包索引并安装软件包（允许apt通过HTTPS使用仓库）： sudo apt-get update sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common # 安装GPG证书 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # 写入软件源信息 sudo add-apt-repository \u0026#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\u0026#34; # 安装 sudo apt-get -y update sudo apt-get -y install docker-ce 设置镜像加速器 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://p6qarvcy.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker ","date":"2022年12月2日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/docker-basic/","series":[],"smallImg":"","tags":[{"title":"docker","url":"/myblog/tags/docker/"}],"timestamp":1669977260,"title":"Docker-Basic"},{"authors":[],"categories":[{"title":"操作系统","url":"/myblog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"linux","url":"/myblog/categories/linux/"}],"content":"查看linux系统信息 查看内核信息 zzq@Zhao:~$ uname -a Linux Zhao 5.10.16.3-microsoft-standard-WSL2 #1 SMP Fri Apr 2 22:23:49 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux zzq@Zhao:~$ cat /proc/version Linux version 5.10.16.3-microsoft-standard-WSL2 (oe-user@oe-host) (x86_64-msft-linux-gcc (GCC) 9.3.0, GNU ld (GNU Binutils) 2.34.0.20200220) #1 SMP Fri Apr 2 22:23:49 UTC 2021 查看系统的发行版本 zzq@Zhao:~$ ls /etc/*release /etc/lsb-release /etc/os-release zzq@Zhao:~$ cat /etc/os-release NAME=\u0026#34;Ubuntu\u0026#34; VERSION=\u0026#34;20.04.4 LTS (Focal Fossa)\u0026#34; ID=ubuntu ID_LIKE=debian PRETTY_NAME=\u0026#34;Ubuntu 20.04.4 LTS\u0026#34; VERSION_ID=\u0026#34;20.04\u0026#34; HOME_URL=\u0026#34;https://www.ubuntu.com/\u0026#34; SUPPORT_URL=\u0026#34;https://help.ubuntu.com/\u0026#34; BUG_REPORT_URL=\u0026#34;https://bugs.launchpad.net/ubuntu/\u0026#34; PRIVACY_POLICY_URL=\u0026#34;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\u0026#34; VERSION_CODENAME=focal UBUNTU_CODENAME=focal 常见目录 FHS（Filesystem Hierarchy Standard），文件系统层次化标准，该标准规定了 Linux 系统中所有一级目录以及部分二级目录（/usr 和 /var）的用途。发布此标准的主要目的就是为了让用户清楚地了解每个目录应该存放什么类型的文件。\n一级目录 功能（作用） /bin/ 存放系统命令，普通用户和 root 都可以执行。放在 /bin 下的命令在单用户模式下也可以执行 /boot/ 系统启动目录，保存与系统启动相关的文件，如内核文件和启动引导程序（grub）文件等 /dev/ 设备文件保存位置 /etc/ 配置文件保存位置。系统内所有采用默认安装方式（rpm 安装）的服务配置文件全部保存在此目录中，如用户信息、服务的启动脚本、常用服务的配置文件等 /home/ 普通用户的主目录（也称为家目录）。在创建用户时，每个用户要有一个默认登录和保存自己数据的位置，就是用户的主目录，所有普通用户的主目录是在 /home/ 下建立一个和用户名相同的目录。如用户 liming 的主目录就是 /home/liming /lib/ 系统调用的函数库保存位置 /media/ 挂载非移动设备的目录。系统建议用来挂载媒体设备，如软盘和光盘 /mnt/ 挂载移动设备的目录。早期 Linux 中只有这一个挂载目录，并没有细分。系统建议这个目录用来挂载额外的设备，如 U 盘、移动硬盘和其他操作系统的分区 /misc/ 挂载目录。系统建议用来挂载 NFS 服务的共享目录。虽然系统准备了三个默认挂载目录 /media/、/mnt/、/misc/，但是到底在哪个目录中挂载什么设备可以由管理员自己决定。例如，笔者在接触 Linux 的时候，默认挂载目录只有 /mnt/，所以养成了在 /mnt/ 下建立不同目录挂载不同设备的习惯，如 /mnt/cdrom/ 挂载光盘、/mnt/usb/ 挂载 U 盘，都是可以的 /opt/ 第三方安装的软件保存位置。这个目录是放置和安装其他软件的位置，手工安装的源码包软件都可以安装到这个目录中。不过笔者还是习惯把软件放到 /usr/local/ 目录中，也就是说，/usr/local/ 目录也可以用来安装软件 /root/ root 的主目录。普通用户主目录在 /home/ 下，root 主目录直接在“/”下 /sbin/ 保存与系统环境设置相关的命令，只有 root 可以使用这些命令进行系统环境设置，但也有些命令可以允许普通用户查看 /srv/ 服务数据目录。一些系统服务启动之后，可以在这个目录中保存所需要的数据 /tmp/ 临时目录。系统存放临时文件的目录，在该目录下，所有用户都可以访问和写入。建议此目录中不能保存重要数据，最好每次开机都把该目录清空 FHS 针对根目录中包含的子目录仅限于表 1，但除此之外，Linux 系统根目录下通常还包含表 2 中的几个一级目录。\n一级目录 功能（作用） /lost+found/ 当系统意外崩溃或意外关机时，产生的一些文件碎片会存放在这里。在系统启动的过程中，fsck 工具会检查这里，并修复已经损坏的文件系统。这个目录只在每个分区中出现，例如，/lost+found 就是根分区的备份恢复目录，/boot/lost+found 就是 /boot 分区的备份恢复目录 /proc/ 虚拟文件系统。该目录中的数据并不保存在硬盘上，而是保存到内存中。主要保存系统的内核、进程、外部设备状态和网络状态等。如 /proc/cpuinfo 是保存 CPU 信息的，/proc/devices 是保存设备驱动的列表的，/proc/filesystems 是保存文件系统列表的，/proc/net 是保存网络协议信息的\u0026hellip;\u0026hellip; /sys/ 虚拟文件系统。和 /proc/ 目录相似，该目录中的数据都保存在内存中，主要保存与内核相关的信息 usr（注意不是 user），全称为 Unix Software Resource，此目录用于存储系统软件资源。FHS 建议所有开发者，应把软件产品的数据合理的放置在 /usr 目录下的各子目录中，而不是为他们的产品创建单独的目录。\n子目录 功能（作用） /usr/bin/ 存放系统命令，普通用户和超级用户都可以执行。这些命令和系统启动无关，在单用户模式下不能执行 /usr/sbin/ 存放根文件系统不必要的系统管理命令，如多数服务程序，只有 root 可以使用。 /usr/lib/ 应用程序调用的函数库保存位置 /usr/XllR6/ 图形界面系统保存位置 /usr/local/ 手工安装的软件保存位置。我们一般建议源码包软件安装在这个位置 /usr/share/ 应用程序的资源文件保存位置，如帮助文档、说明文档和字体目录 /usr/src/ 源码包保存位置。我们手工下载的源码包和内核源码包都可以保存到这里。不过笔者更习惯把手工下载的源码包保存到 /usr/local/src/ 目录中，把内核源码保存到 /usr/src/linux/ 目录中 /usr/include C/C++ 等编程语言头文件的放置目录 /var 目录用于存储动态数据，例如缓存、日志文件、软件运行过程中产生的文件等。通常，此目录下建议包含如表 4 所示的这些子目录。\n/var子目录 功能（作用） /var/lib/ 程序运行中需要调用或改变的数据保存位置。如 MySQL 的数据库保存在 /var/lib/mysql/ 目录中 /var/log/ 登陆文件放置的目录，其中所包含比较重要的文件如 /var/log/messages, /var/log/wtmp 等。 /var/run/ 一些服务和程序运行后，它们的 PID（进程 ID）保存位置 /var/spool/ 里面主要都是一些临时存放，随时会被用户所调用的数据，例如 /var/spool/mail/ 存放新收到的邮件，/var/spool/cron/ 存放系统定时任务。 /var/www/ RPM 包安装的 Apache 的网页主目录 /var/nis和/var/yp NIS 服务机制所使用的目录，nis 主要记录所有网络中每一个 client 的连接信息；yp 是 linux 的 nis 服务的日志文件存放的目录 /var/tmp 一些应用程序在安装或执行时，需要在重启后使用的某些文件，此目录能将该类文件暂时存放起来，完成后再行删除 根据以上各表列举的各目录及作用，如果我们要做一些实验和练习，需要创建一些临时文件，应该保存在哪里呢？\n答案是用户的主目录或 /tmp/ 临时目录。但是要小心有些目录中不能直接修改和保存数据，比如 /proc/fn/sys/ 目录，因为它们是保存在内存中的，如果在这里写入数据，那么你的内存会越来越小，直至死机；/boot/ 目录也不能保存额外数据，因为 /boot/ 目录会单独分区作为启动分区，如果没有空闲空间，则会导致系统不能正常启动。\n挂载 Linux 系统中“一切皆文件”，所有文件都放置在以根目录为树根的树形目录结构中。在 Linux 看来，任何硬件设备也都是文件，它们各有自己的一套文件系统（文件目录结构）。\n因此产生的问题是，当在 Linux 系统中使用这些硬件设备时，只有将Linux本身的文件目录与硬件设备的文件目录合二为一，硬件设备才能为我们所用。合二为一的过程称为“挂载”。\n挂载，指的就是将设备文件中的顶级目录连接到 Linux 根目录下的某一目录（最好是空目录），访问此目录就等同于访问设备文件。\n纠正一个误区，并不是根目录下任何一个目录都可以作为挂载点，由于挂载操作会使得原有目录中文件被隐藏，因此根目录以及系统原有目录都不要作为挂载点，会造成系统异常甚至崩溃，挂载点最好是新建的空目录。\n举个例子，我们想通过命令行访问某个 U 盘中的数据，图 1 所示为 U 盘文件目录结构和 Linux 系统中的文件目录结构。\n图 1 中可以看到，目前 U 盘和 Linux 系统文件分属两个文件系统，还无法使用命令行找到 U 盘文件，需要将两个文件系统进行挂载。\n接下来，我们在根目录下新建一个目录 /sdb-u，通过挂载命令将 U 盘文件系统挂载到此目录，挂载效果如图 2 所示。\n可以看到，U 盘文件系统已经成为 Linux 文件系统目录的一部分，此时访问 /sdb-u/ 就等同于访问 U 盘。\n前面讲过，根目录下的 /dev/ 目录文件负责所有的硬件设备文件，事实上，当 U 盘插入 Linux 后，系统也确实会给 U 盘分配一个目录文件（比如 sdb1），就位于 /dev/ 目录下（/dev/sdb1），但无法通过 /dev/sdb1/ 直接访问 U 盘数据，访问此目录只会提供给你此设备的一些基本信息（比如容量）。\n硬件设备 文件名称 IDE设备 /dev/hd[a-d]，现在的 IDE设备已经很少见了，因此 一般的硬盘设备会以 /dev/sd 开头。 SCSI/SATA/U盘 /dev/sd[a-p]，一台主机可以有多块硬盘，因此系统 采用 a~p 代表 16 块不同的硬盘。 软驱 /dev/fd[0-1] 打印机 /dev/lp[0-15] 光驱 /dev/cdrom 鼠标 /dev/mouse 磁带机 /dev/st0 或 /dev/ht0 定时任务 crontab服务管理 查看服务是否安装：rpm -qa| grep 'crontab' 服务是否启动：service crond status 启动： service crond start 关闭： service crond stop 开机自启： service crond enable 定时任务编写 编写 crontab -e 查询当前用户定时任务 crontab -l 删除当前用户定时任务 crontab -r cron的全局配置文件 crontab在/etc目录下面存在cron.hourly,cron.daily,cron.weekly,cron.monthly,cron.d五个目录和crontab,cron.deny两个文件。\ncron.daily是每天执行一次的job\ncron.weekly是每个星期执行一次的job\ncron.monthly是每月执行一次的job\ncron.hourly是每个小时执行一次的job\ncron.d是系统自动定期需要做的任务\ncrontab是设定定时任务的可执行文件\ncron.deny文件就是用于控制不让哪些用户使用Crontab的功能\ncron用户配置文件 每个用户都有自己的cron配置文件,通过crontab -e 就可以编辑。 一般情况下我们编辑好用户的cron配置文件保存退出后,系统会自动就存放于/var/spool/cron/目录中,文件以用户名命名. linux的cron服务是每隔一分钟去读取一次/var/spool/cron,/etc/cron.d下面所有的内容. crontab文件格式 minute： 表示分钟，可以是从0到59之间的任何整数。 **hour：**表示小时，可以是从0到23之间的任何整数。 **day：**表示日期，可以是从1到31之间的任何整数。 **month：**表示月份，可以是从1到12之间的任何整数。 **week：**表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 星号（*）：代表每的意思，例如month字段如果是星号，则表示每月都执行该命令操作。 逗号（,）：表示分隔时段的意思，例如，“1,3,5,7,9”。 中杠（-）：表示一个时间范围，例如“2-6”表示“2,3,4,5,6”。 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 定时任务书写要领 **要领1：**定时任务要加注释\n**要领2：**定时任务命令或脚本结尾加 \u0026amp;\u0026gt;/dev/null 或 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 或 1\u0026gt;/dev/null 2\u0026gt;/dev/null\n**要领3：**定时任务执行shell脚本前加/bin/sh，定时任务执行shell脚本不必添加执行权限\n**要领4：**定时任务命令或程序尽量写到脚本里，定时任务只要执行脚本即可\n​ 注意操作步骤：\n（1）、命令行执行\n（2）、编写脚本\n（3）、测试脚本\n（4）、设置定时任务\n**要领5：**生产任务程序不要随意打印输出信息\n**要领6：**定时任务执行的脚本要规范路径 (例如 /server/script)\n**要领7：**配置定时任务要规范操作过程\n**要领8：**定时任务执行特殊的字符需要进行转义，否则会报错，例如 百分号% 转义 %\n**要领9：**定时任务脚本中如果涉及使用到环境变量，必须在脚本中重新定义，不然，定时任务识别不了\n","date":"2022年12月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/linux-%E7%B3%BB%E7%BB%9F%E4%BF%A1%E6%81%AF/","series":[],"smallImg":"","tags":[{"title":"linux","url":"/myblog/tags/linux/"}],"timestamp":1669893680,"title":"Linux 系统信息"},{"authors":[],"categories":[{"title":"操作系统","url":"/myblog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"linux","url":"/myblog/categories/linux/"}],"content":"VboX网络 NAT 网络地址转换Network Address Translation 是从虚拟机访问外部网络的最简单方法。通常，它 不需要在主机网络和来宾系统上进行任何配置 。因此，它是Vbox中的默认联网模式。\n启用了NAT的虚拟机的行为就像是一台通过路由器连接到Internet的真实计算机。在这种情况下，路由器是Vbox网络引擎，该引擎透明地映射来往虚拟机的流量。在Vbox中，此路由器放置在每个虚拟机和主机之间。由于默认情况下虚拟机无法相互通信，因此这种隔离可最大程度地提高安全性。\n虚拟机之间不能相互通信，现实中同一个路由器连接下的机器可以相互通信。\nNAT模式的缺点是，就像路由器后面的专用网络一样，虚拟机是不可见的，外部Internet上的主机不能访问该虚拟机。除非设置端口转发。\n虚拟机发出的网络帧由Vbox的NAT引擎接收，该引擎提取TCP/IP数据并使用主机操作系统发送出去。对于主机上的应用程序，或与主机相同网络上的另一台计算机，数据就好像是由主机上的Vbox发送出来的，使用的是主机的IP地址。Vbox监听已发送数据包的回复数据，然后重新打包并将它们重新发送到其专用网络上的虚拟机.\nVM也可以访问主机的环回接口和在其上运行的网络服务。主机的环回接口可通过IP地址10.0.2.2访问。\n虚拟机从集成到Vbox的DHCP服务器接收专用网络上的网络地址和配置。这样分配给虚拟机的IP地址通常与主机位于完全不同的网络上。由于可以将虚拟机的多个卡设置为使用NAT，因此第一张卡连接到专用网络10.0.2.0，第二张卡连接到网络10.0.3.0，依此类推。如果您需要更改来宾分配的IP范围,参考 Section 9.8, “Fine Tuning the Vbox NAT Engine”.\n配置端口转发 由于虚拟机连接到Vbox内部的专用网络并且对主机不可见，因此主机或同一网络上的其他计算机将无法访问客户机上的网络服务。但是，就像物理路由器一样，Vbox可以通过端口转发使选定的服务对来宾外部的世界可用。这意味着Vbox侦听主机上的某些端口，并在相同或不同端口上将到达主机的所有数据包重新发送给来宾。对于主机上的应用程序或网络上的其他物理或虚拟机，看起来好像代理的服务实际上在主机上运行。\n要配置端口转发，可以使用图形化的端口转发编辑器，该编辑器可在网络设置对话框中找到，用于配置为使用NAT的网络适配器。在这里，您可以将主机端口映射到来宾端口，以将网络流量路由到来宾中的特定端口。\n转发低于1024的主机端口。在基于UNIX的主机(例如Linux，Oracle Solaris和Mac OS X)上，无法从非root用户运行的应用程序绑定到低于1024的端口。因此，如果您尝试配置此类端口转发，则VM将拒绝启动。\nNAT网络 网络地址转换(NAT)服务的工作方式与家用路由器类似，将使用该服务的系统分组到网络中，并防止该网络外部的系统直接访问其内部的系统，但允许内部的系统相互通信并与之通信。外部系统在IPv4和IPv6上使用TCP和UDP。\n网络需要设置成静态IP。\n桥接网络 通过桥接网络，Vbox使用主机系统上的设备驱动程序来过滤来自物理网络适配器的数据。这使Vbox可以拦截来自物理网络的数据并将注入一些其他信息，从而有效地在软件中创建新的网络接口。当来宾使用这种新的软件接口时，它看起来像是使用网络电缆将来宾物理连接到主机系统的主机系统。主机可以通过该接口向来宾发送数据，并从中接收数据。这意味着您可以在客户机与网络的其余部分之间设置路由或桥接。\n要启用桥接网络，请打开虚拟机的“设置”对话框，转到“网络”页面，然后在“附加到”字段的下拉列表中选择“桥接网络”。从页面底部的列表中选择一个主机接口，其中包含系统的物理网络接口。\n内部网络 内部网络类似于桥接网络，因为VM可以直接与外界通信。但是，外部世界仅限于同一主机上连接到同一内部网络的其他VM。\n即使从技术上讲，使用内部网络可以完成的所有操作也可以使用桥接网络来完成，但是内部网络具有安全性优势。在桥接网络模式下，所有流量都通过主机系统的物理接口。因此，可以将诸如Wireshark的数据包嗅探器附加到主机接口，并记录通过它的所有流量。如果出于某种原因，如果您希望同一台计算机上的两个或多个VM进行私下通信，同时对主机系统和用户隐藏其数据，则桥接网络不是一种选择。\n内部网络会根据需要自动创建。没有中央配置。每个内部网络都简单地通过其名称进行标识。一旦有一个以上具有相同内部网络ID的活动虚拟网卡，Vbox支持驱动程序将自动将这些网卡连接起来并充当网络交换机。Vbox支持驱动程序实现了完整的以太网交换机，并支持广播/多播帧和混杂模式。\n为了将VM的网卡连接到内部网络，请将其网络连接模式设置为Internal Networking。在Vbox图形用户界面中使用VM的“设置”对话框。在设置对话框的“网络”类别中，从网络模式的下拉列表中选择“内部网络”。从下面的下拉列表中选择一个现有内部网络的名称，或在“名称”字段中输入一个新名称。\n网络需要设置成静态IP。\nHost-Only网络 可以将仅主机的网络视为桥接和内部网络模式之间的混合。与桥接网络一样，虚拟机可以彼此通信，也可以与主机进行通信，就像它们通过物理以太网交换机连接一样。与内部网络一样，不需要存在物理网络接口，并且由于虚拟机未连接到物理网络接口，因此它们无法与主机外部的世界进行通信\n使用仅主机网络时，Vbox在主机上创建一个新的软件接口，该接口随后出现在现有网络接口旁边。换句话说，尽管使用桥接网络，但现有物理接口用于将虚拟机连接到其中，而仅主机网络则在主机上创建新的回送接口。而且，尽管使用内部网络，但无法看到虚拟机之间的流量，但是可以拦截主机上环回接口上的流量。\n仅主机网络对于预配置的虚拟设备特别有用，在预配置的虚拟设备中，多个虚拟机一起运送并旨在进行协作。例如，一个虚拟机可能包含一个Web服务器，第二个虚拟机可能包含一个数据库，并且由于它们打算互相通信，因此该设备可以指示Vbox为这两个虚拟机建立仅主机的网络。然后，第二个桥接网络会将Web服务器连接到外部，以向其提供数据，但是外部无法连接到数据库。\n根据上面的概述,采用NAT和Host-only来构建虚拟机,这样虚拟机既可以上外网又可以和主机互通.构建过程如下:\n1.在网络选项卡中设置网卡1为NAT 2.在网络选项卡中设置网卡2为Host-only\n虚拟机网络信息\n1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:18:fd:f6 brd ff:ff:ff:ff:ff:ff inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3 valid_lft 85269sec preferred_lft 85269sec inet6 fe80::e87a:c37c:8cb7:d544/64 scope link noprefixroute valid_lft forever preferred_lft forever 3: enp0s8: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 08:00:27:d3:83:40 brd ff:ff:ff:ff:ff:ff inet 192.168.56.101/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8 valid_lft 1129sec preferred_lft 1129sec inet6 fe80::4b78:f1fd:3288:4e78/64 scope link noprefixroute valid_lft forever preferred_lft forever 主机的网络信息\n以太网适配器 VirtualBox Host-Only Network: ​ 连接特定的 DNS 后缀 . . . . . . . : 本地链接 IPv6 地址. . . . . . . . : fe80::d8da:f22f:6843:9cf7%19 IPv4 地址 . . . . . . . . . . . . : 192.168.56.1 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : ​ 无线局域网适配器 WLAN: ​ 连接特定的 DNS 后缀 . . . . . . . : 本地链接 IPv6 地址. . . . . . . . : fe80::81d9:c2b4:1bd5:4d09%10 IPv4 地址 . . . . . . . . . . . . : 192.168.0.105 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : 192.168.0.1 主机通过192.168.56.101访问虚拟机. 虚拟机通过192.168.0.105访问主机.\n重要的配置项 overcommit_memory overcommit_memory是一个内核对内存分配的一种策略,取值又三种分别为0， 1， 2:\novercommit_memory=0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。\novercommit_memory=1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。\novercommit_memory=2， 表示内核允许分配超过所有物理内存和交换空间总和的内存\n如何设置？\n将 vm.overcommit_memory = 1 添加到 /etc/sysctl.conf。 然后重启动或运行命令sysctl vm.overcommit_memory=1使其立即生效。\n配置中文环境 修改配置文件 /etc/locale.conf,内容如下： LANG=zh_CN.UTF-8 将文件重新加入环境变量 source /etc/locale.conf\n查看更改后的系统中的语言变量\n[root@jjj logs]# locale LANG=zh_CN.UTF-8 LC_CTYPE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_NUMERIC=\u0026#34;zh_CN.UTF-8\u0026#34; LC_TIME=\u0026#34;zh_CN.UTF-8\u0026#34; LC_COLLATE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MONETARY=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MESSAGES=\u0026#34;zh_CN.UTF-8\u0026#34; LC_PAPER=\u0026#34;zh_CN.UTF-8\u0026#34; LC_NAME=\u0026#34;zh_CN.UTF-8\u0026#34; LC_ADDRESS=\u0026#34;zh_CN.UTF-8\u0026#34; LC_TELEPHONE=\u0026#34;zh_CN.UTF-8\u0026#34; LC_MEASUREMENT=\u0026#34;zh_CN.UTF-8\u0026#34; LC_IDENTIFICATION=\u0026#34;zh_CN.UTF-8\u0026#34; LC_ALL= man 显示中文 查找man中文安装包：yum list | grep man.*zh 安装中文包: yum -y install man-pages-zh-CN.noarch 创建别名: vim .bashrc , 添加 alias cman='man -M /usr/share/man/zh_CN' source使环境变量生效: source .bashrc 常见问题 Linux下执行程序出现 Text file busy 时的解决办法。 使用 fuser 命令查看程序文件被哪个进程占用，然后用 kill 命令杀死该进程，即解决问题。fuser命令是用来显示所有正在使用着指定的file, file system 或者 socket 的进程信息。\n[root@localhost]# fuser \u0026lt;程序文件名\u0026gt; \u0026lt;程序文件名\u0026gt;: 50340 [root@localhost]# kill -9 50340 注意：在普通用户下使用fuser是没有结果的，要切换至root用户。\n","date":"2022年12月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/linux-%E6%9D%82%E9%A1%B9/","series":[],"smallImg":"","tags":[{"title":"linux","url":"/myblog/tags/linux/"}],"timestamp":1669893680,"title":"Linux 杂项"},{"authors":[],"categories":[{"title":"操作系统","url":"/myblog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"linux","url":"/myblog/categories/linux/"}],"content":"进程管理 在操作系统中，所有可以执行的程序与命令都会产生进程。只是有些程序和命令非常简单，如 ls 命令、touch 命令等，它们在执行完后就会结束，相应的进程也就会终结，所以我们很难捕捉到这些进程。但是还有一些程和命令，比如 httpd 进程，启动之后就会一直驻留在系统当中，我们把这样的进程称作常驻内存进程。\n某些进程会产生一些新的进程，我们把这些进程称作子进程，而把这个进程本身称作父进程。比如，我们必须正常登录到 Shell 环境中才能执行系统命令，而 Linux 的标准 Shell 是 bash。我们在 bash 当中执行了 ls 命令，那么 bash 就是父进程，而 ls 命令是在 bash 进程中产生的进程，所以 ls 进程是 bash 进程的子进程。也就是说，子进程是依赖父进程而产生的，如果父进程不存在，那么子进程也不存在了。\n进程启动的方式 在 Linux 系统中，每个进程都有一个唯一的进程号（PID），方便系统识别和调度进程。通过简单地输出运行程序的程序名，就可以运行该程序，其实也就是启动了一个进程。\n总体来说，启动一个进程主要有 2 种途径，分别是通过手工启动和通过调度启动（事先进行设置，根据用户要求，进程可以自行启动。\n手工启动进程 手工启动进程指的是由用户输入命令直接启动一个进程，根据所启动的进程类型和性质的不同，其又可以细分为前台启动和后台启动 2 种方式。\n前台启动进程 这是手工启动进程最常用的方式，因为当用户输入一个命令并运行，就已经启动了一个进程，而且是一个前台的进程，此时系统其实已经处于一个多进程的状态（一个是 Shell 进程，另一个是新启动的进程）。\n假如启动一个比较耗时的进程，然后再把该进程挂起，并使用 ps 命令查看，就会看到该进程在 ps 显示列表中，例如：\n[root@localhost ~]# find / -name demo.jpg \u0026lt;--在根目录下查找 demo.jpg 文件，比较耗时 #此处省略了该命令的部分输出信息 #按“CTRL+Z”组合键，即可将该进程挂起 [root@localhost ~]# ps \u0026lt;--查看正在运行的进程 PID TTY TIME CMD 2573 pts/0 00:00:00 bash 2587 pts/0 00:00:01 find 2588 pts/0 00:00:00 ps 将进程挂起，指的是将前台运行的进程放到后台，并且暂停其运行.\n后台启动进程 进程直接从后台运行，用的相对较少，除非该进程非常耗时，且用户也不急着需要其运行结果的时候，例如，用户需要启动一个需要长时间运行的格式化文本文件的进程，为了不使整个 Shell 在格式化过程中都处于“被占用”状态，从后台启动这个进程是比较明智的选择。\n从后台启动进程，其实就是在命令结尾处添加一个 \u0026quot; \u0026amp;\u0026quot; 符号（注意，\u0026amp; 前面有空格）。输入命令并运行之后，Shell 会提供给我们一个数字，此数字就是该进程的进程号。然后直接就会出现提示符，用户就可以继续完成其他工作，例如：\n[root@localhost ~]# find / -name install.log \u0026amp; [1] 1920 #[1]是工作号，1920是进程号 以上介绍了手工启动的 2 种方式，实际上它们有个共同的特点，就是新进程都是由当前 Shell 这个进程产生的，换句话说，是 Shell 创建了新进程，于是称这种关系为进程间的父子关系，其中 Shell 是父进程，新进程是子进程。\n值得一提的是，一个父进程可以有多个子进程，通常子进程结束后才能继续父进程；当然，如果是从后台启动，父进程就不用等待子进程了。\nLinux调度启动进程 在 Linux 系统中，任务可以被配置在指定的时间、日期或者系统平均负载量低于指定值时自动启动。\n例如，Linux 预配置了重要系统任务的运行，以便可以使系统能够实时被更新，系统管理员也可以使用自动化的任务来定期对重要数据进行备份。\n实现调度启动进程的方法有很多，例如通过 crontab、at 等命令。\n软件安装 安装包 Linux下的软件包可细分为两种，分别是源码包和二进制包。\n源码包就是一大堆源代码程序，是由程序员按照特定的格式和语法编写出来的。 我们都知道，计算机只能识别机器语言，也就是二进制语言，所以源码包的安装需要一名“翻译官”将“abcd”翻译成二进制语言，这名“翻译官”通常被称为编译器。\n源码包的编译是很费时间的，况且绝多大数用户并不熟悉程序语言，在安装过程中我们只能祈祷程序不要报错，否则初学者很难解决。\n为了解决使用源码包安装方式的这些问题，Linux 软件包的安装出现了使用二进制包的安装方式。\n二进制包，也就是源码包经过成功编译之后产生的包。由于二进制包在发布之前就已经完成了编译的工作，因此用户安装软件的速度较快（同 Windows下安装软件速度相当），且安装过程报错几率大大减小。\n二进制包是 Linux 下默认的软件安装包，因此二进制包又被称为默认安装软件包。目前主要有以下 2 大主流的二进制包管理系统：\nRPM 包管理系统：功能强大，安装、升级、査询和卸载非常简单方便，因此很多 Linux 发行版都默认使用此机制作为软件安装的管理方式，例如 Fedora、CentOS、SuSE 等。\nDPKG 包管理系统：由 Debian Linux 所开发的包管理机制，通过 DPKG 包，Debian Linux 就可以进行软件包管理，主要应用在 Debian 和 Ubuntu 中。\n源码包 VS RPM二进制包 源码包一般包含多个文件，为了方便发布，通常会将源码包做打包压缩处理，Linux 中最常用的打包压缩格式为“tar.gz”，因此源码包又被称为 Tarball。\nTarball 是 Linux 系统的一款打包工具，可以对源码包进行打包压缩处理，人们习惯上将最终得到的打包压缩文件称为 Tarball 文件。\n源码包需要我们自己去软件官方网站进行下载，包中通常包含以下内容：\n源代码文件。\n配置和检测程序（如 configure 或 config 等）。\n软件安装说明和软件说明（如 INSTALL 或 README）。\n总的来说，使用源码包安装软件具有以下几点好处：\n开源。如果你有足够的能力，则可以修改源代码。\n可以自由选择所需的功能。\n因为软件是编译安装的，所以更加适合自己的系统，更加稳定，效率也更高。\n卸载方便。\n但同时，使用源码包安装软件也有几点不足：\n安装过程步骤较多，尤其是在安装较大的软件集合时（如 LAMP 环境搭建），容易出现拼写错误。\n编译时间较长，所以安装时间比二进制安装要长。\n因为软件是编译安装的，所以在安装过程中一旦报错，新手很难解决。\n使用 RMP 包安装软件具有以下 2 点好处：\n包管理系统简单，只通过几个命令就可以实现包的安装、升级、査询和卸载。\n安装速度比源码包安装快得多。\n与此同时，使用 RMP 包安装软件有如下不足：\n经过编译，不能在看到源代码。\n功能选择不如源码包灵活。\n依赖性。有时我们会发现，在安装软件包 a 时需要先安装 b 和 c，而在安装 b 时需要先安装 d 和 e。这就需要先安装 d 和 e，再安装 b 和 c，最后才能安装 a。比如，我买了一个漂亮的灯具，打算安装在客厅里，可是在安装灯具之前，客厅需要有顶棚，并且顶棚需要刷好油漆。安装软件和装修及其类似，需要有一定的顺序，但是有时依赖性会非常强。\nrpm包的命名规则 RPM 二进制包命名的一般格式如下：\n包名-版本号-发布次数-发行商-Linux平台-适合的硬件平台-包扩展名 例如，RPM 包的名称是httpd-2.2.15-15.el6.centos.1.i686.rpm，其中：\nhttped：软件包名。这里需要注意，httped 是包名，而 httpd-2.2.15-15.el6.centos.1.i686.rpm 通常称为包全名，包名和包全名是不同的，在某些 Linux 命令中，有些命令（如包的安装和升级）使用的是包全名，而有些命令（包的查询和卸载）使用的是包名，一不小心就会弄错。\n2.2.15：包的版本号，版本号的格式通常为主版本号.次版本号.修正号。\n15：二进制包发布的次数，表示此 RPM 包是第几次编程生成的。\nel*：软件发行商，el6 表示此包是由 Red Hat 公司发布，适合在 RHEL 6.x (Red Hat Enterprise Unux) 和 CentOS 6.x 上使用。\ncentos：表示此包适用于 CentOS 系统。\ni686：表示此包使用的硬件平台，目前的 RPM 包支持的平台如表 1 所示：\n平台名称 适用平台信息 i386 386 以上的计算机都可以安装 i586 686 以上的计算机都可以安装 i686 奔腾 II 以上的计算机都可以安装，目前所有的 CPU 是奔腾 II 以上的，所以这个软件版本居多 x86_64 64 位 CPU 可以安装 noarch 没有硬件限制 rpm：RPM 包的扩展名，表明这是编译好的二进制包，可以使用 rpm 命令直接安装。此外，还有以 src.rpm 作为扩展名的 RPM 包，这表明是源代码包，需要安装生成源码，然后对其编译并生成 rpm 格式的包，最后才能使用 rpm 命令进行安装。 RPM包安装 RPM包默认安装路径 通常情况下，RPM 包采用系统默认的安装路径，所有安装文件会按照类别分散安装到表 1 所示的目录中。\n安装路径 含 义 /etc/ 配置文件安装目录 /usr/bin/ 可执行的命令安装目录 /usr/lib/ 程序所使用的函数库保存位置 /usr/share/doc/ 基本的软件使用手册保存位置 /usr/share/man/ 帮助文件保存位置 RPM 包的默认安装路径是可以通过命令查询的。 除此之外，RPM 包也支持手动指定安装路径，但此方式并不推荐。因为一旦手动指定安装路径，所有的安装文件会集中安装到指定位置，且系统中用来查询安装路径的命令也无法使用（需要进行手工配置才能被系统识别），得不偿失。\n与 RPM 包不同，源码包的安装通常采用手动指定安装路径（习惯安装到 /usr/local/ 中）的方式。既然安装路径不同，同一 apache 程序的源码包和 RPM 包就可以安装到一台 Linux 服务器上（但同一时间只能开启一个，因为它们需要占用同一个 80 端口）。\nRPM 包的安装 [root@localhost ~]# rpm -ivh 包全名 -i：安装（install）;\n-v：显示更详细的信息（verbose）;\n-h：打印 #，显示安装进度（hash）;\n例如，使用此命令安装 apache 软件包，如下所示：\n[root@localhost ~]# rpm -ivh \\ /mnt/cdrom/Packages/httpd-2.2.15-15.el6.centos.1.i686.rpm Preparing... #################### [100%] 1:httpd #################### [100%] 注意，直到出现两个 100% 才是真正的安装成功，第一个 100% 仅表示完成了安装准备工作。\n此命令还可以一次性安装多个软件包，仅需将包全名用空格分开即可.\n如果还有其他安装要求（比如强制安装某软件而不管它是否有依赖性），可以通过以下选项进行调整：\n-nodeps：不检测依赖性安装。软件安装时会检测依赖性，确定所需的底层软件是否安装，如果没有安装则会报错。如果不管依赖性，想强制安装，则可以使用这个选项。注意，这样不检测依赖性安装的软件基本上是不能使用的，所以不建议这样做。\n-replacefiles：替换文件安装。如果要安装软件包，但是包中的部分文件已经存在，那么在正常安装时会报\u0026quot;某个文件已经存在\u0026quot;的错误，从而导致软件无法安装。使用这个选项可以忽略这个报错而覆盖安装。\n-replacepkgs：替换软件包安装。如果软件包已经安装，那么此选项可以把软件包重复安装一遍。\n-force：强制安装。不管是否已经安装，都重新安装。也就是 -replacefiles 和 -replacepkgs 的综合。\n-test：测试安装。不会实际安装，只是检测一下依赖性。\n-prefix：指定安装路径。为安装软件指定安装路径，而不使用默认安装路径。\nRPM包的升级 [root@localhost ~]# rpm -Uvh 包全名 -U（大写）选项的含义是：如果该软件没安装过则直接安装；若安装则升级至最新版本。\n[root@localhost ~]# rpm -Fvh 包全名 -F（大写）选项的含义是：如果该软件没有安装，则不会安装，必须安装有较低版本才能升级。\nRPM包的卸载 RPM 软件包的卸载很简单，使用如下命令即可：\n[root@localhost ~]# rpm -e 包名 -e 选项表示卸载，也就是 erase 的首字母。\nRPM 软件包的卸载要考虑包之间的依赖性。例如，我们先安装的 httpd 软件包，后安装 httpd 的功能模块 mod_ssl 包，那么在卸载时，就必须先卸载 mod_ssl，然后卸载 httpd，否则会报错。\n如果卸载 RPM 软件不考虑依赖性，执行卸载命令会包依赖性错误，例如：\n[root@localhost ~]# rpm -e httpd error: Failed dependencies: httpd-mmn = 20051115 is needed by (installed) mod_wsgi-3.2-1.el6.i686 httpd-mmn = 20051115 is needed by (installed) php-5.3.3-3.el6_2.8.i686 httpd-mmn = 20051115 is needed by (installed) mod_ssl-1:2.2.15-15.el6. centos.1.i686 httpd-mmn = 20051115 is needed by (installed) mod_perl-2.0.4-10.el6.i686 httpd = 2.2.15-15.el6.centos.1 is needed by (installed) httpd-manual-2.2. 15-15.el6.centos.1 .noarch httpd is needed by (installed) webalizer-2.21_02-3.3.el6.i686 httpd is needed by (installed) mod_ssl-1:2.2.15-15.el6.centos.1.i686 httpd=0:2.2.15-15.el6.centos.1 is needed by(installed)mod_ssl-1:2.2.15-15.el6.centos.1.i686 查询软件包是否安装 [root@localhost ~]# rpm -q 包名 -q 表示查询，是 query 的首字母。\n注意这里使用的是包名，而不是包全名。因为已安装的软件包只需给出包名，系统就可以成功识别（使用包全名反而无法识别）。\n查询系统中所有安装的软件包 [root@localhost ~]# rpm -qa libsamplerate-0.1.7-2.1.el6.i686 startup-notification-0.10-2.1.el6.i686 gnome-themes-2.28.1-6.el6.noarch fontpackages-filesystem-1.41-1.1.el6.noarch gdm-libs-2.30.4-33.el6_2.i686 gstreamer-0.10.29-1.el6.i686 redhat-lsb-graphics-4.0-3.el6.centos.i686 …省略部分输出… 查询软件包的详细信息 [root@localhost ~]# rpm -qi httpd Name : httpd Relocations:(not relocatable) #包名 Version : 2.2.15 Vendor:CentOS #版本和厂商 Release : 15.el6.centos.1 Build Date: 2012年02月14日星期二 06时27分1秒 #发行版本和建立时间 Install Date: 2013年01月07日星期一19时22分43秒 Build Host: c6b18n2.bsys.dev.centos.org #安装时间 Group : System Environment/Daemons Source RPM: httpd-2.2.15-15.el6.centos.1.src.rpm #组和源RPM包文件名 Size : 2896132 License: ASL 2.0 #软件包大小和许可协议 Signature :RSA/SHA1,2012年02月14日星期二 19时11分00秒，Key ID 0946fca2c105b9de #数字签名 Packager：CentOS BuildSystem \u0026lt;http://bugs.centos.org\u0026gt; URL : http://httpd.apache.org/ #厂商网址 Summary : Apache HTTP Server #软件包说明 Description: The Apache HTTP Server is a powerful, efficient, and extensible web server. #描述 -i 选项表示查询软件信息，是 information 的首字母。\n除此之外，还可以查询未安装软件包的详细信息，命令格式为：\n[root@localhost ~]# rpm -qip 包全名 -p 选项表示查询未安装的软件包，是 package 的首字母。\n注意，这里用的是包全名，且未安装的软件包需使用“绝对路径+包全名”的方式才能确定包。\n查询软件包的文件列表 通过前面的学习我们知道，rpm 软件包通常采用默认路径安装，各安装文件会分门别类安放在适当的目录文件下。使用 rpm 命令可以查询到已安装软件包中包含的所有文件及各自安装路径，命令格式为：\n[root@localhost ~]# rpm -ql 包名 -l 选项表示列出软件包所有文件的安装目录。\n例如，查看 apache 软件包中所有文件以及各自的安装位置，可使用如下命令：\n[root@localhost ~]# rpm -ql httpd /etc/httpd /etc/httpd/conf /etc/httpd/conf.d /etc/httpd/conf.d/README /etc/httpd/conf.d/welcome.conf /etc/httpd/conf/httpd.conf /etc/httpd/conf/magic …省略部分输出… 同时，rpm 命令还可以查询未安装软件包中包含的所有文件以及打算安装的路径，命令格式如下：\n[root@localhost ~]# rpm -qlp 包全名 -p 选项表示查询未安装的软件包信息，是 package 的首字母。\n注意，由于软件包还未安装，因此需要使用“绝对路径+包全名”的方式才能确定包。\n查询系统文件属于哪个RPM包 rpm -ql 命令是通过软件包查询所含文件的安装路径，rpm 还支持反向查询，即查询某系统文件所属哪个 RPM 软件包。其命令格式如下：\n[root@localhost ~]# rpm -qf 系统文件名 -f 选项的含义是查询系统文件所属哪个软件包，是 file 的首字母。\n注意，只有使用 RPM 包安装的文件才能使用该命令，手动方式建立的文件无法使用此命令。\n查询软件包的依赖关系 使用 rpm 命令安装 RPM 包，需考虑与其他 RPM 包的依赖关系。rpm -qR 命令就用来查询某已安装软件包依赖的其他包，该命令的格式为：\n[root@localhost ~]# rpm -qR 包名 -R（大写）选项的含义是查询软件包的依赖性，是 requires 的首字母。\n提取RPM包文件 在服务器使用过程，如果系统文件被误修改或误删除，可以考虑使用 cpio 命令提取出原 RPM 包中所需的系统文件，从而修复被误操作的源文件。\nRPM 包允许逐个提取包中文件，使用的命令格式如下：\n[root@localhost ~] rpm2cpio 包全名|cpio -idv .文件绝对路径 该命令中，rpm2cpio 就是将 RPM 包转换为 cpio 格式的命令，通过 cpio 命令即可从 cpio 文件库中提取出指定文件。\n举个例子，假设我们不小心把 /bin/ls 命令删除了，通常有以下 2 种方式修复：\n将 coreutils-8.4-19.el6.i686 包（包含 ls 命令的 RPM 包）通过 -force 选项再安装一遍； 使用 cpio 命令从 coreutils-8.4-19.el6.i686 包中提取出 /bin/ls 文件，然后将其复制到相应位置； [root@localhost ~]# mv /bin/ls /root/ #把/bin/ls命令移动到/root/目录下，造成误删除的假象 [root@localhost ~]# ls -bash: ls: command not found #这时执行ls命令，系统会报\u0026#34;命令没有找到\u0026#34;错误 [root@localhost ~]# rpm2cpio /mnt/cdrom/Packages/coreutils-8.4-19.el6.i686.rpm |cpio -idv ./bin/ls #提取ls命令文件到当前目录下 [root@localhost ~]# cp /root/bin/ls /bin/ #把提取出来的ls命令文件复制到/bin/目录下 [root@localhost ~]#ls anaconda-ks.cfg bin inittab install.log install.log.syslog ls #可以看到，ls命令又可以正常使用了 cpio命令 cpio 命令用于从归档包中存入和读取文件，换句话说，cpio 命令可以从归档包中提取文件（或目录），也可以将文件（或目录）复制到归档包中。\n归档包，也可称为文件库，其实就是 cpio 或 tar 格式的文件，该文件中包含其他文件以及一些相关信息（文件名、访问权限等）。归档包既可以是磁盘中的文件，也可以是磁带或管道。\ncpio 命令可以看做是备份或还原命令，因为它可以将数据（文件）备份到 cpio 归档库，也可以利用 cpio 文档库对数据进行恢复。\n使用 cpio 命令备份或恢复数据，需注意以下几点：\n使用 cpio 备份数据时如果使用的是绝对路径，那么还原数据时会自动恢复到绝对路径下；同理，如果备份数据使用的是相对路径，那么数据会还原到相对路径下。\ncpio 命令无法自行指定备份（或还原）的文件，需要目标文件（或目录）的完整路径才能成功读取，因此此命令常与 find 命令配合使用。\ncpio 命令恢复数据时不会自动覆盖同名文件，也不会创建目录（直接解压到当前文件夹）。\ncpio 命令主要有以下 3 种基本模式：\n\u0026ldquo;-o\u0026rdquo; 模式：指的是 copy-out 模式，就是把数据备份到文件库中，命令格式如下： [root@localhost ~]# cpio -o[vcB] \u0026gt; [文件丨设备] 各选项含义如下：\n-o：copy-out模式，备份；\n-v：显示备份过程；\n-c：使用较新的portable format存储方式；\n-B：设定输入/输出块为 5120Bytes，而不是模式的 512Bytes；\n比如，使用 cpio 备份数据的命令如下：\n[root@localhost ~]#find /etc -print | cpio -ocvB \u0026gt; /root/etc.cpio #利用find命令指定要备份/etc/目录，使用\u0026gt;导出到etc.cpio文件 [root@localhost ~]# ll -h etc.cpio -rw--r--r--.1 root root 21M 6月5 12:29 etc.cpio #etc.cpio文件生成 \u0026ldquo;-i\u0026rdquo; 模式：指的是 copy-in 模式，就是把数据从文件库中恢复，命令格式如下： [root@localhost ~]# cpio -i[vcdu] \u0026lt; [文件|设备] 各选项的含义为：\n-i：copy-in 模式，还原；\n-v：显示还原过程；\n-c：较新的 portable format 存储方式；\n-d：还原时自动新建目录；\n-u：自动使用较新的文件覆盖较旧的文件；\n比如，使用 cpio 恢复之前备份的数据，命令如下：\n[root@localhost ~]# cpio -idvcu \u0026lt; /root/etc.cpio #还原etc的备份 #如果大家査看一下当前目录/root/，就会发现没有生成/etc/目录。这是因为备份时/etc/目录使用的是绝对路径，所以数据直接恢复到/etc/系统目录中，而没有生成在/root/etc/目录中 \u0026ldquo;-p\u0026rdquo; 模式：指的是复制模式，使用 -p 模式可以从某个目录读取所有文件，但并不将其备份到 cpio 库中，而是直接复制为其他文件。 例如，使用 -p 将 /boot/ 复制到 /test/boot 目录中可以执行如下命令：\n[root@localhost ~]# cd /tmp/ #进入/tmp/目录 [root@localhost tmp]#rm -rf* #删除/tmp/目录中的所有数据 [root@localhost tmp]# mkdir test #建立备份目录 [root@localhost tmp]# find /boot/ -print | cpio -p /tmp/test #备份/boot/目录到/tmp/test/目录中 [root@localhost tmp]# ls test/boot #在/tmp/test/目录中备份出了/boot/目录 Linux重建RPM数据库 我们知道，RPM 包是很多 Linux 发行版（Fefora、RedHat、SuSE 等）采用的软件包管理方式，安装到系统中的各 RPM 包，其必要信息都会保存到 RPM 数据库中，以便用户使用 rpm 命令对软件包执行查询、安装和卸载等操作。\n但并非所有的用户操作都“按常理出牌”，例如 RPM 包在升级过程被强行退出、RPM 包安装意外中断等误操作，都可能使 RPM 数据库出现故障，后果是当安装、删除、査询软件包时，请求无法执行，如图 1 所示：\n这时就需要重建 RPM 数据库，执行如下 2 步操作：\n删除当前系统中已损坏的RPM数据库，执行如下命令：\n[root@localhost ~]# rm -f /var/lib/rpm/_db.* 重建 RPM 数据库，执行如下命令：\n[root@localhost -]# rpm -rebuilddb 这一步需花费一定时间才能完成。\n除了用户误操作导致 RPM 数据库崩溃，有些黑客入侵系统后，为避免系统管理员通过 RPM 包校验功能检测出问题，会更改 RPM 数据库。\nYUM安装 RPM 软件包（包含 SRPM 包）的依赖性主要体现在 RPM 包安装与卸载的过程中。\n例如，如果采用最基础的方式（基础服务器方式）安装 Linux 系统，则 gcc 这个软件是没有安装的，需要自己手工安装。当你使用 rpm 命令安装 gcc 软件的 RPM 包，就会发生依赖性错误，错误提示信息如下所示：\n[root@localhost ~]# rpm -ivh /mnt/cdrom/Packages/ gcc-4.4.6-4.el6.i686.rpm error: Failed dependencies: \u0026lt;―依赖性错误 cloog-ppi \u0026gt;= 0.15 is needed by gcc-4.4.6-4.el6.i686 cpp = 4.4.6-4.el6 is needed by gcc-4.4.6-4.el6.i686 glibc-devel \u0026gt;= 2.2.90-12 is needed by gcc-4.4.6-4.el6.i686 除此之外，报错信息中还会明确给出各个依赖软件的版本要求：\n\u0026ldquo;\u0026gt;=\u0026quot;：表示版本要大于或等于所显示版本；\n\u0026ldquo;\u0026lt;=\u0026quot;：表示版本要小于或等于所显示版本；\n\u0026ldquo;=\u0026quot;：表示版本要等于所显示版本；\nLinux 系统中，RPM 包之间的依赖关系大致可分为以下 3 种：\n树形依赖（A-B-C-D）：要想安装软件 A，必须先安装 B，而安装 B 需要先安装 C…….解决此类型依赖的方法是从后往前安装，即先安装 D，再安装 C，然后安装 B，最后安装软件 A。 环形依赖（A-B-C-D-A）：各个软件安装的依赖关系构成“环状”。解决此类型依赖的方法是用一条命令同时安装所有软件包，即使用 rpm -ivh 软件包A 软件包B \u0026hellip;。 模块依赖：软件包的安装需要借助其他软件包的某些文件（比如库文件），解决模块依赖最直接的方式是通过 http://www.rpmfind.net 网站找到包含此文件的软件包，安装即可。 以上 3 种 RPM 包的依赖关系，给出的解决方案都是手动安装，比较麻烦。yum安装给出了解决方案。\nyum，全称\u0026quot;Yellow dog Updater,Modified\u0026rdquo;，CentOS 系统上的软件包管理器，它能够自动下载 RPM 包并安装，更重要的是，它可以自动处理软件包之间的依赖性关系，一次性安装所有依赖的软件包，无需一个个安装。\nyum 在服务器端存有所有的 RPM 包，并将各个包之间的依赖关系记录在文件中，当管理员使用 yum 安装 RPM 包时，yum 会先从服务器端下载包的依赖性文件，通过分析此文件从服务器端一次性下载所有相关的 RPM 包并进行安装。\nyum 软件可以用 rpm 命令安装，安装之前可以通过如下命令查看 yum 是否已安装：\n[root@localhost ~]# rpm -qa | grep yum yum-metadata-parser-1.1.2-16.el6.i686 yum-3.2.29-30.el6.centos.noarch yum-utils-1.1.30-14.el6.noarch yum-plugin-fastestmirror-1.1.30-14.el6.noarch yum-plugin-security-1.1.30-14.el6.noarch yum 源 使用 yum 安装软件包之前，需指定好 yum 下载 RPM 包的位置，此位置称为 yum 源。换句话说，yum 源指的就是软件安装包的来源。\n使用 yum 安装软件时至少需要一个 yum 源。yum 源既可以使用网络 yum 源，也可以将本地光盘作为 yum 源。接下来就给大家介绍这两种 yum 源的搭建方式。\n网络 yum 源搭建 一般情况下，只要你的主机网络正常，可以直接使用网络 yum 源，不需要对配置文件做任何修改。\n网络 yum 源配置文件位于 /etc/yum.repos.d/ 目录下，文件扩展名为\u0026rdquo;.repo\u0026rdquo;（只要扩展名为 \u0026ldquo;.repo\u0026rdquo; 的文件都是 yum 源的配置文件）。\n[root@localhost ~]# ls /etc/yum.repos.d/ CentOS-Base.repo CentOS-Media.repo CentOS-Debuginfo.repo.bak CentOS-Vault.repo 可以看到，该目录下有 4 个 yum 配置文件，通常情况下 CentOS-Base.repo 文件生效。我们可以尝试打开此文件，命令如下：\n[root@localhost yum.repos.d]# vim /etc/yum.repos.d/ CentOS-Base.repo [base] name=CentOS-$releasever - Base mirrorlist=http://mirrorlist.centos.org/? release= $releasever\u0026amp;arch=$basearch\u0026amp;repo=os baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6 …省略部分输出… 此文件中含有 5 个 yum 源容器，这里只列出了 base 容器，其他容器和 base 容器类似。base 容器中各参数的含义分别为：\n[base]：容器名称，一定要放在[]中。\nname：容器说明，可以自己随便写。\nmirrorlist：镜像站点，这个可以注释掉。\nbaseurl：我们的 yum 源服务器的地址。默认是 CentOS 官方的 yum 源服务器，是可以使用的。如果你觉得慢，则可以改成你喜欢的 yum 源地址。\nenabled：此容器是否生效，如果不写或写成 enabled 则表示此容器生效，写成 enable=0 则表示此容器不生效。\ngpgcheck：如果为 1 则表示 RPM 的数字证书生效；如果为 0 则表示 RPM 的数字证书不生效。\ngpgkey：数字证书的公钥文件保存位置。不用修改。\n本地 yum 源 在无法联网的情况下，yum 可以考虑用本地光盘（或安装映像文件）作为 yum 源。\nLinux 系统安装映像文件中就含有常用的 RPM 包，我们可以使用压缩文件打开映像文件（iso文件），进入其 Packages 子目录，如图 1 所示\n可以看到，该子目录下含有几乎所有常用的 RPM 包，因此使用系统安装映像作为本地 yum 源没有任何问题。\n在 /etc/yum.repos.d/ 目录下有一个 CentOS-Media.repo 文件，此文件就是以本地光盘作为 yum 源的模板文件，只需进行简单的修改即可，步骤如下：\n放入 CentOS 安装光盘，并挂载光盘到指定位置。命令如下：\n[root@localhost ~]# mkdir /mnt/cdrom #创建cdrom目录，作为光盘的挂载点 [root@localhost ~]# mount /dev/cdrom /mnt/cdrom/ mount: block device/dev/srO is write-protected, mounting read-only #挂载光盘到/mnt/cdrom目录下 修改其他几个 yum 源配置文件的扩展名，让它们失效，因为只有扩展名是\u0026quot;*.repo\u0026quot;的文件才能作为 yum 源配置文件。当也可以删除其他几个 yum 源配置文件，但是如果删除了，当又想用网络作为 yum 源时，就没有了参考文件，所以最好还是修改扩展名。 命令如下：\n[root@localhost ~]# cd /etc/yum.repos.d/ [root@localhost yum.repos.d]# mv CentOS-Base, repo CentOS-Base.repo.bak [root@localhost yum.repos.d]#mv CentOS-Debuginfo.repo CentOS-Debuginfo.repo.bak [root@localhost yum.repos.d]# mv CentOS-Vault.repo CentOS-Vault.repo.bak 修改光盘 yum 源配置文件 CentOS-Media.repo，参照以下方修改：\n[root@localhost yum.repos.d]# vim CentOS-Media.repo [c6-media] name=CentOS-$releasever - Media baseurl=file:///mnt/cdrom #地址为你自己的光盘挂载地址 #file:///media/cdrom/ #file:///media/cdrecorder/ #注释这两个的不存在地址 gpgcheck=1 enabled=1 #把enabled=0改为enabled=1, 让这个yum源配置文件生效 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6 yum命令 查询命令 使用 yum 对软件包执行查询操作，常用命令可分为以下几种：\nyum list：查询所有已安装和可安装的软件包。例如： [root@localhost yum.repos.d]# yum list #查询所有可用软件包列表 Installed Packages #已经安装的软件包 ConsdeKit.i686 0.4.1-3.el6 @anaconda-CentOS-201207051201 J386/6.3 ConsdeKit-libs.i686 0.4.1-3.el6 @anaconda-CentOS-201207051201 J386/6.3 …省略部分输出… Available Packages #还可以安装的软件包 389-ds-base.i686 1.2.10.2-15.el6 c6-media 389-ds-base-devel.i686 1.2.10.2-15.el6 c6-media #软件名 版本 所在位置（光盘） …省略部分输出… yum list 包名：查询执行软件包的安装情况。例如： [root@localhost yum.repos.d]# yum list samba Available Packages samba.i686 3.5.10-125.el6 c6-media #查询 samba 软件包的安装情况 yum search 关键字：从 yum 源服务器上查找与关键字相关的所有软件包。例如：\n[root@localhost yum.repos.d]# yum search samba #搜索服务器上所有和samba相关的软件包 ========================N/S Matched: samba ============================= samba-client.i686：Samba client programs samba-common.i686：Files used by both Samba servers and clients samba-doc.i686: Documentation for the Samba suite …省略部分输出… Name and summary matches only, use\u0026#34;search all\u0026#34; for everything. yum info 包名：查询执行软件包的详细信息。例如：\n[root@localhost yum.repos.d]# yum info samba #查询samba软件包的信息 Available Packages \u0026lt;-没有安装 Name : samba \u0026lt;-包名 Arch : i686 \u0026lt;-适合的硬件平台 Version : 3.5.10 \u0026lt;―版本 Release : 125.el6 \u0026lt;—发布版本 Size : 4.9M \u0026lt;—大小 Repo : c6-media \u0026lt;-在光盘上 …省略部分输出… 安装命令 [root@localhost yum.repos.d]# yum -y install 包名 其中：\ninstall：表示安装软件包。\n-y：自动回答 yes。如果不加 -y，那么每个安装的软件都需要手工回答 yes；\n升级命令 使用 yum 升级软件包，需确保 yum 源服务器中软件包的版本比本机安装的软件包版本高。\nyum 升级软件包常用命令如下：\nyum -y update：升级所有软件包。不过考虑到服务器强调稳定性，因此该命令并不常用。\nyum -y update 包名：升级特定的软件包。\nyum 卸载命令 使用 yum 卸载软件包时，会同时卸载所有与该包有依赖关系的其他软件包，即便有依赖包属于系统运行必备文件，也会被 yum 无情卸载，带来的直接后果就是使系统崩溃。\n除非你能确定卸载此包以及它的所有依赖包不会对系统产生影响，否则不要使用 yum 卸载软件包。\n[root@localhost yum.repos.d]# yum remove 包名 #卸载指定的软件包 yum管理软件组 在安装 Linux 系统时，我们可以根据需要自定义安装软件包，如图 1 所示：\n选择“Customize now”，会进入图 2 所示的页面：\n图 2 中所示为 Linux 列出的许多软件包组，例如编辑器、系统工具、开发工具等。在此页面，我们可以根据需要选择要安装的软件包。\n除了像图 1、图 2 这样在系统安装过程中自选软件包组进行安装之外，当系统安装完成后，我们也可以通过 yum 命令来管理图 2 中的这些软件包组。\nyum 命令除了可以对软件包进行查询、安装、升级和卸载外，还可完成对软件包组的查询、安装和卸载操作。\n既然是软件包组，说明包含不只一个软件包，通过 yum 命令可以查询某软件包组中具体包含的软件包，命令格式如下：\n[root@localhost ~]#yum groupinfo 软件组名 #查询软件组中包含的软件 例如，查询 Web Server 软件包组中包含的软件包，可使用如下命令：\n[root@localhost ~]#yum groupinfo \u0026#34;Web Server\u0026#34; #查询软件组\u0026#34;Webserver\u0026#34;中包含的软件 使用 yum 安装软件包组的命令格式如下：\n[root@localhost ~]#yum groupinstall 软件组名 #安装指定软件组，组名可以由grouplist查询出来 yum 卸载软件包组的命令格式如下：\n[root@localhost ~]# yum groupremove 软件组名 #卸载指定软件组 yum 软件包组管理命令更适合安装功能相对集中的软件包集合。例如，在初始安装 Linux 时没有安装图形界面，但后来发现需要图形界面的支持，这时可以手工安装图形界面软件组（X Window System 和 Desktop），就可以使用图形界面了。\n源码包安装 Linux 系统中，绝大多数软件的源代码都是用 C 语言编写的，少部分用 C++（或其他语言）编写。因此要想安装源码包，必须安装 gcc 编译器（如果涉及 C++ 源码程序，还需要安装 gcc-c++）。\n除了安装编译器，还需要安装 make 编译命令。要知道，编译源码包可不像编译一个 hello.c 文件那样轻松，包中含大量的源码文件，且文件之间有着非常复杂的关联，直接决定着各文件编译的先后顺序，因此手动编译费时费力，而使用 make 命令可以完成对源码包的自动编译。\n安装流程 本节仍然以安装 apache 为例，安装过程分为如下几步：\n下载 apache 源码包。该软件的源码包可通过官方网站 http://httpd.apache.org/download.cgi#apache24 下载，得到的源码包格式为压缩包（ \u0026ldquo;.tar.gz\u0026rdquo; 或 \u0026ldquo;.tar.bz2\u0026rdquo; ）。 将各种文件分门别类保存在对应的目录中，应该成为合格 Linux 管理员约定俗成的习惯。Linux 系统中用于保存源代码的位置主要有 2 个，分别是 \u0026ldquo;/usr/src\u0026rdquo; 和 \u0026ldquo;/usr/local/src\u0026rdquo;，其中 \u0026ldquo;/usr/src\u0026rdquo; 用来保存内核源代码，\u0026quot;/usr/local/src\u0026quot; 用来保存用户下载的源代码。\n将源码包进行解压缩，使用命令如下：\n[root@localhost ~]#tar -zxvf httpd-2.2.9.tar.gz|more 进入解压目录，执行如下命令：\n[root@localhost ~]# ls anaconda-ks.cfg httpd-2.2.9 httpd-2.2.9.tar.gz install.log install.log.syslog [root@localhost ~]# cd httpd-2.2.9 ./configure 软件配置与检查。这一步主要完成以下 3 项任务：\n检测系统环境是否符合安装要求。\n定义需要的功能选项。通过 \u0026ldquo;./configure\u0026ndash;prefix=安装路径\u0026rdquo; 可以指定安装路径。注意，configure 不是系统命令，而是源码包软件自带的一个脚本程序，所以必须采用 \u0026ldquo;./configure\u0026rdquo; 方式执行（\u0026quot;./\u0026quot; 代表在当前目录下）。\n\u0026ldquo;./configure\u0026rdquo; 支持的功能选项较多，可执行 \u0026ldquo;./configure\u0026ndash;help\u0026rdquo; 命令查询其支持的功能\n把系统环境的检测结果和定义好的功能选项写入 Makefile 文件，因为后续的编译和安装需要依赖这个文件的内容。\n此步具体执行代码如下：\n[root@localhost httpd-2.2.9]# ./configure --prefix=/usr/local/apache2 checking for chosen layout...Apache checking for working mkdir -p…yes checking build system type...i686-pc-linux-gnu checking host system type...i686-pc-linux-gnu checking target system typa...i686-pc-linux-gnu …省略部分输出… make 编译。make 会调用 gcc 编译器，并读取 Makefile 文件中的信息进行系统软件编译。编译的目的就是把源码程序转变为能被 Linux 识别的可执行文件，这些可执行文件保存在当前目录下。执行的编译命令如下：\n[root@localhost httpd-2.2.9]# make 正式开始安装软件，这里通常会写清程序的安装位置，如果没有，则建议读者把安装的执行过程保存下来，以备将来删除软件时使用。安装指令如下： [root@localhost httpd-2.2.9]# make install 整个过程不报错，即为安装成功。\n安装源码包过程中，如果出现“error”（或“warning”）且安装过程停止，表示安装失败；反之，如果仅出现警告信息，但安装过程还在继续，这并不是安装失败，顶多使软件部分功能无法使用。\n注意，如果在 \u0026ldquo;./configure\u0026rdquo; 或 \u0026ldquo;make\u0026rdquo; 编译中报错，则在重新执行命令前一定要执行 make clean 命令，它会清空 Makefile 文件或编译产生的 \u0026ldquo;.o\u0026rdquo; 头文件。\n卸载源码包 通过源码包方式安装的各个软件，其安装文件独自保存在 /usr/local/ 目录下的各子目录中。例如，apache 所有的安装文件都保存在 /usr/local/apache2 目录下。这就为源码包的卸载提供了便利。\n源码包的卸载，只需要找到软件的安装位置，直接删除所在目录即可，不会遗留任何垃圾文件。需要读者注意的是，在删除软件之前，应先将软件停止服务。\n以删除 apache 为例，只需关闭 apache 服务后执行如下命令即可：\n[root@localhost ~]# rm -rf /usr/local/apache2/ 升级源码包 Linux 系统中更新用源码包安装的软件，除了卸载重装这种简单粗暴的方法外，还可以下载补丁文件更新源码包，用新的源码包重新编译安装软件。比较两种方式，后者更新软件的速度更快。\n使用补丁文件更新源码包，省去了用 ./configured 生成新的 Makefile 文件，还省去了大量的编译工作，因此效率更高。\ndiff命令 Linux 系统中可以使用 diff 命令对比出新旧软件的不同，并生成补丁文件。\ndiff 命令基本格式为：\n[root@localhost ~]# diff 选项 old new #比较old和new文件的不同 此命令中可使用如下几个选项：\n-a：将任何文档当作文本文档处理；\n-b：忽略空格造成的不同；\n-B：忽略空白行造成的不同；\n-I：忽略大小写造成的不同；\n-N：当比较两个目录时，如果某个文件只在一个目录中，则在另一个目录中视作空文件；\n-r：当比较目录时，递归比较子目录；\n-u：使用同一输出格式；\n从生成补丁文件，到使用其实现更新软件的目的，为了让读者清楚地了解整个过程的来龙去脉，下面我们自己创建两个文件（分别模拟旧软件和新软件），通过对比新旧文件生成补丁文件，最后利用补丁文件更新旧文件，具体步骤如下：\n创建两个文件，执行如下命令： [root@localhost ~]# mkdir test #建立测试目录 [root@localhost ~]# cd test #进入测试目录 [root@localhost test]# vi old.txt our school is lampbrother #文件old.txt，为了便于比较，将每行分开 [root@localhost test]# vi new.txt our school is lampbrother in Beijing #文件new.txt 利用 diff 命令，比较两个文件（old.txt 和 new.txt）的不同，并生成补丁文件（txt.patch），执行代码如下： [root@localhost test]# diff -Naur /root/test/old.txt /root/test/new.txt \u0026gt; txt. patch #比较两个文件的不同，同时生成txt.patch补丁文件 [root@localhost test]#vi txt.patch #查看一下这个文件 --/root/test/old.txt 2012-11-23 05:51:14.347954373 +0800 #前一个文件 + + + /root/test/new.txt 2012-11-23 05:50:05.772988210 +0800 #后一个文件 @@-2, 3+2, 5@@ school is lampbrother +in +beijing #后一个文件比前一个文件多两行（用+表示） 利用补丁文件 txt.patch 更新 old.txt 旧文件，实现此步操作需利用 patch 命令，该命令基本格式如下： [root@localhost test]# patch -pn \u0026lt; 补丁文件 #按照补丁文件进行更新 -pn 选项中，n 为数字（例如 p1、p2、p3 等），pn 表示按照补丁文件中的路径，指定更新文件的位置。\n这里对 -pn 选项的使用做一下额外说明。我们知道，补丁文件是要打入旧文件的，但是当前所在目录和补丁文件中记录的目录不一定是匹配的，需要 \u0026ldquo;-pn\u0026rdquo; 选项来同步两个目录。\n例如，当前位于 \u0026ldquo;/root/test/\u0026rdquo; 目录下（要打补丁的旧文件就在当前目录下），补丁文件中记录的文件目录为 \u0026ldquo;/root/test/dd.txt\u0026rdquo;，如果写入 \u0026ldquo;-p1\u0026rdquo;（在补丁文件目录中取消一级目录），那么补丁文件会打入 \u0026ldquo;root/test/root/test/old.txt\u0026rdquo; 文件中，这显然是不对的；如果写入的是 \u0026ldquo;-p2\u0026rdquo;（在补丁文件目录中取消二级目录），补丁文件会打入 \u0026ldquo;/root/test/test/old.txt\u0026rdquo; 文件中，这显然也不对。如果写入的是 \u0026ldquo;-p3\u0026rdquo;（在补丁文件目录中取消三级目录），补丁文件会打入 \u0026ldquo;/root/test/old.txt\u0026rdquo; 文件中，old.txt 文件就在这个目录下，所以应该用 \u0026ldquo;-p3\u0026rdquo; 选项。\n如果当前所在目录是 \u0026ldquo;/root/\u0026rdquo; 目录呢？因为补丁文件中记录的文件目录为 \u0026ldquo;/root/test/old.txt\u0026rdquo;，所以这里就应该用 \u0026ldquo;-p2\u0026rdquo; 选项（代表取消两级目录），补丁打在当前目录下的 \u0026ldquo;test/old.txt\u0026rdquo; 文件上。\n因此，-pn 选项可以这样理解，即想要在补丁文件中所记录的目录中取消几个 \u0026ldquo;/\u0026quot;，n 就是几。去掉目录的目的是和当前所在目录匹配。\n现在更新 \u0026ldquo;old.txt\u0026rdquo; 文件，命令如下：\n[root@localhost test]# patch -p3 \u0026lt; txt.patch patching file old.txt #给old.txt文件打补丁 [root@localhost test]# cat old.txt #查看一下dd.txt文件的内容 our school is lampbrother in Beijing #多出了in Beijing两行 可以看到，通过使用补丁文件 txt.patch 对旧文件进行更新，使得旧文件和新文件完全相同。\n通过这个例子，大家要明白以下两点：\n给旧文件打补丁依赖的不是新文件，而是补丁文件，所以即使新文件被删除也没有关系。 补丁文件中记录的目录和当前所在目录需要通过 \u0026ldquo;-pn\u0026rdquo; 选项实现同步，否则更新可能失败。 本节仍以 apache 为例，通过从官网上下载的补丁文件 \u0026ldquo;mod_proxy_ftp_CVE-2008-2939.diff\u0026rdquo;，更新 httpd-2.2.9 版本的 apache。\n具体更新步骤如下：\n从 apache 官网上下载补丁文件； 复制补丁文件到 apache 源码包解压目录中，执行命令如下： [root@localhost ~]# cp mod_proxy_ftp_CVE-2008-2939.diff httpd-2.2.9 给旧 apache 打入补丁，具体执行命令如下： [root@localhost ~]# cd httpd-2.2.9 #进入apache源码目录 [root@localhost httpd-2.2.9]# vi mod_proxy_ftp_CVE-2008-2939.diff #查看补丁文件 --modules/proxy/mod_proxy_ftp.c (Revision 682869) + + + modules/proxy/mod_proxy_ftp.c (Revision 682870) …省略部分输出… #查看一下补丁文件中记录的目录，以便一会儿和当前所在目录同步 [root@localhost httpd-2.2.9]# patch - p0 \u0026lt; mod_proxy_ftp_CVE-2008-2939.diff #打入补丁 为什么是 \u0026ldquo;-p0\u0026rdquo; 呢？因为当前在 \u0026ldquo;/root/httpd-2.2.9\u0026rdquo; 目录中，但补丁文件中记录的目录是 \u0026ldquo;modules/proxy/mod_proxy_ftp.c\u0026rdquo;，就在当前所在目录中，因此一个 \u0026ldquo;/\u0026rdquo; 都不需要去掉，所以是 \u0026ldquo;-p0\u0026rdquo;。\n重新编译 apache 源码包，执行如下命令： [root@localhost httpd-2.2.9]# make 安装 apache，执行如下命令：\n[root@localhost httpd-2.2.9]# make install 不难发现，打补丁更新软件的过程比安装软件少了 \u0026ldquo;./configure\u0026rdquo; 步骤，且编译时也只是编译变化的位置，编译速度更快。\nlinux函数库 Linux 系统中存在大量的函数库。简单来讲，函数库就是一些函数的集合，每个函数都具有独立的功能且能被外界调用。我们在编写代码时，有些功能根本不需要自己实现，直接调用函数库中的函数即可。\n需要注意的是，函数库中的函数并不是以源代码的形式存在的，而是经过编译后生成的二进制文件，这些文件无法独立运行，只有链接到我们编写的程序中才可以运行。\nLinux 系统中的函数库分为 2 种，分别是静态函数库（简称静态库）和动态函数库（也称为共享函数库，简称动态库或共享库），两者的主要区别在于，程序调用函数时，将函数整合到程序中的时机不同：\n静态函数库在程序编译时就会整合到程序中，换句话说，程序运行前函数库就已经被加载。这样做的好处是程序运行时不再需要调用外部函数库，可直接执行；缺点也很明显，所有内容都整合到程序中，编译文件会比较大，且一旦静态函数库改变，程序就需要重新编译。\n动态函数库在程序运行时才被加载（如图 1 所示），程序中只保存对函数库的指向（程序编译仅对其做简单的引用）。 使用动态函数库的好处是，程序生成的可执行程序体积比较小，且升级函数库时无需对整个程序重新编译；缺点是，如果程序执行时函数库出现问题，则程序将不能正确运行。\nLinux 系统中，静态函数库文件扩展名是 \u0026ldquo;.a\u0026rdquo;，文件通常命令为 libxxx.a（xxx 为文件名）；动态函数库扩展名为 \u0026ldquo;.so\u0026rdquo;，文件通常命令为 libxxx.so.major.minor（xxx 为文件名，major 为主版本号，minor 为副版本号）。\n目前，Linux 系统中大多数都是动态函数库（主要考虑到软件的升级方便），其中被系统程序调用的函数库主要存放在 \u0026ldquo;/usr/lib\u0026rdquo; 和 \u0026ldquo;/lib\u0026rdquo; 中；Linux 内核所调用的函数库主要存放在 \u0026ldquo;/lib/modules\u0026rdquo; 中。\n注意，函数库（尤其是动态函数库）的存放位置非常重要，轻易不要做更改。\n函数库安装 Linux 发行版众多，不同 Linux 版本安装函数库的方式不同。CentOS 中，安装函数库可直接使用 yum 命令。\n例如，安装 curses 函数库命令如下：\n[root@Linux ~]# yum install ncurses-devel 正常情况下，函数库安装完成后就可以直接被系统识别，但凡事都有万一。这里先想一个问题，如何查看可执行程序调用了哪些函数库呢？通过以下命令即可：\n[root@localhost ~]# ldd -v 可执行文件名 -v 选项的含义是显示详细版本信息（不是必须使用）。\n例如，查看 ls 命令调用了哪些函数库，命令如下：\n[root@localhost ~]# ldd /bin/ls linux-gate.so.1 =\u0026gt; (0x00d56000) libselinux.so.1 =\u0026gt;/lib/libselinux.so.1 (0x00cc8000) librt.so.1 =\u0026gt;/lib/librt.so.1 (0x00cb8000) libcap.so.2 =\u0026gt; /lib/libcap.so.2 (0x00160000) libacl.so.1 =\u0026gt; /lib/libacl.so.1 (0x00140000) libc.so.6 =\u0026gt; /lib/libc.so.6 (0x00ab8000) libdl.so.2 =\u0026gt; /lib/libdl.so.2 (0x00ab0000) /lib/ld-linux.so.2 (0x00a88000) libpthread.so.0 =\u0026gt; /lib/libpthread.so.0 (0x00c50000) libattr.so.1 =\u0026gt;/lib/libattr.so.1 (0x00158000) 如果函数库安装后仍无法使用（运行程序时会提示找不到某个函数库），这时就需要对函数库的配置文件进行手动调整，也很简单，只需进行如下操作：\n将函数库文件放入指定位置（通常放在 \u0026ldquo;/usr/lib\u0026rdquo; 或 \u0026ldquo;/lib\u0026rdquo; 中），然后把函数库所在目录写入 \u0026ldquo;/etc/ld.so.conf\u0026rdquo; 文件。例如： [root@localhost ~]# cp *.so /usr/lib/ #把函数库复制到/usr/lib/目录中 [root@localhost ~]# vi /etc/ld.so.conf #修改函数库配置文件 include ld.so.conf.d/*.conf /usr/lib #写入函数库所在目录（其实/usr/lib/目录默认已经被识别） 注意，这里写入的是函数库所在的目录，而不单单是函数库的文件名。另外，如果自己在其他目录中创建了函数库文件，这里也可以直接在 \u0026ldquo;/etc/ld.so.conf\u0026rdquo; 文件中写入函数库文件所在的完整目录。\n使用 ldconfig 命令重新读取 /etc/ld.so.conf 文件，把新函数库读入缓存。命令如下： [root@localhost ~]# ldconfig #从/etc/ld.so.conf文件中把函数库读入缓存 [root@localhost ~]# ldconfig -p #列出系统缓存中所有识别的函数库 服务管理 我们知道，系统服务是在后台运行的应用程序，并且可以提供一些本地系统或网络的功能。我们把这些应用程序称作服务，也就是 Service。不过，我们有时会看到 Daemon 的叫法，Daemon 的英文原意是\u0026quot;守护神\u0026rdquo;，在这里是\u0026quot;守护进程\u0026quot;的意思。\n那么，什么是守护进程？它和服务又有什么关系呢？守护进程就是为了实现服务、功能的进程。比如，我们的 apache 服务就是服务（Service），它是用来实现 Web 服务的。那么，启动 apache 服务的进程是哪个进程呢？就是 httpd 这个守护进程（Daemon）。也就是说，守护进程就是服务在后台运行的真实进程。\n如果我们分不清服务和守护进程，那么也没有什么关系，可以把服务与守护进程等同起来。在 Linux 中就是通过启动 httpd 进程来启动 apache 服务的，你可以把 httpd 进程当作 apache 服务的别名来理解。\n服务分类 Linux 中的服务按照安装方法不同可以分为 RPM 包默认安装的服务和源码包安装的服务两大类。其中，RPM 包默认安装的服务又因为启动与自启动管理方法不同分为独立的服务和基于 xinetd 的服务。服务分类的关系图如图 1 所示。\n源码包安装到我们手工指定的位置当中，而 RPM 包安装到系统默认位置当中（可以通过\u0026quot;rpm -ql 包名\u0026quot;命令查询）。也就是说，RPM 包安装到系统默认位置，可以被服务管理命令识别；但是源码包安装到手工指定位置，当然就不能被服务管理命令识别了（可以手工修改为被服务管理命令识别）。\n所以，RPM 包默认安装的服务和源码包安装的服务的管理方法不同，我们把它们当成不同的服务分类。\nRPM 包默认安装的服务又可以分为两种：\n独立的服务：就是独立启动的意思，这种服务可以自行启动，而不用依赖其他的管理服务。因为不依赖其他的管理服务，所以，当客户端请求访问时，独立的服务响应请求更快速。目前，Linux 中的大多数服务都是独立的服务，如 apache 服务、FTP 服务、Samba 服务等。\n基于 xinetd 的服务：这种服务就不能独立启动了，而要依靠管理服务来调用。这个负责管理的服务就是 xinetd 服务。xinetd 服务是系统的超级守护进程，其作用就是管理不能独立启动的服务。当有客户端请求时，先请求 xinetd 服务，由 xinetd 服务去唤醒相对应的服务。当客户端请求结束后，被唤醒的服务会关闭并释放资源。这样做的好处是只需要持续启动 xinetd 服务，而其他基于 xinetd 的服务只有在需要时才被启动，不会占用过多的服务器资源。但是这种服务由于在有客户端请求时才会被唤醒，所以响应时间相对较长。\n源码包安装的服务。这些服务是通过源码包安装的，所以安装位置都是手工指定的。由于不能被系统中的服务管理命令直接识别，所以这些服务的启动与自启动方法一般都是源码包设计好的。每个源码包的启动脚本都不一样，一般需要查看说明文档才能确定。\n查看服务 我们已经知道 Linux 服务的分类了，那么应该如何区分这些服务呢？首先要区分 RPM 包默认安装的服务和源码包安装的服务。源码包安装的服务是不能被服务管理命令直接找到的，而且一般会安装到 /usr/local/ 目录中。\n也就是说，在 /usr/local/ 目录中的服务都应该是通过源码包安装的服务。RPM 包默认安装的服务都会安装到系统默认位置，所以是可以被服务管理命令（如 service、chkconfig）识别的。\n其次，在 RPM 包默认安装的服务中怎么区分独立的服务和基于 xinetd 的服务？这就要依靠 chkconfig 命令了。chkconfig 是管理 RPM 包默认安装的服务的自启动的命令，这里仅利用这条命令的查看功能。使用这条命令还能看到 RPM 包默认安装的所有服务。命令格式如下：\n[root@localhost ~]# chkconfig --list [服务名] \u0026ndash;list：列出 RPM 包默认安装的所有服务的自启动状态； [root@localhost ~]# chkconfig -list #列出系统中RPM包默认安装的所有服务的自启动状态 abrt-ccpp 0:关闭 1:关闭 2:关闭 3:启用 4:关闭 5:启用 6:关闭 abrt-oops 0:关闭 1:关闭 2:关闭 3:启用 4:关闭 5:启用 6:关闭 …省略部分输出… udev-post 0:关闭 1:启用 2:启用 3:启用 4:启用 5:启用 6:关闭 ypbind 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭 这条命令的第一列为服务的名称，后面的 0~6 代表在不同的运行级别中这个服务是否开机时自动启动。这些服务都是独立的服务，因为它们不需要依赖其他任何服务就可以在相应的运行级别启动或自启动。但是没有看到基于 xinetd 的服务，那是因为系统中默认没有安装 xinetd 这个超级守护进程，需要我们手工安装。\n安装命令如下：\n[root@localhost ~]# rpm -ivh /mnt/cdrom/Packages/ xinetd-2.3.14-34.el6.i686.rpm Preparing... ############### [100%] 1:xinetd ############### [100%] #xinetd超级守护进程 这里需要注意的是，在 Linux 中基于 xinetd 的服务越来越少，原先很多基于 xinetd 的服务在新版本的 Linux 中已经变成了独立的服务。安装完 xinetd 超级守护进程之后，我们再查看一下，命令如下：\n[root@localhost ~]# chkconfig --list abrt-ccpp 0:关闭 1:关闭 2:关闭 3:启用 4:关闭 5:启用 6:关闭 abrt-oops 0:关闭 1:关闭 2:关闭 3:启用 4:关闭 5:启用 6:关闭 …省略部分输出… udev-post 0:关闭 1:启用 2:启用 3：启用 4:启用 5:启用 6:关闭 xinetd 0:关闭 1:关闭 2:关闭 3:启用 4:启用 5:启用 6:关闭 ypbind 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭 基于 xinetd 的服务： chargen-dgram：关闭 chargen-stream：关闭 cvs：关闭 daytime-dgram：关闭 daytime-stream：关闭 discard-dgram：关闭 discard-stream：关闭 echo-dgram：关闭 echo-stream：关闭 rsync：关闭 tcpmux-server：关闭 time-dgram：关闭 time-stream：关闭 在刚刚的独立的服务之下出现了一些基于 xinetd 的服务，这些服务没有自己的运行级别，因为它们不是独立的服务，到底在哪个运行级别可以自启动，则要看 xinetd 服务是在哪个运行级别自启动的。\n服务启动 独立的服务要想启动，主要有两种方法。\n使用/etc/init.d/目录中的启动脚本来启动独立的服务,我们以启动 RPM 包默认安装的 httpd 服务为例，命令如下：\n[root@localhost ~]# /etc/init.d/httpd start 正在启动httpd: [确定] #启动httpd服务 [root@localhost ~]# /etc/init.d/httpd status httpd (pid 13313)正在运行… #查询httpd服务状态，并能够看到httpd服务的PID [root@localhost ~]#/etc/init.d/httpd stop 停止 httpd: [确定] #停止httpd服务 [root@localhost ~]#/etc/init.d/httpd restart 停止httpd: [失败] 正在启动httpd: [确定] 重启动httpd服务 使用service命令来启动独立的服务:\n[root@localhost ~]# service 独立服务名 start|stop|restart|... service 命令实际上只是一个脚本，这个脚本仍然需要调用 /etc/init.d/ 中的启动脚本来启动独立的服务。而且 service 命令是红帽系列 Linux 的专有命令，其他的 Linux 发行版本不一定拥有这条命令，所以我们并不推荐使用 service 命令来启动独立的服务。\n开机启动 有三种方式实现开机自启。\nchkconfig命令 管理独立服务的自启动，用法如下:\nchkconfig [--level 运行级别][独立服务名][on|off] \u0026ndash;level: 设定在哪个运行级别中开机自启动（on），或者关闭自启动（off）； [root@localhost ~]# chkconfig --list | grep httpd httpd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭 #查询httpd的自启动状态。所有的级别都是不自启动的 [root@localhost ~]# chkconfig --level 2345 httpd on #设置apache服务在进入2、3、4、5级别时自启动 [root@localhost ~]# chkconfig --list | grep httpd httpd 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭 #查询apache服务的自启动状态。发现在2、3、4、5这4个运行级别中变为了\u0026#34;启用\u0026#34; 修改 /etc/rc.d/rc.local 文件，设置服务自启动 这个文件是在系统启动时，在输入用户名和密码之前最后读取的文件（注意：/etc/rc.d/rc.loca和/etc/rc.local 文件是软链接，修改哪个文件都可以）。这个文件中有什么命令，都会在系统启动时调用。\n如果我们把服务的启动命令放入这个文件，这个服务就会在开机时自启动。命令如下：\n[root@localhost ~]#vi /etc/rc.d/rc.local #!/bin/sh # #This script will be executed *after* all the other init scripts. #You can put your own initialization stuff in here if you don\u0026#39;t want to do the full Sys V style init stuff. touch /var/lock/subsys/local /etc/rc.d/init.d/httpd start #在文件中加入apache的启动命令 这样，只要重启之后，apache 服务就会开机自启动了。推荐大家使用这种方法管理服务的自启动，有两点好处：\n第一，如果大家都采用这种方法管理服务的自启动，当我们碰到一台陌生的服务器时，只要查看这个文件就知道这台服务器到底自启动了哪些服务，便于集中管理。\n第二，chkconfig 命令只能识别 RPM 包默认安装的服务，而不能识别源码包安装的服务。 源码包安装的服务的自启动也是通过 /etc/rc.d/rc.local 文件实现的，所以不会出现同一台服务器自启动了两种安装方法的同一个服务。\n还要注意一下，修改 /etc/rc.d/rc.local 配置文件的自启动方法和 chkconfig 命令的自启动方法是两种不同的自启动方法。所以，就算通过修改 /etc/rc.d/rc.local 配置文件的方法让某个独立的服务自启动了，执行\u0026quot;chkconfig \u0026ndash;list\u0026quot;命令并不到有什么变化。\n使用 ntsysv 命令管理自启动 使用 ntsysv 命令调用窗口模式来管理服务的自启动，非常简单。命令格式如下：\n[root@localhost ~]# ntsysv [--level 运行级别] \u0026ndash;level 运行级别：可以指定设定自启动的运行级别； [root@localhost ~]# ntsysv --level 235 #只设定2、3、5级别的服务自启动 [root@localhost ~]# ntsysv #按默认的运行级别设置服务自启动 这个命令的操作是这样的：\n上下键：在不同服务之间移动；\n空格键：选定或取消服务的自启动。也就是在服务之前是否输入\u0026quot;*\u0026quot;；\nTab键：在不同项目之间切换；\nF1键：显示服务的说明；\n需要注意的是，ntsysv 命令不仅可以管理独立服务的自启动，也可以管理基于 xinetd 服务的自启动。也就是说，只要是 RPM 包默认安装的服务都能被 ntsysv 命令管理。但是源码包安装的服务不行。\n这样管理服务的自启动多么方便，为什么还要学习其他的服务自启动管理命令呢？ ntsysv 命令虽然简单，但它是红帽系列 Linux 的专有命令，其他的 Linux 发行版本不一定拥有这条命令，而且条命令也不能管理源码包安装的服务，所以我们推荐大家使用 /etc/rc.d/rc.local 文件来管理服务的自启动。\nxinetd 服务 基于 xinetd 的服务没有自己独立的启动脚本程序，是需要依赖 xinetd 的启动脚本来启动的。xinetd 本身是独立的服务，所以 xinetd 服务自己的启动方法和独立服务的启动方法是一致的。\n但是，所有基于 xinetd 这个超级守护进程的其他服务就不是这样的了，必须修改该服务的配置文件，才能启动基于 xinetd 的服务。所有基于 xinetd 服务的配置文件都保存在 /etc/xinetd.d/ 目录中。\n我们使用 Telnet 服务来举例。Telnet 服务是用来进行系统远程管理的，端口是 23。不过需要注意的是，Telnet 服务的远程管理数据在网络中是明文传输的，非常不安全，所以在生产服务器上是不建议启动 Telnet 服务的。在生产服务器上，远程管理使用的是 ssh 协议，ssh 协议是加密的，更加安全。\nTelnet 服务也是分为\u0026quot;客户端/服务器端\u0026quot;的，其中服务器端是用来启动 Telnet 服务的，并不安全；客户端是用来连接服务器端或测试服务器的端口是否开启的，在实际工作中我们主要使用 Telnet 客户端来测试远程服务器开启了哪些端口。\n虽然 Telnet 服务不安全，但 Telnet 服务是基于 xinetd 的服务，我们使用 Telnet 服务来学习一下基于 xinetd 服务的启动管理。在目前的 Linux 系统中，Telnet 的服务器端都是不安装的，如果进行测试，则需要手工安装。安装命令如下：\n[root@localhost ~]#rpm-ivh/mnt/cdroin/Packages/telnet-server-0.17-47.el6.i686.rpm [100%] ############### Preparing... 1:telnet-server ############### [100%] #安装 [root@localhost ~]# chkconfig -list #安装之后查询一下 …省略部分输出... 基于xinetd的服务： chargen-dgram：关闭 chargen-stream：关闭 cvs：关闭 daytime-dgram：关闭 daytime-stream：关闭 discard-dgram：关闭 discard-stream：关闭 echo-dgram：关闭 echo-stream：关闭 rsync：关闭 tcpmux-server：关闭 telnet:关闭 time-dgram：关闭 time-stream：关闭 #Telnet服务已经安装，是基于xinetd的服务，自启动状态是关闭 接下来我们就要启动 Telnet 服务了。既然基于 xinetd 服务的配置文件都在 /etc/xinetd.d/ 目录中，那么 Telnet 服务的配置文件就是 /etc/xinetd.d/telnet。我们打开这个文件看看，如下：\n[root@localhost ~]#vi /etc/xinetd.d/telnet #default: on #description: The telnet server serves telnet sessions; it uses \\ #unencrypted username/password pairs for authentication. service telnet #服务的名称为telnet { flags = REUSE #标志为REUSE，设定TCP/IP socket可重用 socketjtype = stream #使用 TCP协议数据包 wait = no #允许多个连接同时连接 user = root #启动服务的用户为root server = /usr/sbin/in.telnetd #服务的启动程序 log_on_failure += USERID #登录失败后，记录用户的ID disable = yes #服务不启动 } 如果想要启动 Telnet 服务，则只需要把 /etc/xinetd.d/telnet 文件中的\u0026quot;disable=yes\u0026quot;改为\u0026quot;disable=no\u0026quot;即可，\u0026ldquo;disable\u0026quot;代表取消，\u0026ldquo;disable=yes\u0026quot;代表取消是 yes，当然不启动服务；\u0026ldquo;disable=no\u0026quot;代表取消是 no，当然就是启动服务了。具体命令如下：\n[root@localhost ~]#vi /etc/xinetd.d/telnet #修改配置文件 service telnet { …省略部分输出… disable = no #把 yes 改为no } [root@localhost ~]# service xinetd restart #重启xinetd服务 停止 xinetd: [确定] 正在启动xinetd: [确定] [root@localhost ~]# netstat -tlun|grep 23 tcp 0 0 :::23 :::* LISTEN #查看端口，23端口启动，表示Telne服务已经启动了 基于 xinetd 服务的启动都是这样的，只需修改 /etc/xinetd.d/ 目录中的配置文件，然后重启 xientd 服务即可。\n基于xientd 服务的自启动 基于 xinetd 服务的自启动管理有两种方法，分别是通过 chkconfig 命令管理自启动和通过 ntsysv 命令管理自启动。但是不能通过修改 /etc/rc.d/rc.local 配置文件来管理自启动，因为基于 xinetd 的服务没有自己的启动脚本程序。我们分别来看看。\n使用 chkconfig 命令管理自启动 chkconfig 自启动管理命令可以管理所有 RPM 包默认安装的服务，所以也可以用来管理基于 xinetd 服务的自启动。命令格式如下：\n[root@localhost ~]# chkconfig 服务名 on|off #基于xinetd的服务没有自己的运行级别，而依靠xinetd服务的运行级别，所以不用指定--level选项 [root@localhost ~]# chkconfig telnet on #启动Telnet服务的自启动 [root@localhost ~]# chkconfig --list|grep telnet telnet:启用 #查看服务的自启动，Telnet服务变为了\u0026#34;启用\u0026#34; [root@localhost ~]# chkconfig telnet off #关闭Telnet服务的自启动 [root@localhost ~]# chkconfig --list|grep telnet telnet:关闭 #查看服务的自启动，Telnet服务变为了 \u0026#34;关闭\u0026#34; Linux源码包服务管理 源码包服务中所有的文件都会安装到指定目录当中，并且没有任何垃圾文件产生（Linux 的特性），所以服务的管理脚本程序也会安装到指定目录中。源码包服务的启动管理方式就是在服务的安装目录中找到管理脚本，然后执行这个脚本。\n问题来了，每个服务的启动脚本都是不一样的，我们怎么确定每个服务的启动脚本呢？还记得在安装源码包服务时，我们强调需要査看每个服务的说明文档吗（一般是 INSTALL 或 READEM）？在这个说明文档中会明确地告诉大家服务的启动脚本是哪个文件。\n我们用 apache 服务来举例。一般 apache 服务的安装位置是 /usr/local/apache2/ 目录，那么 apache 服务的启动脚本就是 /usr/local/apache2/bin/apachectl 文件（查询 apache 说明文档得知）。启动命令如下：\n[root@localhost ~]# /usr/local/apache2/bin/apachectl start|stop|restart|... #源码包服务的启动管理 源码包服务的白启动管理也不能依靠系统的服务管理命令，而只能把标准启动命令写入 /etc/rc.d/rc.local 文件中。系统在启动过程中读取 /etc/rc.d/rc.local 文件时，就会调用源码包服务的启动脚本，从而让该服务开机自启动。\n在默认情况下，源码包服务是不能被系统的服务管理命令所识别和管理的，但是如果我们做一些设定，则也是可以让源码包服务被系统的服务管理命令所识别和管理的。不过笔者并不推荐大家这样做，因为这会让本来区别很明确的源码包服务和 RPM 包服务变得容易混淆，不利于系统维护和管理。\n我们做一个实验，看看如何把源码包安装的 apache 服务变为和 RPM 包默认安装的 apache 服务一样，可以被 service、chkconfig、ntsysv 命令所识别。实验如下：\n[root@localhost ~]# ln -s /usr/local/apache2/bin/apachectl /etc/±nit.d/apache #service命令其实只是在/etc/init.d/目录中查找是否有服务的启动脚本，所以我们只需要做一个软链接,把源码包的启动脚本链接到/etc/init.d/目录中,就能被service命令所管理了。为了照顾大家的习惯，我把软链接文件命名为apache,注意这不是RPM包默认安装的apache服务 [root@localhost ~]# service apache restart #虽然RPM包默认安装的apache服务被卸载了,但是service命令也能够生效 让源码包安装的apache服务能被chkconfig命令管理自启动:\n[root@localhost ~]# vi /etc/init.d/apache #修改源码包安装的apache服务的启动脚本(注意此文件是软链接,所以修改的还是源码包启动脚本) #!/bin/sh # #chkconfig: 35 86 76 #指定httpd脚本可以被chkconfig命令所管理 #格式是：chkconfig：运行级别 启动顺序 关闭顺序 #这里我们让apache服务在3和5级别中能被chkconfig命令所管理，启动顺序是S86，关闭顺序是K76 #(自定顺序，不要和系统中已有的启动顺序冲突) #description: source package apache #说明，内容随意 #以上两句话必须加入,才能被chkconfig命令所识别 ...省略部分输出... [root@localhost ~]# chkconfig --add apache #让chkconfig命令能够管理源码包安装的apache服务 [root01ocalhost ~]# chkconfig --list | grep apache apache 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭 #很神奇吧,虽然RPM包默认安装的apache服务被删除了,但是chkconfig命令可以管理源码包安装的tapache服务 ","date":"2022年12月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/linux%E8%BD%AF%E4%BB%B6%E5%92%8C%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","series":[],"smallImg":"","tags":[{"title":"linux","url":"/myblog/tags/linux/"}],"timestamp":1669893680,"title":"Linux软件和服务管理"},{"authors":[],"categories":[{"title":"操作系统","url":"/myblog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"linux","url":"/myblog/categories/linux/"}],"content":"性能指标 CPU CPU 是操作系统稳定运行的根本，CPU 的速度与性能很大一部分决定了系统整体的性能，因此 CPU 数量越多、主频越高，服务器性能也就相对越好。\n但亊实也并非完全如此，目前大部分 CPU 在同一时间内只能运行一个线程，超线程的处理器可以在同一时间运行多个线程，因而可以利用处理器的超线程特性提髙系统性能。\n而在 Linux 系统下，只有运行 SMP 内核才能支持超线程，但是安装的 CPU 数量越多，从超线程获得的性能上的提高就越少。另外，Linux 内核会把多核的处理器当作多个单独的 CPU 来识别，例如两颗 4 核的 CPU 在 Linux 系统下会认为是 8 颗 CPU。\n注意，从性能角度来讲，两颗 4 核的 CPU 和 8 颗单核的 CPU 并不完全等价，根据权威部门得出的测试结论，前者的整体性能要低于后者 25%〜30%。\n在 Linux 系统中，邮件服务器、动态 Web 服务器等应用对 CPU 性能的要求相对较高，因此对于这类应用，要把 CPU 的配置和性能放在主要位置。\n内存 内存的大小也是影响 Linux 性能的一个重要的因素。内存太小，系统进程将被阻塞，应用也将变得缓慢，甚至失去响应；内存太大，会导致资源浪费。\nLinux 系统采用了物理内存和虚拟内存的概念，虚拟内存虽然可以缓解物理内存的不足，但是占用过多的虚拟内存，应用程序的性能将明显下降。要保证应用程序的高性能运行，物理内存一定要足够大，但不应过大，否则会造成内存资源的浪费。\n例如，在一个 32 位处理器的 Linux 操作系统上，超过 8GB 的物理内存都将被浪费。因此，要使用更大的内存，建议安装 64 位的操作系统，同时开启 Linux 的大内存内核支持。\n不仅如此，由于处理器寻址范围的限制，在 32 位 Linux 操作系统上，应用程序单个进程最大只能使用 2GB 的内存。这样即使系统有更大的内存，应用程序也无法“享”用，解决的办法就是使用 64 位处理器，安装 64 位操作系统，在 64 位操作系统下，可以满足所有应用程序对内存的使用需求，几乎没有限制。\n对内存性能要求比较的应用有打印服务器、数据库服务器和静态 Web 服务器等，因此对于这类应用，要把内存大小放在主要位置。\n磁盘读写（I/O）能力 磁盘的 I/O 能力会直接影响应用程序的性能。比如说，在一个需要频繁读写的应用中，如果磁盘 I/O 性能得不到满足，就会导致应用的停滞。\n不过，好在现今的磁盘都采用了很多方法来提高 I/O 性能，比如常见的磁盘 RAID 技术。\nRAID 的英文全称为 Redundant Array of Independent Disks，翻译成中文为独立磁盘冗余阵列，简称磁盘阵列。RAID 通过把多块独立的磁盘（物理硬盘）按不同方式组合起来，形成一个磁盘组（逻辑硬盘），从而提供比单个硬盘更高的 I/O 性能和数据冗余。\n通过 RAID 技术组成的磁盘组，就相当于一个大硬盘，用户可以对它进行分区格式化、建立文件系统等操作，跟单个物理硬盘一模一样，惟一不同的是 RAID 磁盘组的 I/O 性能比单个硬盘要高很多，同时对数据的安全性也有很大提升。\n有关 RAID 更多的介绍，可阅读《Linux RAID（磁盘列阵）完全攻略》一节做深入了解。\n网络带宽 Linux 下的各种应用，一般都是基于网络的，因此网络带宽也是影响性能的一个重要因素，低速的、不稳定的网络将导致网络应用程序的访问阻塞；而稳定、高速的带宽，可以保证应用程序在网络上畅通无阻地运行。\n幸运的是，现在的网络一般都是千兆带宽，或者光纤网络，带宽问题对应用程序性能造成的影响也在逐步降低。\n通过对以上 4 个方面的讲述，不难看出，各个方面之间都是相互依赖的，不能孤立地从某个方面来排查问题。换句话说，当一个方面出现性能问题时，往往会引发其他方面出现问题。\n例如，大量的磁盘读写势必消耗 CPU 和 I/O 资源，而内存的不足会导致频繁地进行内存页写入磁盘、磁盘写到内存的操作，造成磁盘 I/O 瓶颈，同时大量的网络流量也会造成 CPU 过载。总之，在处理性能问题时，应纵观全局，从各个方面进行综合考虑。\n性能监控命令 netstat：查看网络端口 /etc/services 文件下记录了服务和端口的映射关系。\nnetstat命令用来查看端口信息，主要选项：\n-a：列出系统中所有网络连接，包括已经连接的网络服务、监听的网络服务和 Socket 套接字；\n-t：列出 TCP 数据；\n-u：列出 UDF 数据；\n-l：列出正在监听的网络服务（不包含已经连接的网络服务）；\n-n：用端口号来显示而不用服务名；\n-p：列出该服务的进程 ID (PID)；\n[root@localhost ~]# netstat -tlunp #列出系统中所有已经启动的服务（已经监听的端口），但不包含已经连接的网络服务 Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:53575 0.0.0.0:* LISTEN 1200/rpc.statd tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1181/rpcbind tcp 0 0 0.0.0.0:22 O.O.O.O:* LISTEN 1405/sshd tcp 0 0 127.0.0.1:631 O.O.O.O:* LISTEN 1287/cupsd tcp 0 0 127.0.0.1:25 O.O.O.O:* LISTEN 1481/master 执行这条命令会看到服务器上所有已经开启的端口，也就是说，通过这些端口就可以知道当前服务器上开启了哪些服务。\n解释一下命令的执行结果：\nProto：数据包的协议。分为 TCP 和 UDP 数据包；\nRecv-Q：表示收到的数据已经在本地接收缓冲，但是还没有被进程取走的数据包数量；\nSend-Q：对方没有收到的数据包数量；或者没有 Ack 回复的，还在本地缓冲区的数据包数量；\nLocal Address：本地 IP : 端口。通过端口可以知道本机开启了哪些服务；\nForeign Address：远程主机：端口。也就是远程是哪个 IP、使用哪个端口连接到本机。由于这条命令只能查看监听端口，所以没有 IP 连接到到本机；\nState:连接状态。主要有已经建立连接（ESTABLISED）和监听（LISTEN）两种状态，当前只能查看监听状态；\nPID/Program name：进程 ID 和进程命令；\n[root@localhost ~]# netstat -an #查看所有的网络连接，包括已连接的网络服务、监听的网络服务和Socket套接字 Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:53575 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN tcp 0 0 192.168.0.210:22 192.168.0.105:4868 ESTABLISHED tcp 0 0 :::57454 :::* LISTEN ...省略部分输出... udp 0 0 :::932 :::* Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path #Socket套接字输出,后面有具体介绍 Unix 2 [ ACC ] STREAM LISTENING 11712 /var/run/dbus/system_bus_socket unix 2 [ ACC ] STREAM LISTENING 8450 @/com/ubuntu/upstart unix 7. [ ] DGRAM 8651 @/org/kernel/udev/udevd unix 2 [ ACC ] STREAM LISTENING 11942 @/var/run/hald/dbus-b4QVLkivf1 ...省略部分输出... 执行\u0026quot;netstat -an\u0026quot;命令能査看更多的信息，在 Stated 中也看到了已经建立的连接（ESTABLISED）。这是 ssh 远程管理命令产生的连接，ssh 对应的端口是 22。\n而且我们还看到了 Socket 套接字。在服务器上，除网络服务可以绑定端口，用端口来接收客户端的请求数据外，系统中的网络程序或我们自己开发的网络程序也可以绑定端口，用端口来接收客户端的请求数据。这些网络程序就是通过 Socket 套接字来绑定端口的。也就是说，网络服务或网络程序要想在网络中传递数据，必须利用 Socke 套接字绑定端口，并进行数据传递。\n使用\u0026quot;netstat -an\u0026quot;命令查看到的这些 Socke 套接字虽然不是网络服务，但是同样会占用端口，并在网络中传递数据。\n解释一下 Socket 套接字的输出：\nProto：协议，一般是unix；\nRefCnt：连接到此Socket的进程数量；\nFlags：连接标识；\nType：Socket访问类型；\nState：状态，LISTENING表示监听，CONNECTED表示已经建立连接；\nI-Node：程序文件的 i 节点号；\nPath：Socke程序的路径，或者相关数据的输出路径；\nvmstat命令 vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。他是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。\n[root@localhost ~]# vmstat 2 3 procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 8 247512 39660 394168 0 0 31 8 86 269 0 1 98 1 0 0 0 8 247480 39660 394172 0 0 0 0 96 147 4 0 96 0 0 0 0 8 247484 39660 394172 0 0 0 66 95 141 2 2 96 0 0 Procs（进程）\nr: 运行队列中进程数量,也就是多少个进程分配到了CPU，当这个值超过了CPU的数目，表示CPU出现瓶颈了。\nb: 表示阻塞的进程，比如正在等待I/O或者内存交换等\nMemory（内存）\nswpd: 使用虚拟内存大小 ，如果大于0，表示你的机器物理内存不足了。\nfree: 空闲物理内存大小\nbuff: 用作缓冲的内存大小 ，一般对块设备的读写才需要缓冲。\ncache: 表示page cached的内存大小，也就是缓存大小。频繁访问的文件会被缓存到内存当中。如果cache值比较大，而IO中的bi比较小，说明文件系统效率比较好。\nSwap\nsi: 表示有磁盘调入内存，也就是内存进入内存交换区的内存大小；通俗的讲就是 每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。\nso: 每秒写入交换区的内存大小，由内存调入磁盘 。\n一般情况下si、so的值都为0，如果si、so的值长期不为0，则说明系统内存不足，需要增加系统内存\nIO（现在的Linux版本块的大小为1kb）\nbi: 每秒读取的块数\nbo: 每秒写入的块数\n如果bi+bo的值过大，且wa值较大，则表示系统磁盘IO瓶颈\nsystem（系统）\nin: 每秒中断数，包括时钟中断\ncs: 每秒上下文切换数\n这两个值越大，则由内核消耗的CPU就越多\nCPU（以百分比表示）\nus: 用户进程执行时间百分比(user time),us的值比较高时，说明用户进程消耗的CPU时间多。 如果长期大于50%，则需要考虑优化程序或者算法\nsy: 内核系统进程执行时间百分比(system time),sy的值高时，说明系统内核消耗的CPU资源多。 一般来说us+sy应该小于80%，如果大于80%，说明可能存在CPU瓶颈\nwa: IO等待时间百分比,wa的值高时，说明IO等待比较严重。引起I/O等待的原因可能是磁盘大量随机读写造成的，也可能是磁盘或者服务器的带宽瓶颈造成的。\nid: 表示CPU处在空间状态的时间百分比\nsar命令 sar 命令很强大，是分析系统性能的重要工具之一，通过该命令可以全面地获取系统的 CPU、运行队列、磁盘读写（I/O）、分区（交换区）、内存、CPU 中断和网络等性能数据。\nsar 命令的基本格式如下：\n[root@localhost ~]# sar [options] [-o filename] interval [count] 此命令格式中，各个参数的含义如下：\n-o filename：其中，filename 为文件名，此选项表示将命令结果以二进制格式存放在文件中；\ninterval：表示采样间隔时间，该参数必须手动设置；\ncount：表示采样次数，是可选参数，其默认值为 1；\noptions：为命令行选项，由于 sar 命令提供的选项很多，这里不再一一介绍，仅列举出常用的一些选项及对应的功能，如表 1 所示。\nsar命令选项 功能 -A 显示系统所有资源设备（CPU、内存、磁盘）的运行状况。 -u 显示系统所有 CPU 在采样时间内的负载状态。 -P 显示当前系统中指定 CPU 的使用情况。 -d 显示系统所有硬盘设备在采样时间内的使用状态。 -r 显示系统内存在采样时间内的使用情况。 -b 显示缓冲区在采样时间内的使用情况。 -v 显示 inode 节点、文件和其他内核表的统计信息。 -n 显示网络运行状态，此选项后可跟 DEV（显示网络接口信息）、EDEV（显示网络错误的统计数据）、SOCK（显示套接字信息）和 FULL（等同于使用 DEV、EDEV和SOCK）等，有关更多的选项，可通过执行 man sar 命令查看。 -q 显示运行列表中的进程数、进程大小、系统平均负载等。 -R 显示进程在采样时的活动情况。 -y 显示终端设备在采样时间的活动情况。 -w 显示系统交换活动在采样时间内的状态。 【例 1】如果想要查看系统 CPU 的整理负载状况，每 3 秒统计一次，统计 5 次，可以执行如下命令：\n[root@localhost ~]# sar -u 3 5 Linux 2.6.32-431.el6.x86_64 (localhost) 10/28/2019 _x86_64_ (8 CPU) 04:02:46 AM CPU %user %nice %system %iowait %steal %idle 04:02:49 AM all 1.69 0.00 2.03 0.00 0.00 96.27 04:02:52 AM all 1.68 0.00 0.67 0.34 0.00 97.31 04:02:55 AM all 2.36 0.00 1.69 0.00 0.00 95.95 04:02:58 AM all 0.00 0.00 1.68 0.00 0.00 98.32 04:03:01 AM all 0.33 0.00 0.67 0.00 0.00 99.00 Average: all 1.21 0.00 1.35 0.07 0.00 97.37 此输出结果统计的是系统中包含的 8 颗 CPU 的整体运行状况，每项的输出都非常直观，其中最后一行（Average）是汇总行，是对上面统计信息的一个平均值。\n需要指出的是，sar 输出结果中第一行包含了 sar 命令本身的统计消耗，因此 %user 列的值会偏高一点，但这并不会对统计结果产生很大影响。\n另外，在一个多 CPU 的系统中，如果程序使用了单线程，就会出现“CPU 整体利用率不高，但系统应用响应慢”的现象，造成此现象的原因在于，单线程只使用一个 CPU，该 CPU 占用率为 100%，无法处理其他请求，但除此之外的其他 CPU 却处于闲置状态，进而整体 CPU 使用率并不高。\n针对这个问题，可以使用 sar 命令单独查看系统中每个 CPU 的运行状态，例如：\n[root@localhost ~]# sar -P 0 3 5 Linux 2.6.32-431.el6.x86_64 (localhost) 10/28/2019 _x86_64_ (8 CPU) 04:44:57 AM CPU %user %nice %system %iowait %steal %idle 04:45:00 AM 0 8.93 0.00 1.37 0.00 0.00 89.69 04:45:03 AM 0 6.83 0.00 1.02 0.00 0.00 92.15 04:45:06 AM 0 0.67 0.00 0.33 0.33 0.00 98.66 04:45:09 AM 0 0.67 0.00 0.33 0.00 0.00 99.00 04:45:12 AM 0 2.38 0.00 0.34 0.00 0.00 97.28 Average: 0 3.86 0.00 0.68 0.07 0.00 95.39 注意，sar 命令对系统中 CPU 的计数是从数字 0 开始的，因此上面执行的命令表示对系统中第一颗 CPU 的运行状态进行统计。如果想单独统计系统中第 5 颗 CPU 的运行状态，可以执行sar -P 4 3 5命令。\n【例 2】如果想要查看系统磁盘的读写性能，可执行如下命令：\n[root@localhost ~]# sar -d 3 5 Linux 2.6.32-431.el6.x86_64 (localhost) 10/25/2019 _x86_64_ (1 CPU) 06:36:52 AM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 06:36:55 AM dev8-0 3.38 0.00 502.26 148.44 0.08 24.11 4.56 1.54 06:36:55 AM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 06:36:58 AM dev8-0 1.49 0.00 29.85 20.00 0.00 1.75 0.75 0.11 06:36:58 AM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 06:37:01 AM dev8-0 68.26 6.96 53982.61 790.93 3.22 47.23 3.54 24.17 06:37:01 AM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 06:37:04 AM dev8-0 111.69 3961.29 154.84 36.85 1.05 9.42 3.44 38.43 06:37:04 AM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 06:37:07 AM dev8-0 1.67 136.00 2.67 83.20 0.01 6.20 6.00 1.00 Average: DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util Average: dev8-0 34.45 781.10 9601.22 301.36 0.78 22.74 3.50 12.07 此输出结果中，各个列表头的含义如下：\ntps：每秒从物理磁盘 I/O 的次数。注意，多个逻辑请求会被合并为一个 I/O 磁盘请求，一次传输的大小是不确定的；\nrd_sec/s：每秒读扇区的次数；\nwr_sec/s：每秒写扇区的次数；\navgrq-sz：平均每次设备 I/O 操作的数据大小（扇区）；\navgqu-sz：磁盘请求队列的平均长度；\nawait：从请求磁盘操作到系统完成处理，每次请求的平均消耗时间，包括请求队列等待时间，单位是毫秒（1 秒=1000 毫秒）；\nsvctm：系统处理每次请求的平均时间，不包括在请求队列中消耗的时间；\n%util：I/O 请求占 CPU 的百分比，比率越大，说明越饱和。\n【例 2】如果想要查看内存的使用情况，可执行如下命令：\n[root@localhost ~]# sar -r 2 3 Linux 2.6.32-431.el6.x86_64 (localhost) 10/29/2019 _x86_64_ (8 CPU) 04:54:20 AM kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit 04:54:22 AM 1218760 834228 40.63 53228 424908 738312 18.08 04:54:24 AM 1218744 834244 40.64 53228 424908 738312 18.08 04:54:26 AM 1218712 834276 40.64 53228 424908 738312 18.08 Average: 1218739 834249 40.64 53228 424908 738312 18.08 此输出结果中，各个参数表示的含义如下：\nkbmemfree：表示空闲的物理内存的大小；\nkbmemeused：表示已使用的物理内存的大小；\n%memused：表示已使用内存占总内存大小的百分比；\nkbbuffers：表示缓冲区所使用的物理内存的大小；\nkbcached：表示告诉缓存所使用的物理内存的大小；\nkbcommit 和 %commit：分别表示当前系统中应用程序使用的内存大小和百分比；\n相比 free 命令，sar 命令的输出信息更加人性化，不仅给出了内存使用量，还给出了内存使用的百分比以及统计的平均值。比如说，仅通过 %commit 一项就可以得知，当前系统中的内存资源充足。\niostat iostat 命令主要用于统计磁盘 I/O 状态，但也能用来查看 CPU 的使用情况，只不过使用此命令仅能显示系统所有 CPU 的平均状态，无法向 sar 命令那样做具体分析。\n使用 iostat 命令查看 CPU 运行状态，需要使用该命令提供的 -c 选项，该选项的作用是仅显示系统 CPU 的运行情况。例如：\n[root@localhost ~]# iostat -c Linux 2.6.32-431.el6.x86_64 (localhost) 10/28/2019 _x86_64_ (8 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.07 0.00 0.12 0.09 0.00 99.71 可以看到，此输出结果中包含的项和 sar 命令的输出项完全相同。\nuptime uptime 命令是监控系统性能最常用的一个命令，主要用来统计系统当前的运行状况。例如：\n[root@localhost ~]# uptime 05:38:26 up 1:47, 2 users, load average: 0.12, 0.08, 0.08 该命令的输出结果中，各个数据所代表的含义依次是：系统当前时间、系统运行时长、当前登陆系统的用户数量、系统分别在 1 分钟、5 分钟和 15 分钟内的平均负载。\n这里需要注意的是，load average 这 3 个输出值一般不能大于系统 CPU 的个数。例如，本测试系统有 8 个 CPU，如果 load average 中这 3 个值长期大于 8，就说明 CPU 很繁忙，负载很高，系统性能可能会受到影响；如果偶尔大于 8 则不用担心，系统性能一般不会受到影响；如果这 3 个值小于 CPU 的个数（如本例所示），则表示 CPU 是非常空闲的。\n总的来说，本节介绍了 4 个可查看 CPU 性能的命令，但这些命令也仅能查看 CPU 是否繁忙、负载是否过大，无法知道造成这种现象的根本原因。因此，在明确判断出系统 CPU 出现问题之后，还要结合 top、ps 等命令，进一步检查出是哪些进程造成的。\n另外要知道的是，引发 CPU 资源紧张的原因有多个，可能是应用程序不合理造成的，也可能是硬件资源匮乏引起的。因此，要学会具体问题具体分析，或者优化应用程序，或者增加系统 CPU 资源。\nfree [root@localhost ~]# free -m total used free shared buffers cached Mem: 2004 573 1431 0 47 201 -/+ buffers/cache: 323 1680 Swap: 1983 0 1983 从输出结果可以看到，该系统共 2GB 内存，其中系统空闲内存还有 1431MB，并且 swap 交换分区还未使用，因此可以判断出当前系统的内存资源还非常充足。\n除此之外，free 命令还可以实时地监控内存的使用状况，通过使用 -s 选项，可以实现在指定的时间段内不间断地监控内存的使用情况。例如：\n[root@localhost ~]# free -m -s 5 total used free shared buffers cached Mem: 2004 571 1433 0 47 202 -/+ buffers/cache: 321 1683 Swap: 1983 0 1983 total used free shared buffers cached Mem: 2004 571 1433 0 47 202 -/+ buffers/cache: 321 1683 Swap: 1983 0 1983 #省略后续输出 要想实现动态地监控内存使用状况，除了使用 free 命令提供的 -s 选项，还可以借助 watch 命令。通过给 watch 命令后面添加需要运行的命令，watch 就会自行重复去运行这个命令（默认 2 秒执行一次），例如：\n[root@localhost ~]# watch -n 3 -d free Every 3.0s: free Tue Oct 29 03:05:43 2019 total used free shared buffers cached Mem: 2052988 586504 1466484 0 49184 207360 -/+ buffers/cache: 329960 1723028 Swap: 2031608 0 2031608 上面执行的命令中，-n 选项用于执行重复执行的间隔时间，-d 选项用于在显示数据时，高亮显示变动了的数据。\ndmesg：查看被内核杀死的进程 Linux dmesg（英文全称：display message）dmesg 命令主要用来显示内核信息。使用 dmesg 可以有效诊断机器硬件故障或者添加硬件出现的问题。另外，使用 dmesg 可以确定您的服务器安装了哪些硬件。每次系统重启，系统都会检查所有硬件并将信息记录下来。执行/bin/dmesg 命令可以查看该记录，开机信息亦保存在/var/log目录中，名称为dmesg的文件里。\n也可以使用该命令查看进程被杀死的信息，如下：\n$ dmesg | tail [1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0 [...] [1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child [1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB [2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request. Check SNMP counters. 该命令会输出系统日志的最后10行。示例中的输出，可以看见一次内核的oom kill和一次TCP丢包。这些日志可以帮助排查性能问题。千万不要忘了这一步。\npidstat：查看进程的CPU $ pidstat 1 Linux 3.13.0-49-generic (titanclusters-xxxxx) 07/14/2015 _x86_64_ (32 CPU) 07:41:02 PM UID PID %usr %system %guest %CPU CPU Command 07:41:03 PM 0 9 0.00 0.94 0.00 0.94 1 rcuos/0 07:41:03 PM 0 4214 5.66 5.66 0.00 11.32 15 mesos-slave 07:41:03 PM 0 4354 0.94 0.94 0.00 1.89 8 java 07:41:03 PM 0 6521 1596.23 1.89 0.00 1598.11 27 java 07:41:03 PM 0 6564 1571.70 7.55 0.00 1579.25 28 java 07:41:03 PM 60004 60154 0.94 4.72 0.00 5.66 9 pidstat 07:41:03 PM UID PID %usr %system %guest %CPU CPU Command 07:41:04 PM 0 4214 6.00 2.00 0.00 8.00 15 mesos-slave 07:41:04 PM 0 6521 1590.00 1.00 0.00 1591.00 27 java07:41:04 PM 0 6564 1573.00 10.00 0.00 1583.00 28 java 07:41:04 PM 108 6718 1.00 0.00 0.00 1.00 0 snmp-pass 07:41:04 PM 60004 60154 1.00 4.00 0.00 5.00 9 pidstat pidstat命令输出进程的CPU占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个JAVA进程占用了将近1600%的CPU时间，既消耗了大约16个CPU核心的运算资源。\n","date":"2022年12月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/linux%E6%80%A7%E8%83%BD%E7%AE%A1%E7%90%86/","series":[],"smallImg":"","tags":[{"title":"linux","url":"/myblog/tags/linux/"}],"timestamp":1669893680,"title":"Linux性能管理"},{"authors":[],"categories":[{"title":"操作系统","url":"/myblog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"linux","url":"/myblog/categories/linux/"}],"content":"登陆 Linux 系统时，虽然输入的是自己的用户名和密码，但其实 Linux 并不认识你的用户名称，它只认识用户名对应的 ID 号（也就是一串数字）。\n要论证 \u0026ldquo;Linux系统不认识用户名\u0026rdquo; 也很简单，网络上下载过 \u0026ldquo;.tar.gz\u0026rdquo; 或 \u0026ldquo;.tar.bz2\u0026rdquo; 格式的文件，解压缩之后的文件中，有时，你会发现文件拥有者的属性显示的是一串数字，这串数字就是用户的 ID（UID）号。之所以没有显示出用户名称，是因为找不到UID对应的用户。\nLinux 系统中，每个用户的 ID 细分为 2 种，分别是用户 ID（User ID，简称 UID）和组 ID（Group ID，简称 GID），这与文件有拥有者和拥有群组两种属性相对应。\n管理用户的文件 创建用户的时候，会默认分配与用户同名的用户组，这个创建时自动分配的用户组叫做初始组。 后面又给该用户添加的其他用户组，叫做附加组。\n每个文件都有自己的拥有者 ID 和群组 ID，当显示文件属性时，系统会根据 /etc/passwd 和 /etc/group 文件中的内容，分别找到 UID 和 GID 对应的用户名和群组名，然后显示出来。\n/etc/passwd 文件 root@zzq:~# cat /etc/passwd root❌0:0:root:/root:/bin/bash daemon❌1:1:daemon:/usr/sbin:/usr/sbin/nologin bin❌2:2:bin:/bin:/usr/sbin/nologin sys❌3:3:sys:/dev:/usr/sbin/nologin sync❌4:65534:sync:/bin:/bin/sync 这些用户中的绝大多数是系统或服务正常运行所必需的用户，这种用户通常称为系统用户或伪用户。系统用户无法用来登录系统，但也不能删除，因为一旦删除，依赖这些用户运行的服务或程序就不能正常执行，会导致系统问题。\n不仅如此，每行用户信息都以 \u0026ldquo;：\u0026rdquo; 作为分隔符，划分为 7 个字段，每个字段所表示的含义如下：\n用户名：密码：UID（用户ID）：GID（组ID）：描述性信息：主目录：默认Shell\n密码 \u0026ldquo;x\u0026rdquo; 表示此用户设有密码，但不是真正的密码，真正的密码保存在 /etc/shadow 文件中。此文件只有 root 用户可以浏览和操作，这样就最大限度地保证了密码的安全。需要注意的是，虽然 \u0026ldquo;x\u0026rdquo; 并不表示真正的密码，但也不能删除，如果删除了 \u0026ldquo;x\u0026rdquo;，那么系统会认为这个用户没有密码，从而导致只输入用户名而不用输入密码就可以登陆\nUID UID，也就是用户 ID。每个用户都有唯一的一个 UID，Linux 系统通过 UID 来识别不同的用户。 实际上，UID 就是一个 0~65535 之间的数，不同范围的数字表示不同的用户身份。\nUID 范围 用户身份 0 超级用户。UID 为 0 就代表这个账号是管理员账号。在 Linux 中，如何把普通用户升级成管理员呢？只需把其他用户的 UID 修改为 0 就可以了，这一点和 Windows 是不同的。不过不建议建立多个管理员账号。 1~499 系统用户（伪用户）。也就是说，此范围的 UID 保留给系统使用。其中，1~99 用于系统自行创建的账号；100~499 分配给有系统账号需求的用户。 其实，除了 0 之外，其他的 UID 并无不同，这里只是默认 500 以下的数字给系统作为保留账户，只是一个公认的习惯而已。 500~65535 普通用户。通常这些 UID 已经足够用户使用了。但不够用也没关系，2.6.x 内核之后的 Linux 系统已经可以支持 2^32^ 个 UID 了。 GID 全称“Group ID”，简称“组ID”，表示用户初始组的组 ID 号。这里需要解释一下初始组和附加组的概念。\n初始组，指用户登陆时就拥有这个用户组的相关权限。每个用户的初始组只能有一个，通常就是将和此用户的用户名相同的组名作为该用户的初始组。比如说，我们手工添加用户 lamp，在建立用户 lamp 的同时，就会建立 lamp 组作为 lamp 用户的初始组。\n附加组，指用户可以加入多个其他的用户组，并拥有这些组的权限。每个用户只能有一个初始组，除初始组外，用户再加入其他的用户组，这些用户组就是这个用户的附加组。附加组可以有多个，而且用户可以有这些附加组的权限。\n举例来说，刚刚的 lamp 用户除属于初始组 lamp 外，我又把它加入了 users 组，那么 lamp 用户同时属于 lamp 组和 users 组，其中 lamp 是初始组，users 是附加组。\n当然，初始组和附加组的身份是可以修改的，但是我们在工作中不修改初始组，只修改附加组，因为修改了初始组有时会让管理员逻辑混乱。\n需要注意的是，在 /etc/passwd 文件的第四个字段中看到的 ID 是这个用户的初始组。\n描述性信息 这个字段并没有什么重要的用途，只是用来解释这个用户的意义而已。\n主目录 也就是用户登录后有操作权限的访问目录，通常称为用户的主目录。\n例如，root 超级管理员账户的主目录为 /root，普通用户的主目录为 /home/yourIDname，即在 /home/ 目录下建立和用户名相同的目录作为主目录，如 lamp 用户的主目录就是 /home/lamp/ 目录。\n默认的Shell Shell 就是 Linux 的命令解释器，是用户和 Linux 内核之间沟通的桥梁。\n我们知道，用户登陆 Linux 系统后，通过使用 Linux 命令完成操作任务，但系统只认识类似 0101 的机器语言，这里就需要使用命令解释器。也就是说，Shell 命令解释器的功能就是将用户输入的命令转换成系统可以识别的机器语言。\n通常情况下，Linux 系统默认使用的命令解释器是 bash（/bin/bash），当然还有其他命令解释器，例如 sh、csh 等。\n在 /etc/passwd 文件中，大家可以把这个字段理解为用户登录之后所拥有的权限。如果这里使用的是 bash 命令解释器，就代表这个用户拥有权限范围内的所有权限。例如：\n[root@localhost ~]# vi /etc/passwd lamp❌502:502::/home/lamp:/bin/bash 我手工添加了 lamp 用户，它使用的是 bash 命令解释器，那么这个用户就可以使用普通用户的所有权限。\n如果我把 lamp 用户的 Shell 命令解释器修改为 /sbin/nologin，那么，这个用户就不能登录了，例如：\n[root@localhost ~]# vi /etc/passwd lamp❌502:502::/home/lamp:/sbin/nologin 因为 /sbin/nologin 就是禁止登录的 Shell。同样，如果我在这里放入的系统命令，如 /usr/bin/passwd，例如：\n[root@localhost ~]#vi /etc/passwd lamp❌502:502::/home/lamp:/usr/bin/passwd 那么这个用户可以登录，但登录之后就只能修改自己的密码。但是，这里不能随便写入和登陆没有关系的命令（如 ls），系统不会识别这些命令，同时也就意味着这个用户不能登录。\n/etc/shadow 文件 存储 Linux 系统中用户的密码信息，又称为“影子文件”。只有 root 用户拥有读权限，其他用户没有任何权限，这样就保证了用户密码的安全性。\nkibana:*:19068:0:99999:7::: elastic:$6$jylN2qTRibNDyZEP$W3BZjYRU5fwTBx4Fy4gB04qZh82q4GGcT4x8jqosTgs7FvIJ2ia.LVUy01whTPe45j6RqM.C.BuuxYGp8SZH9.:19068:0:99999:7::: elasticsearch:!:19068:0:99999:7::: wang:!:19102:0:99999:7::: wang2:!:19102:0:99999:7::: 每行用户信息被划分为 9 个字段，格式如下：\n用户名：加密密码：最后一次修改时间：最小修改时间间隔：密码有效期：密码需要变更前的警告天数：密码过期后的宽限时间：账号失效时间：保留字段\n所有伪用户的密码都是 ! 或 *，代表没有密码是不能登录的。当然，新创建的用户如果不设定密码，那么它的密码项也是 !，代表这个用户没有密码，不能登录。\n最后一次修改时间 此字段表示最后一次修改密码的时间，可是，为什么 root 用户显示的是 15775 呢？\n这是因为，Linux 计算日期的时间是以 1970 年 1 月 1 日作为 1 不断累加得到的时间，到 1971 年 1 月 1 日，则为 366 天。这里显示 15775 天，也就是说，此 root 账号在 1970 年 1 月 1 日之后的第 15775 天修改的 root 用户密码。\n最小修改时间间隔 最小修改间隔时间，也就是说，该字段规定了从第 3 字段（最后一次修改密码的日期）起，多长时间之内不能修改密码。如果是 0，则密码可以随时修改；如果是 10，则代表密码修改后 10 天之内不能再次修改密码。\n密码有效期 为了强制要求用户变更密码，这个字段可以指定距离第 3 字段（最后一次更改密码）多长时间内需要再次变更密码，否则该账户密码进行过期处理。该字段的默认值为 99999，也就是 273 年，可认为是永久生效。如果改为 90，则表示密码被修改 90 天之后必须再次修改，否则该用户即将过期。管理服务器时，通过这个字段强制用户定期修改密码。\n密码需要变更前的警告天数 当账户密码有效期快到时，系统会发出警告信息给此账户，提醒用户 \u0026ldquo;再过 n 天你的密码就要过期了，请尽快重新设置你的密码！\u0026quot;。\n该字段的默认值是 7，也就是说，距离密码有效期的第 7 天开始，每次登录系统都会向该账户发出 \u0026ldquo;修改密码\u0026rdquo; 的警告信息。\n密码过期后的宽限天数 也称为“口令失效日”，简单理解就是，在密码过期后，用户如果还是没有修改密码，则在此字段规定的宽限天数内，用户还是可以登录系统的；如果过了宽限天数，系统将不再让此账户登陆，也不会提示账户过期，是完全禁用。\n比如说，此字段规定的宽限天数是 10，则代表密码过期 10 天后失效；如果是 0，则代表密码过期后立即失效；如果是 -1，则代表密码永远不会失效。\n账号失效时间 使用自 1970 年 1 月 1 日以来的总天数作为账户的失效时间。该字段表示，账号在此字段规定的时间之外，不论你的密码是否过期，都将无法使用！\n该字段通常被使用在具有收费服务的系统中。\n保留 这个字段目前没有使用，等待新功能的加入。\n忘记密码怎么办 对于普通账户的密码遗失，可以通过 root 账户解决，它会重新给你配置好指定账户的密码，而不需知道你原有的密码（利用 root 的身份使用 passwd 命令即可）。\n如果 root 账号的密码遗失，则需要重新启动进入单用户模式，系统会提供 root 权限的 bash 接口，此时可以用 passwd 命令修改账户密码；也可以通过挂载根目录，修改 /etc/shadow，将账户的 root 密码清空的方法。\n/etc/group文件 用户组配置文件，即用户组的所有信息都存放在此文件中。\nkibana❌120: elastic❌1000: elasticsearch❌1001: wang❌1002: wang2❌1003: 分为 4 个字段，每个字段对应的含义为：\n组名：密码：GID：该用户组中的用户列表\n组密码 和 /etc/passwd 文件一样，这里的 \u0026ldquo;x\u0026rdquo; 仅仅是密码标识，真正加密后的组密码默认保存在 /etc/gshadow 文件中。\n不过，用户设置密码是为了验证用户的身份，那用户组设置密码是用来做什么的呢？用户组密码主要是用来指定组管理员的，由于系统中的账号可能会非常多，root 用户可能没有时间进行用户的组调整，这时可以给用户组指定组管理员，如果有用户需要加入或退出某用户组，可以由该组的组管理员替代 root 进行管理。但是这项功能目前很少使用，我们也很少设置组密码。如果需要赋予某用户调整某个用户组的权限，则可以使用 sudo 命令代替。\n组中的用户 此字段列出每个群组包含的所有用户。需要注意的是，如果该用户组是这个用户的初始组，则该用户不会写入这个字段，可以这么理解，该字段显示的用户都是这个用户组的附加用户。\n一般情况下，用户的初始组就是在建立用户的同时建立的和用户名相同的组。\n/etc/login.defs文件 用于在创建用户时，对用户的一些基本属性做默认设置，例如指定用户 UID 和 GID 的范围，用户的过期时间，密码的最大长度，等等。\n需要注意的是，该文件的用户默认配置对 root 用户无效。并且，当此文件中的配置与 /etc/passwd 和 /etc/shadow 文件中的用户信息有冲突时，系统会以/etc/passwd 和 /etc/shadow 为准。\n设置项 含义 MAIL_DIR /var/spool/mail 创建用户时，系统会在目录 /var/spool/mail 中创建一个用户邮箱， 比如 lamp 用户的邮箱是 /var/spool/mail/lamp。 PASS_MAX_DAYS 99999 密码有效期，99999 是自 1970 年 1 月 1 日起密码有效的天数， 相当于 273 年，可理解为密码始终有效。 PASS_MIN_DAYS 0 表示自上次修改密码以来，最少隔多少天后用户才能再次修改密码， 默认值是 0。 PASS_MIN_LEN 5 指定密码的最小长度，默认不小于 5 位，但是现在用户登录时验证 已经被 PAM 模块取代，所以这个选项并不生效。 PASS_WARN_AGE 7 指定在密码到期前多少天，系统就开始通过用户密码即将到期，默认 为 7 天。 UID_MIN 500 指定最小 UID 为 500，也就是说，添加用户时，默认 UID 从 500 开始。 注意，如果手工指定了一个用户的 UID 是 550，那么下一个创建的用户的 UID 就会从 551 开始，哪怕 500~549 之间的 UID 没有使用。 UID_MAX 60000 指定用户最大的 UID 为 60000。 GID_MIN 500 指定最小 GID 为 500，也就是在添加组时，组的 GID 从 500 开始。 GID_MAX 60000 用户 GID 最大为 60000。 CREATE_HOME yes 指定在创建用户时，是否同时创建用户主目录，yes 表示创建，no 则不 创建，默认是 yes。 UMASK 077 用户主目录的权限默认设置为 077。 USERGROUPS_ENAB yes 指定删除用户的时候是否同时删除用户组，准备地说，这里指的是删除 用户的初始组，此项的默认值为 yes。 ENCRYPT_METHOD SHA512 指定用户密码采用的加密规则，默认采用 SHA512，这是新的密码 加密模式，原先的 Linux 只能用 DES 或 MD5 加密。 管理用户的命令 创建用户 使用 useradd 命令新建用户，该命令常用的选项如下:\n选项 含义 -u UID 手工指定用户的 UID，注意 UID 的范围（不要小于 500）。 -d 主目录 手工指定用户的主目录。主目录必须写绝对路径，而且如果 需要手工指定主目录，则一定要注意权限； -c 用户说明 手工指定/etc/passwd文件中第 5 个字段的描述性内容 -g 组名 手工指定用户的初始组。一般以和用户名相同的组作为用户 的初始组，在创建用户时会默认建立初始组。一旦手动指定， 则系统将不会创建此默认的初始组目录。 -G 组名 指定用户的附加组。我们把用户加入其他组，一般都使用附加组； -s shell 手工指定用户的登录 Shell，默认是 /bin/bash； -e 曰期 指定用户的失效曰期，格式为 \u0026ldquo;YYYY-MM-DD\u0026rdquo;。 也就是 /etc/shadow 文件的第八个字段； -o 允许创建的用户的 UID 相同。例如，执行 \u0026ldquo;useradd -u 0 -o usertest\u0026rdquo; 命令 建立用户 usertest，它的 UID 和 root 用户的 UID 相同，都是 0； -m 建立用户时强制建立用户的家目录。在建立系统用户时，该选项是默认的； -r 创建系统用户，也就是 UID 在 1~499 之间，供系统程序使用的用户。由于 系统用户主要用于运行系统所需服务的权限配置，因此系统用户的创建默认 不会创建主目录。 其实，系统已经帮我们规定了非常多的默认值，在没有特殊要求下，无需使用任何选项即可成功创建用户。例如：\nroot@zzq:~# useradd lamp 不要小看这条简单的命令，它会完成以下几项操作：\n在 /etc/passwd 文件中创建一行与 lamp 用户相关的数据\n在 /etc/shadow 文件中新增了一行与 lamp 用户密码相关的数据\n在 /etc/group 文件中创建一行与用户名一模一样的群组\n在 /etc/gshadow 文件中新增一行与新增群组相关的密码信息\n创建用户的主目录（/home/lamp/目录）和邮箱（/var/spool/mail/lamp文件）\n将 /etc/skel 目录中的配置文件复制到新用户的主目录中\nuseradd 命令在添加用户时参考的默认值文件主要有两个，分别是 /etc/default/useradd 和 /etc/login.defs。\n[root@localhost ~]#vim /etc/default/useradd # useradd defaults file GR0UP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes 参数 含义 GR0UP=100 这个选项用于建立用户的默认组，也就是说，在添加每个用户时， 用户的初始组就是 GID 为 100 的这个用户组。但 CentOS 并不 是这样的，而是在添加用户时会自动建立和用户名相同的组作为 此用户的初始组。也就是说这个选项并不会生效。 Linux 中默认用户组有两种机制：一种是私有用户组机制，系统会创建 一个和用户名相同的用户组作为用户的初始组；另一种是公共用户组机制， 系统用 GID 是 100 的用户组作为所有新建用户的初始组。目前我们采用的 是私有用户组机制。 HOME=/home 指的是用户主目录的默认位置，所有新建用户的主目录默认都在 /home/ 下，刚刚新建的 lamp1 用户的主目录就为 /home/lamp1/。 INACTIVE=-1 指的是密码过期后的宽限天数，也就是 /etc/shadow 文件的第七个字段。 这里默认值是 -1，代表所有新建立的用户密码永远不会失效。 EXPIRE= 表示密码失效时间，也就是 /etc/shadow 文件的第八个字段。默认值是空， 代表所有新建用户没有失效时间，永久有效。 SHELL=/bin/bash 表示所有新建立的用户默认 Shell 都是 /bin/bash。 SKEL=/etc/skel 在创建一个新用户后，你会发现，该用户主目录并不是空目录，而是有 .bash_profile、.bashrc 等文件，这些文件都是从 /etc/skel 目录中自动 复制过来的。因此，更改 /etc/skel 目录下的内容就可以改变新建用户默认 主目录中的配置文件信息。 CREATE_MAIL_SPOOL=yes 指的是给新建用户建立邮箱，默认是创建。也就是说，对于所有的新建用户， 系统都会新建一个邮箱，放在 /var/spool/mail/ 目录下，和用户名相同。 例如，lamp1 的邮箱位于 /var/spool/mail/lamp1。 修改用户密码 普通用户只能使用 passwd 命令修改自己的密码，而不能修改其他用户的密码。并且，普通用户修改自己的密码需要先输入自己的旧密码，只有旧密码输入正确才能输入新密码。另外，此种修改方式对密码的复杂度有严格的要求，新密码太短、太简单，都会被系统检测出来并禁止用户使用。\nroot用户则没有上述限制。\n# 查询密码信息，也就是 /etc/shadow 文件中此用户密码的内容。 # 仅 root 用户可用； root@zzq:/var/spool/mail# passwd -S zzq zzq P 04/20/2022 0 99999 7 -1 # 锁定用户，仅 root 用户可用 # 该选项会在 /etc/shadow 文件中指定用户的加密密码串前添加 \u0026#34;!\u0026#34;，使密码失效。 root@zzq:/var/spool/mail# passwd -l zzq passwd: password expiry information changed. # 解锁用户，仅 root 用户可用 root@zzq:/var/spool/mail# passwd -u zzq passwd: password expiry information changed. #调用管道符，给 lamp 用户设置密码 \u0026#34;123\u0026#34; [root@localhost ~]# echo \u0026#34;123\u0026#34; | passwd --stdin lamp 除了 passwd -S 命令可以查看用户的密码信息外，还可以利用 chage 命令，它可以显示更加详细的用户密码信息，并且和 passwd 命令一样，提供了修改用户密码信息的功能。此外，还可以强制用户在第一次登录后，必须先修改密码，并利用新密码重新登陆系统。下面演示这个示例：\n#创建新用户 lamp [root@localhost ~]#useradd lamp #设置用户初始密码为 lamp [root@localhost ~]#echo \u0026#34;lamp\u0026#34; | passwd --stdin lamp #通过chage命令设置此账号密码创建的日期为 1970 年 1 月 1 日（0 就表示这一天），这样用户登陆后就必须修改密码 [root@localhost ~]#chage -d 0 lamp 我们尝试用 lamp 用户登陆系统：\nlocal host login:lamp Password: \u0026lt;--输入密码登陆 You are required to change your password immediately (root enforced) changing password for lamp. \u0026lt;--有一些提示，就是说明 root 强制你登录后修改密码 (current)UNIX password: #输入旧密码 New password: Retype new password: #输入两次新密码 删除用户 userdel 命令功能很简单，就是删除用户的相关数据。此命令只有 root 用户才能使用。\n# -r 选项表示在删除用户的同时删除用户的家目录。 userdel -r zzq 修改用户信息 方式有两种：\n使用 Vim 文本编辑器手动修改涉及用户信息的相关文件（/etc/passwd、/etc/shadow、/etc/group、/etc/gshadow）\nusermod 命令专门用于修改用户信息。\n这里一定要分清 useradd 命令和 usermod 命令的区别，前者用于添加用户，当然，添加用户时可以对用户信息进行定制；后者针对与已存在的用户，使用该命令可以修改它们的信息。\n主要选项：\n-c 用户说明：修改用户的说明信息，即修改 /etc/passwd 文件目标用户信息的第 5 个字段；\n-d 主目录：修改用户的主目录，即修改 /etc/passwd 文件中目标用户信息的第 6 个字段，需要注意的是，主目录必须写绝对路径；\n-e 日期：修改用户的失效曰期，格式为 \u0026ldquo;YYYY-MM-DD\u0026rdquo;，即修改 /etc/shadow 文件目标用户密码信息的第 8 个字段；\n-g 组名：修改用户的初始组，即修改 /etc/passwd 文件目标用户信息的第 4 个字段（GID）；\n-u UID：修改用户的UID，即修改 /etc/passwd 文件目标用户信息的第 3 个字段（UID）；\n-G 组名：修改用户的附加组，其实就是把用户加入其他用户组，即修改 /etc/group 文件；\n-l 用户名：修改用户名称；\n-L：临时锁定用户（Lock）；\n-U：解锁用户（Unlock），和 -L 对应；\n-s shell：修改用户的登录 Shell，默认是 /bin/bash。\n查看用户和用户组 查看用户是否存在\n# gid(初始组ID), groups是用户所在的所有组 root@zzq:~# id wang uid=1002(wang) gid=1002(wang) groups=1002(wang) 用户切换 su su 是最简单的用户切换命令，通过该命令可以实现任何身份的切换，包括从普通用户切换为 root 用户、从 root 用户切换为普通用户以及普通用户之间的切换。\n普通用户之间切换以及普通用户切换至 root 用户，都需要知晓对方的密码，只有正确输入密码，才能实现切换；从 root 用户切换至其他用户，无需知晓对方密码，直接可切换成功。\n重要选项：\n-：当前用户不仅切换为指定用户的身份，同时所用的工作环境也切换为此用户的环境（包括 PATH 变量、MAIL 变量等），使用 - 选项可省略用户名，默认会切换为 root 用户。\n-l：同 - 的使用类似，也就是在切换用户身份的同时，完整切换工作环境，但后面需要添加当前账号。\n-p：表示切换为指定用户的身份，但不改变当前的工作环境（不使用切换用户的配置文件）。\n-m：和 -p 一样；\n-c 命令：仅切换用户执行一次命令，执行后自动切换回来，该选项后通常会带有要执行的命令。\n注意，使用 su 命令时，有 - 和没有 - 是完全不同的，- 选项表示在切换用户身份的同时，连当前使用的环境变量也切换成指定用户的。我们知道，环境变量是用来定义操作系统环境的，因此如果系统环境没有随用户身份切换，很多命令无法正确执行。\n举个例子，普通用户 lamp 通过 su 命令切换成 root 用户，但没有使用 - 选项，这样情况下，虽然看似是 root 用户，但系统中的 $PATH 环境变量依然是 lamp 的（而不是 root 的），因此当前工作环境中，并不包含 /sbin、/usr/sbin等超级用户命令的保存路径，这就导致很多管理员命令根本无法使用。不仅如此，当 root 用户接受邮件时，会发现收到的是 lamp 用户的邮件，因为环境变量 $MAIL 也没有切换。\n示例：使用别的用户执行命令\nsu - zzq -c \u0026#34;ls /etc\u0026#34; sudo 查看当前登录用户 whoami 命令打印当前执行操作的用户名\nwho am i 命令打印登陆当前 Linux 系统的用户名\n[Cyuyan@localhost ~]$ whoami Cyuyan [Cyuyan@localhost ~]$ who am i Cyuyan pts/0 2017-10-09 15:30 (:0.0) [Cyuyan@localhost ~] su - root [root@localhost ~]$ whoami root [root@localhost ~]$ who am i Cyuyan pts/0 2017-10-09 15:30 (:0.0) 也就是说，使用 su 或者 sudo 命令切换用户身份，骗得过 whoami，但骗不过 who am i。要解释这背后的运行机制，需要搞清楚什么是实际用户（UID）和有效用户（EUID，即 Effective UID）。\n所谓实际用户，指的是登陆 Linux 系统时所使用的用户，因此在整个登陆会话过程中，实际用户是不会发生变化的；而有效用户，指的是当前执行操作的用户，也就是说真正决定权限高低的用户，这个是能够利用 su 或者 sudo 命令进行任意切换的。\n一般情况下，实际用户和有效用户是相同的，如果出现用户身份切换的情况，它们会出现差异。需要注意的是，实际用户和有效用户出现差异，切换用户并不是唯一的触发机制，至于其他的触发条件，后续章节会做详细介绍。\n使用 compgen 查看存在的用户 如果只想列出用户名（而不包含其他的附加信息），可以使用带有 -u 选项的 compgen 命令：\ncompgen -u 其输出如下：\n$ compgen -u root daemon bin sys sync games man lp mail 列出所有在线用户 如果我们想要查看当前哪些用户已经登录到当前的 Linux 系统中，可以使用 who 命令，它将会列出当前已连接到系统中的用户名与其活动会话：\nuser@system:~$ who johndoe :0 2019-01-28 21:35 (:0) harrysmith pts/0 2019-02-01 09:51 (192.168.1.1) stevejones pts/1 2019-02-02 09:51 (192.168.1.173) 上述输出不仅会列出已连接到系统的用户名，而且还会显示其是如何连接的，以及何时、从何处开始连接的。\n第一列即为用户名。 第二列显示它的连接类型；如果是“:N”形式的，其中N是一个数字，那么表示是使用图形用户界面（GUI）或桌面会话，比如Gnome，XDE等；如果显示的是“pts/N”形式的，其中N是一个数字，则表示它是通过 ssh 协议（命令行）建立的连接。 第三列显示其连接到系统的开始时间（日期和时间）；第四列和最后一列显示连接的位置，如果是远程连接，它会显示进行连接的IP地址，如果是本地（如GUI），它会显示 \u0026ldquo;(:N)\u0026quot;，其中 N 是本列中的会话编号，与第二列中的编号相匹配。 用户组命令 添加用户组：groupadd\n-g GID：指定组 ID；\n-r：创建系统群组。\n修改用户组：groupmod\n-g GID：修改组 ID；\n-n 新组名：修改组名；groupmod -n newgroup oldgroup\n删除用户组：groupdel\n如果有群组还是某用户的初始群组，则无法使用 groupdel 命令成功删除 ","date":"2022年12月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/linux%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90/","series":[],"smallImg":"","tags":[{"title":"linux","url":"/myblog/tags/linux/"}],"timestamp":1669893680,"title":"Linux用户和权限"},{"authors":[],"categories":[{"title":"操作系统","url":"/myblog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"linux","url":"/myblog/categories/linux/"}],"content":"历史上Linux的启动一直采用init进程，即下面的命令用来启动服务：\n$ sudo /etc/init.d/apache2 start #或者 $ service apache2 start 这种方法有两个缺点:\n启动时间长。init进程是串行启动，只有前一个进程启动完，才会启动下一个进程。\n启动脚本复杂。init进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。\nSystemd就是为了解决这些问题而诞生的。它的设计目标是，为系统的启动和管理提供一套完整的解决方案，根据Linux惯例，字母d是守护进程（daemon）的缩写，Systemd这个名字的含义，就是它要守护整个系统。\n概述 使用了Systemd，就不需要再用init了。Systemd取代了initd，成为系统的第一个进程（PID 等于 1），其他进程都是它的子进程。\nSystemd的优点是功能强大，使用方便，缺点是体系庞大，非常复杂。事实上，现在还有很多人反对使用Systemd，理由就是它过于复杂，与操作系统的其他部分强耦合，违反”keep simple, keep stupid”的Unix哲学。\n管理命令 Systemd并不是一个命令，而是一组命令，涉及到系统管理的方方面面。\nsystemctl 是Systemd的主命令，用于管理系统 #重启系统 $ sudo systemctl reboot #关闭系统，切断电源 $ sudo systemctl poweroff #CPU停止工作 $ sudo systemctl halt #暂停系统 $ sudo systemctl suspend #让系统进入冬眠状态 $ sudo systemctl hibernate #让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep #启动进入救援状态（单用户状态） $ sudo systemctl rescue systemd-analyze 命令用于查看启动耗时 #查看启动耗时 [root@k8s ~]# systemd-analyze Startup finished in 2.102s (kernel) + 2.416s (initrd) + 24.551s (userspace) = 29.070s #查看每个服务的启动耗时 [root@k8s ~]# systemd-analyze blame 11.097s docker.service 6.188s vdo.service 6.137s tuned.service 5.248s kdump.service #显示瀑布状的启动过程流 [root@k8s ~]# systemd-analyze critical-chain The time after the unit is active or started is printed after the \u0026#34;@\u0026#34; character. The time the unit takes to start is printed after the \u0026#34;+\u0026#34; character. multi-user.target @24.534s └─docker.service @13.436s +11.097s └─network-online.target @13.434s └─network.target @13.397s └─network.service @12.627s +769ms └─NetworkManager-wait-online.service @11.482s +1.143s └─NetworkManager.service @8.147s +3.332s └─dbus.service @7.517s └─basic.target @7.223s └─sockets.target @7.222s └─dbus.socket @7.222s └─sysinit.target @7.202s └─systemd-update-utmp.service @7.155s +45ms └─auditd.service @6.569s +584ms └─systemd-tmpfiles-setup.service @6.538s +29ms └─rhel-import-state.service @6.452s +84ms └─local-fs.target @6.450s └─boot.mount @3.685s +815ms └─local-fs-pre.target @3.684s └─lvm2-monitor.service @1.416s +2.268s #显示指定服务的启动流 $ systemd-analyze critical-chain atd.service hostnamectl 命令用于查看当前主机的信息 #显示当前主机的信息 [root@k8s ~]# hostnamectl Static hostname: k8s.node2 Icon name: computer-vm Chassis: vm Machine ID: e52a6046468046e6ae525e5fc2e64dd5 Boot ID: 43cacabf46904955a4cb2053c6de911f Virtualization: vmware Operating System: CentOS Linux 7 (Core) CPE OS Name: cpe:/o:centos:centos:7 Kernel: Linux 3.10.0-862.el7.x86_64 Architecture: x86-64 #设置主机名。 $ sudo hostnamectl set-hostname rhel7 localectl 命令用于查看本地化设置 #查看本地化设置 [root@k8s ~]# localectl System Locale: LANG=zh_CN.UTF-8 VC Keymap: cn X11 Layout: cn #设置本地化参数。 $ sudo localectl set-locale LANG=en_GB.utf8 $ sudo localectl set-keymap en_GB timedatectl 命令用于查看当前时区设置\n#查看当前时区设置 [root@k8s ~]# timedatectl Local time: 六 2022-04-02 16:11:30 CST Universal time: 六 2022-04-02 08:11:30 UTC RTC time: 六 2022-04-02 08:11:30 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: yes NTP synchronized: yes RTC in local TZ: no DST active: n/a #显示所有可用的时区 [root@k8s ~]# timedatectl list-timezones America/Indiana/Indianapolis America/Indiana/Knox America/Indiana/Marengo America/Indiana/Petersburg America/Indiana/Tell_City America/Indiana/Vevay America/Indiana/Vincennes America/Indiana/Winamac America/Inuvik America/Iqaluit #设置当前时区 $ sudo timedatectl set-timezone America/New_York $ sudo timedatectl set-time YYYY-MM-DD $ sudo timedatectl set-time HH:MM:SS loginctl 命令用于查看当前登录的用户\n#列出当前session [root@k8s ~]# loginctl list-sessions SESSION UID USER SEAT 3 0 root 1 0 root seat0 2 0 root 3 sessions listed. # 列出当前用户 [root@k8s ~]# loginctl list-users UID USER 0 root 1 users listed. # 查看指定用户的信息 [root@k8s ~]# loginctl show-user root UID=0 GID=0 Name=root Timestamp=六 2022-04-02 16:08:01 CST TimestampMonotonic=68310677 RuntimePath=/run/user/0 Slice=user-0.slice Display=1 State=active Sessions=3 2 1 IdleHint=no IdleSinceHint=0 IdleSinceHintMonotonic=0 Linger=no Unit Systemd可以管理所有系统资源，不同的资源统称为 Unit（单位）,Unit一共分成以下12种。\nService unit：系统服务\nTarget unit：多个Unit构成的一个组\nDevice Unit：硬件设备\nMount Unit：文件系统的挂载点\nAutomount Unit：自动挂载点\nPath Unit：文件或路径\nScope Unit：不是由Systemd启动的外部进程\nSlice Unit：进程组\nSnapshot Unit：Systemd快照，可以切回某个快照\nSocket Unit：进程间通信的socket\nSwap Unit：swap文件\nTimer Unit：定时器\n管理命令 查看当前系统的Unit #列出正在运行的Unit $ systemctl list-units UNIT LOAD ACTIVE SUB DESCRIPTION chronyd.service loaded active running NTP client/server crond.service loaded active running Command Scheduler dbus.service loaded active running D-Bus System Message Bus docker.service loaded active running Docker Application Container getty@tty1.service loaded active running Getty on tty1 #列出所有Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all #列出所有没有运行的Unit $ systemctl list-units --all --state=inactive #列出所有加载失败的Unit $ systemctl list-units --failed #列出所有正在运行的、类型为service的Unit $ systemctl list-units --type=service 查看unit的状态 #显示系统状态 [root@k8s ~]# systemctl status ● k8s.node2 State: running Jobs: 0 queued Failed: 0 units Since: 六 2022-04-02 16:06:55 CST; 22min ago CGroup: / ├─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 2 ├─user.slice │ └─user-0.slice │ ├─session-3.scope │ │ ├─1886 sshd: root@notty │ │ └─1932 /usr/libexec/openssh/sftp-server │ ├─session-2.scope │ │ ├─ 1876 sshd: root@pts/0 │ │ ├─ 1888 -bash │ │ ├─ 1921 bash -c while true; do sleep 1;head -v -n 8 /proc/memin │ │ ├─12099 sleep 1 │ │ ├─12100 systemctl status │ │ └─12101 less │ └─session-1.scope │ ├─ 709 login -- root │ └─1795 -bash └─system.slice #显示单个Unit的状态 $ sysystemctl status bluetooth.service #显示远程主机的某个Unit的状态 $ systemctl -H root@rhel7.example.com status httpd.service 除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用:\n#显示某个Unit是否正在运行 $ systemctl is-active application.service #显示某个Unit是否处于启动失败状态 $ systemctl is-failed application.service #显示某个Unit服务是否建立了启动链接 $ systemctl is-enabled application.service unit启停命令 #立即启动一个服务 $ sudo systemctl start apache.service #立即停止一个服务 $ sudo systemctl stop apache.service #重启一个服务 $ sudo systemctl restart apache.service #杀死一个服务的所有子进程 $ sudo systemctl kill apache.service #重新加载一个服务的配置文件 $ sudo systemctl reload apache.service #重载所有修改过的配置文件 $ sudo systemctl daemon-reload #显示某个 Unit 的所有底层参数 [root@k8s ~]# systemctl show docker Type=notify Restart=on-failure NotifyAccess=main RestartUSec=100ms TimeoutStartUSec=0 TimeoutStopUSec=1min 30s WatchdogUSec=0 WatchdogTimestamp=六 2022-04-02 16:07:22 CST WatchdogTimestampMonotonic=29053314 StartLimitInterval=60000000 StartLimitBurst=3 #显示某个 Unit 的指定属性的值 [root@k8s ~]# systemctl show -p TasksCurrent docker TasksCurrent=25 #设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500 依赖关系\nUnit之间存在依赖关系：A依赖于B，就意味着Systemd在启动A的时候，同时会去启动B。\n[root@k8s ~]# systemctl list-dependencies docker docker.service ● ├─system.slice ● ├─basic.target ● │ ├─microcode.service ● │ ├─rhel-dmesg.service ● │ ├─selinux-policy-migrate-local-changes@targeted.service ● │ ├─paths.target ● │ ├─slices.target ● │ │ ├─-.slice ● │ │ └─system.slice ● │ ├─sockets.target ● │ │ ├─dbus.socket ● │ │ ├─dm-event.socket ● │ │ ├─rpcbind.socket ● │ │ ├─systemd-initctl.socket Unit的配置文件 每一个Unit都有一个配置文件，告诉Systemd怎么启动这个Unit。Systemd默认从目录/etc/systemd/system/读取配置文件。但是里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录。\nsystemctl enable命令用于在上面两个目录之间，建立符号链接关系:\n$ sudo systemctl enable clamd@scan.service #等同于 $ sudo ln -s \u0026#39;/usr/lib/systemd/system/clamd@scan.service\u0026#39; \u0026#39;/etc/systemd/system/multi-user.target.wants/clamd@scan.service\u0026#39; 如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动，与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。\n配置文件的后缀名，就是该Unit的种类，比如sshd.socket；如果省略，Systemd默认后缀名为.service，所以sshd会被理解成sshd.service。\n查看配置文件状态 [root@k8s system]# systemctl list-unit-files UNIT FILE STATE proc-sys-fs-binfmt_misc.automount static dev-hugepages.mount static dev-mqueue.mount static proc-sys-fs-binfmt_misc.mount static sys-fs-fuse-connections.mount static sys-kernel-config.mount static sys-kernel-debug.mount static tmp.mount disabled brandbot.path disabled systemd-ask-password-console.path static systemd-ask-password-plymouth.path static systemd-ask-password-wall.path static 每个配置文件的状态，一共有四种：\nenabled：已建立启动链接\ndisabled：没建立启动链接\nstatic：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖\nmasked：该配置文件被禁止建立启动链接\n一旦修改配置文件，就要让 SystemD 重新加载配置文件，然后重新启动，否则修改不会生效。\n$ sudo systemctl daemon-reload $ sudo systemctl restart httpd.service 配置文件的格式 配置文件就是普通的文本文件，可以用文本编辑器打开。\n# systemctl cat命令可以查看配置文件的内容。 $ systemctl cat atd.service [Unit] Description=ATD daemon [Service] Type=forking ExecStart=/usr/bin/atd [Install] WantedBy=multi-user.target 从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区别名，比如[Unit]。注意，配置文件的区块名和字段名，都是大小写敏感的。每个区块内部是一些等号连接的键值对。注意，键值对的等号两侧不能有空格。\n[Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下：\nDescription：简短描述\nDocumentation：文档地址\nRequires：当前Unit依赖的其他Unit，如果它们没有运行，当前Unit会启动失败\nWants：与当前Unit配合的其他Unit，如果它们没有运行，当前Unit不会启动失败\nBindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前Unit停止运行\nBefore：如果该字段指定的Unit也要启动，那么必须在当前Unit之后启动\nAfter：如果该字段指定的Unit也要启动，那么必须在当前Unit之前启动\nConflicts：这里指定的Unit 不能与当前Unit同时运行\nCondition\u0026hellip;：当前Unit运行必须满足的条件，否则不会运行\nAssert\u0026hellip;：当前Unit运行必须满足的条件，否则会报启动失败\n[Install]通常是配置文件的最后一个区块，用来定义如何启动，以及是否开机启动。它的主要字段如下：\nWantedBy：它的值是一个或多个Target，当前Unit激活时（enable）符号链接会放入/etc/systemd/system目录下面以Target名+.wants后缀构成的子目录中\nRequiredBy：它的值是一个或多个Target，当前Unit激活时，符号链接会放入/etc/systemd/system目录下面以Target 名 + .required后缀构成的子目录中\nAlias：当前Unit 可用于启动的别名\nAlso：当前Unit激活（enable）时，会被同时激活的其他Unit\n[Service]区块用来Service的配置，只有Service类型的Unit才有这个区块。它的主要字段如下：\nType：定义启动时的进程行为。它有以下几种值。\nType=simple：默认值，执行ExecStart指定的命令，启动主进程\nType=forking：以fork方式从父进程创建子进程，创建后父进程会立即退出\nType=oneshot：一次性进程，Systemd会等当前服务退出，再继续往下执行\nType=dbus：当前服务通过D-Bus启动\nType=notify：当前服务启动完毕，会通知Systemd，再继续往下执行\nType=idle：若有其他任务执行完毕，当前服务才会运行\nExecStart：启动当前服务的命令\nExecStartPre：启动当前服务之前执行的命令\nExecStartPost：启动当前服务之后执行的命令\nExecReload：重启当前服务时执行的命令\nExecStop：停止当前服务时执行的命令\nExecStopPost：停止当其服务之后执行的命令\nRestartSec：自动重启当前服务间隔的秒数\nRestart：定义何种情况Systemd会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog\nTimeoutSec：定义Systemd停止当前服务之前等待的秒数\nEnvironment：指定环境变量\nUnit配置文件的完整字段清单，请参考官方文档。\nTarget 启动计算机的时候，需要启动大量的Unit。如果每一次启动，都要一一写明本次启动需要哪些Unit，显然非常不方便。Systemd的解决方案就是Target。\n简单说，Target就是一个Unit组，包含许多相关的Unit。启动某个Target的时候，Systemd就会启动里面所有的Unit。从这个意义上说，Target这个概念类似于“状态点”，启动某个Target就好比启动到某种状态。\n传统的init启动模式里面，有RunLevel的概念，跟Target的作用很类似。不同的是，RunLevel是互斥的，不可能多个RunLevel同时启动，但是多个Target可以同时启动。\n#查看当前系统的所有Target $ systemctl list-unit-files --type=target #查看一个 Target 包含的所有 Unit $ systemctl list-dependencies multi-user.target #查看启动时的默认 Target $ systemctl get-default #设置启动时的默认Target $ sudo systemctl set-default multi-user.target #切换Target时，默认不关闭前一个Target启动的进程， # systemctl isolate命令改变这种行为， #关闭前一个Target里面所有不属于后一个Target的进程 $ sudo systemctl isolate multi-user.target 它与init进程的主要差别如下：\n默认的RunLevel（在/etc/inittab文件设置）现在被默认的Target取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。\n启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的RunLevel目录（比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。\n配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。\n日志管理 Systemd统一管理所有Unit的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。\n#查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl #查看内核日志（不显示应用日志） $ sudo journalctl -k #查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 #查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 #查看指定时间的日志 $ sudo journalctl --since=\u0026#34;2012-10-30 18:17:16\u0026#34; $ sudo journalctl --since \u0026#34;20 min ago\u0026#34; $ sudo journalctl --since yesterday $ sudo journalctl --since \u0026#34;2015-01-10\u0026#34; --until \u0026#34;2015-01-11 03:00\u0026#34; $ sudo journalctl --since 09:00 --until \u0026#34;1 hour ago\u0026#34; #显示尾部的最新10行日志 $ sudo journalctl -n #显示尾部指定行数的日志 $ sudo journalctl -n 20 #实时滚动显示最新日志 $ sudo journalctl -f #查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd #查看指定进程的日志 $ sudo journalctl _PID=1 #查看某个路径的脚本的日志 $ sudo journalctl /usr/bin/bash #查看指定用户的日志 $ sudo journalctl _UID=33 --since today #查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today #实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f #合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today #查看指定优先级（及其以上级别）的日志，共有8级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b #日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager #以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json #以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.serviceqq -o json-pretty #显示日志占据的硬盘空间 $ sudo journalctl --disk-usage #指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G #指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years syslog 和 rsyslog 参考： Rsyslog日志系统_Syslog (sohu.com)\n系统日志（Syslog）协议是在一个IP网络中转发系统日志信息的标准，它是在美国加州大学伯克利软件分布研究中心（BSD）的TCP/IP系统实施中开发的，目前已成为工业标准协议，可用它记录设备的日志。Syslog记录着系统中的任何事件，管理者可以通过查看系统记录随时掌握系统状况。系统日志通过Syslog进程记录系统的有关事件，也可以记录应用程序运作事件。通过适当配置，还可以实现运行Syslog协议的机器之间的通信。通过分析这些网络行为日志，可追踪和掌握与设备和网络有关的情况。\n在Unix类操作系统上，syslog广泛应用于系统日志。syslog日志消息既可以记录在本地文件中，也可以通过网络发送到接收syslog的服务器。接收syslog的服务器可以对多个设备的syslog消息进行统一的存储，或者解析其中的内容做相应的处理。常见的应用场景是网络管理工具、安全管理系统、日志审计系统。\n完整的syslog日志中包含产生日志的程序模块（Facility）、严重性（Severity或 Level）、时间、主机名或IP、进程名、进程ID和正文。在Unix类操作系统上，能够按Facility和Severity的组合来决定什么样的日志消息是否需要记录，记录到什么地方，是否需要发送到一个接收syslog的服务器等。由于syslog简单而灵活的特性，syslog不再仅限于Unix类主机的日志记录，任何需要记录和发送日志的场景，都可能会使用syslog。\nrsyslog可以简单的理解为syslog的超集，在老版本的Linux系统中，Red Hat Enterprise Linux 3/4/5默认是使用的syslog作为系统的日志工具，从RHEL 6 开始系统默认使用了rsyslog。\n它所做的事就是统一记录系统的各个子系统产生的日志。但是像FTP、HTTP它们都有自己日志记录格式，而不是系统的Rsyslog。在Rsyslog系统有两个进程分别是klogd,syslogd。而为什么需要两个守护进程呢?是因为内核跟其他信息需要记录的详细程度及格式的不同。\nklogd：记录内核信息，系统启动中在登录之前使用的都是物理终端/dev/console，这个时候虚拟终端还没有启动而内核启动日志都存放在/var/log/dmesg文件中，使用dmesg命令可以查看。\nsyslogd：记录非内核系统产生的信息，当系统启动/sbin/init程序时产生的日志都存放在以下各个日志文件中。\n/var/log/message #标准系统错误信息；\n/var/log/maillog #邮件系统产生的日志信息；\n/var/log/secure #记录系统的登录情况；\n/var/log/dmesg #记录linux系统在引导过程中的各种记录信息；\n/var/log/cron #记录crond计划任务产生的时间信息；\n/var/log/lastlog #记录每个用户最近的登录事件；\n/var/log/wtmp #记录每个用户登录、注销及系统启动和停机事件；\n/var/run/btmp #记录失败的、错误的登录尝试及验证事件；\n另外当日志文件过大时会通过系统crontab定义日志滚动的，也称日志切割，由logrotate控制其配置文件/etc/logrotate.conf，然后再由系统任务计划执行。logrotate负责备份和删除旧日志, 以及更新日志文件。后面详说。\n日志配置 /etc/rsyslog.conf 是rsyslog服务的总配置文件\n/etc/rsyslog.d该目录是单独配置的rsyslog配置文件\n配置文件示例：\n# 表示将所有facility的info级别,但不包括mail,authpriv,cron相关的信息,记录到 /var/log/messages文件 *.info;mail.none;authpriv.none;cron.none /var/log/messages # 表示将权限,授权相关的所有基本的信息,记录到/var/log/secure文件中.这个文件的权限是600 authpriv.* /var/log/secure # 表示将mail相关的所有基本的信息记录到/var/log/maillog文件中,可以看到路径前面有一个\u0026#34;-\u0026#34;而\u0026#34;-\u0026#34; 表示异步写入磁盘 mail.* -/var/log/maillog # 表示将任务计划相关的所有级别的信息记录到/var/log/cron文件中 cron.* /var/log/cron # 表示将所有facility的emerg级别的信息,发送给登录到系统上的所有用户 *.emerg * # 表示将uucp及news的crit级别的信息记录到/var/log/spooler文件中 uucp,news.crit /var/log/spooler # 表示将local7的所有级别的信息记录到/var/log/boot.log文件中上面说过local0 到local7这8个是用户自定义使用的,这里的local7记录的是系统启动相关的信息 local7.* /var/log/boot.log 配置文件 /etc/rsyslog.conf 有下面几个核心配置：\nmodules，模块，配置加载的模块，如：ModLoad imudp.so配置加载UDP传输模块\nglobal directives，全局配置，配置ryslog守护进程的全局属性，比如主信息队列大小（MainMessageQueueSize）\nrules，规则（选择器+动作），每个规则行由两部分组成，selector部分和action部分，这两部分由一个或多个空格或tab分隔，selector部分指定源和日志等级，action部分指定对应的操作\n模板（templates）： 允许你指定日志信息的格式，也可用于生成动态文件名，或在规则中使用\n输出（outputs）\nsyslog协议格式定义如下：\nfacility.priority action facility标识系统需要记录日志的子系统，大概有以下子系统:\n日志类型 日志内容 auth 用户认证时产生的日志 authpriv ssh、ftp等登录信息的验证信息 daemon 一些守护进程产生的日志 ftp FTP产生的日志 lpr 打印相关活动 mark 服务内部的信息，时间标识 news 网络新闻传输协议(nntp)产生的消息。 syslog 系统日志 security uucp Unix-to-Unix Copy 两个unix之间的相关通信 console 针对系统控制台的消息。 cron 系统执行定时任务产生的日志。 kern 系统内核日志 local0~local7 自定义程序使用 mail 邮件日志 user 用户进程 priority用来标识日志级别,级别越低信息越详细，有以下日志级别，从上到下，级别从高到低，记录的信息越来越少：\n日志等级 说明 7 emerg 紧急情况，系统不可用（例如系统崩溃），一般会通知所有用户。 6 alert 需要立即修复的告警。 5 crit 危险情况，例如硬盘错误，可能会阻碍程序的部分功能。 4 error/err 一般错误消息。 3 warning/warn 警告。 2 notice 不是错误，但是可能需要处理。 1 info 通用性消息，一般用来提供有用信息。 0 debug 调试程序产生的信息。 none 没有优先级，不记录任何日志消息。 ","date":"2022年12月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/systemd%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","series":[],"smallImg":"","tags":[{"title":"linux","url":"/myblog/tags/linux/"}],"timestamp":1669893680,"title":"Systemd服务管理"},{"authors":[],"categories":[{"title":"linux","url":"/myblog/categories/linux/"}],"content":"环境变量 在 Linux 系统中，环境变量是用来定义系统运行环境的一些参数，比如每个用户不同的家目录（HOME）、邮件存放位置（MAIL）等。\n值得一提的是，Linux 系统中环境变量的名称一般都是大写的，这是一种约定俗成的规范。\n我们可以使用 env 命令来查看到 Linux 系统中所有的环境变量，执行命令如下：\n[root@localhost ~]# env ORBIT_SOCKETDIR=/tmp/orbit-root HOSTNAME=livecd.centos GIO_LAUNCHED_DESKTOP_FILE_PID=2065 TERM=xterm SHELL=/bin/bash ...... 下面是几个常用的环境变量：\n环境变量名称 作用 HOME 用户的主目录（也称家目录） SHELL 用户使用的 Shell 解释器名称 PATH 定义命令行解释器搜索用户执行命令的路径 EDITOR 用户默认的文本解释器 RANDOM 生成一个随机数字 LANG 系统语言、语系名称 HISTSIZE 输出的历史命令记录条数 HISTFILESIZE 保存的历史命令记录条数 PS1 Bash解释器的提示符 MAIL 邮件保存路径 Linux 作为一个多用户多任务的操作系统，能够为每个用户提供独立的、合适的工作运行环境，因此，一个相同的环境变量会因为用户身份的不同而具有不同的值。\n例如，使用下述命令来查看 HOME 变量在不同用户身份下都有哪些值：\n[root@localhost ~]# echo $HOME /root [root@localhost ~]# su - user1 \u0026lt;--切换到 user1 用户身份 [user1@localhost ~]$ echo $HOME /home/user1 其实，环境变量是由固定的变量名与用户或系统设置的变量值两部分组成的，我们完全可以自行创建环境变量来满足工作需求。例如，设置一个名称为 WORKDIR 的环境变量，方便用户更轻松地进入一个层次较深的目录，执行命令如下：\n[root@localhost ~]# mkdir /home/work1 [root@localhost ~]# WORKDIR=/home/work1 [root@localhost ~]# cd $WORKDIR [root@localhost work1]# pwd /home/work1 但是，这样的环境变量不具有全局性，作用范围也有限，默认情况下不能被其他用户使用。如果工作需要，可以使用 export 命令将其提升为全局环境变量，这样其他用户就可以使用它了：\n[root@localhost work1]# su user1 \u0026lt;-- 切换到 user1，发现无法使用 WORKDIR 自定义变量 [user1@localhost ~]$ cd $WORKDIR [user1@localhost ~]$ echo $WORKDIR [user1@localhost ~]$ exit \u0026lt;--退出user1身份 [root@localhost work1] export WORKDIR [root@localhost work1] su user1 [user1@localhost ~]$ cd $WORKDIR [user1@localhost work1]$ pwd /home/work1 ","date":"2022年12月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/shell/","series":[],"smallImg":"","tags":[{"title":"shell","url":"/myblog/tags/shell/"}],"timestamp":1669892489,"title":"Shell"},{"authors":[],"categories":[{"title":"协议","url":"/myblog/categories/%E5%8D%8F%E8%AE%AE/"}],"content":"远程管理，实际上就是计算机（服务器）之间通过网络进行数据传输（信息交换）的过程，与浏览器需要 HTTP 协议（超文本传输协议）浏览网页一样，远程管理同样需要远程管理协议的支持。\n目前，常用的远程管理协议有以下 4 种：\nRDP（remote desktop protocol）协议：远程桌面协议，大部分 Windows 系统都默认支持此协议，Windows 系统中的远程桌面管理就基于该协议。\nRFB（Remote FrameBuffer）协议：图形化远程管理协议，VNC 远程管理工具就基于此协议。\nTelnet：命令行界面远程管理协议，几乎所有的操作系统都默认支持此协议。此协议的特点是，在进行数据传送时使用明文传输的方式，也就是不对数据进行加密。\nSSH（Secure Shell）协议：命令行界面远程管理协议，几乎所有操作系统都默认支持此协议。和 Telnet 不同，该协议在数据传输时会对数据进行加密并压缩，因此使用此协议传输数据既安全速度又快。\nRDP 协议和 RFB 协议都允许用户通过图形用户界面访问远程系统，但 RFB 协议倾向于传输图像，RDP 协议倾向于传输指令：\nRFB 协议会在服务器端将窗口在显存中画好，然后将图像传给客户端，客户端只需要将得到的图像解码显示即可；\nRDP 会将画图的工作交给客户端，服务器端需要根据客户端的显示能力做适当的调整。\n因此，完成相同的操作，使用 RFB 协议传输的数据量会比 RDP 大，而 RDP 对客户端的要求比 RFB 更苛刻，RFB 适用于瘦客户端，而 RDP 适用于低速网络。\n","date":"2022年12月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/12/%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86%E5%8D%8F%E8%AE%AE/","series":[],"smallImg":"","tags":[{"title":"远程连接","url":"/myblog/tags/%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"},{"title":"协议","url":"/myblog/tags/%E5%8D%8F%E8%AE%AE/"}],"timestamp":1669892198,"title":"远程管理协议"},{"authors":[],"categories":[{"title":"操作系统","url":"/myblog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"linux","url":"/myblog/categories/linux/"}],"content":"软连接 ext4 文件系统 如果要想说清楚 ln 命令，则必须先解释下 ext 文件系统（Linux 文件系统）是如何工作的。而我们的 Linux 目前使用的是 ext4 文件系统。如果用一张示意图来描述 ext4 文件系统：\next4 文件系统会把分区主要分为两大部分（暂时不提超级块）：小部分用于保存文件的 inode (i 节点）信息；剩余的大部分用于保存 block 信息。\ninode 的默认大小为 128 Byte，用来记录文件的权限（r、w、x）、文件的所有者和属组、文件的大小、文件的状态改变时间（ctime）、文件的最近一次读取时间（atime）、文件的最近一次修改时间（mtime）、真正保存文件数据的 block 编号。每个文件需要占用一个 inode。大家如果仔细查看，就会发现 inode 中是不记录文件名的，那是因为文件名记录在文件所在目录的 block 中。\nblock 的大小可以是 1KB、2KB、4KB，默认为 4KB。block 用于实际的数据存储，如果一个 block 放不下数据，则可以占用多个 block。例如，有一个 10KB 的文件需要存储，则会占用 3 个 block，虽然最后一个 block 不能占满，但也不能再放入其他文件的数据。这 3 个 block 有可能是连续的，也有可能是分散的。\n由此，我们可以知道以下 2 个重要的信息：\n每个文件都独自占用一个 inode，文件内容由 inode 的记录来指向；\n如果想要读取文件内容，就必须借助目录中记录的文件名找到该文件的 inode，才能成功找到文件内容所在的 block 块；\n了解了 Linux 系统底层文件的存储状态后，接下来学习 ln 命令。\nln 命令 ln 命令用于给文件创建链接，根据 Linux 系统存储文件的特点，链接的方式分为以下 2 种：\n软链接：A是B的软链接（A和B都是文件名），A的目录项中的inode节点号与B的目录项中的inode节点号不相同，A和B指向的是两个不同的inode，继而指向两块不同的数据块。但是A的数据块中存放的只是B的路径名（可以根据这个找到B的目录项）。A和B之间是“主从”关系，如果B被删除了，A仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。 硬链接：A是B的硬链接（A和B都是文件名），则A的目录项中的inode节点号与B的目录项中的inode节点号相同，即一个inode节点对应两个不同的文件名，两个文件名指向同一个文件，A和B对文件系统来说是完全平等的。如果删除了其中一个，对另外一个没有影响。每增加一个文件名，inode节点上的链接数增加一，每删除一个对应的文件名，inode节点上的链接数减一，直到为0，inode节点和对应的数据块被回收。注：文件和文件名是不同的东西，rm A删除的只是A这个文件名，而A对应的数据块（文件）只有在inode节点链接数减少为0的时候才会被系统回收。 主要区别、限制：\n硬链接：\na：不能对目录创建硬链接，原因有几种，最重要的是：文件系统不能存在链接环（目录创建时的\u0026quot;..\u0026ldquo;除外，这个系统可以识别出来）,存在环的后果会导致例如文件遍历等操作的混乱(du，pwd等命令的运作原理就是基于文件硬链接，顺便一提，ls -l结果的第二列也是文件的硬链接数，即inode节点的链接数)\nb：不能对不同的文件系统创建硬链接,即两个文件名要在相同的文件系统下。\nc：不能对不存在的文件创建硬链接，由原理即可知原因。\n软链接：\na：可以对目录创建软链接，遍历操作会忽略目录的软链接。\nb：可以跨文件系统\nc：可以对不存在的文件创建软链接，因为放的只是一个字符串，至于这个字符串是不是对于一个实际的文件，就是另外一回事了\nln 命令的基本格式如下：\n[root@localhost ~]# ln [选项] 源文件 目标文件 选项：\n-s：建立软链接文件。如果不加 \u0026ldquo;-s\u0026rdquo; 选项，则建立硬链接文件；\n-f：强制。如果目标文件已经存在，则删除目标文件后再建立链接文件；\n【例 1】创建硬链接：\n[root@localhost ~]# touch cangls [root@localhost ~]# ln /root/cangls /tmp #建立硬链接文件，目标文件没有写文件名，会和原名一致 #也就是/tmp/cangls 是硬链接文件 【例 2】创建软链接：\n[root@localhost ~]# touch bols [root@localhost ~]# In -s /root/bols /tmp 这里需要注意的是，软链接文件的源文件必须写成绝对路径，而不能写成相对路径（硬链接没有这样的要求）；否则软链接文件会报错。\n文件操作 ls命令 ls 默认会以文件名排序.\n显示隐藏的目录：\nzzq@Zhao:~/test$ ls aa.sh zzq@Zhao:~/test$ ls -a #显示所有的隐藏文件 . .. .aa aa.sh zzq@Zhao:~/test$ ls -A #只显示有效的隐藏文件 .aa aa.sh 点号开头的文件时隐藏文件\n可读的形式显示目录信息：\nzzq@Zhao:/$ ls -hl total 1.5M lrwxrwxrwx 1 root root 7 Mar 25 2022 bin -\u0026gt; usr/bin drwxr-xr-x 2 root root 4.0K Mar 25 2022 boot drwxr-xr-x 8 root root 2.9K Dec 1 11:04 dev drwxr-xr-x 98 root root 4.0K Dec 1 11:10 etc 在 Linux 中第一个字符代表这个文件是目录、文件或链接文件等等。\n当为 d 则是目录 当为 - 则是文件； 若是 l 则表示为链接文档(link file)； 若是 b 则表示为装置文件里面的可供储存的接口设备(可随机存取装置)； 若是 c 则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。 显示 inode 节点信息：\nzzq@Zhao:/$ ls -i 12 bin 1609 lib 24578 mnt 49153 snap 8193 boot 1610 lib32 连同子目录内容一起列出来:\nzzq@Zhao:~$ ls -R .: aa.txt jb-linux-arm64:Zone.Identifier ./loki-mixin: alerts.libsonnet dashboards jsonnetfile.json ./loki-mixin/dashboards: dashboard-loki-logs.json loki-deletion.libsonnet ./test: aa.sh 按照文件大小排序：\nzzq@Zhao:~$ ls -Slh total 40M -rwxrwxrwx 1 zzq zzq 33M May 30 2022 otelcol-contrib.rpm -rwxrwxrwx 1 root root 7.1M May 14 2022 jb-linux-arm64 -rw-r--r-- 1 zzq zzq 32K Aug 7 11:39 \u0026#39;g | grep -i memory\u0026#39; -rw-r--r-- 1 zzq zzq 5.2K May 30 2022 filename.txt drwxr-xr-x 3 root root 4.0K May 14 2022 loki-mixin drwxr-xr-x 2 zzq zzq 4.0K Dec 1 12:32 test 按照时间排序：\nzzq@Zhao:~$ ls -tlh total 40M drwxr-xr-x 2 zzq zzq 4.0K Dec 1 12:32 test -rw-r--r-- 1 zzq zzq 32K Aug 7 11:39 \u0026#39;g | grep -i memory\u0026#39; -rw-r--r-- 1 zzq zzq 953 Jun 12 22:22 conf -rw-r--r-- 1 zzq zzq 5.2K May 30 2022 filename.txt 逆序显示：\nzzq@Zhao:~$ ls -tlh total 40M drwxr-xr-x 2 zzq zzq 4.0K Dec 1 12:32 test -rw-r--r-- 1 zzq zzq 32K Aug 7 11:39 \u0026#39;g | grep -i memory\u0026#39; -rw-r--r-- 1 zzq zzq 953 Jun 12 22:22 conf -rw-r--r-- 1 zzq zzq 5.2K May 30 2022 filename.txt 显示完整时间：\nzzq@Zhao:~$ ls -tlhr --full-time total 40M -rw-r--r-- 1 root root 663 2022-05-14 20:09:16.399359400 +0800 jb-linux-arm64:Zone.Identifier -rwxrwxrwx 1 root root 7.1M 2022-05-14 20:09:16.399359400 +0800 jb-linux-arm64 drwxr-xr-x 3 root root 4.0K 2022-05-14 20:29:55.376519700 +0800 loki-mixin -rwxrwxrwx 1 zzq zzq 22 2022-05-30 10:31:26.410485200 +0800 test.sh cp命令 cp 命令，主要用来复制文件和目录，同时借助某些选项，还可以实现复制整个目录，以及比对两文件的新旧而予以升级等功能。\n选项：\n-a：相当于 -d、-p、-r 选项的集合，这几个选项我们一一介绍；\n-d：如果源文件为软链接（对硬链接无效），则复制出的目标文件也为软链接；\n-i：询问，如果目标文件已经存在，则会询问是否覆盖；\n-l：把目标文件建立为源文件的硬链接文件，而不是复制源文件；\n-s：把目标文件建立为源文件的软链接文件，而不是复制源文件；\n-p：复制后目标文件保留源文件的属性（包括所有者、所属组、权限和时间）；\n-r：递归复制，用于复制目录；\n-u：若目标文件比源文件有差异，则使用该选项可以更新目标文件，此选项可用于对文件的升级和备用。\n[root@localhost ~]# ln -s /root/cangls /tmp/cangls_slink #建立一个测试软链接文件/tmp/cangls_slink [root@localhost ~]# ll /tmp/cangls_slink lrwxrwxrwx 1 root root 12 6 月 14 05:53 /tmp/cangls_slink -\u0026gt; /root/cangls #源文件本身就是一个软链接文件 [root@localhost ~]# cp /tmp/cangls_slink /tmp/cangls_t1 #复制软链接文件，但是不加\u0026#34;-d\u0026#34;选项 [root@localhost ~]# cp -d /tmp/cangls_slink /tmp/cangls_t2 #复制软链接文件，加入\u0026#34;-d\u0026#34;选项 [root@localhost ~]# ll /tmp/cangls_t1 /tmp/cangls_t2 -rw-r--r-- 1 root root 0 6月 14 05:56 /tmp/cangls_t1 #会发现不加\u0026#34;-d\u0026#34;选项，实际复制的是软链接的源文件，而不是软链接文件 lrwxrwxrwx 1 root root 12 6 月 14 05:56/tmp/ cangls_t2-\u0026gt; /root/ mv命令 mv 命令（move 的缩写），既可以在不同的目录之间移动文件或目录，也可以对文件和目录进行重命名。\n选项：\n-f：强制覆盖，如果目标文件已经存在，则不询问，直接强制覆盖；\n-i：交互移动，如果目标文件已经存在，则询问用户是否覆盖（默认选项）；\n-n：如果目标文件已经存在，则不会覆盖移动，而且不询问用户；\n-v：显示文件或目录的移动过程；\n-u：若目标文件已经存在，但两者相比，源文件更新，则会对目标文件进行升级；\n[root@localhost ~]# touch test1.txt test2.txt test3.txt #建立三个测试文件 [root@localhost ~]# mv -v *.txt /tmp \u0026#34;test1.txt\u0026#34; -\u0026gt; \u0026#34;/tmp/test1.txt\u0026#34; \u0026#34;test2.txt\u0026#34; -\u0026gt; \u0026#34;/tmp/test2.txt\u0026#34; \u0026#34;test3.txt\u0026#34; -\u0026gt; \u0026#34;/tmp/test3.txt\u0026#34; #加入\u0026#34;-v\u0026#34;选项，可以看到有哪些文件进行了移动 压缩文件处理 tar命令 Linux 系统中，最常用的归档（打包,注意不是压缩）命令就是 tar，该命令可以将许多文件一起保存到一个单独的磁带或磁盘中进行归档。不仅如此，该命令还可以从归档文件中还原所需文件，也就是打包的反过程，称为解打包。\n打包 打包常用选项：\n-c ： 将多个文件或目录进行打包。\n-A : 追加 tar 文件到归档文件。\n-f 包名：指定包的文件名。包的扩展名是用来给管理员识别格式的，所以一定要正确指定扩展名；\n-v： 显示打包文件的过程\n【例 1】打包文件和目录：\n#把anacondehks.cfg打包为 anacondehks.cfg.tar文件 tar -cvf ana.tar anaconda-ks.cfg /tmp/ 【例 2】打包并压缩目录:\n首先声明一点，压缩命令不能直接压缩目录，必须先用 tar 命令将目录打包，然后才能用 gzip 命令或 bzip2 命令对打包文件进行压缩。例如：\n[root@localhost ~]ll -d test test.tar drwxr-xr-x 2 root root 4096 6月 17 21:09 test -rw-r--r-- 1 root root 10240 6月 18 01:06 test.tar #我们之前已经把test目录打包成test.tar文件 [root@localhost ~] gzip test.tar [root@localhost ~] ll test.tar.gz -rw-r--r-- 1 root root 176 6月 18 01:06 test.tar.gz #gzip命令会把test.tar压缩成test.tar.gz 解包 解包常用选项：\n-x： 对 tar 包做解打包操作\n-f： 指定要解压的 tar 包的包名。\n-t：只查看 tar 包中有哪些文件或目录，不对 tar 包做解打包操作。\n-C 目录： 指定解打包位置。\n-v：显示解打包的具体过程。\n【例2】解包\ntar -xvf test.tar -C /tmp 【例3】查看包的内容\n[root@localhost ~]# tar -tvf test.tar drwxr-xr-x root/root 0 2016-06-17 21:09 test/ -rw-r-r- root/root 0 2016-06-17 17:51 test/test3 -rw-r-r- root/root 0 2016-06-17 17:51 test/test2 -rw-r-r- root/root 0 2016-06-17 17:51 test/test1 tar 命令是可以同时打包并压缩的，此处常用的选项有以下 2 个，分别是：\n-z：压缩和解压缩 \u0026ldquo;.tar.gz\u0026rdquo; 格式；\n-j：压缩和解压缩 \u0026ldquo;.tar.bz2\u0026quot;格式。\n【例 1】压缩与解压缩 \u0026ldquo;.tar.gz\u0026quot;格式：\n[root@localhost ~]# tar -zcvf tmp.tar.gz /tmp/ #把/temp/目录直接打包压缩为\u0026#34;.tar.gz\u0026#34;格式，通过\u0026#34;-z\u0026#34;来识别格式，\u0026#34;-cvf\u0026#34;和打包选项一致 [root@localhost ~]# tar -zxvf tmp.tar.gz #解压缩与解打包\u0026#34;.tar.gz\u0026#34;格式 【例 2】压缩与解压缩 \u0026ldquo;.tar.bz2\u0026rdquo; 格式:\n[root@localhost ~]# tar -jcvf tmp.tar.bz2 /tmp/ #打包压缩为\u0026#34;.tar.bz2\u0026#34;格式，注意压缩包文件名 [root@localhost ~]# tar -jxvf tmp.tar.bz2 #解压缩与解打包\u0026#34;.tar.bz2\u0026#34;格式 zip命令 压缩常用选项：\n-r：递归压缩目录，及将指定目录下的所有文件以及子目录全部压缩。\n-m：将文件压缩之后，删除原始文件，相当于把文件移到压缩文件中。\n-v：显示详细的压缩过程信息。\n-q：在压缩的时候不显示命令的执行过程。\n-压缩级别：压缩级别是从 1~9 的数字，-1 代表压缩速度更快，-9 代表压缩效果更好。\n-u：更新压缩文件，即往压缩文件中添加新文件。\n【例 1】zip 命令的基本使用：\n[root@localhost ~]# zip ana.zip anaconda-ks.cfg adding: anaconda-ks.cfg (deflated 37%) #压缩 [root@localhost ~]# ll ana.zip -rw-r--r-- 1 root root 935 6月 1716:00 ana.zip #压缩文件生成 【例 2】使用 zip 命令压缩目录，需要使用“-r”选项\n[root@localhost ~]# mkdir dir1 #建立测试目录 [root@localhost ~]# zip -r dir1.zip dir1 adding: dir1/(stored 0%) #压缩目录 [root@localhost ~]# ls -dl dir1.zip -rw-r--r-- 1 root root 160 6月 1716:22 dir1.zip #压缩文件生成 unzip命令 解压缩常用：\n-d 目录名：将压缩文件解压到指定目录下。\n-n：解压时并不覆盖已经存在的文件。\n-o：解压时覆盖已经存在的文件，并且无需用户确认。\n-v：查看压缩文件的详细信息，包括压缩文件中包含的文件大小、文件名以及压缩比等，但并不做解压操作。\n-t：测试压缩文件有无损坏，但并不解压。\n-x 文件列表：解压文件，但不包含文件列表中指定的文件。\n【例 1】直接解压缩：\n[root@localhost ~]# unzip dir1.zip Archive: dir1.zip creating: dirl/ #解压缩 【例 2】使用 -d 选项手动指定解压缩位置:\n[root@localhost ~]# unzip -d /tmp/ ana.zip Archive: ana.zip inflating: /tmp/anaconda-ks.cfg #把压缩包解压到指定位置 gzip命令 常用选项：\n-c:将压缩数据输出到标准输出中，并保留源文件。\n-d:对压缩文件进行解压缩。\n-r:递归压缩指定目录下以及子目录下的所有文件。\n-v:对于每个压缩和解压缩的文件，显示相应的文件名和压缩比。\n-l:对每一个压缩文件，显示以下字段：\n压缩文件的大小；\n未压缩文件的大小；\n压缩比；\n未压缩文件的名称。\n-数字:用于指定压缩等级，-1 压缩等级最低，压缩比最差；-9 压缩比最高。默认压缩比是 -6。\n【例 1】基本压缩：\n[root@localhost ~]# gzip install.log #压缩instal.log 文件 [root@localhost ~]# ls anaconda-ks.cfg install.log.gz install.log.syslog #压缩文件生成，但是源文件也消失了 【例 2】 压缩目录\n[root@localhost ~]# mkdir test [root@localhost ~]# touch test/test1 [root@localhost ~]# touch test/test2 [root@localhost ~]# touch test/test3 #建立测试目录，并在里面建立几个测试文件 [root@localhost ~]# gzip -r test/ #压缩目录，并没有报错 [root@localhost ~]# ls anaconda-ks.cfg anaconda-ks.cfg.gz install.log.gz install.log.syslog test #但是查看发现test目录依然存在，并没有变为压缩文件 [root@localhost ~]# ls test/ testl .gz test2.gz test3.gz #原来gzip命令不会打包目录，而是把目录下所有的子文件分别压缩 gunzip命令 gunzip 是一个使用广泛的解压缩命令，它用于解压被 gzip 压缩过的文件（扩展名为 .gz）。该命令常用的选项：\n-r:递归处理，解压缩指定目录下以及子目录下的所有文件。\n-c:把解压缩后的文件输出到标准输出设备。\n-f:强制解压缩文件，不理会文件是否已存在等情况。\n-l:列出压缩文件内容。\n-v:显示命令执行过程。\n-t:测试压缩文件是否正常，但不对其做解压缩操作。\n【例 1】直接解压缩文件：\n[root@localhost ~]# gunzip install.log.gz 当然，\u0026ldquo;gunzip -r\u0026quot;依然只会解压缩目录下的文件，而不会解打包。要想解压缩\u0026rdquo;.gz\u0026quot;格式，还可以使用 \u0026ldquo;gzip -d\u0026quot;命令，例如：\n[root@localhost ~]# gzip -d anaconda-ks.cfg.gz bzip2命令 bzip2 命令同 gzip 命令类似，只能对文件进行压缩（或解压缩），对于目录只能压缩（或解压缩）该目录及子目录下的所有文件。当执行压缩任务完成后，会生成一个以“.bz2”为后缀的压缩包。\n\u0026ldquo;.bz2\u0026quot;格式是 Linux 的另一种压缩格式，从理论上来讲，\u0026quot;.bz2\u0026quot;格式的算法更先进、压缩比更好；而 \u0026ldquo;.gz\u0026quot;格式相对来讲的时间更快。\n常用选项：\n-d:执行解压缩，此时该选项后的源文件应为标记有 .bz2 后缀的压缩包文件。\n-k:bzip2 在压缩或解压缩任务完成后，会删除原始文件，若要保留原始文件，可使用此选项。\n-f:bzip2 在压缩或解压缩时，若输出文件与现有文件同名，默认不会覆盖现有文件，若使用此选项，则会强制覆盖现有文件。\n-t:测试压缩包文件的完整性。\n-v:压缩或解压缩文件时，显示详细信息。\n-数字:这个参数和 gzip 命令的作用一样，用于指定压缩等级，-1 压缩等级最低，压缩比最差；-9 压缩比最高\nbunzip2命令 要解压“.bz2”格式的压缩包文件，除了使用“bzip2 -d 压缩包名”命令外，还可以使用 bunzip2 命令。\nbunzip2 命令的使用和 gunzip 命令大致相同，bunzip2 命令只能用于解压文件，即便解压目录，也是解压该目录以及所含子目录下的所有文件。\n-k:解压缩后，默认会删除原来的压缩文件。若要保留压缩文件，需使用此参数。\n-f:解压缩时，若输出的文件与现有文件同名时，默认不会覆盖现有的文件。若要覆盖，可使用此选项。\n-v:显示命令执行过程。\n-L:列出压缩文件内容。\n文本处理 cat命令 cat 命令可以用来显示文本文件的内容，也可以把几个文件内容附加到另一个文件中，即连接合并文件。\n常用选项：\n-A:相当于 -vET 选项的整合，用于列出所有隐藏符号；\n-E:列出每行结尾的回车符 $；\n-n:对输出的所有行进行编号；\n-b:同 -n 不同，此选项表示只对非空行进行编号。\n-T:把 Tab 键 ^I 显示出来；\n-V:列出特殊字符；\n-s:当遇到有连续 2 行以上的空白行时，就替换为 1 行的空白行。\n注意，cat 命令用于查看文件内容时，不论文件内容有多少，都会一次性显示。如果文件非常大，那么文件开头的内容就看不到了。\n显示行号：\n[root@localhost ~]# cat -n anaconda-ks.cfg 1 # Kickstart file automatically generated by anaconda. 2 3 4 #version=DEVEL 5 install 6 cdrom …省略部分内容... 将文件 file1.txt 和 file2.txt 的内容合并后输出到文件 file3.txt 中:\n[root@localhost base]# cat file1.txt file2.txt \u0026gt; file3.txt more命令 more 命令可以分页显示文本文件的内容，使用者可以逐页阅读文件中内容。\n选项 含义 -f 计算行数时，以实际的行数，而不是自动换行过后的行数。 -p 不以卷动的方式显示每一页，而是先清除屏幕后再显示内容。 -c 跟 -p 选项相似，不同的是先显示内容再清除其他旧资料。 -s 当遇到有连续两行以上的空白行时，就替换为一行的空白行。 -u 不显示下引号（根据环境变量 TERM 指定的终端而有所不同）。 +n 从第 n 行开始显示文件内容，n 代表数字。 -n 一次显示的行数，n 代表数字。 more 命令的执行会打开一个交互界面，因此读者有必要了解一些交互命令，常用的交互命令如表 2 所示。\n交互指令 功能 h 或 ？ 显示 more 命令交互命令帮助。 q 或 Q 退出 more。 v 在当前行启动一个编辑器。 :f 显示当前文件的文件名和行号。 !\u0026lt;命令\u0026gt; 或 :!\u0026lt;命令\u0026gt; 在子Shell中执行指定命令。 回车键 向下移动一行。 空格键 向下移动一页。 Ctrl+l 刷新屏幕。 = 显示当前行的行号。 ' 转到上一次搜索开始的地方。 Ctrf+f 向下滚动一页。 . 重复上次输入的命令。 / 字符串 搜索指定的字符串。 d 向下移动半页。 b 向上移动一页。 head命令 head 命令可以显示指定文件前若干行的文件内容，该命令常用选项：\n选项 含义 -n K 这里的 K 表示行数，该选项用来显示文件前 K 行的内容； 如果使用 \u0026ldquo;-K\u0026rdquo; 作为参数，则表示除了文件最后 K 行外， 显示剩余的全部内容。 -c K 这里的 K 表示字节数，该选项用来显示文件前 K 个字节的内容； 如果使用 \u0026ldquo;-K\u0026rdquo;，则表示除了文件最后 K 字节的内容，显示剩余 全部内容。 -v 显示文件名； less命令 less 命令的作用和 more 十分类似，都用来浏览文本文件中的内容，不同之处在于，使用 more 命令浏览文件内容时，只能不断向后翻看，而使用 less 命令浏览，既可以向后翻看，也可以向前翻看。\n不仅如此，为了方面用户浏览文本内容，less 命令还提供了以下几个功能：\n使用光标键可以在文本文件中前后（左后）滚屏；\n用行号或百分比作为书签浏览文件；\n提供更加友好的检索、高亮显示等操作；\n兼容常用的字处理程序（如 Vim、Emacs）的键盘操作；\n阅读到文件结束时，less 命令不会退出；\n屏幕底部的信息提示更容易控制使用，而且提供了更多的信息。\n选项 选项含义 -N 显示每行的行号。 -S 行过长时将超出部分舍弃。 -e 当文件显示结束后，自动离开。 -g 只标志最后搜索到的关键同。 -Q 不使用警告音。 -i 忽略搜索时的大小写。 -m 显示类似 more 命令的百分比。 -f 强迫打开特殊文件，比如外围设备代号、目录和二进制文件。 -s 显示连续空行为一行。 -b \u0026lt;缓冲区大小\u0026gt; 设置缓冲区的大小。 -o \u0026lt;文件名\u0026gt; 将 less 输出的内容保存到指定文件中。 -x \u0026lt;数字\u0026gt; 将【Tab】键显示为规定的数字空格。 在使用 less 命令查看文件内容的过程中，和 more 命令一样，也会进入交互界面，因此需要读者掌握一些常用的交互指令：\n交互指令 功能 /字符串 向下搜索“字符串”的功能。 ?字符串 向上搜索“字符串”的功能。 n 重复*前一个搜索（与 / 成 ? 有关）。 N 反向重复前一个搜索（与 / 或 ? 有关）。 b 向上移动一页。 d 向下移动半页。 h 或 H 显示帮助界面。 q 或 Q 退出 less 命令。 y 向上移动一行。 空格键 向下移动一页。 回车键 向下移动一行。 【PgDn】键 向下移动一页。 【PgUp】键 向上移动一页。 Ctrl+f 向下移动一页。 Ctrl+b 向上移动一页。 Ctrl+d 向下移动一页。 Ctrl+u 向上移动半页。 j 向下移动一行。 k 向上移动一行。 G 移动至最后一行。 g 移动到第一行。 ZZ 退出 less 命令。 v 使用配置的编辑器编辑当前文件。 [ 移动到本文档的上一个节点。 ] 移动到本文档的下一个节点。 p 移动到同级的上一个节点。 u 向上移动半页。 tail命令 tail 命令和 head 命令正好相反，它用来查看文件末尾的数据\n此命令常用的选项:\n选项 含义 -n K 这里的 K 指的是行数，该选项表示输出最后 K 行，在此基础上， 如果使用 -n +K，则表示从文件的第 K 行开始输出。 -c K 这里的 K 指的是字节数，该选项表示输出文件最后 K 个字节的内容 ，在此基础上，使用 -c +K 则表示从文件第 K 个字节开始输出。 -f 输出文件变化后新增加的数据。 gep命令 在 UNIX 系统中，搜索的模式（patterns）被称为正则表达式（regular expressions），为了要彻底搜索一个文件，有的用户在要搜索的字符串前加上前缀 global（全面的），一旦找到相匹配的内容，用户就像将其输出（print）到屏幕上，而将这一系列的操作整合到一起就是 global regular expressions print，而这也就是 grep 命令的全称。\ngrep命令能够在一个或多个文件中，搜索某一特定的字符模式（也就是正则表达式），此模式可以是单一的字符、字符串、单词或句子。\n常用的选项：\n选项 含义 -c 仅列出文件中包含模式的行数。 -i 忽略模式中的字母大小写。 -l 列出带有匹配行的文件名。 -n 在每一行的最前面列出行号。 -v 列出没有匹配模式的行。 -w 把表达式当做一个完整的单字符来搜寻，忽略那些部分匹配的行。 注意，如果是搜索多个文件，grep 命令的搜索结果只显示文件中发现匹配模式的文件名；而如果搜索单个文件，grep 命令的结果将显示每一个包含匹配模式的行。\n假设有一份 emp.data 员工清单，现在要搜索此文件，找出职位为 CLERK 的所有员工，则执行命令如下：\n[root@localhost ~]# grep CLERK emp.data 而在此基础上，如果只想知道职位为 CLERK 的员工的人数，可以使用“-c”选项，执行命令如下：\n[root@localhost ~]# grep -c CLERK emp.data sed命令 Vim 采用的是交互式文本编辑模式，你可以用键盘命令来交互性地插入、删除或替换数据中的文本。但本节要讲的 sed 命令不同，它采用的是流编辑模式，最明显的特点是，在 sed 处理数据之前，需要预先提供一组规则，sed 会按照此规则来编辑数据。\nsed 会根据脚本命令来处理文本文件中的数据，此命令执行数据的顺序如下：\n每次仅读取一行内容； 根据提供的规则命令匹配并修改数据。注意，sed 默认不会直接修改源文件数据，而是会将数据复制到缓冲区中，修改也仅限于缓冲区中的数据； 将执行结果输出。 当一行数据匹配完成后，它会继续读取下一行数据，并重复这个过程，直到将文件中所有数据处理完毕。\nsed 命令的基本格式如下：\n[root@localhost ~]# sed [选项] [脚本命令] 文件名 选项 含义 -e 脚本命令 该选项会将其后跟的脚本命令添加到已有的命令中。 -f 脚本命令文件 该选项会将其后文件中的脚本命令添加到已有的命令中。 -n 默认情况下，sed 会在所有的脚本指定执行完毕后，会自动输出处理后的内容，而该选项会屏蔽启动输出，需使用 print 命令来完成输出。 -i 此选项会直接修改源文件，要慎用。 成功使用 sed 命令的关键在于掌握各式各样的脚本命令及格式，它能帮你定制编辑文件的规则。\nsed s 替换文件内容 [address]s/pattern/replacement/flags 其中，address 表示指定要操作的具体行，pattern 指的是需要替换的内容，replacement 指的是要替换的新内容。\nflags 标记 功能 n 1~512 之间的数字，表示指定要替换的字符串出现第几次时才进行替换，例如，一行中有 3 个 A，但用户只想替换第二个 A，这是就用到这个标记； g 对数据中所有匹配到的内容进行替换，如果没有 g，则只会在第一次匹配成功时做替换操作。例如，一行数据中有 3 个 A，则只会替换第一个 A； p 会打印与替换命令中指定的模式匹配的行。此标记通常与 -n 选项一起使用。 w file 将缓冲区中的内容写到指定的 file 文件中； \u0026amp; 用正则表达式匹配的内容进行替换； \\n 匹配第 n 个子串，该子串之前在 pattern 中用 () 指定。 \\ 转义（转义替换部分包含：\u0026amp;、\\ 等）。 比如，可以指定 sed 用新文本替换第几处模式匹配的地方：\n[root@localhost ~]# sed \u0026#39;s/test/trial/2\u0026#39; data4.txt This is a test of the trial script. This is the second test of the trial script. 可以看到，使用数字 2 作为标记的结果就是，sed 编辑器只替换每行中第 2 次出现的匹配模式。\n如果要用新文件替换所有匹配的字符串，可以使用 g 标记：\n[root@localhost ~]# sed \u0026#39;s/test/trial/g\u0026#39; data4.txt This is a trial of the trial script. This is the second trial of the trial script. 我们知道，-n 选项会禁止 sed 输出，但 p 标记会输出修改过的行，将二者匹配使用的效果就是只输出被替换命令修改过的行，例如：\n[root@localhost ~]# cat data5.txt This is a test line. This is a different line. [root@localhost ~]# sed -n \u0026#39;s/test/trial/p\u0026#39; data5.txt This is a trial line. w 标记会将匹配后的结果保存到指定文件中，比如：\n[root@localhost ~]# sed \u0026#39;s/test/trial/w test.txt\u0026#39; data5.txt This is a trial line. This is a different line. [root@localhost ~]#cat test.txt This is a trial line. 在使用 s 脚本命令时，替换类似文件路径的字符串会比较麻烦，需要将路径中的正斜线进行转义，例如：\n[root@localhost ~]# sed \u0026#39;s/\\/bin\\/bash/\\/bin\\/csh/\u0026#39; /etc/passwd sed c 替换整个文本行 c 命令表示将指定行中的所有内容，替换成该选项后面的字符串。该命令的基本格式为：\n[address]c\\用于替换的新文本 [root@localhost ~]# sed \u0026#39;3c\\ \u0026gt; This is a changed line of text.\u0026#39; data6.txt This is line number 1. This is line number 2. This is a changed line of text. This is line number 4. 在这个例子中，sed 编辑器会修改第三行中的文本，其实，下面的写法也可以实现此目的： [root@localhost ~]# sed \u0026#39;/number 3/c\\ \u0026gt; This is a changed line of text.\u0026#39; data6.txt This is line number 1. This is line number 2. This is a changed line of text. This is line number 4. sed y 转换文本内容 y 转换命令是唯一可以处理单个字符的 sed 脚本命令，其基本格式如下：\n[address]y/inchars/outchars/ 转换命令会对 inchars 和 outchars 值进行一对一的映射，即 inchars 中的第一个字符会被转换为 outchars 中的第一个字符，第二个字符会被转换成 outchars 中的第二个字符\u0026hellip;这个映射过程会一直持续到处理完指定字符。如果 inchars 和 outchars 的长度不同，则 sed 会产生一条错误消息。\n举个简单例子：\n[root@localhost ~]# sed \u0026#39;y/123/789/\u0026#39; data8.txt This is line number 7. This is line number 8. This is line number 9. This is line number 4. This is line number 7 again. This is yet another line. This is the last line in the file. 可以看到，inchars 模式中指定字符的每个实例都会被替换成 outchars 模式中相同位置的那个字符。\n转换命令是一个全局命令，也就是说，它会文本行中找到的所有指定字符自动进行转换，而不会考虑它们出现的位置，再打个比方：\n[root@localhost ~]# echo \u0026#34;This 1 is a test of 1 try.\u0026#34; | sed \u0026#39;y/123/456/\u0026#39; This 4 is a test of 4 try. sed 转换了在文本行中匹配到的字符 1 的两个实例，我们无法限定只转换在特定地方出现的字符。\nsed p 打印文本内容 p 命令表示搜索符合条件的行，并输出该行的内容。p 命令常见的用法是打印包含匹配文本模式的行，例如：\n[root@localhost ~]# cat data6.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4. [root@localhost ~]# sed -n \u0026#39;/number 3/p\u0026#39; data6.txt This is line number 3. 可以看到，用 -n 选项和 p 命令配合使用，我们可以禁止输出其他行，只打印包含匹配文本模式的行。\n如果需要在修改之前查看行，也可以使用打印命令，比如与替换或修改命令一起使用。可以创建一个脚本在修改行之前显示该行，如下所示：\n[root@localhost ~]# sed -n \u0026#39;/3/{ \u0026gt; p \u0026gt; s/line/test/p \u0026gt; }\u0026#39; data6.txt This is line number 3. This is test number 3. sed 命令会查找包含数字 3 的行，然后执行两条命令。首先，脚本用 p 命令来打印出原始行；然后它用 s 命令替换文本，并用 p 标记打印出替换结果。输出同时显示了原来的行文本和新的行文本。\nsed w 脚本命令 w 命令用来将文本中指定行的内容写入文件中，此命令的基本格式如下：\n[address]w filename 这里的 filename 表示文件名，可以使用相对路径或绝对路径，但不管是哪种，运行 sed 命令的用户都必须有文件的写权限。\n下面的例子是将数据流中的前两行打印到一个文本文件中：\n[root@localhost ~]# sed \u0026#39;1,2w test.txt\u0026#39; data6.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4. [root@localhost ~]# cat test.txt This is line number 1. This is line number 2. 当然，如果不想让行直接输出，可以用 -n 选项，再举个例子：\n[root@localhost ~]# cat data11.txt Blum, R Browncoat McGuiness, A Alliance Bresnahan, C Browncoat Harken, C Alliance [root@localhost ~]# sed -n \u0026#39;/Browncoat/w Browncoats.txt\u0026#39; data11.txt cat Browncoats.txt Blum, R Browncoat Bresnahan, C Browncoat 可以看到，通过使用 w 脚本命令，sed 可以实现将包含文本模式的数据行写入目标文件。\nsed r 脚本命令 r 命令用于将一个独立文件的数据插入到当前数据流的指定位置，该命令的基本格式为：\n[address]r filename sed 命令会将 filename 文件中的内容插入到 address 指定行的后面，比如说：\n[root@localhost ~]# cat data12.txt This is an added line. This is the second added line. [root@localhost ~]# sed \u0026#39;3r data12.txt\u0026#39; data6.txt This is line number 1. This is line number 2. This is line number 3. This is an added line. This is the second added line. This is line number 4. 如果你想将指定文件中的数据插入到数据流的末尾，可以使用 $ 地址符，例如：\n[root@localhost ~]# sed \u0026#39;$r data12.txt\u0026#39; data6.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4. This is an added line. This is the second added line. sed q 退出脚本命令 q 命令的作用是使 sed 命令在第一次匹配任务结束后，退出 sed 程序，不再进行对后续数据的处理。\n[root@localhost ~]# sed \u0026#39;2q\u0026#39; test.txt This is line number 1. This is line number 2. 可以看到，sed 命令在打印输出第 2 行之后，就停止了，是 q 命令造成的，再比如：\n[root@localhost ~]# sed \u0026#39;/number 1/{ s/number 1/number 0/;q; }\u0026#39; test.txt This is line number 0. 使用 q 命令之后，sed 命令会在匹配到 number 1 时，将其替换成 number 0，然后直接退出。\nsed d 删除文件内容 如果需要删除文本中的特定行，可以用 d 脚本命令，它会删除指定行中的所有内容。但使用该命令时要特别小心，如果你忘记指定具体行的话，文件中的所有内容都会被删除，举个例子：\n[root@localhost ~]# cat data1.txt The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy dog [root@localhost ~]# sed \u0026#39;d\u0026#39; data1.txt #什么也不输出，证明成了空文件 当和指定地址一起使用时，删除命令显然能发挥出大的功用。可以从数据流中删除特定的文本行。\n通过行号指定，比如删除 data6.txt 文件内容中的第 3 行：\n[root@localhost ~]# cat data6.txt This is line number 1. This is line number 2. This is line number 3. This is line number 4. [root@localhost ~]# sed \u0026#39;3d\u0026#39; data6.txt This is line number 1. This is line number 2. This is line number 4. 或者通过特定行区间指定，比如删除 data6.txt 文件内容中的第 2、3行：\n[root@localhost ~]# sed \u0026#39;2,3d\u0026#39; data6.txt This is line number 1. This is line number 4. 也可以使用两个文本模式来删除某个区间内的行，但这么做时要小心，你指定的第一个模式会“打开”行删除功能，第二个模式会“关闭”行删除功能，因此，sed 会删除两个指定行之间的所有行（包括指定的行），例如：\n[root@localhost ~]#sed \u0026#39;/1/,/3/d\u0026#39; data6.txt #删除第 1~3 行的文本数据 This is line number 4. 或者通过特殊的文件结尾字符，比如删除 data6.txt 文件内容中第 3 行开始的所有的内容：\n[root@localhost ~]# sed \u0026#39;3,$d\u0026#39; data6.txt This is line number 1. This is line number 2. 在此强调，在默认情况下 sed 并不会修改原始文件，这里被删除的行只是从 sed 的输出中消失了，原始文件没做任何改变。\nsed a 和 i 插入内容 a 命令表示在指定行的后面附加一行，i 命令表示在指定行的前面插入一行，这里之所以要同时介绍这 2 个脚本命令，因为它们的基本格式完全相同，如下所示：\n[address]a（或 i）\\新文本内容 将一个新行插入到数据流第三行前，执行命令如下：\n[root@localhost ~]# sed \u0026#39;3i\\ \u0026gt; This is an inserted line.\u0026#39; data6.txt This is line number 1. This is line number 2. This is an inserted line. This is line number 3. This is line number 4. 再比如说，将一个新行附加到数据流中第三行后，执行命令如下：\n[root@localhost ~]# sed \u0026#39;3a\\ \u0026gt; This is an appended line.\u0026#39; data6.txt This is line number 1. This is line number 2. This is line number 3. This is an appended line. This is line number 4. 如果你想将一个多行数据添加到数据流中，只需对要插入或附加的文本中的每一行末尾（除最后一行）添加反斜线即可，例如：\n[root@localhost ~]# sed \u0026#39;1i\\ \u0026gt; This is one line of new text.\\ \u0026gt; This is another line of new text.\u0026#39; data6.txt This is one line of new text. This is another line of new text. This is line number 1. This is line number 2. This is line number 3. This is line number 4. 可以看到，指定的两行都会被添加到数据流中。\nsed 脚本命令的寻址方式 前面在介绍各个脚本命令时，我们一直忽略了对 address 部分的介绍。对各个脚本命令来说，address 用来表明该脚本命令作用到文本中的具体行。\n默认情况下，sed 命令会作用于文本数据的所有行。如果只想将命令作用于特定行或某些行，则必须写明 address 部分，表示的方法有以下 2 种：\n以数字形式指定行区间；\n用文本模式指定具体行区间。\n以数字形式指定行区间 当使用数字方式的行寻址时，可以用行在文本流中的行位置来引用。sed 会将文本流中的第一行编号为 1，然后继续按顺序为接下来的行分配行号。\n在脚本命令中，指定的地址可以是单个行号，或是用起始行号、逗号以及结尾行号指定的一定区间范围内的行。这里举一个 sed 命令作用到指定行号的例子：\n[root@localhost ~]#sed \u0026#39;2s/dog/cat/\u0026#39; data1.txt The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy dog 可以看到，sed 只修改地址指定的第二行的文本。下面的例子中使用了行地址区间：\n[root@localhost ~]# sed \u0026#39;2,3s/dog/cat/\u0026#39; data1.txt The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy dog 在此基础上，如果想将命令作用到文本中从某行开始的所有行，可以用特殊地址——美元符（$）：\n[root@localhost ~]# sed \u0026#39;2,$s/dog/cat/\u0026#39; data1.txt The quick brown fox jumps over the lazy dog The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy cat The quick brown fox jumps over the lazy cat 用文本模式指定行区间 sed 允许指定文本模式来过滤出命令要作用的行，格式如下：\n/pattern/command 注意，必须用正斜线将要指定的 pattern 封起来，sed 会将该命令作用到包含指定文本模式的行上。\n举个例子，如果你想只修改用户 demo 的默认 shell，可以使用 sed 命令，执行命令如下：\n[root@localhost ~]# grep demo /etc/passwd demo❌502:502::/home/Samantha:/bin/bash [root@localhost ~]# sed \u0026#39;/demo/s/bash/csh/\u0026#39; /etc/passwd root❌0:0:root:/root:/bin/bash ... demo❌502:502::/home/demo:/bin/csh ... 虽然使用固定文本模式能帮你过滤出特定的值，就跟上面这个用户名的例子一样，但其作用难免有限，因此，sed 允许在文本模式使用正则表达式指明作用的具体行。正则表达式允许创建高级文本模式匹配表达式来匹配各种数据。这些表达式结合了一系列通配符、特殊字符以及固定文本字符来生成能够匹配几乎任何形式文本的简练模式。\nawk命令 和 sed 命令类似，awk 命令也是逐行扫描文件（从第 1 行到最后一行），寻找含有目标文本的行，如果匹配成功，则会在该行上执行用户想要的操作；反之，则不对行做任何处理。\nawk 命令的基本格式为：\n[root@localhost ~] awk [选项] \u0026#39;脚本命令\u0026#39; 文件名 选项 含义 -F fs 指定以 fs 作为输入行的分隔符，awk 命令默认分隔符为空格或制表符。 -f file 从脚本文件中读取 awk 脚本指令，以取代直接在命令行中输入指令。 -v var=val 在执行处理过程之前，设置一个变量 var，并给其初始值设置为 val。 awk 的强大之处在于脚本命令，它由 2 部分组成：匹配规则{执行命令}\n这里的匹配规则，和 sed 命令中的 address 部分作用相同，用来指定脚本命令可以作用到文本内容中的具体行，可以使用字符串（比如 /demo/，表示查看含有 demo 字符串的行）或者正则表达式指定。另外需要注意的是，整个脚本命令是用单引号（\u0026rsquo;\u0026rsquo;）括起，而其中的执行命令部分需要用大括号（{}）括起来。\n在 awk 程序执行时，如果没有指定执行命令，则默认会把匹配的行输出；如果不指定匹配规则，则默认匹配文本中所有的行。\n举个简单的例子：\nzzq@Zhao:~$ awk \u0026#39;/^$/ {print \u0026#34;Blank line\u0026#34;}\u0026#39; aa.txt Blank line Blank line 在此命令中，/^$/ 是一个正则表达式，功能是匹配文本中的空白行，同时可以看到，执行命令使用的是 print 命令，此命令经常会使用，它的作用很简单，就是将指定的文本进行输出。因此，整个命令的功能是，如果 test.txt 有 N 个空白行，那么执行此命令会输出 N 个 Blank line。\nawk 变量 awk 的主要特性之一是其处理文本文件中数据的能力，它会自动给一行中的每个数据元素分配一个变量。\n默认情况下，awk 会将如下变量分配给它在文本行中发现的数据字段：\n$0 代表整个文本行；\n$1 代表文本行中的第 1 个数据字段；\n$2 代表文本行中的第 2 个数据字段；\n$n 代表文本行中的第 n 个数据字段。\n前面说过，在 awk 中，默认的字段分隔符是任意的空白字符（例如空格或制表符）。 在文本行中，每个数据字段都是通过字段分隔符划分的。awk 在读取一行文本时，会用预定义的字段分隔符划分每个数据字段。\n所以在下面的例子中，awk 程序读取文本文件，只显示第 1 个数据字段的值：\n[root@localhost ~]# cat data2.txt One line of test text. Two lines of test text. Three lines of test text. [root@localhost ~]# awk \u0026#39;{print $1}\u0026#39; data2.txt One Two Three 该程序用 $1 字段变量来表示“仅显示每行文本的第 1 个数据字段”。当然，如果你要读取采用了其他字段分隔符的文件，可以用 -F 选项手动指定。\nawk 脚本组合多个命令 awk 允许将多条命令组合成一个正常的程序。要在命令行上的程序脚本中使用多条命令，只要在命令之间放个分号即可，例如：\n[root@localhost ~]# echo \u0026#34;My name is Rich\u0026#34; | awk \u0026#39;{$4=\u0026#34;Christine\u0026#34;; print $0}\u0026#39; My name is Christine 第一条命令会给字段变量 $4 赋值。第二条命令会打印整个数据字段。可以看到，awk 程序在输出中已经将原文本中的第四个数据字段替换成了新值。\n除此之外，也可以一次一行地输入程序脚本命令，比如说：\n[root@localhost ~]# awk \u0026#39;{ \u0026gt; $4=\u0026#34;Christine\u0026#34; \u0026gt; print $0}\u0026#39; My name is Rich My name is Christine 在你用了表示起始的单引号后，bash shell 会使用 \u0026gt; 来提示输入更多数据，我们可以每次在每行加一条命令，直到输入了结尾的单引号。\n注意，此例中因为没有在命令行中指定文件名，awk 程序需要用户输入获得数据，因此当运行这个程序的时候，它会一直等着用户输入文本，此时如果要退出程序，只需按下 Ctrl+D 组合键即可。\nawk从文件中读取脚本 跟 sed 一样，awk 允许将脚本命令存储到文件中，然后再在命令行中引用，比如：\n[root@localhost ~]# cat awk.sh {print $1 \u0026#34;\u0026#39;s home directory is \u0026#34; $6} [root@localhost ~]# awk -F: -f awk.sh /etc/passwd root\u0026#39;s home directory is /root bin\u0026#39;s home directory is /bin daemon\u0026#39;s home directory is /sbin adm\u0026#39;s home directory is /var/adm lp\u0026#39;s home directory is /var/spool/lpd ... Christine\u0026#39;s home directory is /home/Christine Samantha\u0026#39;s home directory is /home/Samantha Timothy\u0026#39;s home directory is /home/Timothy awk.sh 脚本文件会使用 print 命令打印 /etc/passwd 文件的主目录数据字段（字段变量 $6），以及 userid 数据字段（字段变量 $1）。注意，在程序文件中，也可以指定多条命令，只要一条命令放一行即可，之间不需要用分号。\nawk BEGIN关键字 awk 中还可以指定脚本命令的运行时机。默认情况下，awk 会从输入中读取一行文本，然后针对该行的数据执行程序脚本，但有时可能需要在处理数据前运行一些脚本命令，这就需要使用 BEGIN 关键字。\nBEGIN 会强制 awk 在读取数据前执行该关键字后指定的脚本命令，例如：\n[root@localhost ~]# cat data3.txt Line 1 Line 2 Line 3 [root@localhost ~]# awk \u0026#39;BEGIN {print \u0026#34;The data3 File Contents:\u0026#34;} \u0026gt; {print $0}\u0026#39; data3.txt The data3 File Contents: Line 1 Line 2 Line 3 可以看到，这里的脚本命令中分为 2 部分，BEGIN 部分的脚本指令会在 awk 命令处理数据前运行，而真正用来处理数据的是第二段脚本命令。\nawk END关键字 和 BEGIN 关键字相对应，END 关键字允许我们指定一些脚本命令，awk 会在读完数据后执行它们，例如：\n[root@localhost ~]# awk \u0026#39;BEGIN {print \u0026#34;The data3 File Contents:\u0026#34;} \u0026gt; {print $0} \u0026gt; END {print \u0026#34;End of File\u0026#34;}\u0026#39; data3.txt The data3 File Contents: Line 1 Line 2 Line 3 End of File 可以看到，当 awk 程序打印完文件内容后，才会执行 END 中的脚本命令。\n重定向 Linux 中标准的输入设备默认指的是键盘，标准的输出设备默认指的是显示器。而本节所要介绍的输入、输出重定向，完全可以从字面意思去理解，也就是：\n输入重定向：指的是重新指定设备来代替键盘作为新的输入设备；\n输出重定向：指的是重新指定设备来代替显示器作为新的输出设备。\n通常是用文件或命令的执行结果来代替键盘作为新的输入设备，而新的输出设备通常指的就是文件。\n一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件：\n标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。 标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。 标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息。 输入重定向 对于输入重定向来说，其需要用到的符号以及作用如表所示:\n命令符号格式 作用 命令 \u0026lt; 文件 将指定文件作为命令的输入设备 命令 \u0026laquo; 分界符 表示从标准输入设备（键盘）中读入，直到遇到分界符才停止（读入的数据不包括分界符），这里的分界符其实就是自定义的字符串 命令 \u0026lt; 文件 1 \u0026gt; 文件 2 将文件 1 作为命令的输入设备，该命令的执行结果输出到文件 2 中。 默认情况下，cat 命令会接受标准输入设备（键盘）的输入，并显示到控制台，但如果用文件代替键盘作为输入设备，那么该命令会以指定的文件作为输入设备，并将文件中的内容读取并显示到控制台。以 /etc/passwd 文件（存储了系统中所有用户的基本信息）为例，执行如下命令：\n[root@localhost ~]# cat /etc/passwd #这里省略输出信息，读者可自行查看 [root@localhost ~]# cat \u0026lt; /etc/passwd #输出结果同上面命令相同 注意，虽然执行结果相同，但第一行代表是以键盘作为输入设备，而第二行代码是以 /etc/passwd 文件作为输入设备。\n键盘输入的情况：\n[root@localhost ~]# cat \u0026lt;\u0026lt; 0 \u0026gt;c.biancheng.net \u0026gt;Linux \u0026gt;0 c.biancheng.net Linux 可以看到，当指定了 0 作为分界符之后，只要不输入 0，就可以一直输入数据。\n输入重定向：\n[root@localhost ~]# cat a.txt [root@localhost ~]# cat \u0026lt; /etc/passwd \u0026gt; a.txt [root@localhost ~]# cat a.txt #输出了和 /etc/passwd 文件内容相同的数据 可以看到，通过重定向 /etc/passwd 作为输入设备，并输出重定向到 a.txt，最终实现了将 /etc/passwd 文件中内容复制到 a.txt 中。\n输出重定向 相较于输入重定向，我们使用输出重定向的频率更高。并且，和输入重定向不同的是，输出重定向还可以细分为标准输出重定向和错误输出重定向两种技术。\n例如，使用 ls 命令分别查看两个文件的属性信息，但其中一个文件是不存在的，如下所示：\n[root@localhost ~]# touch demo1.txt [root@localhost ~]# ls -l demo1.txt -rw-rw-r--. 1 root root 0 Oct 12 15:02 demo1.txt [root@localhost ~]# ls -l demo2.txt \u0026lt;-- 不存在的文件 ls: cannot access demo2.txt: No such file or directory 上述命令中，demo1.txt 是存在的，因此正确输出了该文件的一些属性信息，这也是该命令执行的标准输出信息；而 demo2.txt 是不存在的，因此执行 ls 命令之后显示的报错信息，是该命令的错误输出信息。\n再次强调，要想把原本输出到屏幕上的数据转而写入到文件中，这两种输出信息就要区别对待。\n在此基础上，标准输出重定向和错误输出重定向又分别包含清空写入和追加写入两种模式。因此，对于输出重定向来说，其需要用到的符号以及作用如表 2 所示。\n命令符号格式 作用 命令 \u0026gt; 文件 将命令执行的标准输出结果重定向输出到指定的文件中， 如果该文件已包含数据，会清空原有数据，再写入新数据。 命令 2\u0026gt; 文件 将命令执行的错误输出结果重定向到指定的文件中， 如果该文件中已包含数据，会清空原有数据，再写入新数据。 命令 \u0026raquo; 文件 将命令执行的标准输出结果重定向输出到指定的文件中， 如果该文件已包含数据，新数据将写入到原有内容的后面。 命令 2\u0026raquo; 文件 将命令执行的错误输出结果重定向到指定的文件中， 如果该文件中已包含数据，新数据将写入到原有内容的后面。 命令 \u0026raquo; 文件 2\u0026gt;\u0026amp;1 或者 命令 \u0026amp;\u0026raquo; 文件 将标准输出或者错误输出写入到指定文件，如果该文件中已包含数据， 新数据将写入到原有内容的后面。注意，第一种格式中，最后的 2\u0026gt;\u0026amp;1 是一体的， 可以认为是固定写法。 新建一个包含有 \u0026ldquo;Linux\u0026rdquo; 字符串的文本文件 Linux.txt，以及空文本文件 demo.txt，然后执行如下命令：\n[root@localhost ~] cat Linux.txt \u0026gt; demo.txt [root@localhost ~] cat demo.txt Linux [root@localhost ~] cat Linux.txt \u0026gt; demo.txt [root@localhost ~] cat demo.txt Linux \u0026lt;--这里的 Linux 是清空原有的 Linux 之后，写入的新的 Linux [root@localhost ~] cat Linux.txt \u0026gt;\u0026gt; demo.txt [root@localhost ~] cat demo.txt Linux Linux \u0026lt;--以追加的方式，新数据写入到原有数据之后 [root@localhost ~] cat b.txt \u0026gt; demo.txt cat: b.txt: No such file or directory \u0026lt;-- 错误输出信息依然输出到了显示器中 [root@localhost ~] cat b.txt 2\u0026gt; demo.txt [root@localhost ~] cat demo.txt cat: b.txt: No such file or directory \u0026lt;--清空文件，再将错误输出信息写入到该文件中 [root@localhost ~] cat b.txt 2\u0026gt;\u0026gt; demo.txt [root@localhost ~] cat demo.txt cat: b.txt: No such file or directory cat: b.txt: No such file or directory \u0026lt;--追加写入错误输出信息 Here Document Here Document 是 Shell 中的一种特殊的重定向方式，用来将输入重定向到一个交互式 Shell 脚本或程序。\n它的基本的形式如下：\ncommand \u0026lt;\u0026lt; delimiter document delimiter 它的作用是将两个 delimiter 之间的内容(document) 作为输入传递给 command。\n结尾的delimiter 一定要顶格写，前面不能有任何字符，后面也不能有任何字符，包括空格和 tab 缩进。 开始的delimiter前后的空格会被忽略掉。 在命令行中通过 wc -l 命令计算 Here Document 的行数：\n$ wc -l \u0026lt;\u0026lt; EOF 欢迎来到 菜鸟教程 www.runoob.com EOF 3 # 输出结果为 3 行 我们也可以将 Here Document 用在脚本中，例如：\ncat \u0026lt;\u0026lt; EOF 欢迎来到 菜鸟教程 www.runoob.com EOF 执行以上脚本，输出结果：\n欢迎来到 菜鸟教程 www.runoob.com /dev/null 文件 如果希望执行某个命令，但又不希望在屏幕上显示输出结果，那么可以将输出重定向到 /dev/null：\n$ command \u0026gt; /dev/null /dev/null 是一个特殊的文件，写入到它的内容都会被丢弃；如果尝试从该文件读取内容，那么什么也读不到。但是 /dev/null 文件非常有用，将命令的输出重定向到它，会起到\u0026quot;禁止输出\u0026quot;的效果。\n如果希望屏蔽 stdout 和 stderr，可以这样写：\n$ command \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 tee命令 tee指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。\ntee [-ai][--help][--version][文件...] -a或\u0026ndash;append:附加到既有文件的后面，而非覆盖它． -i或\u0026ndash;ignore-interrupts: 忽略中断信号。 \u0026ndash;help: 在线帮助。 \u0026ndash;version: 显示版本信息。 使用指令\u0026quot;tee\u0026quot;将用户输入的数据同时保存到文件\u0026quot;file1\u0026quot;和\u0026quot;file2\u0026quot;中，输入如下命令：\n$ #在两个文件中复制内容 ss ss sd sd dd dd ^C zzq@Zhao:~$ cat aa ss sd dd zzq@Zhao:~$ cat bb ss sd dd ","date":"2022年11月30日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","series":[],"smallImg":"","tags":[{"title":"linux","url":"/myblog/tags/linux/"},{"title":"shell","url":"/myblog/tags/shell/"}],"timestamp":1669826657,"title":"Linux常用命令"},{"authors":[],"categories":[{"title":"中间件","url":"/myblog/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"content":"FileBeat 概述 Filebeat 是一个用于转发和集中日志数据的轻量级传送器。作为代理安装在您的服务器上，Filebeat 监控您指定位置的日志文件，收集日志事件，并将它们转发到Elasticsearch或 Logstash以进行索引。\n以下是 Filebeat 的工作原理：当您启动 Filebeat 时，它会启动一个或多个输入，这些输入去您指定的位置中查找日志文件。对于 Filebeat 定位的每个日志，Filebeat 都会启动一个收集器**(harvester)**。每个harvester 读取单个日志以获取新内容并将新日志数据发送到libbeat，libbeat 聚合事件并将聚合数据发送到配置好的输出。\nFilebeat 是 Elastic Beat，基于libbeat 框架。\n为每个文件启动一个收集器， 其逐行读取文件，并将内容发送到输出。 收集器负责打开和关闭文件，这意味着在收集器运行时文件描述符保持打开状态。\nFilebeat 如何保持文件的状态？ Filebeat 会保存每个文件的状态，并经常在将状态刷新到注册表文件。 该状态用于记住收集器读取的最后一个偏移量，并确保发送所有日志行。 如果无法访问 Elasticsearch 或 Logstash 等输出，Filebeat 会跟踪发送的最后几行，并在输出再次可用时继续读取文件。 在 Filebeat 运行时，每个输入的状态信息也会保存在内存中。 当 Filebeat 重新启动时，来自注册表文件的数据用于重建状态，并且 Filebeat 在最后一个已知位置继续每个收集器。\n对于每个输入，Filebeat 都会保存它找到的每个文件的状态。 因为文件可以重命名或移动，所以文件名和路径不足以识别文件。 对于每个文件，Filebeat 都会存储唯一标识符，以检测文件是否以前被收集过。\nFilebeat 如何确保至少一次交付？ Filebeat 保证事件将至少传递到配置的输出一次，并且不会丢失数据。Filebeat 能够实现这种行为是因为它将每个事件的传递状态存储在注册表文件中。\n在定义的输出被阻塞并且没有确认所有事件的情况下，Filebeat 将继续尝试发送事件，直到输出确认它已收到事件。\n如果 Filebeat 在发送事件的过程中关闭，它不会在关闭前等待输出确认所有事件。任何发送到输出但在 Filebeat 关闭之前未确认的事件，在 Filebeat 重新启动时会再次发送。这可确保每个事件至少发送一次，但最终可能会将重复的事件发送到输出。您可以通过设置shutdown_timeout选项将 Filebeat 配置为在关闭之前等待特定的时间。\n与es集成 索引策略 索引生命周期是elasticsearch管理索引的一种方式，可以根据运行状态决定创建新的索引、删除索引等。\n从 7.0 版本开始，Filebeat 在连接支持生命周期管理的es集群时，默认使用索引生命周期管理。具体说，filebeat会在连接ES时，在ES上创建filebeat定义好的生命周期。您可以在 Kibana 的索引生命周期策略 UI 中查看和编辑策略。\n你可以在filebeat使用下面的属性配置索引生命周期策略:\nsetup.ilm.enabled: 有效值为 true、false 和 auto。 在 7.0 及更高版本指定 auto（默认）时，如果在 Elasticsearch 中启用了该功能并具有所需的许可证，Filebeat 会自动使用索引生命周期管理； 否则，Filebeat 会每天创建一个新的索引。 setup.ilm.rollover_alias 索引生命周期写入别名。 默认值为 filebeat-%{[agent.version]}。 设置此选项会更改别名。 setup.ilm.pattern 翻转索引的模式。 默认值为 %{now/d}-000001。配合setup.ilm.rollover_alias决定索引的名称，例如：filebeat-7.7.1-2022.03.17-000001 setup.ilm.policy_name 用于生命周期策略的名称。 默认为filebeat。看上图 setup.ilm.policy_file 包含生命周期策略配置的 JSON 文件的路径。 使用此设置加载您自己定义的生命周期策略。 setup.ilm.check_exists 当设置为 false 时，禁用对现有生命周期策略的检查。 默认值为真。 如果连接到安全集群的 Filebeat 用户没有 read_ilm 权限，您需要禁用此检查。如果将此选项设置为 false，请设置 setup.ilm.overwrite: true 以便可以安装生命周期策略。 setup.ilm.overwrite 设置为 true 时，生命周期策略在启动时被覆盖。 默认值为false。 更多配置参考文档\n索引模板 索引模板定义了您可以在创建新索引时自动应用的设置和映射。 Elasticsearch 根据与索引名称匹配的索引模式将模板应用于新索引。\n您可以调整以下设置以加载自己的模板或覆盖现有模板。\nsetup.template.enabled 设置为 false 可禁用模板加载。如果将此值设置为 false，则必须手动加载模板。\nsetup.template.name 模板的名称。缺省值为filebeat 。版本始终附加到名称后，因此最终名称为 。filebeat-%{[agent.version]}\nsetup.template.pattern 要应用于默认索引设置的模板模式。缺省模式为filebeat-*。Filebeat 版本始终包含在模式中，因此最终模式为 filebeat-%{[agent.version]}-*。通配符用于匹配所有日期。\nsetup.template.fields 描述字段的 YAML 文件的路径。缺省值为fields.yml 。如果设置了相对路径，则将其视为相对于配置路径。\nsetup.template.overwrite 一个布尔值，它指定是否覆盖现有模板。默认值为 false。\nsetup.template.settings es索引的设置信息，例如下面的例子：\nsetup.template.name: \u0026#34;filebeat\u0026#34; setup.template.fields: \u0026#34;fields.yml\u0026#34; setup.template.overwrite: false setup.template.settings: index.number_of_shards: 1 index.number_of_replicas: 1 更多配置参考文档\n与kibana集成 配置 Kibana 仪表板 Filebeat 附带了示例 Kibana 仪表板、可视化效果和搜索，用于在 Kibana 中可视化 Filebeat 数据,例如nginx、mysql等。你可以通过配置kibana连接信息，来将这些 仪表板导入到kibana。\nsetup.kibana.host: \u0026#34;192.0.2.255:5601\u0026#34; setup.kibana.username: \u0026#34;\u0026#34; setup.kibana.password: \u0026#34;\u0026#34; setup.kibana.protocol: \u0026#34;http\u0026#34; setup.kibana.path: /kibana 要加载仪表板，您可以在配置文件的部分中启用仪表板加载，也可以运行setup命令。默认情况下，仪表板加载处于禁用状态。\n启用仪表板加载后，Filebeat 将使用 Kibana API 加载示例仪表板。仅当 Filebeat 启动时，才会尝试加载仪表板。如果 Kibana 在启动时不可用，Filebeat 将因错误而停止。\n要启用仪表板加载，请将以下设置添加到配置文件中：\nsetup.dashboards.enabled: true 更多配置参考文档，如果单纯是日志集成，可能不需要配置这些\n安装 安装命令：\ncurl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.7.1-amd64.deb sudo dpkg -i filebeat-7.7.1-amd64.deb 系统：Ubuntu WSL\n版本：filebeat-7.7.1-amd64.deb\n安装目录信息：\nType Location home /usr/share/filebeat bin /usr/share/filebeat/bin config /etc/filebeat data /var/lib/filebeat logs /var/log/filebeat 快速入门 前置要求：\n安装kibana 安装elasticsearch 启动命令：\nfilebeat -c filebeat.yaml -e 配置 filebeat.registry: flush: 1 #扩展 path.config: /etc/log_agent/filebeat path.data: /var/lib/log_agent/filebeat path.logs: /var/log/log_agent/filebeat filebeat.config.inputs: enabled: true path: ${path.config}/*.yml #扩展 reload.enabled: true reload.period: 10s filebeat.inputs: - type: log enabled: true paths: [\u0026#39;d:\\logs\\**\\*.log\u0026#39;,\u0026#39;e:\\logs\\**\\*.log\u0026#39;] multiline.pattern: \u0026#39;^\\[[0-9]{4}-[0-9]{2}-[0-9]{2}\u0026#39; multiline.negate: true multiline.match: after recursive_glob.enabled: true exclude_lines: [\u0026#39;\\$no_es\u0026#39;] ignore_older: 72h clean_inactive: 120h scan_frequency: 10s fields_under_root: false fields: env: staging #扩展 team: apollo output.elasticsearch: hosts: [\u0026#34;localhost:9200\u0026#34;] # output.console: # pretty: true # output.logstash: # hosts: [\u0026#34;127.0.0.1:5044\u0026#34;] processors: # - add_host_metadata: ~ - script: when: contains: message: \u0026#34;$to_decode\u0026#34; lang: javascript id: url_decode source: \u0026gt; function process(event) { var message=event.Get(\u0026#34;message\u0026#34;); event.Put(\u0026#34;message\u0026#34;, decodeURI(message)); } - script: when: contains: message: \u0026#34;$to_encode\u0026#34; lang: javascript id: password_encode source: \u0026gt; function process(event) { var message=event.Get(\u0026#34;message\u0026#34;); message= message.replace(/\\$to_encode\\{(.*)\\}/,\u0026#34;*****\u0026#34;); event.Put(\u0026#34;message\u0026#34;, message); } - dissect: tokenizer: \u0026#34;[%{log_date}] - %{thread} %{log_level} %{logger} %{msg}\u0026#34; field: \u0026#34;message\u0026#34; target_prefix: \u0026#34;service\u0026#34; - script: lang: javascript id: parse_service source: \u0026gt; function process(event) { var service=event.Get(\u0026#34;log.file.path\u0026#34;); var split=service.split(\u0026#34;\\\\\u0026#34;); var filname=split[split.length-1]; var names=filname.split(\u0026#39;-\u0026#39;); if(names.length==2){ event.Put(\u0026#34;service.name\u0026#34;, names[0]); var index=names[1].indexOf(\u0026#39;.\u0026#39;); if(index!=-1){ event.Put(\u0026#34;service.subName\u0026#34;, names[1].substring(0,index)); } } } - drop_fields: fields: [\u0026#34;agent\u0026#34;, \u0026#34;ecs\u0026#34;] ignore_missing: true 配置项目路径 Filebeat 在path.config查找 Elasticsearch 模板文件，并在path.logs写入日志文件。 Filebeat 在path.data查找其注册表文件。\npath.home: /usr/share/beat path.config: /etc/beat path.data: /var/lib/beat path.logs: /var/log/ home: filebeat的安装路径。默认值为 Filebeat 二进制文件的位置 config: 配置文件路径，包括主 YAML 配置文件和 Elasticsearch 模板文件 data: 数据文件的位置，这些数据文件主要存贮input需要监听的文件信息。filebeat称这些文件为注册表文件。在同一主机上运行多个 Filebeat 实例时，请确保每个实例都具有不同的path.data值。 log: filebeat运行日志的位置。 当你把filebeat.yaml放在外部位置时，可能需要配置上面的信息\n配置全局属性 控制诸如发布者行为和某些文件的位置。下面的配置都在filebeat 命名空间下，即：\nfilebeat.registry.path: ${path.data}/registry registry.path\n注册表的根路径。如果使用相对路径，则将其视为相对于数据路径。缺省值为 ${path.data}/registry。\n注册表将其数据存储在子目录 filebeat/data.json 中。它还包含一个名为 filebeat/meta.json 的元数据文件。元文件包含文件格式版本号。data.json的内容如下：\n[ { \u0026#34;source\u0026#34;: \u0026#34;d:\\\\logs\\\\aa.log\u0026#34;, \u0026#34;offset\u0026#34;: 28, \u0026#34;timestamp\u0026#34;: \u0026#34;2022-03-19T21:16:07.1332085+08:00\u0026#34;, \u0026#34;ttl\u0026#34;: -1, \u0026#34;type\u0026#34;: \u0026#34;log\u0026#34;, \u0026#34;meta\u0026#34;: null, \u0026#34;FileStateOS\u0026#34;: { \u0026#34;idxhi\u0026#34;: 9043968, \u0026#34;idxlo\u0026#34;: 148068, \u0026#34;vol\u0026#34;: 3840767598 } } ] 注册表仅在刷新新事件时更新，而不是在预定义的时间段内更新。这意味着，如果某些状态的 TTL 已过期，则只有在处理新事件时才会删除这些状态。\nregistry.file_permissions\n应用于注册表数据文件的权限掩码。默认值为 0600。\nregistry.flush\n控制何时将注册表项写入磁盘（刷新）的超时值。如果设置为 0s，则在每批事件成功发布后，注册表将写入磁盘。默认值为 0。\n当 Filebeat 正常关闭时，注册表始终会更新。异常关闭后，如果值为 \u0026gt;0s，则注册表将不是最新的。Filebeat 将再次发送已发布的事件（取决于上次更新的注册表文件中的值）。\n设置为值 \u0026gt;0 可减少写入操作，从而帮助 Filebeat 处理更多事件。\nshutdown_timeout\n在 Filebeat 关闭之前等待发布服务器完成发送事件的关闭时间。\n默认情况下，此选项处于禁用状态，Filebeat 不会等待发布者完成发送事件后才关闭。这意味着，当您重新启动 Filebeat 时，将再次发送发送到输出但在 Filebeat 关闭之前未确认的任何事件。\n您可以配置该选项以指定 Filebeat 在关闭之前等待发布服务器完成发送事件的最长时间。\n此选项不建议进行设置，因为正确值在很大程度上取决于 Filebeat 运行的环境和输出的当前状态。\n常规配置选项 由于它们是常用选项，因此它们不带命名空间。这些字段可以在用在input命名空间下。例如：\nname: \u0026#34;my-shipper\u0026#34; tags: [\u0026#34;service-X\u0026#34;, \u0026#34;web-tier\u0026#34;] name\nfilebeat的名称。如果此选项为空，则使用服务器的hostname 。该名称作为agent.name字段的值，包含在每个已发布的事件中。您可以使用该名称对单个 Beat 发送的所有交易进行分组。\ntags\n该值包含在日志事件的tags字段中。该值是数组\ntags: [\u0026#34;my-service\u0026#34;, \u0026#34;hardware\u0026#34;, \u0026#34;test\u0026#34;] fields\n该值包含在日志事件的fields字段中。该值可以是标量值、数组、字典或这些字段的任何嵌套组合\nfields: {project: \u0026#34;myproject\u0026#34;, instance-id: \u0026#34;574734885120952459\u0026#34;} fields_under_root\n如果此选项设置为 true，则fields字段的值将作为顶级域存储在输出文档中，而不是分组到fields子字典下。如果自定义字段名称与其他字段名称冲突，则自定义字段将覆盖其他字段\nprocessors\n数据的处理器列表。对日志事件进行转化解析等操作\nmax_procs\n设置可以同时执行的 CPU 的最大数量。默认值是系统中可用的逻辑 CPU 数。\n加载外部配置文件 Filebeat 可以为输入和模块加载外部配置文件，允许您将配置分成多个较小的配置文件。\n对于输入配置，请在文件部分指定filebeat.config.inputs选项。\nfilebeat.config.inputs: enabled: true path: inputs.d/*.yml 找到的每个文件都必须包含一个或多个输入定义的列表\n每个外部配置文件的第一行必须是以type开头的输入定义。例如：\n- type: log paths: - /var/log/mysql.log scan_frequency: 10s - type: log paths: - /var/log/apache.log scan_frequency: 5s 实时加载配置文件 Filebeat 发生更改时，支持动态重新加载外部配置文件。但是不支持重新加载主配置文件。\nfilebeat.config.inputs: enabled: true path: configs/*.yml reload.enabled: true reload.period: 10s 不要将 period 设置为小于 1s，因为文件的修改时间通常以秒为单位存储。将 period设置为小于 1 将导致不必要的开销\n日志配置 filebeat运行日志配置如下：\nlogging.level: info logging.to_files: true logging.files: path: /var/log/filebeat name: filebeat keepfiles: 7 permissions: 0644 除了在配置文件中设置日志记录选项外，还可以从命令行修改日志记录输出配置。\nlogging.to_stderr\n如果为 true，则将所有日志记录输出写入标准错误输出。这等效于使用-e命令行选项。\nlogging.to_syslog\n如果为 true，则将所有日志记录输出写入系统日志。\nlogging.to_eventlog\n如果为 true，则将所有日志记录输出写入 Windows 事件日志。\nlogging.to_files\n如果为 true，则将所有日志记录输出写入文件。当达到日志文件大小限制时，将自动轮换日志文件。\nlogging.level\ndebug、info、warning、error。缺省日志级别为 info。\nlogging.metrics.enabled\n记录性能指标。默认值为 true。下面是一个示例日志行：\n2017-12-17T19:17:42.667-0500 INFO [metrics] log/log.go:110 Non-zero metrics in the last 30s: beat.info.uptime.ms=30004 beat.memstats.gc_next=5046416 logging.metrics.period\n记录内部指标的时间段。默认值为 30 秒。\nlogging.files.path\n日志文件写入的目录。默认值为日志路径。\nlogging.files.name\n日志写入的文件的名称。默认值为 filebeat。\nlogging.files.rotateeverybytes\n日志文件的最大大小。如果达到限制，将生成一个新的日志文件。默认大小限制为 10485760 （10 MB）。\nlogging.files.keepfiles\n要保留在磁盘上的最新轮换日志文件数。较旧的文件在日志轮换期间被删除。默认值为 7。选项必须在 2 到 1024 个文件的范围内。\nlogging.files.permissions\n轮换日志文件时要应用的权限掩码。默认值为 0600。\n输入 这里主要讲log类型的输入，其他类型请参考官方文档。\nfilebeat.inputs: - type: log paths: - /var/log/system.log - /var/log/wifi.log - type: log paths: - \u0026#34;/var/log/apache2/*\u0026#34; fields: apache: true fields_under_root: true 主要的配置 paths\nGolang Glob模式的文件列表。 例如：/var/log/*/*.log。 这会从 /var/log 的子文件夹中获取所有 .log 文件， 但是不会从 /var/log 文件夹本身获取日志文件。\nrecursive_glob.enabled\n将 ** 扩展为递归 glob 模式。 启用此功能后，每个路径中最右边的 ** 将扩展为固定数量的 glob 模式。 例如：/foo/** 扩展为 /foo、/foo/*、/foo/*/* 等。 如果启用，它将单个**扩展为 8 级深度*模式。\n默认情况下启用此功能。\nencoding\n日志的文件编码。\nexclude_lines\n使用正则表达式排除行。如果指定了多行设置，则在 exclude_lines 过滤行之前，将多行消息合并为一行。\n以下示例将 Filebeat 配置为删除任何以 DBG 开头的行。\nfilebeat.inputs: - type: log ... exclude_lines: [\u0026#39;^DBG\u0026#39;] include_lines\n包含正则表达式匹配的行。 默认情况下，所有行都被导出。 空行被忽略。\n如果指定了多行设置，则每个多行消息在被 include_lines 过滤之前组合成一行。\nfilebeat.inputs: - type: log ... include_lines: [\u0026#39;^ERR\u0026#39;, \u0026#39;^WARN\u0026#39;] 如果同时定义了 include_lines 和 exclude_lines，Filebeat 会先执行 include_lines，然后再执行 exclude_lines。 这两个选项的定义顺序无关紧要。\nharvester_buffer_size\n每个收集器使用的缓冲区大小（以字节为单位）。 默认值为 16384。\nmax_bytes\n单个日志消息可以拥有的最大字节数。 max_bytes 之后的所有字节都被丢弃并且不发送。 默认值为 10MB (10485760)。\nexclude_files\n忽略匹配正则表达式的文件，可以用来进一步窄化paths指定的文件范围。\nfilebeat.inputs: - type: log ... exclude_files: [\u0026#39;\\.gz$\u0026#39;] 多行设置 下面是java中抛出的异常日志。我们要把这个多行归到一行。\n[beat-logstash-some-name-832-2015.11.28] IndexNotFoundException[no such index] at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:566) at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:133) at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:77) at org.elasticsearch.action.admin.indices.delete.TransportDeleteIndexAction.checkBlock(TransportDeleteIndexAction.java:75) 可以发现，正常的行开头都是 [ , 两个 [ 之间的文本，我们可以归为一行。所以我们配置如下：\nmultiline.pattern: \u0026#39;^\\[\u0026#39; multiline.negate: true multiline.match: after 与指定正则表达式匹配的行被视为前一行的延续或新多行事件的开始\nmultiline.negate\n定义模式是否被否定。默认值为false.\nmultiline.match\n指定 Filebeat 如何将匹配的行组合成一个事件。设置为after或before。\n设置为negate 设置为match 结果 例子pattern: ^b false after 匹配模式的连续行被附加到不匹配的前一行。 false before 与模式匹配的连续行被添加到下一个不匹配的行。 true after 不匹配模式的连续行将附加到匹配的前一行。 true before 与模式不匹配的连续行被添加到匹配的下一行。 multiline.flush_pattern\n指定一个正则表达式，其中当前的多行将从内存中刷新，结束多行消息。\nmultiline.max_lines\n可以组合成一个事件的最大行数。如果多行消息包含多于max_lines，则丢弃任何其他行。默认值为 500。\nmultiline.timeout\n在指定的超时之后，即使没有找到新的模式来启动新事件，Filebeat 也会发送多行事件。默认为 5 秒。\n运行方式配置 ignore\\_older 如果启用此选项，Filebeat 将忽略在指定时间跨度之前修改的所有文件。\n如果您长时间保留日志文件，配置ignore_older 可能特别有用。 例如，如果您想启动 Filebeat，但只想发送最新的文件和上周的文件，您可以配置此选项。\n您可以使用时间字符串，例如 2h（2 小时）和 5m（5 分钟）。 默认值为 0，即禁用该设置。\n受此设置影响的文件分为两类：\n之前未曾被收集过的文件 之前读取过，但是长时间没有更新的文件 对于以前从未见过的文件，偏移状态设置为文件末尾。 如果状态已经存在，则偏移量不会改变。 如果稍后再次更新文件，则在设置的偏移位置继续读取。\nignore_older 设置依赖于文件的修改时间来确定文件是否被忽略。 如果在将行写入文件时，文件的修改时间没有更新（这可能在 Windows 上发生），ignore_older 设置可能会导致 Filebeat 忽略该文件。\n在 Filebeat 可以忽略文件之前，必须关闭该文件。 为确保文件在被忽略时不再被收集，您必须将 ignore_older 设置为比 close_inactive 更长的时间。\n如果当前正在收割的文件属于ignore_older，则收集器将首先完成对该文件的读取，并在达到close_inactive后将其关闭。 然后，在那之后，该文件将被忽略。\nscan_frequency\n检查新文件的频率。 例如，如果您指定像 /var/log/* 这样的 glob，则使用 scan_frequency 指定的频率扫描目录中的新文件。 我们不建议将此值设置为 \u0026lt;1s。\n如果您需要近乎实时地发送日志行，请不要使用非常低的 scan_frequency， 而是调整 close_inactive 以便文件处理程序保持打开状态并不断轮询您的文件。\n默认设置为 10 秒。\nscan.sort\n指定扫描的顺序， 可能的值是 modtime 和 filename。 要按文件修改时间排序，请使用 modtime，否则使用 filename。 将此选项留空以禁用它。默认设置为禁用。\nscan.order\n指定升序或降序。可能的值是 asc 或 desc。默认设置为 asc。\ntail_files\n如果此选项设置为 true，Filebeat 会在每个文件的末尾而不是开头开始读取新文件。 当此选项与日志轮换结合使用时，可能会跳过新文件中的第一个日志条目。 默认设置为False。\n此选项适用于 Filebeat 尚未处理的文件。 如果您之前运行过 Filebeat 并且文件的状态已经持久化，tail_files 将不适用。\nsymlinks\n除了常规文件之外，该选项还允许 Filebeat 收集符号链接。收集符号链接时，Filebeat 打开并读取原始文件。\n当您配置符号链接以进行收集时，请确保排除原始路径。如果将单个输入配置为同时获取符号链接和原始文件，Filebeat 将检测到问题并仅处理它找到的第一个文件。但是，如果配置了两个不同的输入（一个用于读取符号链接，另一个用于读取原始路径），则两条路径都将被收集，导致 Filebeat 发送重复数据并且输入会覆盖彼此的状态。\n如果日志文件的符号链接在文件名中包含其他元数据，并且您希望在 Logstash 中处理元数据，则该symlinks选项可能很有用。例如，Kubernetes 日志文件就是这种情况。\n因为这个选项可能会导致数据丢失，所以默认是禁用的。\nbackoff 该backoff选项定义了 Filebeat 在到达 EOF 后再次检查文件之前等待的时间。默认值为 1s，这意味着如果添加了新行，则每秒检查一次文件。这可以实现近乎实时的爬行。每次文件中出现新行时，该backoff值都会重置为初始值。默认值为 1 秒。\nmax\\_backoff Filebeat 在达到 EOF 后再次检查文件之前等待的最长时间。等待时间是依次增加的，例如第一次1秒，第二次2*1秒，第三次**2*2*1，等待时间不会超过max_backoff. 这个2就是因子。默认值为 10 秒。\n要求：backoff \u0026lt;= max_backoff \u0026lt;= scan_frequency。如果max_backoff需要更高，建议改为关闭文件处理程序，让 Filebeat 重新拾取文件。\nbackoff\\_factor 此选项指定等待时间增加的速度。退避因子越大，达到max_backoff值的速度就越快。退避因子呈指数增长。默认值为 2。\nharvester\\_limit 为一个输入并行启动的收集器数量。这与打开的文件处理程序的最大数量直接相关。默认为harvester_limit0，表示没有限制。如果要收集的文件数量超过操作系统的打开文件处理程序限制，此配置很有用。\n对收集器的数量设置限制意味着可能并非所有文件都并行打开。因此，我们建议您将此选项与close_*选项结合使用，以确保更频繁地停止收集器，以便拾取新文件。\n目前，如果可以再次启动新的收集器，则收集器是随机采集的。这意味着可能会启动刚刚关闭然后再次更新的文件的收集器，而不是长时间未收割的文件的收集器。\nclose\\_\\* 配置 close_* 配置选项用于在特定条件或时间后关闭收集器。 关闭收集器意味着关闭文件处理程序。 scan_frequency时间过去后， 将再次收集该文件。 但是，如果在harvester 关闭时移动或删除文件，Filebeat 将无法再次拾取该文件，并且harvester 尚未读取的数据都将丢失。\nclose_inactive\n启用此选项后，如果在指定的时间段内未收集文件，Filebeat 将关闭文件句柄。当收集器读取最后一个日志行时，定义时间段的计数器开始计时。它不是基于文件的修改时间。如果关闭的文件再次更改，则会启动一个新的收集器，并在 scan_frequency 过去后获取最新的更改。\n我们建议您将 close_inactive 设置为大于日志文件更新的值。 例如，如果您的日志文件每隔几秒更新一次，您可以安全地将 close_inactive 设置为 1m。\n将 close_inactive 设置为较低的值意味着文件句柄会更快关闭。 然而，这有副作用，如果收集器关闭，新的日志行不会近乎实时地发送。\n关闭文件的时间戳不依赖于文件的修改时间。 相反，Filebeat 使用一个内部时间戳来反映文件上次获取的时间。 例如，如果 close_inactive 设置为 5 分钟，则 5 分钟的倒计时在 Harvester 读取文件的最后一行后开始。\n您可以使用时间字符串，例如 2h（2 小时）和 5m（5 分钟）。 默认值为 5m。\nclose_renamed\n启用此选项后，Filebeat 会在重命名文件时关闭文件处理程序。 例如，在旋转文件时会发生这种情况。 默认情况下，harvester 保持打开状态并继续读取文件，因为文件处理程序不依赖于文件名。 如果启用了 close_renamed 选项并且文件被重命名或移动，使得它不再与指定的文件模式匹配，则不会再次拾取文件。 Filebeat 将无法完成文件的读取。\n如果您的 Windows 日志轮换系统由于无法轮换文件而显示错误，您应该启用此选项。\nclose_removed\n启用此选项后，Filebeat 会在删除文件时关闭收集器。 通常，只有在 close_inactive 指定的时间内处于非活动状态后，才应删除文件。 但是，如果文件被提前删除并且您没有启用 close_removed，Filebeat 会保持文件打开以确保收集器已完成。 如果此设置导致文件由于过早从磁盘中删除而未完全读取，请禁用此选项。\n默认情况下启用此选项。 如果禁用此选项，则还必须禁用 clean_removed。\n如果您的 Windows 日志轮换系统由于无法轮换文件而显示错误，请确保启用此选项。\nclose_eof\n启用此选项后，Filebeat 会在到达文件末尾时立即关闭文件。 当您的文件只写入一次并且不时常更新时，这很有用。 默认情况下禁用此选项。\nclose_timeout\n启用此选项后，Filebeat 会为每个收集器提供预定义的生命周期。无论读取器在文件中的哪个位置，读取都将在 close_timeout 时间过后停止。\n虽然 close_timeout 将在预定义的超时后关闭文件，但如果文件仍在更新，Filebeat 将根据定义的 scan_frequency 再次启动新的收集器。并且这个收集器的 close_timeout 将重新开始超时倒计时。\n这个选项在输出被阻塞的情况下特别有用。将 close_timeout 设置为 5m 可确保文件定期关闭，以便操作系统可以释放它们。\n如果您将 close_timeout 设置为等于 ignore_older，则如果在收集器关闭时对其进行了修改，则不会拾取该文件。这种设置组合通常会导致数据丢失，并且不会发送完整的文件。\n当您对包含多行事件的日志使用 close_timeout 时，收集器可能会在多行事件的中间停止，这意味着只会发送部分事件。如果再次启动收集器并且文件仍然存在，则只会发送事件的第二部分。\n此选项默认设置为 0，这意味着它被禁用。\nclean\\_\\*配置 clean_* 选项用于清理注册表文件中的状态条目。 这些设置有助于减小注册表文件的大小，并且可以防止潜在的 inode 重用问题。\nclean_inactive\n启用此选项后，Filebeat 会在指定的不活动时间过后删除文件的状态。 只有当文件已经被 Filebeat 忽略时，才能删除状态。 **clean_inactive 设置必须大于 ignore_older **\nscan_frequency 确保在仍在收集文件时不会被删除任何状态。 否则，该设置可能会导致 Filebeat 不断地重新发送完整内容，因为 clean_inactive 会删除 Filebeat 仍检测到的文件的状态。 如果文件被更新或再次出现，则从头开始读取该文件。\nclean_inactive 配置选项对于减小注册表文件的大小很有用，尤其是在每天生成大量新文件的情况下。\n此配置选项对于防止 Linux 上因 inode 重用而导致的 Filebeat 问题也很有用。\nclean_removed\n启用此选项后，如果无法在磁盘上找到文件，Filebeat 会从注册表中清除文件。 这意味着重命名的文件也将被删除。 默认情况下启用此选项。\n如果共享驱动器在短时间内消失并再次出现，则会从头开始重新读取所有文件，因为已从注册表文件中删除了状态。 在这种情况下，我们建议您禁用 clean_removed 选项。\n如果您还禁用 close_removed，则必须禁用此选项。\n机制总结 当文件到末尾时？\n当日志收集到达文件末尾时，收集器会等待backoff（默认1s）,然后重新读取文件是否有更新。 如果文件没有更新，收集器会等待 backoff=backoff(上一次的)*backoff_factor(默认2) 当backoff超过max_backoff时，backoff会重新开始计数。 当文件长时间不更新时？\n当在 close_inactive（默认5m）没有新事件被收集，收集器会被关闭。 经过scan_frequency（默认10s）,收集器会被重新打开。 当文件旋转时？\n文件旋转时，会把当前文件重命名，然后移动位置。然后创建新的空的文件写入新的日志。 默认情况下， 收集器还会监听老文件，即被重命名的文件。直到超过close_inactive时间，才会关闭这个文件。 经过scan_frequency时间，会重新读取这个文件，这种情况明显不是我们想要的。一般旋转后的文件都会被归档，基本不会发生变更了，收集器重新打开这个文件，虽然不会读取已经读取过的数据，但是会占用资源。怎样避免这种情况呢？ ignore_older属性就是解决这个问题的，他会忽略长时间没有更新的文件。 虽然这个文件不会被读取了，但是仍然在在注册表中记录，我们还需要清除这个记录，通过配置clean_inactive 达到目的，这个值要大于ignore_older 当文件删除时？\n文件被删除，收集器仍然会占用这个文件，直到超过close_inactive，该文件才会被真正删除 定义处理器 在将数据发送到配置的输出之前，可以使用处理器来筛选和增强数据。要定义处理器，请指定处理器名称、可选条件和一组参数：\nprocessors: - \u0026lt;processor_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; - \u0026lt;processor_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; \u0026lt;processor_name\u0026gt;指定执行某种操作（如选择导出的字段或向事件添加元数据）的处理器。 \u0026lt;condition\u0026gt;指定可选条件。如果条件存在，则仅当满足条件时才执行操作。如果未设置任何条件，则始终执行该操作。 \u0026lt;parameters\u0026gt;是要传递给处理器的参数列表。 更复杂的条件处理可以通过使用 if-then-else 处理器配置来完成。这允许基于单个条件执行多个处理器。\nprocessors: - if: \u0026lt;condition\u0026gt; then: - \u0026lt;processor_name\u0026gt;: \u0026lt;parameters\u0026gt; - \u0026lt;processor_name\u0026gt;: \u0026lt;parameters\u0026gt; ... else: - \u0026lt;processor_name\u0026gt;: \u0026lt;parameters\u0026gt; - \u0026lt;processor_name\u0026gt;: \u0026lt;parameters\u0026gt; 处理器在哪里有效？ 处理器有效：\n在配置的顶层。处理器应用于 Filebeat 收集的所有数据。 在特定输入下。处理器应用于为该输入收集的数据。 - type: \u0026lt;input_type\u0026gt; processors: - \u0026lt;processor_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; 注意事项 两个正在运行的输入没有定义重叠的文件路径。如果多个输入同时收集同一文件，则可能导致意外行为。 日志轮换导致事件丢失或重复 Filebeat 支持从旋转日志文件中读取数据。但是，某些日志轮换策略在使用 Filebeat 转发消息时可能会导致丢失或重复的事件。要解决此问题，请执行以下操作：\n避免复制和截断日志文件的日志轮换策略 复制和截断输入日志文件的日志轮换策略可能会导致 Filebeat 发送重复事件。发生这种情况是因为 Filebeat 通过 inode 和设备名称标识文件。在日志轮换期间，Filebeat 已处理的行将移动到新文件中。当 Filebeat 遇到新文件时，它会从头开始读取，因为以前的状态信息（偏移量和读取时间戳）与旧文件的 inode 和设备名称相关联。\n此外，如果将行写入日志文件是在复制之后但在截断之前写入日志文件，则复制和截断输入日志文件的策略可能会导致事件丢失。\n确保 Filebeat 配置为从所有轮换的日志中读取 在日志轮换期间移动或重命名输入日志文件时，Filebeat 能够识别该文件已被读取。轮换文件后，将创建一个新的日志文件，并且应用程序将继续日志记录。Filebeat 在下次扫描期间选取新文件。由于文件具有新的 inode 和设备名称，因此 Filebeat 会从头开始读取它。\n若要避免从轮换文件中丢失事件，请将输入配置为从日志文件和所有轮换文件中读取。下面是具体的配置信息。\nlogrotate 是一种用于在 Linux 上执行日志轮换的常用工具，后跟读取所有轮换日志的 Filebeat 配置。\n**logrotate.conf，**日志每天轮换，并使用指定的权限创建新文件。\n/var/log/my-server/my-server.log { daily missingok rotate 7 notifempty create 0640 www-data www-data } 在此示例中，Filebeat 配置为读取所有日志文件，以确保它不会错过任何事件。\nfilebeat.inputs: - type: log enabled: false paths: - /var/log/my-server/my-server.log* logstash还是beats Beats 是轻量级数据传送器，您可以将其作为代理安装在服务器上，以将特定类型的操作数据发送到 Elasticsearch。Beats 占用空间小，使用的系统资源比 Logstash 少。\nLogstash 的占用空间较大，但提供了广泛的输入、过滤器和输出插件，用于从各种源收集、丰富和转换数据。\n规范 如何我们不想在项目中配置filebeat文件，就需要项目产生日志的时候，遵循下面的约定.\n加密 如果某行日志需要加密输出，你在日志中输出 $to_encode{content}， 我们会对这个字符串之后的内容进行 **加密， 注意这种格式不能解密\n解密 如果你的url是加密的，，你在日志中输出 $to_decode， 我们会对这个字符串之后的内容进行base64解密\n排除行 有些时候，我们不希望有些日志输出到es，可以在日志中包含 $no_es 字符串\n日志文件的命名 服务名称-服务类型-其他标识.log\n服务名称用来识别是哪个应用 服务类型有这几类： short：标识是个job（运行完任务之后，进程就不存在了）类型的应用产生的日志。 shell：标识是shell脚本运行后产生的日志。存在shell 调用job的情况，如何关联呢？ service: 标识是一个web服务产生的日志。 如果你不知道这个属性怎么设置，就写成service即可。 服务的名称和类型会在kibana中用于检索。\n日志文件的位置 filebeat默认会读取 /var/lib/applogs （一级目录）目录下的日志，你需要把日志存储到这个目录下的三个子目录（二级目录）：\nshort：对应服务类型short shell：对应服务类型shell service: 对应服务类型service 你可以在二级目录下面新建目录来区分日志，嵌套不要超过三层。超过这些日志数据可能不会被推送。\n之所以对日志这样切分，是为了性能考虑。service类型需要我们一直监听事件 ，shell 和short 我们可以间隔很长时间去监听以下是否有新数据到达。\n日志轮转问题 使用者不需要配置。但我们应该配置\n多行日志 [2022-03-21 14:19:47.891] - [main] ERROR cn.zhao.FileBeatTest zzq exception java.lang.ArithmeticException: / by zero at cn.zhao.FileBeatTest.testError(FileBeatTest.java:19) at cn.zhao.FileBeatTest.main(FileBeatTest.java:13) 请保证每行的开头是 [ , 正则格式是 ^\\[[0-9]{4}-[0-9]{2}-[0-9]{2}\n问题：\n服务名称和服务类型可能不会被很好的规范，使用java-agent技术解决这个问题。\nlinux alias 解决echo 问题？\n主配置文件内容：\nfilebeat.registry: flush: 1 #扩展 path.home: D:\\dev_soft\\filebeat-7.7.1-windows-x86_64 path.config: D:\\filebeat\\config path.data: D:\\filebeat\\data path.logs: D:\\filebeat\\logs filebeat.config.inputs: enabled: true path: ${path.config}/*.yml #扩展 reload.enabled: true reload.period: 10s filebeat.inputs: - type: log enabled: true paths: #扩展 - d:\\logs\\**\\*.log multiline.pattern: \u0026#39;^\\[[0-9]{4}-[0-9]{2}-[0-9]{2}\u0026#39; multiline.negate: true multiline.match: after recursive_glob.enabled: true exclude_lines: [\u0026#39;\\$no_es\u0026#39;] ignore_older: 72h clean_inactive: 120h scan_frequency: 10s filebeat.config.modules: path: ${path.config}/modules.d/*.yml # 扩展 reload.enabled: true #name: # 扩展 tags: [\u0026#34;apollo\u0026#34;,\u0026#34;158459\u0026#34;] # 扩展 fields: env: staging #扩展 # output.elasticsearch: # hosts: [\u0026#34;localhost:9200\u0026#34;] output.console: pretty: true processors: # - add_host_metadata: ~ - script: lang: javascript id: url_decode source: \u0026gt; function process(event) { var message=event.Get(\u0026#34;message\u0026#34;); if(message.indexOf(\u0026#34;$to_decode\u0026#34;)!=-1){ event.Put(\u0026#34;message\u0026#34;, decodeURI(message)); } } - script: lang: javascript id: password_encode source: \u0026gt; function process(event) { var message=event.Get(\u0026#34;message\u0026#34;); if(message.indexOf(\u0026#34;$to_encode\u0026#34;)!=-1){ message= message.replace(/\\$to_encode\\{(.*)\\}/,\u0026#34;*****\u0026#34;); event.Put(\u0026#34;message\u0026#34;, message); } } - dissect: tokenizer: \u0026#34;[%{log_date}] - %{thread} %{log_level} %{logger} %{msg}\u0026#34; field: \u0026#34;message\u0026#34; target_prefix: \u0026#34;service\u0026#34; - script: lang: javascript id: parse_service source: \u0026gt; function process(event) { var service=event.Get(\u0026#34;log.file.path\u0026#34;); var split=service.split(\u0026#34;\\\\\u0026#34;); var filname=split[split.length-1]; var names=filname.split(\u0026#39;-\u0026#39;); if(names.length==2){ event.Put(\u0026#34;service.name\u0026#34;, names[0]); var index=names[1].indexOf(\u0026#39;.\u0026#39;); if(index!=-1){ event.Put(\u0026#34;service.type\u0026#34;, names[1].substring(0,index)); } } } 用户自定义示例 如果上面的规范不能满足你的需求，你可以自定义filebeat配置文件。\n你只需要将定义好的配置文件上传到我们指定的目录即可，大约10s，配置就会生效。\n注意： 自定义支持：\n日志文件的位置 多行 排除行 处理器 下面是该文件的详细格式：\n- type: log enabled: true paths: #扩展 - d:\\logs\\**\\*.log # 日志文件的位置 multiline.pattern: \u0026#39;^\\[[0-9]{4}-[0-9]{2}-[0-9]{2}\u0026#39; #多行内容开始 multiline.negate: true multiline.match: after recursive_glob.enabled: true exclude_lines: [\u0026#39;\\$no_es\u0026#39;] # 排除行的规则 ignore_older: 72h # 默认 clean_inactive: 120h # 默认 scan_frequency: 10s # 默认 processors: # 指定处理器 - \u0026lt;processor_name\u0026gt;: when: \u0026lt;condition\u0026gt; \u0026lt;parameters\u0026gt; 处理器类型请参考 Add fields | Filebeat Reference [7.7] | Elastic\n注意： filebeat的版本是7.x\n上线的步骤：\nudeploy统一部署filbeat ,将著配置文件定义好，将监听配置文件定义好 用户按照规范，是不需要定义filebeat的配置文件的 如果用户想要自定义一些规范，请将配置文件安装到监听配置文件的目录。 ","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/filebeat/","series":[],"smallImg":"","tags":[{"title":"filebeat","url":"/myblog/tags/filebeat/"},{"title":"监控","url":"/myblog/tags/%E7%9B%91%E6%8E%A7/"}],"timestamp":1669580132,"title":"Filebeat"},{"authors":[],"categories":[{"title":"java","url":"/myblog/categories/java/"}],"content":"Feign是一个声明式的Web服务客户端，web调用的代码仅仅只需要声明接口和注解。\n它具有可插入的注释支持，包括Feign注释和JAX-RS注释。 Feign支持可插拔编码器和解码器。 增加了对Spring MVC注释的支持，并默认使用与Spring Web相同HttpMessageConverters。 Spring Cloud集成了CircuitBreaker和Eureka，Spring Cloud LoadBalancer。 快速入门 引入依赖 implementation \u0026#39;org.springframework.cloud:spring-cloud-starter-openfeign\u0026#39; 注解开启 @SpringBootApplication @EnableFeignClients public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 客户端声明 @FeignClient(\u0026#34;stores\u0026#34;) public interface StoreClient { @RequestMapping(method = RequestMethod.GET, value = \u0026#34;/stores\u0026#34;) List\u0026lt;Store\u0026gt; getStores(); @RequestMapping(method = RequestMethod.POST, value = \u0026#34;/stores/{storeId}\u0026#34;, consumes = \u0026#34;application/json\u0026#34;) Store update(@PathVariable(\u0026#34;storeId\u0026#34;) Long storeId, Store store); } @FeignClient的值是服务的名称,主要用来负载均衡.当然也可以用url属性来指定具体的地址.该接口在上下文中注册的bean名称是完全限定名称,你可以使用qualifier属性来指定别名.\n上面的 load-balancer 客户端将要发现“strore”服务实际的物理地址。如果您的应用程序是Eureka客户端，那么它将解析Eureka服务注册表中的服务。如果您不想使用Eureka，则只需在外部配置中配置服务器列表即可.\nSpring Cloud OpenFeign 支持 Spring Cloud LoadBalancer 阻塞模式下所有可用的功能\n配置 feign的核心是命名客户端,每个客户端是一组链接远程服务的组件,开发人员通过@FeignClient注解指定这组组件的名称。Spring Cloud使用FeignClientsConfiguration按需为每个命名客户端创建一个新的集合作为ApplicationContext. 这包含feign.Decoder，feign.Encoder和feign.Contract。 可以使用@FeignClient批注的contextId属性覆盖该集合的名称。\n@EnableFeignClients注解使用在spring配置类上：\nbasePackages：指定client所在包，例如：@EnableFeignClients(basePackages = \u0026quot;com.example.clients\u0026quot;) clients：直接指定具体的client,例如：@EnableFeignClients(clients = InventoryServiceFeignClient.class) Feign 继承支持 Feign 通过单继承接口支持样板 API。 这允许将常见操作分组到方便的基本接口中。\npublic interface UserService { @RequestMapping(method = RequestMethod.GET, value =\u0026#34;/users/{id}\u0026#34;) User getUser(@PathVariable(\u0026#34;id\u0026#34;) long id); } @RestController public class UserResource implements UserService { } package project.user; @FeignClient(\u0026#34;users\u0026#34;) public interface UserClient extends UserService { } 通常不建议在服务器和客户端之间共享一个接口。 它引入了紧耦合，也不是所有维护的 Spring MVC 版本都支持（某些版本没有继承方法参数映射）。\nJAVA配置 Spring Cloud允许您通过使用@FeignClient声明其他配置（在FeignClientsConfiguration之上）来完全控制feign客户端。 例：\n@FeignClient(name = \u0026#34;stores\u0026#34;, configuration = FooConfiguration.class) public interface StoreClient { //.. } 在这种情况下，客户端由FeignClientsConfiguration中默认的组件以及FooConfiguration中的组件组成（后者将覆盖前者）。\nFooConfiguration类不需要被@Configuration标注.注意不要配置在@ComponentScan指定的包范围,否则会成为全局默认配置.\n使用@FeignClient的contextId属性，除了更改ApplicationContext集合的名称之外，，它还会覆盖客户端名称的别名，并将其用作该客户端创建的配置bean名称的一部分。\nname和url属性支持占位符:\n@FeignClient(name = \u0026#34;${feign.name}\u0026#34;, url = \u0026#34;${feign.url}\u0026#34;) public interface StoreClient { //.. } Spring Cloud OpenFeign默认为feign（BeanType beanName：ClassName）提供以下bean：\nDecoder feignDecoder: ResponseEntityDecoder (which wraps a SpringDecoder) , 解析response，使用messageConverters转换实体 Encoder feignEncoder: SpringEncoder , 将请求参数填充到请求体中 ，使用messageConverters转换实体 Logger feignLogger: Slf4jLogger， 定义日志打印的模板方法 MicrometerCapability micrometerCapability: If feign-micrometer is on the classpath and MeterRegistry is available CachingCapability cachingCapability: If @EnableCaching annotation is used. Can be disabled via spring.cloud.openfeign.cache.enabled. 包装其他组件，增强fegin的能力 Contract feignContract: SpringMvcContract 。Feign Contract 对象定义了接口上哪些注解和值是有效的 。SpringMvcContract 提供对 SpringMVC 注释的支持，而不是默认的 Feign 原生注释。 Feign.Builder feignBuilder: FeignCircuitBreaker.Builder Client feignClient: Spring Cloud LoadBalancer 在类路径上，则使用 FeignBlockingLoadBalancerClient。 如果它们都不在类路径上，则使用默认的 feign 客户端。 spring-cloud-starter-openfeign 支持 spring-cloud-starter-loadbalancer。 但是，作为一个可选的依赖项，如果您想使用它，您需要确保将其添加到您的项目中。\n可以通过将feign.okhttp.enabled或feign.httpclient.enabled分别设置为true并将依赖放在类路径上来使用OkHttpClient和ApacheHttpClient作为feign的底层客户端。 您可以在使用OK时使用OkHttpClient或者Apache时使用ClosableHttpClient的bean来自定义所使用的HTTP客户端。\nSpring Cloud OpenFeign 默认情况下不为feign提供以下bean，但仍然从应用程序上下文中查找这些类型的bean以创建feign客户端：\nLogger.Level Retryer ErrorDecoder Request.Options Collection SetterFactory QueryMapEncoder Capability (MicrometerCapability and CachingCapability are provided by default) 默认情况下会创建 Retryer.NEVER_RETRY 类型为 Retryer 的 bean，这将禁用重试。 请注意，这种重试行为与 Feign 默认行为不同，它会自动重试 IOExceptions，openfeign将它们视为与网络相关的瞬态异常，以及从 ErrorDecoder 抛出的任何 RetryableException。\n创建其中一种类型的 bean 并将其放置在 @FeignClient 配置中（例如上面的 FooConfiguration）允许您覆盖所描述的每个 bean。 例子：\n@Configuration public class FooConfiguration { @Bean public Contract feignContract() { return new feign.Contract.Default(); } @Bean public BasicAuthRequestInterceptor basicAuthRequestInterceptor() { return new BasicAuthRequestInterceptor(\u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;); } } 这将 SpringMvcContract 替换为 feign.Contract.Default 并将 RequestInterceptor 添加到 RequestInterceptor 的集合中。\n属性配置方式 @FeignClient 也可以使用配置属性进行配置:\nspring: cloud: openfeign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer defaultQueryParameters: query: queryValue defaultRequestHeaders: header: headerValue requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false encoder: com.example.SimpleEncoder decoder: com.example.SimpleDecoder contract: com.example.SimpleContract capabilities: - com.example.FooCapability - com.example.BarCapability queryMapEncoder: com.example.SimpleQueryMapEncoder metrics.enabled: false @EnableFeignClients 属性 defaultConfiguration 中指定默认配置类。 此配置将适用于所有 feign 客户端。如果您更喜欢使用配置属性来配置所有 @FeignClient，您可以使用 default 名称创建默认配置属性。\nfeign: client: config: default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic 您可以使用 feign.client.config.feignName.defaultQueryParameters 和 feign.client.config.feignName.defaultRequestHeaders 给所有请求添加默认请求参数和请求头。\n如果我们同时创建@Configuration bean 和配置属性，配置属性将获胜。 它将覆盖@Configuration 值。 但是如果你想把优先级改成@Configuration，你可以把feign.client.default-to-properties改成false。\ncontextId 的作用 如果我们想创建多个具有相同名称或 url 的 feign 客户端，以便它们指向同一服务器但每个具有不同的自定义配置，那么我们必须使用 @FeignClient 的 contextId 属性以避免这些配置的bean名称冲突。\n@FeignClient(contextId = \u0026#34;fooClient\u0026#34;, name = \u0026#34;stores\u0026#34;, configuration = FooConfiguration.class) public interface FooClient { //.. } @FeignClient(contextId = \u0026#34;barClient\u0026#34;, name = \u0026#34;stores\u0026#34;, configuration = BarConfiguration.class) public interface BarClient { //.. } 也可以将 FeignClient 配置为不从父上下文继承 bean。 您可以通过覆盖 FeignClientConfigurer bean 中的 inheritParentConfiguration() 以返回 false 来实现此目的：\n@Configuration public class CustomConfiguration{ @Bean public FeignClientConfigurer feignClientConfigurer() { return new FeignClientConfigurer() { @Override public boolean inheritParentConfiguration() { return false; } }; } } SpringEncoder 在我们提供的 SpringEncoder 中，我们为二进制内容类型设置空字符集，为所有其他类型设置 UTF-8。\n您可以修改此行为以通过将 feign.encoder.charset-from-content-type 的值设置为 true 来从 Content-Type 标头字符集派生字符集。\n常用配置 超时设置 我们可以在默认客户端和具名客户端上配置超时。 OpenFeign 使用两个超时参数：\nconnectTimeout 可防止由于服务器处理时间过长而阻塞调用者。 readTimeout 从连接建立时开始应用，并在返回响应时间过长时触发。 日志 为每个创建的 Feign 客户端创建一个logger。 默认情况下，logger的名称是用于创建 Feign 客户端的接口的完整类名。 Feign logging 只响应 DEBUG 级别。所以必须开启下面的级别\nlogging.level.project.user.UserClient: DEBUG 此外还需要将 Logger.Level 设置为 FULL才会打印日志：\n@Configuration public class FooConfiguration { @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; } } NONE: 默认级别 BASIC：仅记录请求方法和 URL 以及响应状态代码和执行时间。 HEADERS：记录基本信息以及请求和响应标头。 FULL：记录请求和响应的标头、正文和元数据。 请求和响应压缩 您可以考虑为您的 Feign 请求启用请求或响应 GZIP 压缩。 您可以通过启用以下属性之一来执行此操作：\nspring.cloud.openfeign.compression.request.enabled=true spring.cloud.openfeign.compression.response.enabled=true Feign 请求压缩为您提供类似于您为 Web 服务器设置的设置：\nspring.cloud.openfeign.compression.request.enabled=true spring.cloud.openfeign.compression.request.mime-types=text/xml,application/xml,application/json spring.cloud.openfeign.compression.request.min-request-size=2048 这些属性允许您选择压缩媒体类型和最小请求阈值长度。\n手动创建客户端 下面是一个示例，它创建了两个具有相同接口的 Feign 客户端，但为每个客户端配置了一个单独的请求拦截器。\n@Import(FeignClientsConfiguration.class) class FooController { private FooClient fooClient; private FooClient adminClient; @Autowired public FooController(Client client, Encoder encoder, Decoder decoder, Contract contract, MicrometerCapability micrometerCapability) { this.fooClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .contract(contract) .addCapability(micrometerCapability) .requestInterceptor(new BasicAuthRequestInterceptor(\u0026#34;user\u0026#34;, \u0026#34;user\u0026#34;)) .target(FooClient.class, \u0026#34;https://PROD-SVC\u0026#34;); this.adminClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .contract(contract) .addCapability(micrometerCapability) .requestInterceptor(new BasicAuthRequestInterceptor(\u0026#34;admin\u0026#34;, \u0026#34;admin\u0026#34;)) .target(FooClient.class, \u0026#34;https://PROD-SVC\u0026#34;); } } 上面例子中的 FeignClientsConfiguration.class 是 Spring Cloud OpenFeign 提供的默认配置。\n断路器 如果 Spring Cloud CircuitBreaker 在类路径上并且 spring.cloud.openfeign.circuitbreaker.enabled=true，Feign 将使用断路器包装所有方法。\n要在每个客户端的基础上禁用 Spring Cloud CircuitBreaker 支持，请创建一个具有“prototype”范围的 vanilla Feign.Builder，例如：\n@Configuration public class FooConfiguration { @Bean @Scope(\u0026#34;prototype\u0026#34;) public Feign.Builder feignBuilder() { return Feign.builder(); } } 更改断路器名称 断路器名称遵循此模式 \u0026lt;feignClientClassName\u0026gt;#\u0026lt;CalledMethod\u0026gt;(\u0026lt;parameterTypes\u0026gt;)。 例如调用上面的FooClient的bar方法，断路器名称将是 FooClient#bar()。\n使用 CircuitBreakerNameResolver bean，更改断路器名称：\n@Configuration public class FooConfiguration { @Bean public CircuitBreakerNameResolver circuitBreakerNameResolver() { return (String feignClientName, Target\u0026lt;?\u0026gt; target, Method method) -\u0026gt; feignClientName + \u0026#34;_\u0026#34; + method.getName(); } } 要启用 Spring Cloud CircuitBreaker 组，请将spring.cloud.openfeign.circuitbreaker.group.enabled属性设置为 true（默认为 false）。\n属性方式配置断路器 假如有下面的客户端：\n@FeignClienturl = \u0026#34;http://localhost:8080\u0026#34;) public interface DemoClient { @GetMapping(\u0026#34;demo\u0026#34;) String getDemo(); } 对应的属性配置：\nfeign: circuitbreaker: enabled: true alphanumeric-ids: enabled: true resilience4j: circuitbreaker: instances: DemoClientgetDemo: minimumNumberOfCalls: 69 timelimiter: instances: DemoClientgetDemo: timeoutDuration: 10s 失败回退 Spring Cloud CircuitBreaker 支持回退的概念：当电路打开或出现错误时执行默认代码路径。 要为给定的 @FeignClient 启用回退，请将fallback属性设置为实现回退的类名。 您还需要将您的实现声明为 Spring bean。\n@FeignClient(name = \u0026#34;test\u0026#34;, url = \u0026#34;http://localhost:${server.port}/\u0026#34;, fallback = Fallback.class) protected interface TestClient { @RequestMapping(method = RequestMethod.GET, value = \u0026#34;/hello\u0026#34;) Hello getHello(); @RequestMapping(method = RequestMethod.GET, value = \u0026#34;/hellonotfound\u0026#34;) String getException(); } @Component static class Fallback implements TestClient { @Override public Hello getHello() { throw new NoFallbackAvailableException(\u0026#34;Boom!\u0026#34;, new RuntimeException()); } @Override public String getException() { return \u0026#34;Fixed response\u0026#34;; } } 如果需要访问触发回退的原因，可以使用 @FeignClient 中的 fallbackFactory 属性。\n@FeignClient(name = \u0026#34;testClientWithFactory\u0026#34;, url = \u0026#34;http://localhost:${server.port}/\u0026#34;, fallbackFactory = TestFallbackFactory.class) protected interface TestClientWithFactory { @RequestMapping(method = RequestMethod.GET, value = \u0026#34;/hello\u0026#34;) Hello getHello(); @RequestMapping(method = RequestMethod.GET, value = \u0026#34;/hellonotfound\u0026#34;) String getException(); } @Component static class TestFallbackFactory implements FallbackFactory\u0026lt;FallbackWithFactory\u0026gt; { @Override public FallbackWithFactory create(Throwable cause) { return new FallbackWithFactory(); } } static class FallbackWithFactory implements TestClientWithFactory { @Override public Hello getHello() { throw new NoFallbackAvailableException(\u0026#34;Boom!\u0026#34;, new RuntimeException()); } @Override public String getException() { return \u0026#34;Fixed response\u0026#34;; } } @Primary注解 将 Feign 与 Spring Cloud CircuitBreaker 回退一起使用时，ApplicationContext 中有多个相同类型的 bean。 这将导致 @Autowired 无法工作，因为没有一个 bean，或者一个标记为primary的 bean。 为了解决这个问题，Spring Cloud OpenFeign 将所有 Feign 实例标记为 @Primary，因此 Spring Framework 知道要注入哪个 bean。 在某些情况下，这可能是不可取的。 要关闭此行为，请将 @FeignClient 的primary属性设置为 false。\n@FeignClient(name = \u0026#34;hello\u0026#34;, primary = false) public interface HelloClient { // methods here } 框架支持 @QueryMap支持 OpenFeign @QueryMap 注释支持将 POJO 用作 GET 参数映射。不幸的是，默认的 OpenFeign QueryMap 注释与 Spring 不兼容，因为它缺少 value 属性。Spring Cloud OpenFeign 提供了一个等效的 @SpringQueryMap 注解，用于将 POJO 或 Map 参数注解为查询参数映射。\n// Params.java public class Params { private String param1; private String param2; // [Getters and setters omitted for brevity] } @FeignClient(\u0026#34;demo\u0026#34;) public interface DemoTemplate { @GetMapping(path = \u0026#34;/demo\u0026#34;) String demoEndpoint(@SpringQueryMap Params params); } 如果您需要对生成的查询参数映射进行更多控制，则可以实现自定义 QueryMapEncoder bean。\nCollectionFormat 支持 我们通过提供@CollectionFormat 注释来支持 feign.CollectionFormat。您可以通过传递所需的 feign.CollectionFormat 作为注释值来注释 Feign 客户端方法。\n在以下示例中，使用 CSV 格式而不是默认的 EXPLODED 来处理方法。\n@FeignClient(name = \u0026#34;demo\u0026#34;) protected interface PageableFeignClient { @CollectionFormat(feign.CollectionFormat.CSV) @GetMapping(path = \u0026#34;/page\u0026#34;) ResponseEntity performRequest(Pageable page); } spring data支持 您可以考虑启用 Jackson Modules 以支持 org.springframework.data.domain.Page 和 org.springframework.data.domain.Sort 解码。\nfeign.autoconfiguration.jackson.enabled=true RefreshScope支持 如果启用了 Feign 客户端刷新，则每个 feign 客户端都会使用 feign.Request.Options 作为刷新范围的 bean 创建。 这意味着可以通过 POST /actuator/refresh 针对任何 Feign 客户端实例刷新诸如 connectTimeout 和 readTimeout 之类的属性。\n默认情况下，Feign 客户端中的刷新行为是禁用的。 使用以下属性启用刷新行为：\nfeign.client.refresh-enabled=true OAuth2 Support 可以通过设置以下标志来启用 OAuth2 支持：\nspring.cloud.openfeign.oauth2.enabled=true 当标志设置为 true 并且存在 oauth2 客户端上下文资源详细信息时，将创建 OAuth2FeignRequestInterceptor 类的 bean。 在每个请求之前，拦截器解析所需的访问令牌并将其作为标头包含在内。 有时，当为 Feign 客户端启用负载平衡时，您可能也希望使用负载平衡来获取访问令牌。 为此，您应该确保负载均衡器位于类路径 (spring-cloud-starter-loadbalancer) 上，并通过设置以下标志显式启用 OAuth2FeignRequestInterceptor 的负载均衡：\nspring.cloud.openfeign.oauth2.load-balanced=true capabilities 功能 Feign capabilities 公开了核心 Feign 组件，以便可以修改这些组件。 例如，capabilities 可以获取客户端，对其进行装饰，并将装饰后的实例返回给 Feign。 对指标库的支持是一个很好的现实例子。 请参阅 Feign 指标。\n创建一个或多个 Capability bean 并将它们放置在 @FeignClient 配置中，让您可以注册它们并修改相关客户端的行为。\n@Configuration public class FooConfiguration { @Bean Capability customCapability() { return new CustomCapability(); } } Feign 指标 如果以下所有条件都为真，则会创建并注册 MicrometerCapability bean，以便您的 Feign 客户端将指标发布到 Micrometer：\nfeign-micrometer 在类路径上 MeterRegistry bean 可用 feign 指标属性设置为 true（默认情况下） spring.cloud.openfeign.metrics.enabled=true (所有客户端) spring.cloud.openfeign.client.config.feignName.metrics.enabled=true (单个客户端) 您还可以通过注册自己的 bean 来自定义 MicrometerCapability：\n@Configuration public class FooConfiguration { @Bean public MicrometerCapability micrometerCapability(MeterRegistry meterRegistry) { return new MicrometerCapability(meterRegistry); } } Feign 缓存 如果使用@EnableCaching 注解，则会创建并注册一个 CachingCapability bean，以便您的 Feign 客户端识别其接口上的 @Cache* 注解：\npublic interface DemoClient { @GetMapping(\u0026#34;/demo/{filterParam}\u0026#34;) @Cacheable(cacheNames = \u0026#34;demo-cache\u0026#34;, key = \u0026#34;#keyParam\u0026#34;) String demoEndpoint(String keyParam, @PathVariable String filterParam); } 如果想禁用：spring.cloud.openfeign.cache.enabled=false\n","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/spring-cloud-openfeign/","series":[],"smallImg":"","tags":[{"title":"spring","url":"/myblog/tags/spring/"},{"title":"spring-clod","url":"/myblog/tags/spring-clod/"},{"title":"spring-cloud-openfeign","url":"/myblog/tags/spring-cloud-openfeign/"}],"timestamp":1669579622,"title":"Spring-Cloud-Openfeign"},{"authors":[],"categories":[{"title":"中间件","url":"/myblog/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"content":"架构 Distributor 分发服务器服务负责处理客户端的传入流。这是日志数据写入路径的第一站。一旦分发服务器接收到一组流，就验证每个流的正确性，并确保其在配置的租户（或全局）限制内。然后将有效的块分割成批，并并行发送给多个ingesters。\nValidation distributor 采取的第一步是确保所有传入数据符合规范。这包括检查标签是否是有效的Prometheus标签，以及确保时间戳不是太旧或太新，或者日志行不是太长。\nPreprocessing 目前，distributor改变传入数据的唯一方法是规范标签。这意味着使{foo=“bar”，bazz=“buzz”}等同于{bazz=”buzz“，foo=”bar“}，或者换句话说，对标签进行排序。这使得Loki可以确定地缓存和散列它们。\nRate limiting distributor还可以根据每个租户对传入日志进行速率限制。它通过检查每个租户的限额并将其除以当前的distributor来实现这一点。这允许在集群级别为每个租户指定速率限制，并使我们能够向上或向下扩展distributor，并相应地调整每个distributor的限额。例如，假设我们有10个distributor，租户A有10MB的费率限制。在限制之前，每个分配器最多允许1MB/秒。现在，假设另一个大租户加入集群，我们需要再组建10个distributor。现在的20家distributor将调整其租户A的费率限制为（10MB/20家distributor）=500KB/s！这就是为什么全局限制允许Loki集群更简单、更安全的操作。\nForwarding 一旦distributor完成了所有的验证任务，它就会将数据转发给最终负责确认写入的ingester 组件。\nReplication factor 为了减少在任何单个ingester上丢失数据的可能性，distributor将在转发写操作时添加复制因子。通常情况下，这是3。复制允许在写入失败的情况下重新启动和rollouts ingester，并在某些情况下增加了防止数据丢失的额外保护。\n对于推送到distributor的每个标签集（称为流），它将对标签进行哈希，根据hash值查找环中的 ingesters （需要多个，根据replication_factor决定）。然后，它将尝试将相同的数据写入到多个ingesters。如果成功写入的次数少于法定人数（quorum ），则会出错。\nquorum 被定义为floor（replication_factor/2）+1。因此，对于replication_factor为3，我们需要两次写入成功。如果成功写入的次数少于两次，则distributor返回错误，可以重试写入。\n不过，复制因素并不是防止数据丢失的唯一方式。ingester 组件现在包括一个预写日志，该日志保存对磁盘的传入写入，以确保在磁盘未损坏的情况下不会丢失这些写入。复制因子和WAL的互补性确保了数据不会丢失，除非这两种机制都出现重大故障（即多个摄取者死亡并丢失/损坏其磁盘）。\nHashing 分发服务器使用一致的哈希和可配置的复制因子来确定ingester 服务的哪些实例应该接收给定的流。\n流是与租户和唯一标签集相关联的一组日志。使用租户ID和标签集对流进行哈希，然后使用哈希查找要将流发送到的ingester 。\n为了进行哈希查找，分发者会找到值大于流哈希值的最小适当令牌。当复制因子大于1时，属于不同ingester 的下一个后续令牌（环中的顺时针方向）也将包含在结果中。\n这种哈希设置的效果是，ingester 拥有的每个令牌都负责一系列哈希。如果存在值为0、25和50的三个令牌，ingester 拥有令牌25负责1-25的哈希范围。\nIngester ingester服务负责将日志数据写入写入路径上的长期存储后端（DynamoDB、S3、Cassandra等），并在读取路径上返回内存查询的日志数据。\ningester接收的每个日志流都在内存中构建成一组多个“块”，并以可配置的间隔刷新到备份存储后端。在以下情况下，块将被压缩并标记为只读：\n当前区块已达到容量（可配置值）。 当前区块已过了太多时间没有更新 发生flush。 每当一个块被压缩并标记为只读时，一个可写块就会取代它。\n如果ingester进程突然崩溃或退出，所有尚未刷新的数据都将丢失。Loki通常被配置为复制每个日志的多个副本（通常为3个），以减轻此风险。\n当持久存储提供程序发生刷新时，将根据其租户、标签和内容对块进行哈希。这意味着具有相同数据副本的多个ingester不会将相同数据写入备份存储两次，但如果对其中一个副本的任何写入失败，将在备份存储中创建多个不同的块对象。有关如何消除重复数据的信息，请参阅查询器。\nTimestamp Ordering 当未配置为接受无序写入时，摄取器将验证摄取的日志行是否正常。当摄取者接收到不符合预期顺序的日志行时，该行将被拒绝，并向用户返回错误。 摄取器验证日志行是否按时间戳升序接收。每个日志都有一个时间戳，该时间戳发生的时间晚于之前的日志。当摄取器接收到不遵循此顺序的日志时，将拒绝日志行并返回错误。\n如果ingester 进程突然崩溃或退出，所有尚未刷新的数据都可能丢失。Loki通常配置有预写日志，该日志可以在ingester 重新启动时重播，并且每个日志的复制因子（通常为3）可以减轻此风险。\n当未配置为接受无序写入时，针对给定流（标签的唯一组合）推送到Loki的所有行必须具有比之前接收到的行更新的时间戳。然而，有两种情况可用于处理具有相同纳秒时间戳的同一流的日志：\n如果传入的行与先前接收的行完全匹配（同时匹配先前的时间戳和日志文本），则传入的行将被视为完全重复的行并被忽略。 如果传入行具有与前一行相同的时间戳，但内容不同，则接受日志行。这意味着可以对同一时间戳使用两个不同的日志行。 虽然ingesters 确实支持通过BoltDB写入文件系统，但这只在单进程模式下工作，因为查询者需要访问同一后端存储，而BoltDB只允许一个进程在给定时间锁定数据库。\nQuery frontend 查询前端将较大的查询拆分为多个较小的查询，在下游查询器上并行执行这些查询，并再次将结果拼接在一起。这可以防止大型（多天等）查询在单个查询器中导致内存不足问题，并有助于更快地执行它们。\n查询前端在内部执行一些查询调整，并将查询保存在内部队列中。在此设置中，查询器充当从队列中提取作业、执行作业并将其返回到查询前端进行聚合的工作人员。查询器需要配置查询前端地址（通过-queries.frontend-address CLI标志），以允许它们连接到查询前端。\n查询前端排队机制用于：\n确保在失败时重试可能导致查询器内存不足（OOM）错误的大型查询。这允许管理员为查询提供不足的内存，或者乐观地并行运行更多的小查询，这有助于降低TCO。 通过使用先进先出队列（FIFO）将多个大型请求分发到所有查询器，防止在单个查询器上护送这些请求。 通过公平调度租户之间的查询，防止单个租户一直占用而拒绝服务（DOSing）其他租户。 查询前端支持缓存度量查询结果，并在后续查询中重用它们。如果缓存的结果不完整，查询前端将计算所需的子查询，并在下游查询器上并行执行它们。查询前端可以选择将查询与其步骤参数对齐，以提高查询结果的可缓存性。结果缓存与任何loki缓存后端兼容（当前为memcached、redis和内存缓存）。\n缓存日志（过滤器、正则表达式）查询正在积极开发中。\nQuerier querier服务使用LogQL查询语言处理查询，从ingesters 和长期存储中获取日志。\n查询器先查询所有ingesters中的内存数据，查询不到则去后端存储运行相同的查询。由于复制因素，查询器可能会收到重复的数据。为了解决这个问题，查询器在内部对具有相同纳秒时间戳、标签集和日志消息的数据进行重复数据消除。\n原理 Rule Grafana Loki 包含一个名为 Ruler 的组件，负责持续评估一组可配置的查询并根据结果执行操作,例如触发告警。支持两种rules：\n告警：根据查询的结果，判断是否触发告警 记录(recording)：将查询的结果作为指标数据发送的存储后端，用于可视化。 告警规则 我们支持与 Prometheus 兼容的警报规则。 警报规则允许您根据 Prometheus 表达式语言表达式定义警报条件，并将有关触发警报的通知发送到外部服务。示例如下：\ngroups: - name: should_fire rules: - alert: HighPercentageError expr: | sum(rate({app=\u0026#34;foo\u0026#34;, env=\u0026#34;production\u0026#34;} |= \u0026#34;error\u0026#34; [5m])) by (job) / sum(rate({app=\u0026#34;foo\u0026#34;, env=\u0026#34;production\u0026#34;}[5m])) by (job) \u0026gt; 0.05 for: 10m labels: severity: page annotations: summary: High request latency - name: credentials_leak rules: - alert: http-credentials-leaked annotations: message: \u0026#34;{{ $labels.job }} is leaking http basic auth credentials.\u0026#34; expr: \u0026#39;sum by (cluster, job, pod) (count_over_time({namespace=\u0026#34;prod\u0026#34;} |~ \u0026#34;http(s?)://(\\\\w+):(\\\\w+)@\u0026#34; [5m]) \u0026gt; 0)\u0026#39; for: 10m labels: severity: critical 记录规则 支持 与 Prometheus 兼容的记录规则。 记录规则允许您预先计算经常需要或计算量大的表达式，并将其结果保存为一组新的时间序列。\nLoki允许您在日志上运行度量查询，这意味着您可以从日志中导出数字聚合，例如从NGINX访问日志中计算一段时间内的请求数。\nname: NginxRules interval: 1m rules: - record: nginx:requests:rate1m expr: | sum( rate({container=\u0026#34;nginx\u0026#34;}[1m]) ) labels: cluster: \u0026#34;us-central1\u0026#34; 此查询（expr）将每1分钟（间隔）执行一次，其结果将存储在我们定义的度量名称（record）中。这个名为nginx:requests:rate1m的度量现在可以发送到普罗米修斯存储。\n配置远程写入 ruler: ... other settings ... remote_write: enabled: true client: url: http://localhost:9090/api/v1/write 规则的存储 Ruler支持五种存储：azure、gcs、s3、swift和local。大多数类型的存储共享rule配置，即将所有rule配置为使用同一后端。\nlocal实现从本地文件系统中读取规则文件。这是一个只读后端，不支持通过Ruler API创建和删除规则。尽管它读取本地文件系统，但如果操作员注意将相同的规则加载到每个Ruler，则该方法仍然可以在分片Ruler配置中使用。例如，这可以通过在每个Ruler pod上安装Kubernetes ConfigMap来实现。\n典型的local配置可能类似于：\n-ruler.storage.type=local -ruler.storage.local.directory=/tmp/loki/rules 使用上述配置，rule将预期以下布局：\n/tmp/loki/rules/\u0026lt;tenant id\u0026gt;/rules1.yaml /rules2.yaml 存储 Grafana Loki需要存储两种不同类型的数据：块和索引。\nLoki在单独的流中接收日志，其中每个流由其租户ID和标签集唯一标识。当来自流的日志条目到达时，它们被压缩为“块”并保存在块存储中。\n索引存储每个流的标签集，并将它们链接到各个块。\n","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/loki/","series":[],"smallImg":"","tags":[{"title":"loki","url":"/myblog/tags/loki/"},{"title":"监控","url":"/myblog/tags/%E7%9B%91%E6%8E%A7/"}],"timestamp":1669578740,"title":"Loki"},{"authors":[],"categories":[{"title":"中间件","url":"/myblog/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"content":"报警 警报规则\n设置评估标准，确定警报实例是否触发。警报规则由一个或多个查询表达式、条件、求值频率以及满足条件的持续时间（可选）组成。\nGrafana支持多维警报，这意味着每个警报规则可以创建多个警报实例。如果您在一个表达式中观察多个序列，这是非常强大的。\n一旦创建了警报规则，它们将经历各种状态和转换。\n命名空间\n创建 Grafana 管理的规则时，该文件夹可用于访问控制。\n组\n组内的所有规则都以相同的时间间隔进行评估。\n组中的警报规则和记录规则将始终按顺序进行评估。\n警报实例\nGrafana 支持多维度警报。每个警报规则可以创建多个警报实例。如果您在单个表达式中观察多个序列，这将非常强大。\n请考虑以下 PromQL 表达式：\nsum by(cpu) ( rate(node_cpu_seconds_total{mode!=\u0026#34;idle\u0026#34;}[1m]) ) 使用此表达式的规则将创建与第一次评估后观察到的 CPU 数量一样多的警报实例，从而允许单个规则报告每个 CPU 的状态。\n标签\n将警报规则及其实例与通知策略和静默相匹配。它们还可以用于按严重程度对警报进行分组。\n通知策略\n设置警报路由的地点、时间和方式。每个通知策略都指定一组标签匹配器，以指示它们负责哪些警报。通知策略有一个分配给它的联络点，该联络点由一个或多个联系人组成。\n联络点\n定义警报触发时如何通知联系人。支持多种ChatOps工具。\n注解\n注释是键值对，提供有关警报的附加元信息。您可以使用以下注释：description、summary、runbook_url、alertId、dashboardUid和panelId。例如，description、summary和runbook URL。这些将显示在规则和警报详细信息的UI上，并且可以在联系人消息模板中使用。\n标签\n标签是键值对，包含有关警报的信息，用于唯一标识警报。警报的标签集将在整个警报评估生成并添加到通知进程中。\n在Grafana中，可以像在Prometheus中那样使用模板注释和标签。以前使用过Prometheus的人应该熟悉$labels变量，它保存警报实例的标签键/值对，以及$value变量，它保持警报实例的评估值。\n在Grafana中，即使您的警报不使用Prometheus数据源，也可以使用来自Promethes的相同变量来模板注释和标签。\n例如，假设我们想在Grafana中创建一个警报，当我们的一个实例停机超过5分钟时通知我们。就像在普罗米修斯中一样，我们可以添加一个摘要注释来显示已关闭的实例：\nInstance {{ $labels.instance }} has been down for more than 5 minutes 对于我们还想知道警报触发时的值，我们可以使用$labels和$value变量添加更多信息摘要：\n{{ $labels.instance }} has a 95th percentile request latency above 1s: {{ $value }}) Grafana和Prometheus的一个区别是，Prometheus使用$value来同时保存警报触发时的标签和条件值。例如 下面的 $value 内容：\n[ var=\u0026#39;B\u0026#39; labels={instance=http_server} value=10 ] 如果警报规则有两个或多个查询，或者使用reduce和数学表达式，则可以使用$values变量对每个查询和表达式的简化结果进行模板化。该变量保存每个简化查询的标签和值，以及任何数学表达式的结果。但是，它不保存每个查询的样本。\n如果此规则创建警报实例，$values将保存reduce表达式B和数学表达式C的结果。它将不会保存查询A返回的结果，因为查询A不会返回单个值，而是会随时间返回一系列值。\n如果我们要编写摘要注释，例如：\n{{ $labels.instance }} has a 95th percentile request latency above 1s: {{ $value }}) 我们会发现，由于警报的条件，数学表达式C必须是布尔比较，它必须返回0或1。我们需要的是归约表达式B的第95个百分位：\n{{ $labels.instance }} has a 95th percentile request latency above 1s: {{ $values.B }}) 我们还可以显示B的标签，但是由于此警报规则只有一个查询，因此B的标签相当于$labels：\n{{ $values.B.Labels.instance }} has a 95th percentile request latency above 1s: {{ $values.B }}) No data and execution errors or timeouts\n如果查询A未返回任何数据，则缩减表达式B也将不返回任何数据。这意味着｛｛$values.B｝｝将为零。为了确保即使查询没有返回数据，注释和标签仍然可以模板化，我们可以使用if语句检查$values.B：\n{{ if $values.B }}{{ $labels.instance }} has a 95th percentile request latency above 1s: {{ $values.B }}){{ end }} 如果规则使用经典条件而不是reduce和数学表达式，则$values包含refID和条件位置的组合。例如，{{ $values.A0 }} and {{ $values.A1 }}。 展开注释和标签时，以下模板变量可用:\nName Description $labels 查询或条件中的标签。例如，｛｛$labels.instance｝｝和｛｛$labels.job｝｝｝。当规则使用经典条件时，此选项不可用 $values 为此警报规则计算的所有reduce表达式和数学表达式的值。例如，｛｛$values.A｝｝、｛｛$values.A.Labels｝和｛｛$values.A.Value｝｝｝，其中A是reduce或数学表达式的refID。如果规则使用经典条件而不是reduce和数学表达式，则$values包含refID和条件位置的组合。 $value 警报实例的值字符串。例如: [ var=\u0026lsquo;A\u0026rsquo; labels={instance=foo} value=10 ]。 使用标签和标签匹配器将警报规则链接到通知策略和静默。这允许一种非常灵活的方式来管理警报实例，指定应该处理它们的策略，以及静默哪些警报。\n标签匹配器由3个不同的部分组成：标签、值和运算符。\n标签字段是要匹配的标签的名称。它必须与标签名称完全匹配。 值字段与指定标签名称的相应值匹配。它的匹配方式取决于Operator。 运算符字段是与标签值匹配的运算符。可用的运算符有： Operator Description = 等于 != 不等于 =~ 正则匹配 !~ 正则不匹配 如果使用多个标签匹配器，则使用AND逻辑运算符将它们组合起来。这意味着所有匹配器必须匹配才能将规则链接到策略。\n有三个关键组件：警报规则状态、警报实例状态和警报规则运行状况。尽管相互关联，但每个组件传递的信息都有细微的不同。\n警报规则状态：\nState Description Normal 评估引擎返回的时间序列均未处于待定或触发状态。 Pending 评估引擎返回的至少一个时间序列处于待定状态。 Firing 评估引擎返回的至少一个时间序列处于firing状态。 警报将首先转换为挂起，然后触发，因此在触发警报之前至少需要两个评估周期。\n警报实例状态:\nState Description Normal 警报的状态既不触发也不挂起，一切正常工作。 Pending 处于活动状态的警报的状态小于配置的阈值持续时间。 Alerting 活动时间超过配置阈值持续时间的警报的状态。 NoData 在配置的时间窗口内未收到任何数据。 Error 尝试评估警报规则时发生的错误。 警报规则运行状况:\nState Description Ok 评估警报规则时没有错误。 Error 评估警报规则时出错。 NoData 在规则评估期间返回的至少一个时间序列中缺少数据。 当警报规则的评估产生状态NoData或Error时，Grafana alerting将生成具有以下附加标签的警报实例：\nLabel Description alertname Either DatasourceNoData or DatasourceError depending on the state. datasource_uid The UID of the data source that caused the state. 配置联系人 通过联系点发送的通知是使用消息模板生成的。Grafana的默认模板基于Go模板系统，其中一些字段被计算为文本，而另一些字段被评估为HTML（这可能会影响转义）。默认模板，在default_template.go中定义，可以参考其写法：\n{{ define \u0026#34;__subject\u0026#34; }}[{{ .Status | toUpper }}{{ if eq .Status \u0026#34;firing\u0026#34; }}:{{ .Alerts.Firing | len }}{{ if gt (.Alerts.Resolved | len) 0 }}, RESOLVED:{{ .Alerts.Resolved | len }}{{ end }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join \u0026#34; \u0026#34; }} {{ if gt (len .CommonLabels) (len .GroupLabels) }}({{ with .CommonLabels.Remove .GroupLabels.Names }}{{ .Values | join \u0026#34; \u0026#34; }}{{ end }}){{ end }}{{ end }} {{ define \u0026#34;__text_values_list\u0026#34; }}{{ $len := len .Values }}{{ if $len }}{{ $first := gt $len 1 }}{{ range $refID, $value := .Values -}} {{ $refID }}={{ $value }}{{ if $first }}, {{ end }}{{ $first = false }}{{ end -}} {{ else }}[no value]{{ end }}{{ end }} {{ define \u0026#34;__text_alert_list\u0026#34; }}{{ range . }} Value: {{ template \u0026#34;__text_values_list\u0026#34; . }} Labels: {{ range .Labels.SortedPairs }} - {{ .Name }} = {{ .Value }} {{ end }}Annotations: {{ range .Annotations.SortedPairs }} - {{ .Name }} = {{ .Value }} {{ end }}{{ if gt (len .GeneratorURL) 0 }}Source: {{ .GeneratorURL }} {{ end }}{{ if gt (len .SilenceURL) 0 }}Silence: {{ .SilenceURL }} {{ end }}{{ if gt (len .DashboardURL) 0 }}Dashboard: {{ .DashboardURL }} {{ end }}{{ if gt (len .PanelURL) 0 }}Panel: {{ .PanelURL }} {{ end }}{{ end }}{{ end }} {{ define \u0026#34;default.title\u0026#34; }}{{ template \u0026#34;__subject\u0026#34; . }}{{ end }} {{ define \u0026#34;default.message\u0026#34; }}{{ if gt (len .Alerts.Firing) 0 }}**Firing** {{ template \u0026#34;__text_alert_list\u0026#34; .Alerts.Firing }}{{ if gt (len .Alerts.Resolved) 0 }} {{ end }}{{ end }}{{ if gt (len .Alerts.Resolved) 0 }}**Resolved** {{ template \u0026#34;__text_alert_list\u0026#34; .Alerts.Resolved }}{{ end }}{{ end }} {{ define \u0026#34;__teams_text_alert_list\u0026#34; }}{{ range . }} Value: {{ template \u0026#34;__text_values_list\u0026#34; . }} Labels: {{ range .Labels.SortedPairs }} - {{ .Name }} = {{ .Value }} {{ end }} Annotations: {{ range .Annotations.SortedPairs }} - {{ .Name }} = {{ .Value }} {{ end }} {{ if gt (len .GeneratorURL) 0 }}Source: [{{ .GeneratorURL }}]({{ .GeneratorURL }}) {{ end }}{{ if gt (len .SilenceURL) 0 }}Silence: [{{ .SilenceURL }}]({{ .SilenceURL }}) {{ end }}{{ if gt (len .DashboardURL) 0 }}Dashboard: [{{ .DashboardURL }}]({{ .DashboardURL }}) {{ end }}{{ if gt (len .PanelURL) 0 }}Panel: [{{ .PanelURL }}]({{ .PanelURL }}) {{ end }} {{ end }}{{ end }} {{ define \u0026#34;teams.default.message\u0026#34; }}{{ if gt (len .Alerts.Firing) 0 }}**Firing** {{ template \u0026#34;__teams_text_alert_list\u0026#34; .Alerts.Firing }}{{ if gt (len .Alerts.Resolved) 0 }} {{ end }}{{ end }}{{ if gt (len .Alerts.Resolved) 0 }}**Resolved** {{ template \u0026#34;__teams_text_alert_list\u0026#34; .Alerts.Resolved }}{{ end }}{{ end }} 以下示例演示如何使用默认模板在Slack中呈现警报消息。消息标题包含正在触发或已解决的警报计数。消息正文列出了警报及其状态:\n下面的示例显示了如何使用自定义模板：\n模板嵌套\n您可以在其他模板中嵌入模板。例如，您可以使用define关键字定义模板片段：\n{{ define \u0026#34;mytemplate\u0026#34; }} {{ len .Alerts.Firing }} firing. {{ len .Alerts.Resolved }} resolved. {{ end }} 然后，可以使用template关键字将自定义模板嵌入此片段中。例如：\nAlert summary: {{ template \u0026#34;mytemplate\u0026#34; . }} 您可以使用以下任何内置模板选项嵌入自定义模板:\ndefault.title 显示高级状态信息。 default.message 提供触发和已解决警报的格式化摘要。 teams.default.message 类似于default.messsage。为Microsoft Teams格式化。 通知策略决定如何将警报路由到联系点。策略具有树结构，其中每个策略可以有一个或多个子策略。除根策略外，每个策略还可以匹配特定的警报标签。每个警报由根策略评估，然后由每个子策略评估。如果为特定策略启用了“继续匹配后续同级节点”选项，则即使在一个或多个匹配之后，评估也会继续。当没有任何子策略匹配时，命中根策略。\n分组是Grafana Alerting的一个新的关键概念，它将类似性质的警报通知分类为单个漏斗。这样，当系统的许多部分同时发生故障，导致大量警报同时触发时，您可以在较大的停机期间正确地路由警报通知。\n例如，假设您有100个服务连接到不同环境中的数据库。这些服务通过标签env=environmentname进行区分。有一个警报规则，用于监视您的服务是否可以访问名为alertname=DatabaseUnreach的数据库。\n当出现网络分区时，一半的服务将无法再访问数据库。结果，会触发50个不同的警报（假设您的服务有一半）。对于这种情况，您希望收到一个带有受影响环境列表的单页通知（而不是50页）。\n您可以将分组配置为group_by:[alertname]（请注意，省略了env标签）。有了这个配置，Grafana会发送一个紧凑的通知，其中包含此警报规则的所有受影响环境。\nGrafana还有一个名为…的特殊标签，您可以使用它按所有标签对所有警报进行分组（有效地禁用分组），因此每个警报都将进入自己的组。它不同于默认的group_by:null，其中所有警报都进入一个组。\n静音定时是警告重复发送的时间间隔。使用它们可以防止警报在特定的重复周期内触发。\n与静音类似，静音计时不会阻止评估警报规则，也不会阻止警报实例在用户界面中显示。它们仅阻止创建通知。\n使用静音停止来自一个或多个警报规则的通知。静默不会阻止评估警报规则。它们也不会停止警告实例在用户界面中显示。静音仅阻止创建通知。沉默只持续一段特定的时间。\n","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/grafana/","series":[],"smallImg":"","tags":[{"title":"grafana","url":"/myblog/tags/grafana/"},{"title":"监控","url":"/myblog/tags/%E7%9B%91%E6%8E%A7/"}],"timestamp":1669578563,"title":"Grafana"},{"authors":[],"categories":[{"title":"操作系统","url":"/myblog/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"linux","url":"/myblog/categories/linux/"},{"title":"Unbutu","url":"/myblog/categories/unbutu/"}],"content":"deb包 查看默认安装位置 查看deb包的安装位置：\nsudo dpkg-deb -c jdk-19_linux-x64_bin.deb 安装deb包 sudo apt-get install -y adduser libfontconfig1 wget https://dl.grafana.com/enterprise/release/grafana-enterprise_9.2.4_amd64.deb sudo dpkg -i grafana-enterprise_9.2.4_amd64.deb ","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/unbutu-%E4%BD%BF%E7%94%A8/","series":[],"smallImg":"","tags":[{"title":"linux","url":"/myblog/tags/linux/"},{"title":"Unbutu","url":"/myblog/tags/unbutu/"}],"timestamp":1669576890,"title":"Unbutu 使用"},{"authors":[],"categories":[{"title":"java","url":"/myblog/categories/java/"}],"content":"java9 模块化 接口里可以添加私有接口 JAVA 8 对接口增加了默认方法的支持，在 JAVA 9 中对该功能又来了一次升级，现在可以在接口里定义私有方法，然后在默认方法里调用接口的私有方法。\npublic interface TestInterface { default void wrapMethod(){ innerMethod(); } private void innerMethod(){ System.out.println(\u0026#34;\u0026#34;); } } 匿名内部类也支持钻石（diamond）运算符 JAVA 5 就引入了泛型（generic），到了 JAVA 7 开始支持钻石（diamond）运算符：\u0026lt;\u0026gt;，可以自动推断泛型的类型：\nList\u0026lt;Integer\u0026gt; numbers = new ArrayList\u0026lt;\u0026gt;(); 但是这个自动推断类型的钻石运算符可不支持匿名内部类，在 JAVA 9 中也对匿名内部类做了支持：\nComparable\u0026lt;Integer\u0026gt; numbers = new Comparable\u0026lt;\u0026gt;() { // 9之前必须指定泛型 ... } 增强的 try-with-resources JAVA 7 中增加了try-with-resources的支持，可以自动关闭资源：\ntry (BufferedReader bufferReader = new BufferedReader(...)) { return bufferReader.readLine(); } 但需要声明多个资源变量时，代码看着就有点恶心了，需要在 try 中写多个变量的创建过程：\ntry (BufferedReader bufferReader0 = new BufferedReader(...); BufferedReader bufferReader1 = new BufferedReader(...)) { return bufferReader0.readLine(); } JAVA 9 中对这个功能进行了增强，可以引用 try 代码块之外的变量来自动关闭：\nBufferedReader bufferReader0 = new BufferedReader(...); BufferedReader bufferReader1 = new BufferedReader(...); try (bufferReader0; bufferReader1) { System.out.println(br1.readLine() + br2.readLine()); } java10 局部变量的自动类型推断（var） JAVA 10 带来了一个很有意思的语法 - var，它可以自动推断局部变量的类型，以后再也不用写类型了，也不用靠 lombok 的 var 注解增强了\nvar message = \u0026#34;Hello, Java 10\u0026#34;; 不过这个只是语法糖，编译后变量还是有类型的，使用时还是考虑下可维护性的问题，不然写多了可就成 JavaScript 风格了\njava11 Lambda 中的自动类型推断（var） JAVA 11 中对 Lambda 语法也支持了 var 这个自动类型推断的变量，通过 var 变量还可以增加额外的注解：\nList\u0026lt;String\u0026gt; languages = Arrays.asList(\u0026#34;Java\u0026#34;, \u0026#34;Groovy\u0026#34;); String language = sampleList.stream() .map((@Nonnull var x) -\u0026gt; x.toUpperCase()) .collect(Collectors.joining(\u0026#34;, \u0026#34;)); assertThat(language).isEqualTo(\u0026#34;Java, Groovy\u0026#34;); javac + java 命令一把梭 以前编译一个 java 文件时，需要先 javac 编译为 class，然后再用 java 执行，现在可以一把梭了：\n$ java HelloWorld.java Hello Java 11! Java Flight Recorder 登陆 OpenJDK Java Flight Recorder 是个灰常好用的调试诊断工具，不过之前是在 Oracle JDK 中，也跟着 JDK 11 开源了，OpenJDK 这下也可以用这个功能，真香！\njava12 更简洁的 switch 语法 在之前的 JAVA 版本中，switch 语法还是比较啰嗦的，如果多个值走一个逻辑需要写多个 case：\nDayOfWeek dayOfWeek = LocalDate.now().getDayOfWeek(); String typeOfDay = \u0026#34;\u0026#34;; switch (dayOfWeek) { case MONDAY: case TUESDAY: case WEDNESDAY: case THURSDAY: case FRIDAY: typeOfDay = \u0026#34;Working Day\u0026#34;; break; case SATURDAY: case SUNDAY: typeOfDay = \u0026#34;Day Off\u0026#34;; } 到了 JAVA 12，这个事情就变得很简单了，几行搞定，而且！还支持返回值：\ntypeOfDay = switch (dayOfWeek) { case MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY -\u0026gt; \u0026#34;Working Day\u0026#34;; case SATURDAY, SUNDAY -\u0026gt; \u0026#34;Day Off\u0026#34;; }; instanceof + 类型强转一步到位 之前处理动态类型碰上要强转时，需要先 instanceof 判断一下，然后再强转为该类型处理：\nObject obj = \u0026#34;Hello Java 12!\u0026#34;; if (obj instanceof String) { String s = (String) obj; int length = s.length(); } 现在 instanceof 支持直接类型转换了，不需要再来一次额外的强转：\nObject obj = \u0026#34;Hello Java 12!\u0026#34;; if (obj instanceof String str) { int length = str.length(); } java13 switch 语法再增强 JAVA 12 中虽然增强了 swtich 语法，但并不能在 -\u0026gt; 之后写复杂的逻辑，JAVA 12 带来了 swtich更完美的体验，就像 lambda 一样，可以写逻辑，然后再返回：\ntypeOfDay = switch (dayOfWeek) { case MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY -\u0026gt; { // do sth... yield \u0026#34;Working Day\u0026#34;; } case SATURDAY, SUNDAY -\u0026gt; \u0026#34;Day Off\u0026#34;; }; 文本块（Text Block）的支持 你是否还在为大段带换行符的字符串报文所困扰，换行吧一堆换行符，不换行吧看着又难受。JAVA 13 中帮你解决了这个恶心的问题，增加了文本块的支持，现在可以开心的换行拼字符串了，就像用模板一样：\nString json = \u0026#34;\u0026#34;\u0026#34; { \u0026#34;id\u0026#34;:\u0026#34;1697301681936888\u0026#34;, \u0026#34;nickname\u0026#34;:\u0026#34;空无\u0026#34;, \u0026#34;homepage\u0026#34;:\u0026#34;https://juejin.cn/user/1697301681936888\u0026#34; } \u0026#34;\u0026#34;\u0026#34;; java14 新增的 record 类型，干掉复杂的 POJO 类 一般我们创建一个 POJO 类，需要定义属性列表，构造函数，getter/setter，比较麻烦。JAVA 14 为我们带来了一个便捷的创建类的方式 - record\npublic record UserDTO(String id,String nickname,String homepage) { }; public static void main( String[] args ){ UserDTO user = new UserDTO(\u0026#34;1697301681936888\u0026#34;,\u0026#34;空无\u0026#34;,\u0026#34;https://juejin.cn/user/1697301681936888\u0026#34;); System.out.println(user.id); System.out.println(user.nickname); System.out.println(user.id); } 不过这个只是一个语法糖，编译后还是一个 Class，和普通的 Class 区别不大\n更直观的 NullPointerException 提示 NullPointerException 算是 JAVA 里最常见的一个异常了，但这玩意提示实在不友好，遇到一些长一点的链式表达式时，没办法分辨到底是哪个对象为空。\n比如下面这个例子中，到底是 innerMap 为空呢，还是 effected 为空呢？\nMap\u0026lt;String,Map\u0026lt;String,Boolean\u0026gt;\u0026gt; wrapMap = new HashMap\u0026lt;\u0026gt;(); wrapMap.put(\u0026#34;innerMap\u0026#34;,new HashMap\u0026lt;\u0026gt;()); boolean effected = wrapMap.get(\u0026#34;innerMap\u0026#34;).get(\u0026#34;effected\u0026#34;); // StackTrace: Exception in thread \u0026#34;main\u0026#34; java.lang.NullPointerException at org.example.App.main(App.java:50) JAVA 14 也 get 到了 JAVAER 们的痛点，优化了 NullPointerException 的提示，让你不在困惑，一眼就能定位到底“空”在哪！\nException in thread \u0026#34;main\u0026#34; java.lang.NullPointerException: Cannot invoke \u0026#34;java.lang.Boolean.booleanValue()\u0026#34; because the return value of \u0026#34;java.util.Map.get(Object)\u0026#34; is null at org.example.App.main(App.java:50) 现在的 StackTrace 就很直观了，直接告诉你 effected 变量为空，再也不用困惑！\n安全的堆外内存读写接口，别再玩 Unsafe 的骚操作了 在之前的版本中，JAVA 如果想操作堆外内存（DirectBuffer），还得 Unsafe 各种 copy/get/offset。现在直接增加了一套安全的堆外内存访问接口，可以轻松的访问堆外内存，再也不用搞 Unsafe 的骚操作了。\n// 分配 200B 堆外内存 MemorySegment memorySegment = MemorySegment.allocateNative(200); // 用 ByteBuffer 分配，然后包装为 MemorySegment MemorySegment memorySegment = MemorySegment.ofByteBuffer(ByteBuffer.allocateDirect(200)); // MMAP 当然也可以 MemorySegment memorySegment = MemorySegment.mapFromPath( Path.of(\u0026#34;/tmp/memory.txt\u0026#34;), 200, FileChannel.MapMode.READ_WRITE); // 获取堆外内存地址 MemoryAddress address = MemorySegment.allocateNative(100).baseAddress(); // 组合拳，堆外分配，堆外赋值 long value = 10; MemoryAddress memoryAddress = MemorySegment.allocateNative(8).baseAddress(); // 获取句柄 VarHandle varHandle = MemoryHandles.varHandle(long.class, ByteOrder.nativeOrder()); varHandle.set(memoryAddress, value); // 释放就这么简单，想想 DirectByteBuffer 的释放……多奇怪 memorySegment.close(); 新增的 jpackage 打包工具，直接打包二进制程序，再也不用装 JRE 了 之前如果想构建一个可执行的程序，还需要借助三方工具，将 JRE 一起打包，或者让客户电脑也装一个 JRE 才可以运行我们的 JAVA 程序。\n现在 JAVA 直接内置了 jpackage 打包工具，帮助你一键打包二进制程序包，终于不用乱折腾了\njava15 ZGC 和 Shenandoah 两款垃圾回收器正式登陆 在 JAVA 15中，ZGC 和 Shenandoah 再也不是实验功能，正式登陆了（不过 G1 仍然是默认的）。如果你升级到 JAVA 15 以后的版本，就赶快试试吧，性能更强，延迟更低\n封闭（Sealed ）类 JAVA 的继承目前只能选择允许继承和不允许继承（final 修饰），现在新增了一个封闭（Sealed ）类的特性，可以指定某些类才可以继承：\npublic sealed interface Service permits Car, Truck { int getMaxServiceIntervalInMonths(); default int getMaxDistanceBetweenServicesInKilometers() { return 100000; } } java16 JAVA 16 在用户可见的地方变化并不多，基本都是 14/15 的实验性内容，到了 16 正式发布，这里就不重复介绍了。\n","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/jdk%E6%96%B0%E7%89%B9%E6%80%A7/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"},{"title":"新特性","url":"/myblog/tags/%E6%96%B0%E7%89%B9%E6%80%A7/"}],"timestamp":1669576723,"title":"Jdk新特性"},{"authors":[],"categories":[{"title":"java","url":"/myblog/categories/java/"}],"content":"执行 查询 要对schema执行查询，请使用适当的参数构建一个新的GraphQL对象，然后调用execute方法。查询的结果是ExecutionResult，它是查询数据和/或错误列表。\nGraphQLSchema schema = GraphQLSchema.newSchema() .query(queryType) .build(); GraphQL graphQL = GraphQL.newGraphQL(schema) .build(); ExecutionInput executionInput = ExecutionInput.newExecutionInput().query(\u0026#34;query { hero { name } }\u0026#34;) .build(); ExecutionResult executionResult = graphQL.execute(executionInput); Object data = executionResult.getData(); List\u0026lt;GraphQLError\u0026gt; errors = executionResult.getErrors(); Data Fetchers 每个graphql字段类型都有一个graphql.schema.DataFetcher与其关联的。通常，您可以依赖graphql.schema.PropertyDataFetcher检查Java POJO对象，以从中提供字段值。如果您没有在字段上指定数据获取器，则将使用此选项。\nDataFetcher userDataFetcher = new DataFetcher() { @Override public Object get(DataFetchingEnvironment environment) { return fetchUserFromDatabase(environment.getArgument(\u0026#34;userId\u0026#34;)); } }; 在上面的示例中，执行将等待数据获取器返回，然后再继续。您可以通过向数据返回CompletionStage来实现DataFetcher的异步执行。\n获取数据的时候发生异常 如果在数据获取器调用期间发生异常，则默认情况下执行策略将生成一个graphql.ExceptionWhileDataFetching错误，并将其添加到结果的错误列表中。请记住，graphql允许有错误的部分结果。这是标准行为的代码：\npublic class SimpleDataFetcherExceptionHandler implements DataFetcherExceptionHandler { private static final Logger log = LoggerFactory.getLogger(SimpleDataFetcherExceptionHandler.class); @Override public void accept(DataFetcherExceptionHandlerParameters handlerParameters) { Throwable exception = handlerParameters.getException(); SourceLocation sourceLocation = handlerParameters.getField().getSourceLocation(); ExecutionPath path = handlerParameters.getPath(); ExceptionWhileDataFetching error = new ExceptionWhileDataFetching(path, exception, sourceLocation); handlerParameters.getExecutionContext().addError(error); log.warn(error.getMessage(), exception); } } 如果抛出的异常本身是GraphqlError，那么它会将该异常的消息和自定义扩展属性传输到ExceptionWhileDataFetching对象中。这允许您将自己的自定义属性放入发送回调用者的graphql错误中。\n例如，假设您的数据获取器抛出了此异常。foo和fizz属性将包含在生成的graphql错误中。\nclass CustomRuntimeException extends RuntimeException implements GraphQLError { @Override public Map\u0026lt;String, Object\u0026gt; getExtensions() { Map\u0026lt;String, Object\u0026gt; customAttributes = new LinkedHashMap\u0026lt;\u0026gt;(); customAttributes.put(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;); customAttributes.put(\u0026#34;fizz\u0026#34;, \u0026#34;whizz\u0026#34;); return customAttributes; } @Override public List\u0026lt;SourceLocation\u0026gt; getLocations() { return null; } @Override public ErrorType getErrorType() { return ErrorType.DataFetchingException; } } 您可以通过创建自己的graphql.execution.DataFetcherExceptionHandler来更改此行为。\n例如，上面的代码记录了底层异常和堆栈跟踪。有些人可能不希望在输出错误列表中看到这一点。所以你可以使用这个机制来改变这种行为。\nDataFetcherExceptionHandler handler = new DataFetcherExceptionHandler() { @Override public void accept(DataFetcherExceptionHandlerParameters handlerParameters) { // // do your custom handling here. The parameters have all you need } }; ExecutionStrategy executionStrategy = new AsyncExecutionStrategy(handler); 返回数据和错误 graphql.execution.DataFetcherResult同时返回数据和多个错误.。或包装在CompletableFuture实例中，用于异步执行。当DataFetcher可能需要从多个源或另一个GraphQL资源检索数据时，这非常有用。\n在本例中，DataFetcher从另一个GraphQL资源中检索用户并返回其数据和错误。\nDataFetcher userDataFetcher = new DataFetcher() { @Override public Object get(DataFetchingEnvironment environment) { Map response = fetchUserFromRemoteGraphQLResource(environment.getArgument(\u0026#34;userId\u0026#34;)); List\u0026lt;GraphQLError\u0026gt; errors = response.get(\u0026#34;errors\u0026#34;).stream() .map(MyMapGraphQLError::new) .collect(Collectors.toList()); return new DataFetcherResult(response.get(\u0026#34;data\u0026#34;), errors); } }; 序列化结果成JSON 调用graphql最常见的方法是通过HTTP，并期望返回JSON响应。所以你需要将graphql.ExecutionResult转换为JSON负载。 一种常见的方法是使用JSON序列化库，如Jackson或GSON。然而，他们具体如何解释数据结果是他们所特有的。例如，null在graphql结果中很重要，因此必须设置json映射器以包含它们。\n为了确保获得100%符合graphql规范的JSON结果，应该对结果调用toSpecification，然后将其作为JSON发送回去。\nExecutionResult executionResult = graphQL.execute(executionInput); Map\u0026lt;String, Object\u0026gt; toSpecificationResult = executionResult.toSpecification(); sendAsJson(toSpecificationResult); graphql java库专注于查询引擎，不关心其他高级应用程序问题，例如：\n数据库访问 数据缓存 数据认证 数据分页 JSON编码 依赖注入 您需要将这些关注点推入业务逻辑层。\n上下文对象 您可以在查询执行期间传入上下文对象，以便更好地调用该业务逻辑。例如，应用程序可能正在执行用户检测，您需要在graphql执行过程中提供这些信息来执行授权。下面的示例显示了如何传递信息来帮助执行查询。\n// 将用户信息设置到上下文， UserContext contextForUser = YourGraphqlContextBuilder.getContextForUser(getCurrentUser()); ExecutionInput executionInput = ExecutionInput.newExecutionInput() .context(contextForUser) .build(); ExecutionResult executionResult = graphQL.execute(executionInput); // 在DataFetcher 获取上下文中的内容 DataFetcher dataFetcher = new DataFetcher() { @Override public Object get(DataFetchingEnvironment environment) { UserContext userCtx = environment.getContext(); Long businessObjId = environment.getArgument(\u0026#34;businessObjId\u0026#34;); return invokeBusinessLayerMethod(userCtx, businessObjId); } }; 数据获取 graphql 如何获取数据 graphql 中的每个字段都有一个 graphql.schema.DataFetcher 与之关联 。一些字段将使用专门的数据获取器代码，该代码知道如何去数据库获取字段信息，而大多数字段只需使用字段名和普通旧Java对象（POJO）模式从返回的内存对象中获取数据即可。\n设想一个如下的类型声明：\ntype Query { products(match : String) : [Product] # a list of products } type Product { id : ID name : String description : String cost : Float tax : Float launchDate(dateFormat : String = \u0026#34;dd, MMM, yyyy\u0026#34;) : String } Query.products 有专门的 DataFetcher ， 例如下面的代码：\nDataFetcher productsDataFetcher = new DataFetcher\u0026lt;List\u0026lt;ProductDTO\u0026gt;\u0026gt;() { @Override public List\u0026lt;ProductDTO\u0026gt; get(DataFetchingEnvironment environment) { DatabaseSecurityCtx ctx = environment.getContext(); List\u0026lt;ProductDTO\u0026gt; products; String match = environment.getArgument(\u0026#34;match\u0026#34;); if (match != null) { products = fetchProductsFromDatabaseWithMatching(ctx, match); } else { products = fetchAllProductsFromDatabase(ctx); } return products; } }; 每个DataFetcher都传递了一个graphql.schema.DataFetchingEnvironment对象，其中包含要获取的字段、已向字段提供的参数以及其他信息，例如字段的类型、其父类型、查询根对象或查询上下文对象。\n一旦我们有了ProductDTO对象的列表，我们通常不需要在每个字段上使用专门的数据获取器。graphql-java附带了一个智能graphql.schema.PropertyDataFetcher，它知道如何根据字段名遵循POJO模式。在上面的示例中，有一个name字段，因此它将尝试查找公共String getName() POJO方法来获取数据。\n然而，您可以在DTO方法中访问graphql.schema.DataFetchingEnvironment对象。这允许您在发送值之前对其进行调整。例如，上面我们有一个launchDate字段，它接受可选的dateFormat参数。我们可以让ProductDTO具有将此日期格式应用于所需格式的逻辑：\nclass ProductDTO { private ID id; private String name; private String description; private Double cost; private Double tax; private LocalDateTime launchDate; // ... public String getName() { return name; } // ... public String getLaunchDate(DataFetchingEnvironment environment) { String dateFormat = environment.getArgument(\u0026#34;dateFormat\u0026#34;); return yodaTimeFormatter(launchDate,dateFormat); } } 自定义PropertyDataFetcher 如上所述，graphql.schema.PropertyDataFetcher是graphql-java中字段的默认数据获取器，它将使用标准模式获取对象字段值。\n它支持POJO方法和Map方法。默认情况下，对于graphql字段fieldX，则可以找到名为fieldX的POJO属性或名为fieldX的map 键。\n但是，graphql模式命名和运行时对象命名之间可能有一些小差异。例如，想象一下Product.description实际上在运行时对应 Java对象中的getDesc()。如果使用SDL指定schema，则可以使用@fetch指令来重新映射:\ndirective @fetch(from : String!) on FIELD_DEFINITION type Product { id : ID name : String description : String @fetch(from:\u0026#34;desc\u0026#34;) cost : Float tax : Float } 这将告诉graphql.schema.PropertyDataFetcher在获取名为description的graphql字段的数据时使用属性名称desc。\n如果您是手动编码模式，那么您可以直接通过在字段数据获取器中进行连接:\nGraphQLFieldDefinition descriptionField = GraphQLFieldDefinition.newFieldDefinition() .name(\u0026#34;description\u0026#34;) .type(Scalars.GraphQLString) .build(); GraphQLCodeRegistry codeRegistry = GraphQLCodeRegistry.newCodeRegistry() .dataFetcher( coordinates(\u0026#34;ObjectType\u0026#34;, \u0026#34;description\u0026#34;), PropertyDataFetcher.fetching(\u0026#34;desc\u0026#34;)) .build(); DataFetchingEnvironment核心方法 T getSource()：source对象用于获取字段的信息。在常见情况下，它是一个内存中的DTO对象，因此简单的POJO getter将用于字段值。在更复杂的情况下，您可以检查它以了解如何获取当前字段的特定信息。在执行graphql字段树时，每个返回的字段值都会成为子字段的源对象。 T getRoot()： 对于顶级字段，root和source是相同的。根对象在查询过程中从不更改，它可能为空，因此不使用 Map\u0026lt;String, Object\u0026gt; getArguments():这表示在字段上提供的参数以及从传入的变量、AST文本和默认参数值解析的参数值。您可以使用字段的参数来控制它返回的值。 T getContext(): 上下文对象在首次查询时设置，并在查询的整个生命周期内保持不变。上下文可以是任何值，通常用于在尝试获取字段数据时为每个数据获取器提供一些所需的调用上下文。例如，当前用户凭证或数据库连接参数可以包含在上下文对象中，以便数据获取器可以进行业务层调用。作为一名graphql系统设计师，您的一个关键设计决定是，如果需要，您将如何在提取器中使用上下文。有些人使用一个依赖框架，该框架将上下文自动注入数据获取器，因此不需要使用它。 ExecutionStepInfo getExecutionStepInfo(): 执行graphql查询会创建字段及其类型的调用树。graphql.execution.ExecutionStepInfo.getParentTypeInfo允许您向上导航，查看导致当前字段执行的类型和字段。由于这在执行期间形成了树路径，因此graphql.execution.ExecutionStepInfo.getPath方法返回该路径的表示。这对于记录和调试查询非常有用。 DataFetchingFieldSelectionSet getSelectionSet(): 选择集表示在当前执行的字段下“选择”的子字段。这有助于提前了解客户需要的子字段信息。 ExecutionId getExecutionId():每个查询执行都有一个唯一的id。您可以在日志中使用它来标记每个单独的查询。 数据映射 graphql的核心是声明一个类型schema，并将其映射到运行时数据上。例如下面的schema:\ntype Query { products(match : String) : [Product] # a list of products } type Product { id : ID name : String description : String cost : Float tax : Float } 然后，我们可以通过类似以下的方式在这个简单模式上运行查询：\nquery ProductQuery { products(match : \u0026#34;Paper*\u0026#34;) { id, name, cost, tax } } 我们将有一个DataFetcher匹配 Query的products字段，负责查找与传入参数匹配的产品列表。 现在假设我们有3个下游服务。一个用于获取产品信息，一个用于获得产品cost 信息，另一个用于计算产品tax信息。\ngraphql-java通过在对象上运行数据获取器获取所有信息并将其映射回模式中指定的类型来工作。我们面临的挑战是将这三种信息来源作为一种统一的类型。\n我们可以在cost 和 tax 字段上指定数据获取器，但这需要更多的维护，可能会导致N+1性能问题。我们最好在Query.products 的 data fetcher 中完成所有这些工作，并在此时创建数据的统一视图:\nDataFetcher productsDataFetcher = new DataFetcher() { @Override public Object get(DataFetchingEnvironment env) { String matchArg = env.getArgument(\u0026#34;match\u0026#34;); List\u0026lt;ProductInfo\u0026gt; productInfo = getMatchingProducts(matchArg); List\u0026lt;ProductCostInfo\u0026gt; productCostInfo = getProductCosts(productInfo); List\u0026lt;ProductTaxInfo\u0026gt; productTaxInfo = getProductTax(productInfo); return mapDataTogether(productInfo, productCostInfo, productTaxInfo); } }; 因此，查看上面的代码，我们有3种类型的信息需要以某种方式组合，以便上面的graphql查询可以访问字段id、name、cost、tax。\n我们有两种方法来创建此映射。一种是通过使用非类型安全的List＜Map＞结构，另一种是创建封装此数据的类型安全类List＜ProductDTO＞。\nMap 的方式如下：\nprivate List\u0026lt;Map\u0026gt; mapDataTogetherViaMap(List\u0026lt;ProductInfo\u0026gt; productInfo, List\u0026lt;ProductCostInfo\u0026gt; productCostInfo, List\u0026lt;ProductTaxInfo\u0026gt; productTaxInfo) { List\u0026lt;Map\u0026gt; unifiedView = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; productInfo.size(); i++) { ProductInfo info = productInfo.get(i); ProductCostInfo cost = productCostInfo.get(i); ProductTaxInfo tax = productTaxInfo.get(i); Map\u0026lt;String, Object\u0026gt; objectMap = new HashMap\u0026lt;\u0026gt;(); objectMap.put(\u0026#34;id\u0026#34;, info.getId()); objectMap.put(\u0026#34;name\u0026#34;, info.getName()); objectMap.put(\u0026#34;description\u0026#34;, info.getDescription()); objectMap.put(\u0026#34;cost\u0026#34;, cost.getCost()); objectMap.put(\u0026#34;tax\u0026#34;, tax.getTax()); unifiedView.add(objectMap); } return unifiedView; } DTO 方式如下：\nclass ProductDTO { private final String id; private final String name; private final String description; private final Float cost; private final Float tax; public ProductDTO(String id, String name, String description, Float cost, Float tax) { this.id = id; this.name = name; this.description = description; this.cost = cost; this.tax = tax; } public String getId() { return id; } public String getName() { return name; } public String getDescription() { return description; } public Float getCost() { return cost; } public Float getTax() { return tax; } } private List\u0026lt;ProductDTO\u0026gt; mapDataTogetherViaDTO(List\u0026lt;ProductInfo\u0026gt; productInfo, List\u0026lt;ProductCostInfo\u0026gt; productCostInfo, List\u0026lt;ProductTaxInfo\u0026gt; productTaxInfo) { List\u0026lt;ProductDTO\u0026gt; unifiedView = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; productInfo.size(); i++) { ProductInfo info = productInfo.get(i); ProductCostInfo cost = productCostInfo.get(i); ProductTaxInfo tax = productTaxInfo.get(i); ProductDTO productDTO = new ProductDTO( info.getId(), info.getName(), info.getDescription(), cost.getCost(), tax.getTax() ); unifiedView.add(productDTO); } return unifiedView; } 异常 如果遇到某些异常情况，graphql引擎可以抛出运行时异常。以下是可以在graphql.execute()调用中抛出的异常列表。\n这些不是执行中的graphql错误，而是执行graphql查询时完全不可接受的条件:\ngraphql.schema.CoercingSerializeException:当一个值不能通过标量类型序列化时，例如String值被强制为Int。 graphql.schema.CoercingParseValueException：当标量类型无法解析值（例如，字符串输入值被解析为Int）时引发。 graphql.execution.UnresolvedTypeException：如果graphql.schema.TypeResolver无法提供给定接口或联合类型的具体对象类型。 graphql.execution.NonNullableValueCoercedAsNullException:如果在执行期间将非空变量参数强制为空值时引发。 graphql.execution.InputMapDefinesTooManyFieldsException:如果用于输入类型对象的映射包含的键多于该输入类型中定义的键，则引发。 graphql.schema.validation.InvalidSchemaException:如果通过graphql.schema.GraphQLSchema.Builder#build()生成schema无效时引发 graphql.execution.UnknownOperationException：如果查询中定义了多个操作，并且缺少操作名称，或者GraphQL查询中没有包含匹配的操作名称。 graphql.GraphQLException：作为通用运行时异常抛出，例如，如果代码在检查POJO时无法访问命名字段，它类似于RuntimeException。 graphql.AssertException： 字段选择 当您具有复合类型（对象或接口类型）并且从该类型中选择了一组子字段时，将发生字段选择。\n例如下面的查询：\nquery { user(userId : \u0026#34;xyz\u0026#34;) { name age weight friends { name } } } 了解字段选择集有助于提高DataFetchers的效率。例如，在上面的查询中，假设用户字段由SQL数据库系统支持。数据获取器可以查看字段选择集并使用不同的查询，因为它知道调用者需要朋友信息和用户信息。\ngraphql.schema.DataFetchingFieldSelectionSet 用于表示选择的字段。他提供了schema中字段/参数和graphql.schema.GraphQLFieldDefinition的映射：\nDataFetcher smartUserDF = new DataFetcher() { @Override public Object get(DataFetchingEnvironment env) { String userId = env.getArgument(\u0026#34;userId\u0026#34;); DataFetchingFieldSelectionSet selectionSet = env.getSelectionSet(); if (selectionSet.contains(\u0026#34;friends/*\u0026#34;)) { return getUserAndTheirFriends(userId); } else { return getUser(userId); } } }; 全局路径匹配系统用于对选择中的字段进行寻址。它基于java.nio.file.FileSystem#getPathMatcher作为实现。这将允许您使用 *, ** and ? 作为特殊匹配字符，例如invoice/customer*将invoice字段与以customer开头的子字段相匹配。每个级别的字段由/分隔，就像文件系统路径一样。\n有一些方法允许您获取有关选择集中字段的更详细信息。例如，如果您经常使用Relay，您希望知道查询的Connection部分中请求了哪些字段:\nquery { users(first:10) { edges { node { name age weight friends { name } } } } } 您可以编写代码来获取与glob匹配的每个特定字段的详细信息:\nDataFetchingFieldSelectionSet selectionSet = env.getSelectionSet(); List\u0026lt;SelectedField\u0026gt; nodeFields = selectionSet.getFields(\u0026#34;edges/nodes/*\u0026#34;); nodeFields.forEach(selectedField -\u0026gt; { System.out.println(selectedField.getName()); System.out.println(selectedField.getFieldDefinition().getType()); DataFetchingFieldSelectionSet innerSelectionSet = selectedField.getSelectionSet(); // this forms a tree of selection and you can get very fancy with it } 字段的可见性 默认情况下，GraphqlSchema中定义的每个字段都可用。在某些情况下，您可能需要根据用户限制某些字段。\n您可以使用graphql.schema.visibility.GraphqlFieldVisibility来实现这一点。\n一个简单的graphql.schema.visibility.BlockedFields实现基于全限定字段名称：\nGraphqlFieldVisibility blockedFields = BlockedFields.newBlock() .addPattern(\u0026#34;Character.id\u0026#34;) .addPattern(\u0026#34;Droid.appearsIn\u0026#34;) .addPattern(\u0026#34;.*\\\\.hero\u0026#34;) // it uses regular expressions .build(); GraphQLCodeRegistry codeRegistry = GraphQLCodeRegistry.newCodeRegistry() .fieldVisibility(blockedFields) .build(); GraphQLSchema schema = GraphQLSchema.newSchema() .query(StarWarsSchema.queryType) .codeRegistry(codeRegistry) .build(); 如果需要，还有另一种实现可以阻止在模式上执行检测。请注意，这会使您的服务器违反graphql规范和大多数客户端的期望，因此请谨慎使用。\nGraphQLCodeRegistry codeRegistry = GraphQLCodeRegistry.newCodeRegistry() .fieldVisibility(NoIntrospectionGraphqlFieldVisibility.NO_INTROSPECTION_FIELD_VISIBILITY) .build(); GraphQLSchema schema = GraphQLSchema.newSchema() .query(StarWarsSchema.queryType) .codeRegistry(codeRegistry) .build(); 您可以创建自己的GraphqlFieldVisibility派生，以检查需要做什么来确定哪些字段应该可见或不可见。\nclass CustomFieldVisibility implements GraphqlFieldVisibility { final YourUserAccessService userAccessService; CustomFieldVisibility(YourUserAccessService userAccessService) { this.userAccessService = userAccessService; } @Override public List\u0026lt;GraphQLFieldDefinition\u0026gt; getFieldDefinitions(GraphQLFieldsContainer fieldsContainer) { if (\u0026#34;AdminType\u0026#34;.equals(fieldsContainer.getName())) { if (!userAccessService.isAdminUser()) { return Collections.emptyList(); } } return fieldsContainer.getFieldDefinitions(); } @Override public GraphQLFieldDefinition getFieldDefinition(GraphQLFieldsContainer fieldsContainer, String fieldName) { if (\u0026#34;AdminType\u0026#34;.equals(fieldsContainer.getName())) { if (!userAccessService.isAdminUser()) { return null; } } return fieldsContainer.getFieldDefinition(fieldName); } } 标量 GraphQL类型系统的叶节点称为标量。一旦达到标量类型，就不能再下降到类型层次结构中。标量类型表示不可分割的值。\nGraphQL规范规定，所有实现都必须具有以下标量类型：\nString aka GraphQLString - UTF‐8 字符串 Boolean aka GraphQLBoolean - true 或者 false. Int aka GraphQLInt Float aka GraphQLFloat ID aka GraphQLID：以与字符串相同的方式序列化的唯一标识符。然而，将其定义为ID意味着它不是人类可读的。 graphql-java-extended-scalars扩展了以下标量：\nLong aka GraphQLLong Short aka GraphQLShort Byte aka GraphQLByte BigDecimal aka GraphQLBigDecimal BigInteger aka GraphQLBigInteger 自定义标量 您可以自定义标量。在这样做时，您将承担在运行时强制值的责任，稍后我们将对此进行解释。 假设我们决定需要一个电子邮件标量类型。它将以电子邮件地址作为输入和输出。\n我们会创建下面的graphql.schema.GraphQLScalarType实例：\npublic static class EmailScalar { public static final GraphQLScalarType EMAIL = GraphQLScalarType.newScalar() .name(\u0026#34;email\u0026#34;) .description(\u0026#34;A custom scalar that handles emails\u0026#34;) .coercing(new Coercing() { @Override public Object serialize(Object dataFetcherResult) { return serializeEmail(dataFetcherResult); } @Override public Object parseValue(Object input) { return parseEmailFromVariable(input); } @Override public Object parseLiteral(Object input) { return parseEmailFromAstLiteral(input); } }) .build(); private static boolean looksLikeAnEmailAddress(String possibleEmailValue) { // ps. I am not trying to replicate RFC-3696 clearly return Pattern.matches(\u0026#34;[A-Za-z0-9]@[.*]\u0026#34;, possibleEmailValue); } private static Object serializeEmail(Object dataFetcherResult) { String possibleEmailValue = String.valueOf(dataFetcherResult); if (looksLikeAnEmailAddress(possibleEmailValue)) { return possibleEmailValue; } else { throw new CoercingSerializeException(\u0026#34;Unable to serialize \u0026#34; + possibleEmailValue + \u0026#34; as an email address\u0026#34;); } } private static Object parseEmailFromVariable(Object input) { if (input instanceof String) { String possibleEmailValue = input.toString(); if (looksLikeAnEmailAddress(possibleEmailValue)) { return possibleEmailValue; } } throw new CoercingParseValueException(\u0026#34;Unable to parse variable value \u0026#34; + input + \u0026#34; as an email address\u0026#34;); } private static Object parseEmailFromAstLiteral(Object input) { if (input instanceof StringValue) { String possibleEmailValue = ((StringValue) input).getValue(); if (looksLikeAnEmailAddress(possibleEmailValue)) { return possibleEmailValue; } } throw new CoercingParseLiteralException( \u0026#34;Value is not any email address : \u0026#39;\u0026#34; + String.valueOf(input) + \u0026#34;\u0026#39;\u0026#34; ); } } 任何自定义标量实现的真正工作都是graphql.schema.Coercing执行。它负责3个功能：\nparseValue : 获取变量输入对象并转换为Java运行时表示 parseLiteral : 采用AST文字graphql.language.Value作为输入并转换为Java运行时表示 serialize : 获取Java对象并将其转换为该标量的输出形状 因此，自定义标量代码必须处理2种形式的输入（parseValue/parseLiteral）和1种形式的输出（serialize）。\n假如有下面的输入：\nmutation Contact($mainContact: Email!) { makeContact(mainContactEmail: $mainContact, backupContactEmail: \u0026#34;backup@company.com\u0026#34;) { id mainContactEmail } } 通过parseValue调用，将$mainContact变量值转换为运行时对象 通过parseLiteral调用以转换AST graphql.language.StringValue “backup@company.com“转换为运行时对象 通过serialize调用，将mainContactEmail的运行时表示转换为可输出的表单 验证输入输出 这些方法可以验证所接收的输入是否有意义。例如，我们的电子邮件标量将尝试验证输入和输出是否确实是电子邮件地址。 graphql.schema.Coercing的规定如下：\nserialize 只能允许抛出 graphql.schema.SerializeException，这表示该值无法序列化为适当的形式。您不能允许其他运行时异常转义此方法以获得用于验证的正常graphql行为。 parseValue只能允许抛出graphql.schema.ParseValueException,这表示无法将值作为输入解析为适当的形式。您不能允许其他运行时异常逃脱此方法以获得用于验证的正常graphql行为。 parseLiteral只能允许抛出graphql.schema.ParseLiteralException，这表明AST值不能作为输入解析为适当的形式。您不能允许任何运行时异常逃脱此方法以获得正常的graphql行为进行验证。 有些人试图依赖运行时异常进行验证，并希望它们以graphql错误的形式出现。事实并非如此。您必须遵循强制方法契约，以允许graphqljava引擎根据标量类型的graphql规范工作。\n创建schema GraphQL API有一个schema，它定义了可以查询或修改的每个字段以及这些字段的类型。graphql-java提供了两种不同的schema定义方式：编程或通过特殊的graphql-dsl（称为SDL）。\nSDL方式:\ntype Foo { bar: String } 代码方式：\nGraphQLObjectType fooType = newObject() .name(\u0026#34;Foo\u0026#34;) .field(newFieldDefinition() .name(\u0026#34;bar\u0026#34;) .type(GraphQLString)) .build(); DataFetcher 和 TypeResolver DataFetcher为字段提供数据（如果是mutation，则会进行更改）。每个字段定义都有一个DataFetcher。如果未配置，则使用PropertyDataFetch。\nPropertyDataFetcher从Map和JavaBeans获取数据。因此，当字段名与源对象的Map键或属性名匹配时，不需要DataFetcher。\nTypeResolver帮助graphql-java决定具体值属于哪种类型。这是Interface和Union所需要的。\n例如，假设您有一个名为MagicUserType的接口，它可以解析回一系列名为Wizard、Witch和Necromancer的Java类。类型解析器负责检查运行时对象，并决定应该使用什么GraphqlObjectType来表示它，从而决定将调用哪些数据获取器和字段。\nnew TypeResolver() { @Override public GraphQLObjectType getType(TypeResolutionEnvironment env) { Object javaObject = env.getObject(); if (javaObject instanceof Wizard) { return env.getSchema().getObjectType(\u0026#34;WizardType\u0026#34;); } else if (javaObject instanceof Witch) { return env.getSchema().getObjectType(\u0026#34;WitchType\u0026#34;); } else { return env.getSchema().getObjectType(\u0026#34;NecromancerType\u0026#34;); } } }; 使用SDL的方式创建Schema 通过SDL定义模式时，在创建可执行模式时，需要提供所需的DataFetcher和TypeResolver。 以以下静态模式定义文件starWarsSchema.graphqls为例：\nschema { query: QueryType } type QueryType { hero(episode: Episode): Character human(id : String) : Human droid(id: ID!): Droid } enum Episode { NEWHOPE EMPIRE JEDI } interface Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! } type Human implements Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! homePlanet: String } type Droid implements Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! primaryFunction: String } 静态架构定义文件starWarsSchema.graphqls包含字段和类型定义，但需要运行时连接才能使其成为真正的可执行模式。\n运行时连接包含DataFetcher、TypeResolver和自定义Scalar，它们是生成完全可执行架构所需的。\n使用此生成器模式将其连接在一起：\nRuntimeWiring buildRuntimeWiring() { return RuntimeWiring.newRuntimeWiring() .scalar(CustomScalar) // this uses builder function lambda syntax .type(\u0026#34;QueryType\u0026#34;, typeWiring -\u0026gt; typeWiring .dataFetcher(\u0026#34;hero\u0026#34;, new StaticDataFetcher(StarWarsData.getArtoo())) .dataFetcher(\u0026#34;human\u0026#34;, StarWarsData.getHumanDataFetcher()) .dataFetcher(\u0026#34;droid\u0026#34;, StarWarsData.getDroidDataFetcher()) ) .type(\u0026#34;Human\u0026#34;, typeWiring -\u0026gt; typeWiring .dataFetcher(\u0026#34;friends\u0026#34;, StarWarsData.getFriendsDataFetcher()) ) // you can use builder syntax if you don\u0026#39;t like the lambda syntax .type(\u0026#34;Droid\u0026#34;, typeWiring -\u0026gt; typeWiring .dataFetcher(\u0026#34;friends\u0026#34;, StarWarsData.getFriendsDataFetcher()) ) // or full builder syntax if that takes your fancy .type( newTypeWiring(\u0026#34;Character\u0026#34;) .typeResolver(StarWarsData.getCharacterTypeResolver()) .build() ) .build(); } 最后，您可以通过将静态模式和连接组合在一起来生成可执行模式，如以下示例所示：\nSchemaParser schemaParser = new SchemaParser(); SchemaGenerator schemaGenerator = new SchemaGenerator(); File schemaFile = loadSchema(\u0026#34;starWarsSchema.graphqls\u0026#34;); TypeDefinitionRegistry typeRegistry = schemaParser.parse(schemaFile); RuntimeWiring wiring = buildRuntimeWiring(); GraphQLSchema graphQLSchema = schemaGenerator.makeExecutableSchema(typeRegistry, wiring); 除了上面显示的生成器样式之外，TypeResolver和DataFetcher也可以使用WiringFactory接口进行连接。这允许更动态的运行时连接，因为可以检查SDL定义以决定连接什么。例如，您可以查看SDL指令或SDL定义的其他方面，以帮助您决定创建什么运行时。\nRuntimeWiring buildDynamicRuntimeWiring() { WiringFactory dynamicWiringFactory = new WiringFactory() { @Override public boolean providesTypeResolver(TypeDefinitionRegistry registry, InterfaceTypeDefinition definition) { return getDirective(definition,\u0026#34;specialMarker\u0026#34;) != null; } @Override public boolean providesTypeResolver(TypeDefinitionRegistry registry, UnionTypeDefinition definition) { return getDirective(definition,\u0026#34;specialMarker\u0026#34;) != null; } @Override public TypeResolver getTypeResolver(TypeDefinitionRegistry registry, InterfaceTypeDefinition definition) { Directive directive = getDirective(definition,\u0026#34;specialMarker\u0026#34;); return createTypeResolver(definition,directive); } @Override public TypeResolver getTypeResolver(TypeDefinitionRegistry registry, UnionTypeDefinition definition) { Directive directive = getDirective(definition,\u0026#34;specialMarker\u0026#34;); return createTypeResolver(definition,directive); } @Override public boolean providesDataFetcher(TypeDefinitionRegistry registry, FieldDefinition definition) { return getDirective(definition,\u0026#34;dataFetcher\u0026#34;) != null; } @Override public DataFetcher getDataFetcher(TypeDefinitionRegistry registry, FieldDefinition definition) { Directive directive = getDirective(definition, \u0026#34;dataFetcher\u0026#34;); return createDataFetcher(definition,directive); } }; return RuntimeWiring.newRuntimeWiring() .wiringFactory(dynamicWiringFactory).build(); } 指令 假如有下面的类型：\ntype Employee id : ID name : String! startDate : String! salary : Float } 向每个能看到该员工姓名的人发布工资信息可能不是您想要的。相反，你需要某种访问控制，这样如果你的角色是经理，你就可以看到薪水，否则你就得不到数据。\n指令可以帮助您更容易地声明这一点。我们的上述声明大致如下：\ndirective @auth(role : String!) on FIELD_DEFINITION type Employee id : ID name : String! startDate : String! salary : Float @auth(role : \u0026#34;manager\u0026#34;) } class AuthorisationDirective implements SchemaDirectiveWiring { @Override public GraphQLFieldDefinition onField(SchemaDirectiveWiringEnvironment\u0026lt;GraphQLFieldDefinition\u0026gt; environment) { String targetAuthRole = (String) environment.getDirective().getArgument(\u0026#34;role\u0026#34;).getValue(); GraphQLFieldDefinition field = environment.getElement(); GraphQLFieldsContainer parentType = environment.getFieldsContainer(); // // build a data fetcher that first checks authorisation roles before then calling the original data fetcher // DataFetcher originalDataFetcher = environment.getCodeRegistry().getDataFetcher(parentType, field); DataFetcher authDataFetcher = new DataFetcher() { @Override public Object get(DataFetchingEnvironment dataFetchingEnvironment) throws Exception { Map\u0026lt;String, Object\u0026gt; contextMap = dataFetchingEnvironment.getContext(); AuthorisationCtx authContext = (AuthorisationCtx) contextMap.get(\u0026#34;authContext\u0026#34;); if (authContext.hasRole(targetAuthRole)) { return originalDataFetcher.get(dataFetchingEnvironment); } else { return null; } } }; // // now change the field definition to have the new authorising data fetcher environment.getCodeRegistry().dataFetcher(parentType, field, authDataFetcher); return field; } } // // we wire this into the runtime by directive name // RuntimeWiring.newRuntimeWiring() .directive(\u0026#34;auth\u0026#34;, new AuthorisationDirective()) .build(); 这修改了GraphQLFieldDefinition，使得只有在当前授权上下文具有管理器角色时才会调用其原始数据获取器。您使用什么机制进行授权取决于您。例如，您可以使用SpringSecurity，graphql-java并不真正关心。\n您将在graphql输入的执行“上下文”对象中提供此授权检查器，以便稍后可以在DataFetchingEnvironment中访问它:\nAuthorisationCtx authCtx = AuthorisationCtx.obtain(); ExecutionInput executionInput = ExecutionInput.newExecutionInput() .query(query) .context(authCtx) .build(); 声明指令 为了在SDL中使用指令，graphql规范要求在使用它之前必须声明它的形状。我们上面的@auth指令示例在使用之前需要这样声明。\n# This is a directive declaration directive @auth(role : String!) on FIELD_DEFINITION type Employee id : ID # and this is a usage of that declared directive salary : Float @auth(role : \u0026#34;manager\u0026#34;) } 一个例外是@deprecated指令，它为您隐式声明如下：\ndirective @deprecated(reason: String = \u0026#34;No longer supported\u0026#34;) on FIELD_DEFINITION | ENUM_VALUE 有效的SDL指令位置如下：\nSCHEMA, SCALAR, OBJECT, FIELD_DEFINITION, ARGUMENT_DEFINITION, INTERFACE, UNION, ENUM, ENUM_VALUE, INPUT_OBJECT, INPUT_FIELD_DEFINITION 指令通常应用于字段定义，但正如您所看到的，有许多地方可以应用它们。\n日期格式是一个贯穿各领域的问题，我们只需要编写一次并在许多领域应用它。 下面演示了一个示例模式指令，它可以将日期格式应用于LocaleDate对象的字段。 这个例子中最棒的是，它为应用它的每个字段添加了一个额外的格式参数。因此，客户端可以选择您为每个请求提供的日期格式。\ndirective @dateFormat on FIELD_DEFINITION type Query { dateField : String @dateFormat } 那么我们的运行时代码可以是：\npublic static class DateFormatting implements SchemaDirectiveWiring { @Override public GraphQLFieldDefinition onField(SchemaDirectiveWiringEnvironment\u0026lt;GraphQLFieldDefinition\u0026gt; environment) { GraphQLFieldDefinition field = environment.getElement(); GraphQLFieldsContainer parentType = environment.getFieldsContainer(); // // DataFetcherFactories.wrapDataFetcher is a helper to wrap data fetchers so that CompletionStage is handled correctly // along with POJOs // DataFetcher originalFetcher = environment.getCodeRegistry().getDataFetcher(parentType, field); DataFetcher dataFetcher = DataFetcherFactories.wrapDataFetcher(originalFetcher, ((dataFetchingEnvironment, value) -\u0026gt; { DateTimeFormatter dateTimeFormatter = buildFormatter(dataFetchingEnvironment.getArgument(\u0026#34;format\u0026#34;)); if (value instanceof LocalDateTime) { return dateTimeFormatter.format((LocalDateTime) value); } return value; })); // // This will extend the field by adding a new \u0026#34;format\u0026#34; argument to it for the date formatting // which allows clients to opt into that as well as wrapping the base data fetcher so it // performs the formatting over top of the base values. // FieldCoordinates coordinates = FieldCoordinates.coordinates(parentType, field); environment.getCodeRegistry().dataFetcher(coordinates, dataFetcher); return field.transform(builder -\u0026gt; builder .argument(GraphQLArgument .newArgument() .name(\u0026#34;format\u0026#34;) .type(Scalars.GraphQLString) .defaultValueProgrammatic(\u0026#34;dd-MM-YYYY\u0026#34;) ) ); } private DateTimeFormatter buildFormatter(String format) { String dtFormat = format != null ? format : \u0026#34;dd-MM-YYYY\u0026#34;; return DateTimeFormatter.ofPattern(dtFormat); } } static GraphQLSchema buildSchema() { String sdlSpec = \u0026#34;directive @dateFormat on FIELD_DEFINITION\\n\u0026#34; + \u0026#34;type Query {\\n\u0026#34; + \u0026#34; dateField : String @dateFormat \\n\u0026#34; + \u0026#34;}\u0026#34;; TypeDefinitionRegistry registry = new SchemaParser().parse(sdlSpec); RuntimeWiring runtimeWiring = RuntimeWiring.newRuntimeWiring() .directive(\u0026#34;dateFormat\u0026#34;, new DateFormatting()) .build(); return new SchemaGenerator().makeExecutableSchema(registry, runtimeWiring); } public static void main(String[] args) { GraphQLSchema schema = buildSchema(); GraphQL graphql = GraphQL.newGraphQL(schema).build(); Map\u0026lt;String, Object\u0026gt; root = new HashMap\u0026lt;\u0026gt;(); root.put(\u0026#34;dateField\u0026#34;, LocalDateTime.of(1969, 10, 8, 0, 0)); String query = \u0026#34;\u0026#34; + \u0026#34;query {\\n\u0026#34; + \u0026#34; default : dateField \\n\u0026#34; + \u0026#34; usa : dateField(format : \\\u0026#34;MM-dd-YYYY\\\u0026#34;) \\n\u0026#34; + \u0026#34;}\u0026#34;; ExecutionInput executionInput = ExecutionInput.newExecutionInput() .root(root) .query(query) .build(); ExecutionResult executionResult = graphql.execute(executionInput); Map\u0026lt;String, Object\u0026gt; data = executionResult.getData(); // data[\u0026#39;default\u0026#39;] == \u0026#39;08-10-1969\u0026#39; // data[\u0026#39;usa\u0026#39;] == \u0026#39;10-08-1969\u0026#39; } 请注意，SDL定义没有格式参数，一旦应用了指令连接，它就被添加到字段定义中，因此客户端可以开始使用它。 请注意，graphql-java没有随此实现一起提供。这里只提供了一个示例，说明您可以自己添加什么。\n指令链 指令按照遇到的顺序应用。例如，想象一下改变字段值大小写的指令。\ndirective @uppercase on FIELD_DEFINITION directive @lowercase on FIELD_DEFINITION directive @mixedcase on FIELD_DEFINITION directive @reversed on FIELD_DEFINITION type Query { lowerCaseValue : String @uppercase upperCaseValue : String @lowercase mixedCaseValue : String @mixedcase # # directives are applied in order hence this will be lower, then upper, then mixed then reversed # allTogetherNow : String @lowercase @uppercase @mixedcase @reversed } 当执行上述指令时，每个指令将一个应用于另一个之上。每个指令实现都应该小心地保留以前的数据获取器以保持行为（当然，除非您打算放弃它）\n","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/graphql-java%E5%AE%9E%E7%8E%B0/","series":[],"smallImg":"","tags":[{"title":"graphql","url":"/myblog/tags/graphql/"}],"timestamp":1669575738,"title":"Graphql Java实现"},{"authors":[],"categories":[{"title":"规范","url":"/myblog/categories/%E8%A7%84%E8%8C%83/"}],"content":"GraphQL 是一个用于 API 的查询语言，是一个使用基于类型系统来执行查询的服务端运行时。GraphQL 并没有和任何特定数据库或者存储引擎绑定，而是依靠你现有的代码和数据支撑。\nschema定义 schema定义由普通对象类型和内置类型组成。其中内置类型是query(用于查询)和mutation（用于修改） ，两者之一必须存在schema文件中（ 因为其是GraphQL 查询的入口）。有必要记住的是，除了作为 schema 的入口，Query 和 Mutation 类型与其它 GraphQL 对象类型别无二致，它们的字段也是一样的工作方式。\n下面是一个示例文件：\nscalar LocalDate type Query { #必须类型 queryUsers: [User] queryByBirth(birth:LocalDate):User queryByDetail(birth:LocalDate,name:String):User } type User { # 可选类型 id: String name: String age: Int birth: LocalDate } 类型 标量类型 GraphQL 自带一组默认标量类型：\nInt：有符号 32 位整数。 Float：有符号双精度浮点值。 String：UTF‐8 字符序列。 Boolean：true 或者 false。 ID：ID 标量类型表示一个唯一标识符，通常用以重新获取对象或者作为缓存中的键。ID 类型使用和 String 一样的方式序列化； 当然我们也可以自定义标量类型，例如上面的 LocalDate 。 除此之外，还需要在我们的实现中定义序列化、反序列化和验证等方法。\n枚举类型 enum Episode { NEWHOPE EMPIRE JEDI } 列表类型 在 GraphQL schema 语言中，我们通过将类型包在方括号（[ 和 ]）中的方式来标记列表：\nmyField: [String] 接口 接口是一个抽象类型，它包含某些字段，而对象类型必须包含这些字段，才能算实现了这个接口。\ninterface Animal { id: ID! name: String! } 具体的实现：\ntype Cat implements Animal{ id: ID! name: String! color: String } 联合类型 union SearchResult = Human | Droid | Starship 联合类型的成员需要是具体对象类型；你不能使用接口或者其他联合类型来创造一个联合类型。\n输入类型（Input Types） 目前为止，我们只讨论过将例如枚举和字符串等标量值作为参数传递给字段，但是怎么传递复杂对象呢？这在变更（mutation）中特别有用。答案是输入对象，其看上去和常规对象一模一样，除了关键字是 input 而不是 type：\ninput ReviewInput { stars: Int! commentary: String } 你可以像这样在变更（mutation）中使用输入对象类型：\nmutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) { createReview(episode: $ep, review: $review) { stars commentary } } 输入：\n{ \u0026#34;ep\u0026#34;: \u0026#34;JEDI\u0026#34;, \u0026#34;review\u0026#34;: { \u0026#34;stars\u0026#34;: 5, \u0026#34;commentary\u0026#34;: \u0026#34;This is a great movie!\u0026#34; } } 输出：\n{ \u0026#34;data\u0026#34;: { \u0026#34;createReview\u0026#34;: { \u0026#34;stars\u0026#34;: 5, \u0026#34;commentary\u0026#34;: \u0026#34;This is a great movie!\u0026#34; } } } 非空限制 type Character { name: String! appearsIn: [Episode]! } 类型名后面添加一个感叹号!将其标注为非空，这表示我们的服务器对于这个字段，总是会返回一个非空值，如果它结果得到了一个空值，那么事实上将会触发一个 GraphQL 执行错误，以让客户端知道发生了错误。\n非空和列表修饰符可以组合使用。例如你可以要求一个非空字符串的数组：\nmyField: [String!] 这表示数组本身可以为空，但是其不能有任何空值成员。用 JSON 举例如下：\nmyField: null // 有效 myField: [] // 有效 myField: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] // 有效 myField: [\u0026#39;a\u0026#39;, null, \u0026#39;b\u0026#39;] // 错误 然后，我们来定义一个不可为空的字符串数组：\nmyField: [String]! 这表示数组本身不能为空，但是其可以包含空值成员：\nmyField: null // 错误 myField: [] // 有效 myField: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] // 有效 myField: [\u0026#39;a\u0026#39;, null, \u0026#39;b\u0026#39;] // 有效 参数 GraphQL 对象类型上的每一个字段都可能有零个或者多个参数，表示可以在该字段上进行筛选。例如下面的 length 字段：\ntype Starship { id: ID! name: String! length(unit: LengthUnit = METER): Float } 所有参数都是具名的,上面的例子中，unit是参数的名称，LengthUnit是参数的类型，METER是默认值。\n查询 基础查询 { hero { name # 查询可以有注释 friends { name } } } 返回结果：\n{ \u0026#34;data\u0026#34;: { \u0026#34;hero\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;R2-D2\u0026#34;, \u0026#34;friends\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Luke Skywalker\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Han Solo\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Leia Organa\u0026#34; } ] } } } 带参数的查询 单个参数：\n{ human(id: \u0026#34;1000\u0026#34;) { name height } } 多个参数：\n{ human(id: \u0026#34;1000\u0026#34;) { name height(unit: FOOT) } } 别名 通过不同参数值来查询相同字段。这便是为何你需要别名 —— 这可以让你重命名结果中的字段为任意的名字。\n{ empireHero: hero(episode: EMPIRE) { name } jediHero: hero(episode: JEDI) { name } } { \u0026#34;data\u0026#34;: { \u0026#34;empireHero\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Luke Skywalker\u0026#34; }, \u0026#34;jediHero\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;R2-D2\u0026#34; } } } 变量 上面讲述的所有例子中，参数是限定好的。有些情况下，我们需要动态选择参数。变量可以帮我实现这个功能。\n使用变量之前，我们得做三件事：\n使用 $variableName 替代查询中的静态值。 声明 $variableName 为查询接受的变量之一。 将 variableName: value 传递到查询中。 { \u0026#34;graphiql\u0026#34;: true, \u0026#34;variables\u0026#34;: { \u0026#34;episode\u0026#34;: JEDI } } # 传递变量 query HeroNameAndFriends($episode: Episode = \u0026#34;JEDI\u0026#34;) { #声明变量 hero(episode: $episode) {# 使用变量 name friends { name } } } 这样一来，我们的客户端代码就只需要传入不同的变量，而不用构建一个全新的查询了。这事实上也是一个良好实践，意味着查询的参数将是动态的 —— 我们决不能使用用户提供的值来字符串插值以构建查询。\n操作名称 上面的示例中，我们使用了操作名称：HeroNameAndFriends。这是详细写法，也鼓励这么做。因为它对于调试和服务器端日志记录非常有用。\n片段 片段是可复用单元\n{ leftComparison: hero(episode: EMPIRE) { ...comparisonFields # 使用片段 } rightComparison: hero(episode: JEDI) { ...comparisonFields } } # 声明片段 fragment comparisonFields on Character { name appearsIn friends { name } } 在片段中使用变量：\nquery HeroComparison($first: Int = 3) { leftComparison: hero(episode: EMPIRE) { ...comparisonFields } rightComparison: hero(episode: JEDI) { ...comparisonFields } } fragment comparisonFields on Character { name friendsConnection(first: $first) { totalCount edges { node { name } } } } 内联片段 如果你查询的字段返回的是接口或者联合类型，那么你可能需要使用内联片段来取出下层具体类型的数据：\nquery HeroForEpisode($ep: Episode!) { hero(episode: $ep) { name ... on Droid { primaryFunction } ... on Human { height } } } 传入变量：\n{ \u0026#34;ep\u0026#34;: \u0026#34;JEDI\u0026#34; } 返回数据\n{ \u0026#34;data\u0026#34;: { \u0026#34;hero\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;R2-D2\u0026#34;, \u0026#34;primaryFunction\u0026#34;: \u0026#34;Astromech\u0026#34; } } } 如果要请求具体类型上的字段，你需要使用一个类型条件内联片段。因为第一个片段标注为 \u0026hellip; on Droid，primaryFunction 仅在 hero 返回的 Character 为 Droid 类型时才会执行。\n内省 我们有时候会需要去问 GraphQL Schema 它支持哪些查询。GraphQL 通过内省系统让我们可以做到这点！\n查询所有类型：\n{ __schema { types { name } } } 返回结果：\n{ \u0026#34;data\u0026#34;: { \u0026#34;__schema\u0026#34;: { \u0026#34;types\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Boolean\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Int\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;LocalDate\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Query\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;String\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;User\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;__Directive\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;__DirectiveLocation\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;__EnumValue\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;__Field\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;__InputValue\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;__Schema\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;__Type\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;__TypeKind\u0026#34; } ] } } } String, Boolean - 这些是内建的标量，由类型系统提供。 __Schema, __Type,__TypeKind, __Field, __InputValue, __EnumValue, __Directive - 这些有着两个下划线的类型是内省系统的一部分。 修改 GraphQL 的大部分讨论集中在数据获取，但是任何完整的数据平台也都需要一个改变服务端数据的方法。\nmutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) { createReview(episode: $ep, review: $review) { stars commentary } } 变量：\n{ \u0026#34;ep\u0026#34;: \u0026#34;JEDI\u0026#34;, \u0026#34;review\u0026#34;: { \u0026#34;stars\u0026#34;: 5, \u0026#34;commentary\u0026#34;: \u0026#34;This is a great movie!\u0026#34; } } { \u0026#34;data\u0026#34;: { \u0026#34;createReview\u0026#34;: { \u0026#34;stars\u0026#34;: 5, \u0026#34;commentary\u0026#34;: \u0026#34;This is a great movie!\u0026#34; } } } 注意 createReview 字段如何返回了新建的 review 的 stars 和 commentary 字段。\n查询字段时，是并行执行，而变更字段时，是线性执行，一个接着一个。\n这意味着如果我们一个请求中发送了两个 incrementCredits 变更，第一个保证在第二个之前执行，以确保我们不会出现竞态。\n指令 我们上面讨论的变量使得我们可以避免手动字符串插值构建动态查询。传递变量给参数解决了一大堆这样的问题，但是我们可能也需要一个方式使用变量动态地改变我们查询的结构。\nquery Hero($episode: Episode, $withFriends: Boolean!) { hero(episode: $episode) { name friends @include(if: $withFriends) { name } } } 传入变量：\n{ \u0026#34;episode\u0026#34;: \u0026#34;JEDI\u0026#34;, \u0026#34;withFriends\u0026#34;: false } 输出结果：\n{ \u0026#34;data\u0026#34;: { \u0026#34;hero\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;R2-D2\u0026#34; } } } 尝试修改上面的变量，传递 true 给 withFriends，看看结果的变化。\n我们用了 GraphQL 中一种称作指令的新特性。一个指令可以附着在字段或者片段包含的字段上，然后以任何服务端期待的方式来改变查询的执行。GraphQL 的核心规范包含两个指令，其必须被任何规范兼容的 GraphQL 服务器实现所支持：\n@include(if: Boolean) 仅在参数为 true 时，包含此字段。 @skip(if: Boolean) 如果参数为 true，跳过此字段。 HTTP请求 你的 GraphQL HTTP 服务器应当能够处理 HTTP GET 和 POST 方法。\nGET 请求 在收到一个 HTTP GET 请求时，应当在 “query” 查询字符串（query string）中指定 GraphQL 查询。例如，如果我们要执行以下 GraphQL 查询：\n{ me { name } } 此请求可以通过 HTTP GET 发送，如下所示：\nhttp://myapi/graphql?query={me{name}} 查询变量可以作为 JSON 编码的字符串发送到名为 variables 的附加查询参数中。如果查询包含多个具名操作，则可以使用一个 operationName 查询参数来控制哪一个应当执行。\nPOST 请求 标准的 GraphQL POST 请求应当使用 application/json 内容类型（content type），并包含以下形式 JSON 编码的请求体：\n{ \u0026#34;query\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;operationName\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;variables\u0026#34;: { \u0026#34;myVariable\u0026#34;: \u0026#34;someValue\u0026#34;, ... } } operationName 和 variables 是可选字段。仅当查询中存在多个操作时才需要 operationName。\n除了上边这种请求之外，我们还建议支持另外两种情况：\n如果存在 “query” 这一查询字符串参数（如上面的 GET 示例中），则应当以与 HTTP GET 相同的方式进行解析和处理。 如果存在 “application/graphql” Content-Type 头，则将 HTTP POST 请求体内容视为 GraphQL 查询字符串。 如果你使用的是 express-graphql，那么你已经直接获得了这些支持。\n响应 无论使用任何方法发送查询和变量，响应都应当以 JSON 格式在请求正文中返回。如规范中所述，查询结果可能会是一些数据和一些错误，并且应当用以下形式的 JSON 对象返回：\n{ \u0026#34;data\u0026#34;: { ... }, \u0026#34;errors\u0026#34;: [ ... ] } 如果没有返回错误，响应中不应当出现 \u0026quot;errors\u0026quot; 字段。如果没有返回数据，则 根据 GraphQL 规范，只能在执行期间发生错误时才能包含 \u0026quot;data\u0026quot; 字段。\n","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/graphql%E8%A7%84%E8%8C%83/","series":[],"smallImg":"","tags":[{"title":"graphql","url":"/myblog/tags/graphql/"}],"timestamp":1669575738,"title":"Graphql规范"},{"authors":[],"categories":[{"title":"java","url":"/myblog/categories/java/"}],"content":"注解驱动 Spring for GraphQL提供了一个基于注释的编程模型，其中@Controller组件使用注释来声明具有灵活方法签名的处理程序方法，以获取特定GraphQL字段的数据。例如：\n@Controller public class GreetingController { @QueryMapping public String hello() { return \u0026#34;Hello, world!\u0026#34;; } } 将此方法绑定到查询，即查询类型下的字段。 如果未在注释上声明，则根据方法名确定查询。 Spring使用RuntimeWiring.Builder将上述处理程序方法注册为名为“hello”的查询graphql.schema.DataFetcher。\nAnnotatedControllerConfigurer 检测 @Controller bean 并通过 RuntimeWiring.Builder 将标注的方法注册为 DataFetchers。 它是 RuntimeWiringConfigurer 的一个实现，可以添加到 GraphQlSource.Builder。 Spring Boot 自动将 AnnotatedControllerConfigurer 声明为 bean，并将所有 RuntimeWiringConfigurer bean 添加到 GraphQlSource.Builder 并启用对带注释的 DataFetchers 的支持。\n@SchemaMapping @SchemaMapping 注解将方法映射到 GraphQL schema中的字段，并将其声明为该字段的 DataFetcher。 注解可以指定类型名称，以及字段名称：\n@Controller public class BookController { @SchemaMapping(typeName=\u0026#34;Book\u0026#34;, field=\u0026#34;author\u0026#34;) public Author getAuthor(Book book) { // ... } } @SchemaMapping 注解也可以省略这些属性，在这种情况下，字段名称默认为方法名称，而类型名称默认为方法参数的简单类名称。 例如，下面默认键入Book和字段author：\n@Controller public class BookController { @SchemaMapping public Author author(Book book) { // ... } } @SchemaMapping 注解可以在类级别声明，为类中的所有处理程序方法指定默认类型名称:\n@Controller @SchemaMapping(typeName=\u0026#34;Book\u0026#34;) public class BookController { // @SchemaMapping methods for fields of the \u0026#34;Book\u0026#34; type } @QueryMapping、@MutationMapping 和@SubscriptionMapping 是复合注解，它们本身使用@SchemaMapping 进行标注，并且typeName 分别预设为Query、Mutation 或Subscription。\n方法签名 schema映射处理程序方法可以具有以下任何方法参数：\nMethod Argument Description @Argument 用于访问绑定到更高级别、类型化对象的命名字段参数。 @Arguments 用于访问绑定到更高级别、类型化对象的所有字段参数。 @Argument Map\u0026lt;String, Object\u0026gt; 用于访问参数的原始map，其中@Argument没有name属性。 @Arguments Map\u0026lt;String, Object\u0026gt; 用于访问参数的原始映射。 @ProjectedPayload Interface 用于通过项目接口访问字段参数。 \u0026ldquo;Source\u0026rdquo; 用于访问字段的源（即父/容器）实例。 DataLoader 用于访问DataLoaderRegistry中的DataLoader。 @ContextValue 用于从DataFetchingEnvironment中的主GraphQLContext访问属性。 @LocalContextValue 用于从DataFetchingEnvironment中的本地GraphQLContext访问属性。 GraphQLContext 用于从DataFetchingEnvironment访问上下文。 java.security.Principal 从Spring Security上下文中获取（如果可用）。 @AuthenticationPrincipal 从Spring Security上下文访问Authentication#getPrincipal（）。 DataFetchingFieldSelectionSet 通过DataFetchingEnvironment访问查询的选择集。 Locale, Optional 用于从DataFetchingEnvironment访问区域设置。 DataFetchingEnvironment 用于直接访问基础DataFetchingEnvironment。 schema映射处理程序方法可以返回：\n任何类型的解析值。 Mono 和Flux 用于异步值。 支持控制器方法和响应式 DataFetcher 中描述的任何 DataFetcher。 java.util.concurrent.Callable 以异步方式生成值。 为此，必须使用 Executor 配置 AnnotatedControllerConfigurer。 @Argument 在 GraphQL Java 中，DataFetchingEnvironment 提供了对特定字段的参数值映射的访问。 这些值可以是简单的标量值（例如 String、Long）、用于更复杂输入的Map 或列表。\n使用 @Argument 注释将参数绑定到目标对象并注入到处理程序方法中。 绑定是通过将参数值映射到预期方法参数类型的主数据构造函数来执行的，或者通过使用默认构造函数来创建对象，然后将参数值映射到它的属性。 这是递归重复的，使用所有嵌套的参数值并相应地创建嵌套的目标对象。 例如：\nquery { bookById(id: \u0026#34;book-1\u0026#34;) { id name author { id lastName } } } type Query { bookById(id:String):Book } @Controller public class BookController { @QueryMapping public Book bookById(@Argument String id) { // ... } @MutationMapping public Book addBook(@Argument BookInput bookInput) { // ... } } 默认情况下，如果方法参数名称可用，则它用于查找参数。 如果需要，您可以通过注解自定义名称，例如 @Argument(\u0026ldquo;bookInput\u0026rdquo;)。\n如果绑定失败，则会引发 BindException，绑定问题累积为字段错误，其中每个错误的字段是发生问题的参数路径。\n您可以将 @Argument 与 Map\u0026lt;String, Object\u0026gt; 参数一起使用，以获取所有参数值的原始映射。 不得设置 @Argument 上的 name 属性。\n@Arguments @Arguments 绑定参数到对象类型，而 @Argument 则绑定到简单参数。\n例如，@Argument BookInput bookInput 使用参数“bookInput”的值来初始化 BookInput对象。\n您可以将 @Arguments 与 Map\u0026lt;String, Object\u0026gt; 参数一起使用，以获取所有参数值的原始映射。\n@ProjectedPayload 当 Spring Data 在类路径上时，参数投影由 Spring Data 的接口投影提供。\n要使用它，请创建一个使用 @ProjectedPayload 注释的接口并将其声明为控制器方法参数。 如果参数使用@Argument 进行注释，则它适用于 DataFetchingEnvironment.getArguments() 映射中的单个参数。 在没有 @Argument 的情况下声明时，投影适用于完整参数映射中的顶级参数。\n@Controller public class BookController { @QueryMapping public Book bookById(BookIdProjection bookId) { // ... } @MutationMapping public Book addBook(@Argument BookInputProjection bookInput) { // ... } } @ProjectedPayload interface BookIdProjection { Long getId(); } @ProjectedPayload interface BookInputProjection { String getName(); @Value(\u0026#34;#{target.author + \u0026#39; \u0026#39; + target.name}\u0026#34;) String getAuthorAndName(); } Source 在 GraphQL Java 中，DataFetchingEnvironment 提供对字段源（即父/容器）实例的访问。 要访问它，只需声明预期目标类型的方法参数。\n@Controller public class BookController { @SchemaMapping public Author author(Book book) { // ... } } 源方法参数还有助于确定映射的类型名称。 如果 Java 类的简单名称与 GraphQL 类型匹配，则无需在 @SchemaMapping 注解中显式指定类型名称。\nDataLoader 当您为实体注册批量加载功能时，如批量加载中所述，您可以通过声明 DataLoader 类型的方法参数来访问实体的 DataLoader 并使用它来加载实体：\n@Controller public class BookController { public BookController(BatchLoaderRegistry registry) { registry.forTypePair(Long.class, Author.class).registerMappedBatchLoader((authorIds, env) -\u0026gt; { // return Map\u0026lt;Long, Author\u0026gt; }); } @SchemaMapping public CompletableFuture\u0026lt;Author\u0026gt; author(Book book, DataLoader\u0026lt;Long, Author\u0026gt; loader) { return loader.load(book.getAuthorId()); } } 默认情况下，BatchLoaderRegistry 使用值类型的完整类名（例如 Author 的类名）作为注册键，因此只需使用泛型类型声明 DataLoader 方法参数即可提供足够的信息来在 DataLoaderRegistry 中定位它。 作为后备，DataLoader 方法参数解析器还将尝试将方法参数名称作为键，但通常这不是必需的。\n请注意，对于许多加载相关实体的情况，@SchemaMapping 只是委托给 DataLoader，您可以使用下一节中描述的 @BatchMapping 方法来减少样板。\nValidation 当找到 javax.validation.Validator bean 时，AnnotatedControllerConfigurer 启用对带注释的控制器方法的 Bean Validation 的支持。 通常，bean 的类型为 LocalValidatorFactoryBean。\nBean 验证允许您声明类型的约束：\npublic class BookInput { @NotNull private String title; @NotNull @Size(max=13) private String isbn; } 然后，您可以使用 @Valid 注释控制器方法参数以在方法调用之前对其进行验证：\n@Controller public class BookController { @MutationMapping public Book addBook(@Argument @Valid BookInput bookInput) { // ... } } 如果在验证期间发生错误，则会引发 ConstraintViolationException。 您可以使用异常解决链来决定如何将其转换为错误以包含在 GraphQL 响应中，从而将其呈现给客户端。\nBean 验证对@Argument、@Arguments 和@ProjectedPayload 方法参数很有用，但更普遍地适用于任何方法参数。\n@BatchMapping 批量加载通过使用 org.dataloader.DataLoader 延迟加载单个实体实例来解决 N+1 选择问题，因此它们可以一起加载。 例如：\n@Controller public class BookController { public BookController(BatchLoaderRegistry registry) { registry.forTypePair(Long.class, Author.class).registerMappedBatchLoader((authorIds, env) -\u0026gt; { // return Map\u0026lt;Long, Author\u0026gt; }); } @SchemaMapping public CompletableFuture\u0026lt;Author\u0026gt; author(Book book, DataLoader\u0026lt;Long, Author\u0026gt; loader) { return loader.load(book.getAuthorId()); } } 对于加载关联实体的直接情况，如上所示，@SchemaMapping 方法只是委托给 DataLoader。 这是可以通过 @BatchMapping 方法避免的样板。 例如：\n@Controller public class BookController { @BatchMapping public Mono\u0026lt;Map\u0026lt;Book, Author\u0026gt;\u0026gt; author(List\u0026lt;Book\u0026gt; books) { // ... } } 以上成为 BatchLoaderRegistry 中的批量加载函数，其中键是 Book 实例，加载的值是它们的作者。 此外，DataFetcher 也透明地绑定到 Book 类型的 author 字段，它只是为作者委托 DataLoader，给定它的源/父 Book 实例。\n默认情况下，字段名默认为方法名，而类型名默认为输入List元素类型的简单类名。 两者都可以通过注释属性进行自定义。 类型名称也可以从类级别@SchemaMapping 继承。\n数据集成 Spring for GraphQL 允许您利用现有的 Spring 技术，遵循常见的编程模型公开底层数据源。\n本节讨论 Spring Data 的集成层，它提供了一种将 Querydsl 或 Query by Example 存储库适应 DataFetcher 的简单方法，包括自动检测选项和标记为 @GraphQlRepository 的存储库的 GraphQL 查询注册。\nQuerydsl Spring for GraphQL 支持使用 Querydsl ，通过 Spring Data Querydsl 扩展来获取数据。 Querydsl 通过使用注释处理器生成元模型，提供了一种灵活但类型安全的方法来表达查询谓词。\n例如，将存储库声明为 QuerydslPredicateExecutor：\npublic interface AccountRepository extends Repository\u0026lt;Account, Long\u0026gt;, QuerydslPredicateExecutor\u0026lt;Account\u0026gt; { } 然后用它来创建一个DataFetcher：\n// For single result queries DataFetcher\u0026lt;Account\u0026gt; dataFetcher = QuerydslDataFetcher.builder(repository).single(); // For multi-result queries DataFetcher\u0026lt;Iterable\u0026lt;Account\u0026gt;\u0026gt; dataFetcher = QuerydslDataFetcher.builder(repository).many(); 现在可以通过 RuntimeWiringConfigurer 注册上述 DataFetcher。\nDataFetcher 从 GraphQL 请求参数构建一个 Querydsl 谓词，并使用它来获取数据。 Spring Data 支持 JPA、MongoDB 和 LDAP 的 QuerydslPredicateExecutor。\n如果存储库是 ReactiveQuerydslPredicateExecutor，则构建器返回 DataFetcher\u0026lt;Mono\u0026gt; 或 DataFetcher\u0026lt;Flux\u0026gt;。 Spring Data MongoDB 支持这种变体。\n构建 要在您的构建中配置 Querydsl，请遵循官方参考文档：\ndependencies { annotationProcessor \u0026#34;com.querydsl:querydsl-apt:$querydslVersion:jpa\u0026#34;, \u0026#39;org.hibernate.javax.persistence:hibernate-jpa-2.1-api:1.0.2.Final\u0026#39;, \u0026#39;javax.annotation:javax.annotation-api:1.3.2\u0026#39; } compileJava { options.annotationProcessorPath = configurations.annotationProcessor } webmvc-http 示例将 Querydsl 用于 artifactRepositories。\n自定义 QuerydslDataFetcher 支持自定义 GraphQL 参数如何绑定到属性以创建 Querydsl 谓词。 默认情况下，每个可用属性的参数都绑定为“等于”。 要自定义它，您可以使用 QuerydslDataFetcher 构建器方法来提供 QuerydslBinderCustomizer。\n存储库本身可能是 QuerydslBinderCustomizer 的一个实例。 这是在自动注册期间自动检测并透明应用的。 但是，当手动构建 QuerydslDataFetcher 时，您将需要使用构建器方法来应用它。\nQuerydslDataFetcher 支持接口和 DTO 投影来转换查询结果，然后再返回这些结果以进行进一步的 GraphQL 处理。\n要将 Spring Data 投影与 Querydsl 存储库一起使用，请创建投影接口或目标 DTO 类，并通过 projectAs 方法对其进行配置，以获得生成目标类型的 DataFetcher：\nclass Account { String name, identifier, description; Person owner; } interface AccountProjection { String getName(); String getIdentifier(); } // For single result queries DataFetcher\u0026lt;AccountProjection\u0026gt; dataFetcher = QuerydslDataFetcher.builder(repository).projectAs(AccountProjection.class).single(); // For multi-result queries DataFetcher\u0026lt;Iterable\u0026lt;AccountProjection\u0026gt;\u0026gt; dataFetcher = QuerydslDataFetcher.builder(repository).projectAs(AccountProjection.class).many(); 自动注册 如果存储库使用@GraphQlRepository 进行注释，则会自动为尚未注册 DataFetcher 且返回类型与存储库域类型匹配的查询注册。 这包括单值和多值查询。\n默认情况下，查询返回的 GraphQL 类型的名称必须与存储库域类型的简单名称匹配。 如果需要，您可以使用 @GraphQlRepository 的 typeName 属性来指定目标 GraphQL 类型名称。\n自动注册检测给定存储库是否实现 QuerydslBinderCustomizer 并通过 QuerydslDataFetcher 构建器方法透明地应用它。\n自动注册是通过可从 QuerydslDataFetcher 获得的内置 RuntimeWiringConfigurer 执行的。 Boot 启动器会自动检测 @GraphQlRepository bean 并使用它们来初始化 RuntimeWiringConfigurer。\n自动注册不支持自定义。 如果需要，您需要使用 QueryByExampleDataFetcher 通过 RuntimeWiringConfigurer 手动构建和注册 DataFetcher。\nQuery by Example Spring Data 支持使用 Query by Example 来获取数据。 Query by Example (QBE) 是一种简单的查询技术，不需要您通过特定于store的查询语言编写查询。\n首先声明一个存储库 QueryByExampleExecutor：\npublic interface AccountRepository extends Repository\u0026lt;Account, Long\u0026gt;, QueryByExampleExecutor\u0026lt;Account\u0026gt; { } 使用 QueryByExampleDataFetcher 将存储库转换为 DataFecher：\n// For single result queries DataFetcher\u0026lt;Account\u0026gt; dataFetcher = QueryByExampleDataFetcher.builder(repository).single(); // For multi-result queries DataFetcher\u0026lt;Iterable\u0026lt;Account\u0026gt;\u0026gt; dataFetcher = QueryByExampleDataFetcher.builder(repository).many(); 现在可以通过 RuntimeWiringConfigurer 注册上述 DataFetcher。\nDataFetcher 使用 GraphQL 参数映射来创建存储库的域类型，并将其用作示例对象来获取数据。 Spring Data 支持 JPA、MongoDB、Neo4j 和 Redis 的 QueryByExampleDataFetcher。\n如果存储库是 ReactiveQueryByExampleExecutor，则构建器返回 DataFetcher\u0026lt;Mono\u0026gt; 或 DataFetcher\u0026lt;Flux\u0026gt;。 Spring Data 支持 MongoDB、Neo4j、Redis 和 R2dbc 的这种变体。\nQueryByExampleDataFetcher 支持接口和 DTO 投影来转换查询结果，然后再返回这些结果以进行进一步的 GraphQL 处理。\n要将 Spring Data 投影与 Query by Example 存储库一起使用，请创建投影接口或目标 DTO 类，并通过 projectAs 方法对其进行配置，以获得生成目标类型的 DataFetcher：\nclass Account { String name, identifier, description; Person owner; } interface AccountProjection { String getName(); String getIdentifier(); } // For single result queries DataFetcher\u0026lt;AccountProjection\u0026gt; dataFetcher = QueryByExampleDataFetcher.builder(repository).projectAs(AccountProjection.class).single(); // For multi-result queries DataFetcher\u0026lt;Iterable\u0026lt;AccountProjection\u0026gt;\u0026gt; dataFetcher = QueryByExampleDataFetcher.builder(repository).projectAs(AccountProjection.class).many(); 如果存储库使用@GraphQlRepository 进行注释，则会自动为尚未注册 DataFetcher 且返回类型与存储库域类型匹配的查询注册。 这包括单值和多值查询。\n默认情况下，查询返回的 GraphQL 类型的名称必须与存储库域类型的简单名称匹配。 如果需要，您可以使用 @GraphQlRepository 的 typeName 属性来指定目标 GraphQL 类型名称。\n自动注册是通过可从 QueryByExampleDataFetcher 获得的内置 RuntimeWiringConfigurer 执行的。 Boot 启动器会自动检测 @GraphQlRepository bean 并使用它们来初始化 RuntimeWiringConfigurer。\n自动注册不支持自定义。 如果需要，您需要使用 QueryByExampleDataFetcher 通过 RuntimeWiringConfigurer 手动构建和注册 DataFetcher。\n服务器传输 GraphQL后端支持三种协议：HTTP , WebSocket 和 RSocket.\nHTTP GraphQlHttpHandler接受GraphQl请求，并委托给拦截链处理请求。 有两个变体，一个用于Spring MVC，另一个用于Spring WebFlux。 两者都异步处理请求，并且具有等效的功能，但是分别依靠阻塞和非阻塞I/O编写HTTP响应。\nGraphQL必须使用POST请求，请求体使用json格式。一旦成功解码了JSON请求体，HTTP响应状态始终为200，并且GraphQL请求执行中的任何错误都会显示在GraphQL响应的error部分中。默认和首选的媒体类型是 application/graphql+json，但也支持application/json。\nGraphQlHttpHandler 通过声明 RouterFunction bean 来公开为 HTTP 端点。 Boot starter 会执行此操作。\n拦截器 服务器传输允许在GraphQl Java引擎被调用之前和之后拦截请求。\nHTTP和WebSocket 调用 零个或多个WebGraphQlinterceptor的链条，然后是executionGraphQlService，其调用GraphQl Java引擎。 WebGraphQLinterceptor允许应用程序拦截传入请求并执行以下操作之一：\n检查HTTP请求信息 自定义graphql.ExecutionInput 添加HTTP响应信息 自定义graphql.ExecutionResult 例如，拦截器可以将HTTP请求标头传递到DataFetcher：\nclass HeaderInterceptor implements WebGraphQlInterceptor { @Override public Mono\u0026lt;WebGraphQlResponse\u0026gt; intercept(WebGraphQlRequest request, Chain chain) { String value = request.getHeaders().getFirst(\u0026#34;myHeader\u0026#34;); request.configureExecutionInput((executionInput, builder) -\u0026gt; builder.graphQLContext(Collections.singletonMap(\u0026#34;myHeader\u0026#34;, value)).build()); return chain.next(request); } } @Controller class MyController { @QueryMapping Person person(@ContextValue String myHeader) { // ... } } 同样的，拦截器可以访问控制器添加到GraphQlContext的值：\n@Controller class MyController { @QueryMapping Person person(GraphQLContext context) { context.put(\u0026#34;cookieName\u0026#34;, \u0026#34;123\u0026#34;); } } // Subsequent access from a WebGraphQlInterceptor class HeaderInterceptor implements WebGraphQlInterceptor { @Override public Mono\u0026lt;WebGraphQlResponse\u0026gt; intercept(WebGraphQlRequest request, Chain chain) { return chain.next(request).doOnNext(response -\u0026gt; { String value = response.getExecutionInput().getGraphQLContext().get(\u0026#34;cookieName\u0026#34;); ResponseCookie cookie = ResponseCookie.from(\u0026#34;cookieName\u0026#34;, value).build(); response.getResponseHeaders().add(HttpHeaders.SET_COOKIE, cookie.toString()); }); } } WebGraphQlHandler 可以修改 ExecutionResult，例如，检查和修改在执行开始之前引发且无法使用 DataFetcherExceptionResolver 处理的请求验证错误：\nstatic class RequestErrorInterceptor implements WebGraphQlInterceptor { @Override public Mono\u0026lt;WebGraphQlResponse\u0026gt; intercept(WebGraphQlRequest request, Chain chain) { return chain.next(request).map(response -\u0026gt; { if (response.isValid()) { return response; } List\u0026lt;GraphQLError\u0026gt; errors = response.getErrors().stream() .map(error -\u0026gt; { GraphqlErrorBuilder\u0026lt;?\u0026gt; builder = GraphqlErrorBuilder.newError(); // ... return builder.build(); }) .collect(Collectors.toList()); return response.transform(builder -\u0026gt; builder.errors(errors).build()); }); } } 使用WebGraphQlHandler配置WebGraphQlinterceptor链。 这是由启动器支持的，请参见Web端点。\n请求执行过程 ExecutionGraphQlService是spring调用GraphQl Java执行请求的主要抽象。主要实现是DefaultExecutionGraphQlService，配置了GraphQlSource，以访问graphql.graphql实例进行调用。\nGraphQLSource GraphQlSource 是一个核心 Spring 抽象，用于访问 graphql.GraphQL 实例以用于请求执行。 它提供了一个构建器 API 来初始化 GraphQL Java 并构建一个 GraphQlSource。\n调用GraphQlSource.schemaResourceBuilder()创建默认的GraphQlSource 构建器，支持 Reactive DataFetcher, Context Propagation, 和 Exception Resolution.\nSpring Boot启动器通过默认的GraphQlSource.builder初始化GraphQlSource实例，还可以启用以下内容：\n从指定的位置加载schema文件 暴露适用于GraphQlSource.builder的属性。 探测 RuntimeWiringConfigurer bean 探测 Instrumentation bean ，用于 GraphQL metrics. 探测 DataFetcherExceptionResolver bean 探测 SubscriptionExceptionResolver bean 对于进一步的自定义，您可以声明自己的 GraphQlSourceBuilderCustomizer bean； 例如，用于配置您自己的 ExecutionIdProvider：\n@Configuration(proxyBeanMethods = false) class GraphQlConfig { @Bean public GraphQlSourceBuilderCustomizer sourceBuilderCustomizer() { return (builder) -\u0026gt; builder.configureGraphQl(graphQlBuilder -\u0026gt; graphQlBuilder.executionIdProvider(new CustomExecutionIdProvider())); } } schema 资源加载 GraphQlSource.Builder 可以配置一个或多个 Resource 实例被解析，然后合并在一起。 这意味着可以从任何位置加载chema文件。\n默认情况下，Spring Boot 启动器在位置 classpath:graphql/**（通常为 src/main/resources/graphql）下查找扩展名为“.graphqls”或“.gqls”的模式文件。 您还可以使用文件系统位置或 Spring 资源层次结构支持的任何位置，包括从远程位置、存储或内存加载模式文件的自定义实现。\n使用 classpath*:graphql/**/ 跨多个类路径位置查找模式文件，例如 跨多个模块。\nchema 创建 默认情况下，GraphQlSource.builder使用GraphQl Java 的 GraphQLSchemaGenerato 创建graphql.schema.GraphQLSchema。 这适用于大多数应用程序，但是，如有必要，您可以通过构建器模式创建：\nGraphQlSource.Builder builder = ... builder.schemaResources(..) .configureRuntimeWiring(..) .schemaFactory((typeDefinitionRegistry, runtimeWiring) -\u0026gt; { // create GraphQLSchema }) RuntimeWiringConfigurer 你可以使用RuntimeWiringConfigurer 注册：\n自定义标量类型 指令处理代码 TypeResolver ，如果你想覆盖默认的TypeResolver 字段的DataFetcher，大多数程序会配置AnnotatedControllerConfigurer， 其将注解的方法配置成 DataFetcher . Spring Boot启动器默认情况下添加了AnnotatedControllerConfigurer 与 Web 框架不同，GraphQL 不使用 Jackson 注释来驱动 JSON 序列化/反序列化。 自定义数据类型及其序列化必须描述为标量。\nSpring Boot启动器检测到类型为RuntimeWiringConfigurer的bean ，并将其注册在GraphQlSource.builder中。 这意味着在大多数情况下，您将在配置中具有以下内容：\n@Configuration public class GraphQlConfig { @Bean public RuntimeWiringConfigurer runtimeWiringConfigurer(BookRepository repository) { GraphQLScalarType scalarType = ... ; SchemaDirectiveWiring directiveWiring = ... ; DataFetcher dataFetcher = QuerydslDataFetcher.builder(repository).single(); return wiringBuilder -\u0026gt; wiringBuilder .scalar(scalarType) .directiveWiring(directiveWiring) .type(\u0026#34;Query\u0026#34;, builder -\u0026gt; builder.dataFetcher(\u0026#34;book\u0026#34;, dataFetcher)); } } 默认的TypeResolver GraphQlSource.Builder 使用 ClassNameTypeResolver 作为默认的 TypeResolver ， 用于尚未通过RuntimeWiringConfigurer注册的GraphQL接口和联合。GraphQL Java中TypeResolver的目的是为从DataFetcher返回的GraphQL接口或Union字段的值确定GraphQL对象类型。\nClassNameTypeResolver尝试将值的简单类名与GraphQL对象类型匹配，如果不成功，它还会导航其超级类型，包括基类和接口，以查找匹配项。ClassNameTypeResolver提供了一个选项，用于配置名称提取函数以及Class-to-GraphQL对象类型名称映射，这将有助于覆盖更多的角点情况：\nGraphQlSource.Builder builder = ... ClassNameTypeResolver classNameTypeResolver = new ClassNameTypeResolver(); classNameTypeResolver.setClassNameExtractor((klass) -\u0026gt; { // Implement Custom ClassName Extractor here }); builder.defaultTypeResolver(classNameTypeResolver); 缓存 GraphQLJava必须在执行操作之前解析并验证该操作。这可能会显著影响性能。为了避免重新解析和验证的需要，应用程序可以配置一个缓存和重用Document实例的PreparsedDocumentProvider。GraphQL Java文档通过PreparsedDocumentProvider提供了有关查询缓存的更多详细信息。\n在Spring GraphQL中，您可以通过 GraphQlSource.Builder#configureGraphQl 注册PreparsedDocumentProvider:\n// Typically, accessed through Spring Boot\u0026#39;s GraphQlSourceBuilderCustomizer GraphQlSource.Builder builder = ... // Create provider PreparsedDocumentProvider provider = ... builder.schemaResources(..) .configureRuntimeWiring(..) .configureGraphQl(graphQLBuilder -\u0026gt; graphQLBuilder.preparsedDocumentProvider(provider)) 指令 GraphQL Java提供SchemaDirectiveWiring契约，帮助应用程序检测和处理指令。您可以通过RuntimeWiringConfigurer注册SchemaDirectiveWiring：\n@Configuration public class GraphQlConfig { @Bean public RuntimeWiringConfigurer runtimeWiringConfigurer() { return builder -\u0026gt; builder.directiveWiring(new MySchemaDirectiveWiring()); } } 上下文传播 Spring for GraphQL支持将上下文从服务器传输透明地传播到DataFetcher及其调用的其他组件。这包括来自Spring MVC请求处理线程的ThreadLocal上下文和来自WebFlux处理管道的Reactor上下文。\nWebMvc 由GraphQL Java调用的DataFetcher和其他组件可能不总是在与Spring MVC处理程序相同的线程上执行，例如，如果异步WebGraphQlInterceptor或DataFetchers切换到不同的线程。\nSpring for GraphQL支持将ThreadLocal值从Servlet容器线程传播到DataFetcher和GraphQL Java调用的其他组件在其上执行的线程。为此，应用程序需要创建ThreadLocalAccessor以提取感兴趣的ThreadLocal值：\npublic class RequestAttributesAccessor implements ThreadLocalAccessor { private static final String KEY = RequestAttributesAccessor.class.getName(); @Override public void extractValues(Map\u0026lt;String, Object\u0026gt; container) { container.put(KEY, RequestContextHolder.getRequestAttributes()); } @Override public void restoreValues(Map\u0026lt;String, Object\u0026gt; values) { if (values.containsKey(KEY)) { RequestContextHolder.setRequestAttributes((RequestAttributes) values.get(KEY)); } } @Override public void resetValues(Map\u0026lt;String, Object\u0026gt; values) { RequestContextHolder.resetRequestAttributes(); } } ThreadLocalAccessor可以在WebGraphHandler builder中注册。Boot starter检测这种类型的bean，并自动为Spring MVC应用程序注册它们，请参阅Web端点部分。\n异常解析 GraphQL Java应用程序可以注册DataFetcherExceptionHandler，以决定如何在GraphQL响应的“error”部分中表示数据层的异常。\nSpring for GraphQL有一个内置的DataFetcherExceptionHandler，它被配置为供默认GraphQLSource builder使用。它允许应用程序注册一个或多个按顺序调用的SpringDataFetcherExceptionResolver组件，直到将异常解析为graphql.GraphQLError对象（可能为空）列表。\nDataFetcherExceptionResolver是一个异步协定。对于大多数实现，扩展DataFetcherExceptionResolverAdapter并重写其同步解析异常的resolveToSingleError或resolveToMultipleErrors方法之一就足够了。\n可以通过graphql.ErrorClassification将GraphQLError分配给类别。在Spring GraphQL中，您还可以通过ErrorType进行分配，ErrorType具有以下常见分类，应用程序可以使用这些分类对错误进行分类：\nBAD_REQUEST UNAUTHORIZED FORBIDDEN NOT_FOUND INTERNAL_ERROR 如果异常仍未解决，则默认情况下，它被分类为INTERNAL_ERROR，并带有一条包含类别名称和DataFetchingEnvironment中的executionId的通用消息。该消息故意不透明，以避免泄漏实现细节。应用程序可以使用DataFetcherExceptionResolver自定义错误详细信息。\n未解决的异常与executionId一起记录在ERROR级别，以与发送到客户端的错误相关。在DEBUG级别记录已解决的异常。\n请求异常 GraphQL Java引擎在解析请求时可能会遇到验证或其他错误，从而阻止请求执行。在这种情况下，响应包含一个带有null的“data”键和一个或多个全局请求级“errors”，即没有字段路径。\nDataFetcherExceptionResolver无法处理此类全局错误，因为它们是在执行开始之前和调用任何DataFetcher之前引发的。应用程序可以使用传输级拦截器来检查和转换ExecutionResult中的错误。请参见WebGraphQlInterceptor下的示例。\n订阅异常 订阅请求的发布服务器可能会以错误信号完成，在这种情况下，底层传输（例如WebSocket）会发送带有GraphQL错误列表的最终“错误”类型消息。\nDataFetcherExceptionResolver无法解决订阅发布服务器的错误，因为数据DataFetcher最初只创建发布服务器。之后，传输订阅发布服务器，然后发布服务器可能会出错。\n应用程序可以注册SubscriptionExceptionResolver，以解决订阅发布服务器的异常，从而将这些异常解析为要发送给客户端的GraphQL错误。\n批量加载 给定一本书及其作者，我们可以为一本书创建一个DataFetcher，为其作者创建另一个DataFetcher。这允许选择有作者或没有作者的书籍，但这意味着书籍和作者不会一起加载，这在查询多本书时尤其低效，因为每本书的作者都是单独加载的。这就是所谓的N+1选择问题。\nDataLoader GraphQLJava提供了一种用于批量加载相关实体的DataLoader机制。您可以在GraphQL Java文档中找到完整的详细信息。以下是其工作原理的总结：\n在DataLoaderRegistry中注册DataLoader，它可以在给定唯一键的情况下加载实体。 DataFetcher可以访问DataLoader，并使用它们按id加载实体。 DataLoader通过返回future来延迟加载，以便可以在批处理中完成。 DataLoader维护加载实体的每个请求缓存，可以进一步提高效率。 BatchLoaderRegistry GraphQL Java中的完整批处理加载机制需要实现多个BatchLoader接口中的一个，然后用DataLoaderRegistry中的名称将这些接口包装并注册为DataLoader。\nSpring GraphQL中的API略有不同。对于注册，只有一个中央BatchLoaderRegistry公开工厂方法和一个生成器来创建和注册任意数量的批加载函数：\n@Configuration public class MyConfig { public MyConfig(BatchLoaderRegistry registry) { registry.forTypePair(Long.class, Author.class).registerMappedBatchLoader((authorIds, env) -\u0026gt; { // return Mono\u0026lt;Map\u0026lt;Long, Author\u0026gt; }); // more registrations ... } } Spring Boot starter声明了一个BatchLoaderRegistrybean，您可以将其注入到您的配置中，如上所示，或者注入到任何组件中，如控制器，以便注册批加载函数。然后，BatchLoaderRegistry被注入DefaultExecutionGraphQlService，在那里它确保每个请求的DataLoader注册。\n默认情况下，DataLoader名称基于目标实体的类名。这允许@SchemaMapping方法使用泛型类型声明DataLoader参数，而无需指定名称。但是，如果需要，可以通过BatchLoaderRegistry生成器以及其他DataLoader选项自定义名称。\n在许多情况下，当加载相关实体时，您可以使用@BatchMapping控制器方法，这是一种快捷方式，可以替代直接使用BatchLoaderRegistry和DataLoader的需要。BatchLoaderRegistry还提供了其他重要的好处。它支持从批处理加载函数和@BatchMapping方法访问相同的GraphQLContext，并确保上下文传播到它们。这就是为什么应用程序需要使用它。可以直接执行自己的DataLoader注册，但这样的注册将放弃上述好处。\n测试批量加载 首先让BatchLoaderRegistry在DataLoaderRegistry上执行注册：\nBatchLoaderRegistry batchLoaderRegistry = new DefaultBatchLoaderRegistry(); // perform registrations... DataLoaderRegistry dataLoaderRegistry = DataLoaderRegistry.newRegistry().build(); batchLoaderRegistry.registerDataLoaders(dataLoaderRegistry, graphQLContext); 现在，您可以按如下方式访问和测试各个DataLoader：\nDataLoader\u0026lt;Long, Book\u0026gt; loader = dataLoaderRegistry.getDataLoader(Book.class.getName()); loader.load(1L); loader.loadMany(Arrays.asList(2L, 3L)); List\u0026lt;Book\u0026gt; books = loader.dispatchAndJoin(); // actual loading assertThat(books).hasSize(3); assertThat(books.get(0).getName()).isEqualTo(\u0026#34;...\u0026#34;); // ... ","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/graphql-spring/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"},{"title":"spring","url":"/myblog/tags/spring/"},{"title":"graphql","url":"/myblog/tags/graphql/"}],"timestamp":1669575733,"title":"Graphql-Spring"},{"authors":[],"categories":[{"title":"中间件","url":"/myblog/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"content":"collector基本组件 Receiver Filelog Receiver Field Default Description include required 匹配的文件列表，支持glob模式 exclude [] 排除的文件列表，支持glob模式 start_at end 启动时，从哪里开始读取日志。选项是beginning 或 end multiline 定义日志行，默认文件中的每行作为一个日志行，注意和操作符recombine的区别 。multiline定义了什么是日志行。 recombine是将多个日志行合并在一起。 force_flush_period 500ms 自上次从文件读取数据以来的时间，在此之后，当前缓冲的日志应发送到管道等待的时间。零意味着永远等待新数据 encoding utf-8 文件的编码 include_file_name true 是否添加文件名称到属性 log.file.name. include_file_path false 是否添加文件路径到属性 log.file.path. include_file_name_resolved false 是否将符号链接解析后的文件名添加到属性log.file.name_resolved。 include_file_path_resolved false 是否将符号链接解析后的文件路径添加到属性log.file.path_resolved。 poll_interval 200ms 文件系统轮询之间的持续时间 fingerprint_size 1kb 用于标识文件的字节数。 max_log_size 1MiB 日志行的最大大小 max_concurrent_files 1024 并发读取日志的最大日志文件数。如果包含模式中匹配的文件数超过此数，则将批量处理文件。每个poll_interval 处理一批 attributes {} 要添加到entry的 属性键：值对的映射 resource {} 要添加到entry 资源的键：值对的映射 operators [] 处理日志的操作 operators converter { max_flush_count: 100, flush_interval: 100ms, worker_count:max(1,runtime.NumCPU()/4) } 键：值对的映射，用于配置entry.Entry到plog.LogRecord storage 存储扩展的ID。扩展名将用于存储文件检查点，这允许接收器在收集器重新启动的情况下从停止的位置开始。 Processors Processors 用于pipeline 的各个阶段。通常，Processors 在数据导出之前对其进行预处理（例如修改属性或修改采样率），或帮助确保数据成功通过管道（例如批处理/重试）。\n推荐的 Processors 默认情况下，不启用 Processors 。根据使用的数据源，可能启用多个Processors 。 并非所有Processors 都支持所有数据源。 此外，处理器的顺序很重要。下面是各类型数据处理的最佳顺序。\nTraces\nmemory_limiter any sampling processors Any processor relying on sending source from Context (e.g. k8sattributes) batch any other processors Metrics\nmemory_limiter Any processor relying on sending source from Context (e.g. k8sattributes) batch any other processors Memory Limiter Processor 内存限制器处理器用于防止收集器出现内存不足的情况。鉴于采集器处理的数据量和类型是特定于环境的，采集器的资源利用率也取决于配置的处理器，因此必须对内存使用情况进行检查。 memory_limiter处理器允许定期检查内存使用情况，如果超过了定义的限制，则会开始丢弃数据并强制GC减少内存消耗。 memory_limiter使用软内存和硬内存限制。硬限制始终高于或等于软限制。 当内存使用超过软限制时，处理器将开始丢弃数据，并将错误返回到管道中的前一个组件（通常应该是接收器）。 当内存使用超过硬限制时，除了丢弃数据之外，处理器还会强制执行垃圾收集，以尝试释放内存。 当内存使用率降至软限制以下时，将恢复正常操作（不再丢弃数据，也不会执行强制垃圾收集）。 软限制和硬限制之间的差异通过spike_limit_mib配置选项定义。设定值时，应确保在内存检查间隔之间内存使用量的增加不会超过此值（否则内存使用量可能会超过硬限制，即使是暂时的）。spike_limit_mib的值建议是硬限制的20%。对于尖峰流量或更长的检查间隔，可能需要更大的spike_limit_mib值。 请注意，虽然处理器可以帮助缓解内存不足的情况，但它并不能取代收集器的正确大小和配置。请记住，如果超过软限制，收集器将向所有接收操作返回错误，直到释放足够的内存。这将导致数据丢失。 强烈建议在每个收集器上配置ballastextension和memory_limiter处理器。ballast 应配置为分配给收集器的内存的1/3至1/2。memory_limiter处理器应该是管道中定义的第一个处理器（紧跟在接收器之后）。这是为了确保可以将背压发送到适用的接收器，并在触发memory_limiter时最小化数据丢失的可能性。\nmemory_limiter 需要 ballast 扩展 来做一些底层操作。ballast 是 go控制gc的一种方式。\n配置选项：\ncheck_interval ：默认0s, 检测内存使用情况的间隔。建议值为1秒。如果收集器的预期流量非常高，则减少check_interval或增加spike_limit_mib，以避免内存使用超过硬限制。 limit_mib ：默认0，进程堆分配的最大内存量（以MiB为单位）。请注意，通常进程的总内存使用量将比该值高约50MiB。这定义了硬限制。 spike_limit_mib ： 默认20%，内存使用量测量之间的最大峰值。该值必须小于limit_mib。软限值将等于（limit_mib-spike_limit_mib）。spike_limit_mib的建议值约为20%的limit_mib。 limit_percentage ：默认0，进程堆要分配的最大总内存量。这种配置在带有cgroups的Linux系统上受支持，并且打算在动态平台（如docker）中使用。此选项用于从总可用内存中计算memory_limit。例如，设置为75%，总内存为1GiB，将导致750MiB的限制。固定内存设置（limit_mib）优先于百分比配置。 spike_limit_percentage ： 默认0，内存使用量测量之间的最大峰值。该值必须小于limit_percentage。此选项用于从总可用内存中计算spike_limit_mib。例如，在总内存为1GiB的情况下设置25%将导致250MiB的峰值限制。此选项仅用于limit_percentage。 配置的示例：\nprocessors: memory_limiter: check_interval: 1s limit_mib: 1500 spike_limit_mib: 300 extensions: memory_ballast: size_mib: 500 processors: memory_limiter: check_interval: 1s limit_percentage: 50 spike_limit_percentage: 30 Batch Processor batch processor 接受spans, metrics, logs，并将它们放入批处理中。批处理有助于更好地压缩数据，并减少传输数据所需的传出连接数。此处理器支持基于大小和时间的批处理。 强烈建议在每个收集器上配置批处理器。批处理器应在memory_limiter 以及任何采样处理器 之后的管道中定义。这是因为批处理应该发生在任何数据丢失（如采样）之后。 配置选项：\nsend_batch_size ：默认8192， timeout ：默认200ms send_batch_max_size ：默认0，批次大小的上限。0表示批次大小没有上限。此属性可确保将较大的批次拆分为较小的单元。它必须大于或等于send_batch_size。 数据所有权 管道中数据（pdata.Traces, pdata.Metrics 和 pdata.Logs）的所有权在数据通过管道时传递。数据由 receiver 创建，然后当调用ConsumeTraces/ConumeMetrics/ConsumeLogs函数时，所有权被传递给第一个processor 。 注意：receiver 可能连接到多条pipelines，在这种情况下，相同的数据将扇出连接器，传递到所有连接的pipelines。 从数据所有权的角度来看，管道可以在两种模式下工作：\n独家数据所有权 共享数据所有权 模式在启动期间根据处理器报告的数据修改意图定义。每个处理器通过Capabilities函数返回的结构的MutatesData字段报告意图。如果管道中的任何处理器声明要修改数据，则该管道将以独占所有权模式工作。此外，具有独占所有权模式的接收器，其对应的管道也将以独占所有权方式运行。\n独占模式 在独占所有权模式下，数据在给定时刻由特定处理器独占，处理器可以自由修改其拥有的数据。 独占模式仅适用于从同一接收器接收数据的管道。如果管道被标记为处于独占模式，则从共享接收器接收的任何数据都将在扇出连接器处克隆，然后再传递到每个管道。这确保了每个管道都有自己的独占数据副本，并且可以在管道中安全地修改数据。 数据的独占所有权允许处理器在拥有数据时自由修改数据（例如，参见attributesprocessor）。处理器对数据的所有权持续时间是从ConsumeTraces/ConumeMetrics/ConsumeLogs调用开始，直到处理器调用下一个处理器的ConsumeTrace/Conumemetrics/ConsumeLogs函数，该函数将所有权传递给下一个处理者。此后，处理器不得再读取或写入数据，因为新所有者可能会同时修改数据。\n共享模式 在共享所有权模式下，没有特定的处理器拥有数据，也不允许任何处理器修改共享数据。 在此模式下，不在连接到多个管道的接收器的扇出连接器处执行克隆。在这种情况下，所有这样的管道将看到相同的数据共享副本。禁止以共享所有权模式运行的管道中的处理器修改其通过ConsumeTraces/ConumeMetrics/ConsumeLogs调用接收的原始数据。处理器只能读取数据，但不能修改数据。 如果处理器在执行处理时需要修改数据，但不想承担独占模式带来的数据克隆成本，则处理器可以声明不修改数据，并使用任何不同的技术来确保原始数据不被修改。例如，处理器可以为pdata.Traces/pdata.Metrics/pdata.Logs的各个子部分实现写时复制方法。 如果处理器使用这种技术，则应声明其不打算通过在其能力中设置MutatesData=false来修改原始数据，以避免将管道标记为独占所有权，并避免独占所有权部分中描述的数据克隆成本。\nextension 扩展提供了收集器主要功能之上的功能。通常，扩展用于实现可以添加到收集器的组件，但不需要直接访问遥测数据，也不属于管道的一部分（如接收器、处理器或导出器）。示例扩展包括：响应健康检查请求的健康检查扩展或允许获取收集器性能配置文件的PProf扩展。 为服务指定扩展的顺序很重要，因为这是每个扩展启动的顺序，也是它们关闭的相反顺序。例如：\nservice: # Extensions specified below are going to be loaded by the service in the # order given below, and shutdown on reverse order. extensions: [memory_ballast, zpages] Memory Ballast 内存镇流器扩展使应用程序能够为进程配置内存镇流器。有关详细信息，请参见：\nGo memory ballast blogpost Golang issue related to this 配置选项：\nsize_mib (default = 0, disabled): 是内存镇流器大小，单位为MiB。如果同时指定了size_in_percentage和size_mib ，则优先级高于size_in_percentage 。 size_in_percentage (default = 0, disabled): 基于总内存百分比设置内存镇流器，值范围为1-100。它在容器化（如docker、k8s）和物理主机环境中都受支持。 extensions: memory_ballast: size_mib: 64 zPages zPages对于进程内诊断非常有用，无需依赖任何后端来检查trace或span。 配置选项：\nendpoint (default = localhost:55679)：指定为zPages提供服务的HTTP端点。使用localhost:使其仅在本地可用，或使用“:”使其在所有网络接口上可用。 配置示例：\nextensions: zpages: 暴漏的端点：\nhttp://localhost:55679/debug/servicez：ServiceZ概述了收集器服务以及对pipelinez、extensionz和featurez zPages的快速访问。该页面还提供构建和运行时信息。 http://localhost:55679/debug/pipelinez：PipelineZ可以深入了解收集器中正在运行的管道。您可以找到关于类型的信息，如果数据发生了变异，以及用于每个管道的接收器、处理器和导出器。 http://localhost:55679/debug/extensionz：ExtensionZ显示收集器中活动的扩展。 http://localhost:55679/debug/featurez：FeatureZ列出了可用的要素及其当前状态和描述。 http://localhost:55679/debug/tracez：例如，TraceZ路由可用于按延迟桶检查和分类跨度 （0us、10us、100us、1ms、10ms、100ms、1s、10s、1ms）它们还允许您快速检查错误样本\nhttp://localhost:55679/debug/rpcz：Rpcz路由可用于帮助检测远程过程调用（RPC）的统计信息。 File Storage 文件存储扩展可以将状态持久化到本地文件系统。 扩展需要对目录进行读写访问。可以使用默认目录，但它必须已经存在，扩展才能运行。 配置：\ndirectory是专用数据存储目录的相对或绝对路径。在Windows上，默认目录为%ProgramData%\\Otelcol\\FileStorage，否则为/var/lib/otelcol/file_storage。 timeout是待文件锁定的最长时间。在大多数情况下，不需要修改该值。默认超时为1s。 compaction 定义了压缩文件的方式和时间。有两种可用的压缩模式（这两种模式都可以同时设置）： compaction.on_start (default: false):收集器启动时发生 compaction.on_rebound (default: false), 当满足某些标准时在线发生；下面将详细讨论 compaction.directory : 指定用于压缩的目录（作为中间步骤）。 compaction.max_transaction_size (default: 65536): 定义压缩事务的最大大小。值为零将忽略事务大小。 compaction.rebound_needed_threshold_mib (default: 100) : 当分配的数据超过此数量时，将启用“需要压缩”标志 compaction.rebound_trigger_threshold_mib (default: 10) : 如果设置了“需要压缩”标志，并且分配的数据低于该值，则将开始压缩，并清除“需要压缩的”标志 compaction.check_interval (default: 5s) : 指定检查y压缩条件的频率 在某些工作负载（例如，持久性队列）中，存储可能会显著增长（例如，当导出器由于网络问题而无法发送数据时），然后随着基础问题的消失（例如，网络连接恢复），存储将被清空。这留下了一个需要回收的重要空间。在线发生这种情况的最佳条件是在存储大量耗尽之后，这由bounder_trigger_threshold_mib控制。为了确保这一点不太敏感，还有一个rebound_neeed_threshold_mib，它指定了要考虑在线压缩必须满足的总声明空间大小。考虑下图中满足回弹（在线）压实条件的示例。\n▲ │ │ XX............. m │ XXXX............ e ├───────────XXXXXXX..........──────────── rebound_needed_threshold_mib m │ XXXXXXXXX.......... o │ XXXXXXXXXXX......... r │ XXXXXXXXXXXXXXXXX.... y ├─────XXXXXXXXXXXXXXXXXXXXX..──────────── rebound_trigger_threshold_mib │ XXXXXXXXXXXXXXXXXXXXXXXXXX......... │ XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX └──────────────── time ─────────────────► │ | | issue draining compaction happens starts begins and 回收空间 X - 实际使用的空间 . - 已申请但不再使用的空间 extensions: file_storage: file_storage/all_settings: directory: /var/lib/otelcol/mydir timeout: 1s compaction: on_start: true directory: /tmp/ max_transaction_size: 65_536 service: extensions: [file_storage, file_storage/all_settings] pipelines: traces: receivers: [nop] processors: [nop] exporters: [nop] # Data pipeline is required to load the config. receivers: nop: processors: nop: exporters: nop: Exportor 基础配置 这是其他导出程序可以依赖的helper导出程序。它主要提供排队重试和资源属性到度量标签的转换。 配置项目：\nretry_on_failure enabled (default = true) initial_interval (default = 5s): 第一次失败后等待重试的时间；如果enabled为false，则忽略 max_interval (default = 30s): 是回退的上限；如果enabled为false，则忽略 max_elapsed_time (default = 300s): 尝试发送批处理所花费的最大时间；如果enabled为false，则忽略 sending_queue enabled (default = true) num_consumers (default = 10): 消费者数量；如果enabled为false，则忽略 queue_size (default = 5000): 丢弃前内存中保留的最大批数；如果enabled为false，则忽略。用户应将其计算为num_seconds*request_per_second/request_per_batch，其中： num_seconds是后端中断时要缓冲的秒数 requests_per_second是每秒的平均请求数 requests_per_batch是每个批次的平均请求数（如果使用批次处理器，则可以使用度量batch_send_size进行估计） timeout (default = 5s): 每次尝试向后端发送数据的等待时间 持久化队列 要使用持久队列，需要设置以下设置： sending_queue：storage (default = none): 设置后，启用持久性并使用指定为持久性队列的存储扩展的组件 可以使用sending_queue控制存储到磁盘的最大批数。queue_size参数（与内存缓冲类似，默认为5000）。 启用持久队列后，将使用提供的存储扩展对批进行缓冲-文件存储是一种流行且安全的选择。如果收集器实例在持久队列中有一些数据时被终止，则在重新启动时将拾取这些数据并继续导出。\n┌─Consumer #1─┐ │ ┌───┐ │ ──────Deleted────── ┌───►│ │ 1 │ ├───► Success Waiting in channel x x x │ │ └───┘ │ for consumer ───┐ x x x │ │ │ │ x x x │ └─────────────┘ ▼ x x x │ ┌─────────────────────────────────────────x─────x───┐ │ ┌─Consumer #2─┐ │ x x x │ │ │ ┌───┐ │ │ ┌───┐ ┌───┐ ┌───┐ ┌─x─┐ ┌───┐ ┌─x─┐ ┌─x─┐ │ │ │ │ 2 │ ├───► Permanent -\u0026gt; X │ n+1 │ n │ ... │ 6 │ │ 5 │ │ 4 │ │ 3 │ │ 2 │ │ 1 │ ├────┼───►│ └───┘ │ failure │ └───┘ └───┘ └───┘ └───┘ └───┘ └───┘ └───┘ │ │ │ │ │ │ │ └─────────────┘ └───────────────────────────────────────────────────┘ │ ▲ ▲ ▲ ▲ │ ┌─Consumer #3─┐ │ │ │ │ │ │ ┌───┐ │ │ │ │ │ │ │ │ 3 │ ├───► (in progress) write read └─────┬─────┘ ├───►│ └───┘ │ index index │ │ │ │ ▲ │ │ └─────────────┘ │ │ │ │ currently │ ┌─Consumer #4─┐ │ dispatched │ │ ┌───┐ │ Temporary │ └───►│ │ 4 │ ├───► failure │ │ └───┘ │ │ │ │ │ │ │ └─────────────┘ │ │ ▲ │ │ └── Retry ───────┤ │ │ │ │ └────────────────────────────────────── Requeuing ◄────── Retry limit exceeded ───┘ receivers: otlp: protocols: grpc: exporters: otlp: endpoint: \u0026lt;ENDPOINT\u0026gt; sending_queue: storage: file_storage/otc extensions: file_storage/otc: directory: /var/lib/storage/otc timeout: 10s service: extensions: [file_storage] pipelines: metrics: receivers: [otlp] exporters: [otlp] logs: receivers: [otlp] exporters: [otlp] traces: receivers: [otlp] exporters: [otlp] 日志处理 日志表示 Entry 是日志数据在管道中移动时的基本表示。所有 operators 都可以创建、修改或消费条目。\n{ \u0026#34;resource\u0026#34;: { \u0026#34;uuid\u0026#34;: \u0026#34;11112222-3333-4444-5555-666677778888\u0026#34;, }, \u0026#34;attributes\u0026#34;: { \u0026#34;env\u0026#34;: \u0026#34;prod\u0026#34;, }, \u0026#34;body\u0026#34;: { \u0026#34;message\u0026#34;: \u0026#34;Something happened.\u0026#34;, \u0026#34;details\u0026#34;: { \u0026#34;count\u0026#34;: 100, \u0026#34;reason\u0026#34;: \u0026#34;event\u0026#34;, }, }, \u0026#34;timestamp\u0026#34;: \u0026#34;2020-01-31T00:00:00-00:00\u0026#34;, \u0026#34;severity\u0026#34;: 30, \u0026#34;severity_text\u0026#34;: \u0026#34;INFO\u0026#34;, } resource: 用于描述日志源 attributes：为日志提供附加上下文的键/值对。消费者通常使用此值来过滤日志。 body: 日志的内容。该值通常在管道中被修改和重组。它可以是字符串、数字或对象。 表达式 表达式允许在静态配置中包含动态业务逻辑规则，从而提供了配置灵活性。最值得注意的是，表达式可以用于根据正在处理的日志条目的内容路由消息并添加新字段。\n支持的数据类型 strings - 单引号或双引号 (e.g. \u0026ldquo;hello\u0026rdquo;, \u0026lsquo;hello\u0026rsquo;) numbers - e.g. 103, 2.5, .5 ，10_000_000_000 arrays - e.g. [1, 2, 3] maps - e.g. {foo: \u0026ldquo;bar\u0026rdquo;} booleans - true and false nil - nil 数据访问 可以使用.或[]语法访问结构字段和映射元素。 foo.Field bar[\u0026#34;some-key\u0026#34;] 函数访问： 使用括号调用函数foo.Method() 运算符 数学运算符： ● + (addition) ● - (subtraction) ● * (multiplication) ● / (division) ● % (modulus) ● ** (pow)\n比较运算符： ● == (equal) ● != (not equal) ● \u0026lt; (less than) ● \u0026gt; (greater than) ● \u0026lt;= (less than or equal to) ● \u0026gt;= (greater than or equal to)\n逻辑运算符： ● not or ! ● and or \u0026amp;\u0026amp; ● or or ||\n字符串运算符： ● + (concatenation) ● matches (regex match) ● contains (string contains) ● startsWith (has prefix) ● endsWith (has suffix)\n\u0026#34;hello\u0026#34; matches \u0026#34;h.*\u0026#34; 成员运算符： ● in (contain) ● not in (does not contain)\nuser.Group in [\u0026#34;human_resources\u0026#34;, \u0026#34;marketing\u0026#34;] \u0026#34;foo\u0026#34; in {foo: 1, bar: 2} 序列运算符：\nuser.Age in 18..45 三元运算符\nuser.Age \u0026gt; 30 ? \u0026#34;mature\u0026#34; : \u0026#34;immature\u0026#34; 内置函数 ● len ：数组， map 或字符串的长度 ● all ：如果所有元素都满足谓词，则返回true ● none ：（如果所有元素都不满足谓词，则返回true） ● any ：（如果任何元素满足谓词，则返回true） ● one ：（如果只有一个元素满足谓词，则返回true） ● filter ：（按谓词筛选数组） ● map： （将所有项目与闭包进行映射） ● count ：（返回满足谓词的元素数）\nall(Tweets, {.Size \u0026lt; 280}) one(Participants, {.Winner}) 闭包 闭包是一个接受单个参数的表达式。要访问参数，请使用#符号。\nmap(0..9, {# / 2}) 如果数组的元素是对象，则访问对象字段时，可以省略#符号（#.Value变为.Value）。\nfilter(Tweets, {len(.Value) \u0026gt; 280}) 切片\narray = [1,2,3,4,5]. array[1:5] == [2,3,4] array[3:] == [4,5] array[:4] == [1,2,3] array[:] == array collector支持表达式中有几个特殊变量：\nbody attributes resource timestamp env() 是一个允许您读取环境变量的函数 - type: metadata attributes: stack: \u0026#39;EXPR(env(\u0026#34;STACK\u0026#34;))\u0026#39; 如果 field 不是以 resource, attributes, or body 开头, 则 默认是body . 例如, my_value 等于 body.my_value.\n- type: add field: body.key3 value: val3 - type: remove field: body.key2.nested_key1 - type: add field: attributes.my_attribute value: my_attribute_value { \u0026#34;timestamp\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;attributes\u0026#34;: {}, \u0026#34;body\u0026#34;: { \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;: { \u0026#34;nested_key1\u0026#34;: \u0026#34;nested_value1\u0026#34;, \u0026#34;nested_key2\u0026#34;: \u0026#34;nested_value2\u0026#34; } } } { \u0026#34;timestamp\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;my_attribute\u0026#34;: \u0026#34;my_attribute_value\u0026#34; }, \u0026#34;body\u0026#34;: { \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;: { \u0026#34;nested_key2\u0026#34;: \u0026#34;nested_value2\u0026#34; }, \u0026#34;key3\u0026#34;: \u0026#34;value3\u0026#34; } } 日志文件采集的底层原理 指纹 使用指纹识别和跟踪文件。指纹是文件的前N个字节，默认N为1000。 当文件小于N字节时，指纹是文件的全部内容。小于N字节的指纹将使用前缀检查与其他指纹进行比较。随着文件的增长，其指纹将被更新，直到它达到N的完整大小。 处理具有相同指纹的多个文件时，就像它们是同一个文件一样。 最常见的情况是，在依赖于复制/截断策略的文件轮换过程中观察到这种情况。复制文件后，但在截断原始文件之前，两个具有相同内容的文件会短暂存在。如果file_input操作符碰巧同时观察到两个文件，它将检测到重复的指纹并只摄取其中一个文件。 如果将日志复制到多个文件，或者手动复制日志文件，则不认为摄取重复的日志有任何重要价值。因此，指纹无法区分这些文件，并且不支持自动对同一内容进行双重摄取。\nReaders 是一个方便的结构，它的存在是为了管理文件及其相关元数据。其包括：\n文件句柄（可能是打开的，也可能是关闭的） 文件指纹 文件读取的偏移量（也叫 checkpoint） 文件路径 解码器 Reader的功能 正如名称所暗示的，当数据写入文件时，Readers 负责消费数据。 在Readers 开始使用之前，它将查找文件的最后已知偏移量。如果文件的偏移量未知，则读取器将根据start_at设置查找文件的开头或结尾。然后从那里开始阅读。 当一个文件比指纹的长度短时，它的读取器会不断地附加到指纹上，因为它会消耗新写入的数据。 Readers 使用bufio.Scanner 消费文件。Scanner 的缓冲区大小由max_log_size设置定义，Scanner 的拆分功能由multiline 设置定义。 当从文件中读取每个日志时，根据编码函数对其进行解码，然后从operator发出。 每当发出日志时，读取器的偏移量都会相应地更新。\n持久化 Readers总是用打开的文件句柄实例化。最终，文件句柄被关闭，但Readers不会立即被丢弃。相反，它被维护固定数量的轮询周期，作为对文件元数据的引用，这对于检测已移动或复制的文件以及调用元数据可能很有用。 Readers 保持一段固定的时间，然后丢弃。 当file_input操作符使用持久性机制来保存和调用其状态时，它只是设置和获取一部分Readers。这些Readers包含了准确拾取operator 停止的位置所需的所有信息。\n轮转 文件系统按poll_interval设置定义的定期间隔进行轮询。 每个轮询周期都经过一系列步骤，如下所示：\n出队：如果从上一个循环中有任何匹配项排队，则会有适当数量的匹配项出队列，并像处理新匹配的文件集一样进行处理。 老化：如果上一个循环中没有剩余排队的文件，那么所有先前匹配的文件都已被消费，我们准备再次查询文件系统。在这样做之前，我们将增加所有历史Reader的“世代”。最终，这些Reader将根据他们的世代丢弃。 匹配： 将在文件系统中搜索路径与include设置匹配的文件。 与exclude 设置匹配的文件将被丢弃。 作为一种特殊情况，在第一个轮询周期中，如果没有匹配的文件，则会打印警告。不管如何，执行都会继续。 入队： 如果匹配文件的数量小于或等于max_concurrent_files设置定义的最大并发度，则不会发生排队。 否则，将发生排队，这意味着： 匹配的文件被分成两组，第一组足够小，可以容纳max_concurrent_files，第二组包含剩余的文件（称为队列）。 当前轮询间隔将开始处理第一组文件。 后续轮询周期将从队列中取出匹配项，直到队列为空。 始终遵守max_concurrent_files设置。 打开：将打开每个匹配的文件。注： 自文件匹配以来，已经过了一小段时间。 此时可能已将其移动或删除。 在文件匹配和打开之间只应进行最少的一组操作。 如果打开时发生错误，则会记录该错误。 指纹： 读取每个文件的前N个字节。 排除： 空文件将立即关闭并丢弃。（没有什么可读的。） 此批次中发现的指纹相互对照以检测重复。重复的文件将立即关闭并丢弃。在绝大多数情况下，这发生在使用复制/截断方法的文件轮换期间。 创建Reader: 每个文件句柄与一些元数据一起打包到一个Reader中: 在创建读取器期间，文件的指纹与先前已知的指纹交叉引用。 如果文件的指纹与最近看到的指纹相匹配，那么元数据将从Reader的上一次迭代中复制过来。最重要的是，以这种方式精确地保持偏移。 如果文件的指纹与最近看到的任何文件都不匹配，则根据start_at设置初始化其偏移量。 丢失文件的检测: 指纹用于将此轮询周期中的匹配文件与上一轮询周期的匹配文件进行交叉引用。在上一周期中匹配但在此周期中不匹配的文件称为“丢失文件”。 文件“丢失”有几个原因: 文件可能已被删除，通常是由于旋转限制或基于ttl的修剪。 文件可能已旋转到其他位置。如果文件被移动，则上一个轮询周期中的打开文件句柄可能有用。 消费： 丢失的文件将被消耗。在某些情况下，如删除，此操作将失败。但是，如果一个文件被移动了，我们可能可以消费它的其余内容。 我们不希望再次匹配此文件，因此我们所能做的最好的事情就是完成对其当前内容的消费。 我们可以合理地预期，在大多数情况下，这些文件不再被写入。 匹配的文件（来自此轮询周期）将被消费。 这些文件句柄将保持打开状态，直到下一个轮询周期，届时它们将用于检测并潜在地消费丢失的文件。 通常，我们可以再次找到这些文件中的大部分。然而，这些文件被贪婪地消费，以防我们再也看不到它们。 同时使用所有打开的文件。这包括上一个周期中丢失的文件和此周期中匹配的文件。 关闭: 上一个轮询周期中的所有文件都将关闭。 归档： 在当前轮询周期中创建的Reader将添加到历史记录中。 相同的Reader采用单独的片保留，以便在下一个轮询周期中轻松访问。 修剪：存在3代的Reader被清除。 持久化：Reader的历史记录与提供给operator的任何持久性机制同步。 结束 poll: 此时，operator 处于空闲状态，直到轮询计时器再次启动。 其他细节 启动逻辑 每当operator 启动时：\n请求Reader的历史记录，如轮询周期的步骤12-14所述。 启动轮询计时器。 关闭逻辑 当Operator停机时，会发生以下情况：\n如果当前没有轮询周期，操作员只需关闭所有打开的文件。 否则，当前轮询周期会被发出立即停止的信号，这反过来又会向所有Reader发出立即停止信号。 如果Reader空闲或处于日志条目之间，它将立即返回。否则，它将在消耗最后一个日志条目后返回。 一旦所有Reader停止，轮询周期的剩余部分将照常完成，包括标记为关闭、归档、修剪和持久性的步骤。 流程的缺陷 当必须强制执行最大并发时，可能会丢失数据 如果以下两种情况都成立，Operator可能会丢失少量日志：\n匹配的文件数超过了max_concurrent_files设置允许的最大并发度。 文件正在“丢失”。也就是说，文件轮换将文件移出运算符的匹配模式，这样后续轮询周期将找不到这些文件。 当这两种情况都发生时，Oprator不可能同时：\n遵守指定的并发限制。 如果文件从匹配模式中旋转出来，在关闭之前仍可能会被消费。 当这种情况发生时，必须进行设计权衡。可在以下两种情况中选择：\n确保始终遵守max_concurrent_files。 可能会丢失一小部分日志条目。 当前的设计选择保证最大程度的并发，因为如果不这样做，可能会损害Operator的主机系统。虽然日志丢失并不理想，但它不太可能损害Operator的主机系统，因此被认为是两个选项中更容易接受的。 通过复制/截断进行文件旋转时，可能会丢失数据 如果以下两种情况都成立，操作员可能会丢失少量日志：\n正在使用复制/截断策略旋转文件。 文件正在“丢失”。也就是说，文件轮换将文件移出运算符的匹配模式，这样后续轮询周期将找不到这些文件。 当这两种情况都发生时，可能会在操作员有机会消费新数据之前将文件写入（然后复制到其他位置），然后截断。 在Windows上使用通过移动/创建的文件轮换时，可能无法使用文件 在Windows上，使用“移动/创建”策略旋转文件可能会导致错误和数据丢失，因为Golang当前不支持用于FILE_SHARE_DELETE的Windows机制。\n","date":"2022年11月27日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/2022/11/opentelemetry/","series":[],"smallImg":"","tags":[{"title":"监控","url":"/myblog/tags/%E7%9B%91%E6%8E%A7/"},{"title":"opentelemetry","url":"/myblog/tags/opentelemetry/"}],"timestamp":1669552871,"title":"Opentelemetry"},{"authors":[],"categories":[],"content":"实体图主要有两个作用：\n显示系统范围内的主要实体 显示实体之间的相互关系 实体是系统内可以定义的事物或概念，也就是数据库中的表。 在ER图，实现表示成圆角矩形\n实体还可以进一步分为弱实体和复合实体：\n弱实体必须依赖另一个实体存在，例如成绩单必须依赖学生存在，因此成绩单是弱实体。弱实体使用双线矩形表示。 复合常常用于实现两个多是个实体的M:N关系，他由每个关联实体的主键组成，用矩形内加菱形来表示 实体属性，对应数据表中的列，表示实体的特性\n复合属性 多值属性： 双线椭圆表示 派生属性：非永久性存储于数据库的属性，由其他属性或其他数据（如当前日期）派生出来，用虚线椭圆表示 可选属性： 在椭圆的文字后用（O）来表示 联系属性：联系属性用于表示多个实体之间联系所具有的属性，一般来讲M:N的两个实体具有联系属性，在1：1和1：M的实体联系中，联系属性并不需要。 主键，简写PK,用于界定数据表中记录的唯一性\n外键，用于识别实体之间的关系\n关系，表示两个实体之间以某种方式相互关联\n基数，定义一个实体与另一个实体的关系里面，某方可能出现的次数。\nER图在以下的层次上抽象：\n概念数据模型 逻辑数据模型 物理数据模型 一般而言，业务分析人员使用概念和逻辑模型来展示系统中存在的业务对象，而数据库设计人员会为概念和逻辑模型加入更多的细节，进而生成物理模型，好为创建实际的数据库做准备。\n下面是三种模式的区别：\nER对象 概念模型 逻辑模型 物理模型 实体【名称】 Y Y Y 关系 Y Y Y 列 Y Y 列的类型 随意 Y 主键 Y 外键 Y 概念模型定义了系统中存在的业务对象以及他们之间的关系。建立概念模型，是为了识别所涉及的业务对象，来呈现系统的宏观图像。概念模型定义了那些实体存在，而非那些表。例如，逻辑和物理模型中可能存在多对多关系的表，但在概念模型下，他们只会表示为无基数的关系。\n逻辑模型是概念模型的详细版本，通过明确定义每个实体中的列并引入操作和事务来让概念模型丰富起来。虽然逻辑模型仍是高层次的设计（非为特定数据库系统绘制），但是已经很接近了。\n物理模型是数据库的实际设计蓝图。物理数据模型通过为每列执行类型，长度，非空等信息来详细刻画逻辑模型。由于物理模型表达了如何在特定的DNMS中构造和关系数据，因此设计时需要考虑实际数据库的需要和限制。\n","date":"1年1月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/1/01/","series":[],"smallImg":"","tags":[],"timestamp":-62135596800,"title":""},{"authors":[],"categories":[],"content":" 静态语言\n编译成可执行文件，部署简单\n语言层面的并发\n环境安装 配置下面的环境变量： GOROOT: 安装目录\nPATH: go可执行文件目录(bin)\nGOPATH: C:\\Users\\13675\\GoProjects\n测试安装，执行下面的命令 C:\\Users\\13675\u0026gt;go version go version go1.20.1 windows/amd64 安装vscode，安装go插件\n配置代理：\nC:\\Users\\13675\u0026gt;go env -w GO111MODULE=on C:\\Users\\13675\u0026gt;go env -w GOPROXY=https://goproxy.cn,direct Go1.12版本之后，开始使用go mod模式来管理依赖环境了, 要启用go module支持首先要设置环境变量GO111MODULE，它有三个可选值：off、on、auto，默认值是auto。\nGO111MODULE=off禁用模块支持，编译时会从GOPATH和vendor文件夹中查找包。 GO111MODULE=on启用模块支持，编译时会忽略GOPATH和vendor文件夹，只根据 go.mod下载依赖。 GO111MODULE=auto，当项目在$GOPATH/src外且项目根目录有go.mod文件时，开启模块支持。 vscode 安装go开发工具包（vs code就会提供诸如代码提示、代码自动补全等功能），Ctrl+Shift+P 打开命令窗口，输入Go:Install/Update Tools，就会弹出一个列表，然后全部勾选。\n编写代码 hello.go：\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;hello\u0026#34;) } 运行 go run .\\hello.go\ngo build hello.go：编译\ngo run hello.go ： 执行\n语法 package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。main 函数是每一个可执行程序所必须包含的，一般来说都是在启动后第一个执行的函数（如果有 init() 函数则会先执行该函数）。\n单行注释以// 开头。多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾，且不可以嵌套使用。\n当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 private ）\n数据类型 布尔：只可以是常量 true 或者 false 数字：整型 int 和浮点型 float 字符串 派生类型： 指针类型（Pointer） 数组类型 结构体类型(struct) 联合体类型 (union) 函数类型 切片类型 接口类型（interface） Map 类型 Channel 类型 变量声明 指定变量类型，声明后若不赋值，使用默认值：\nvar v_name int 根据值自行判定变量类型:\nvar v_name = value 省略var, 注意 :=左侧的变量不应该是已经声明过的，否则会导致编译错误:\nvar a int = 10 // 变量类型可以省略，依赖自动推断 var b = 10 c := 10 //只能在函数体内声明 多变量声明\n//类型相同多个变量, 非全局变量 var vname1, vname2, vname3 type vname1, vname2, vname3 = v1, v2, v3 var vname1, vname2, vname3 = v1, v2, v3 //和python很像,不需要显示声明类型，自动推断 vname1, vname2, vname3 := v1, v2, v3 // 短变量声明，仅适用于函数或方法内部，多个变量一起声明时，左侧至少有一个未声明过的变量，否则编译错误，已声明过的变量会退化为赋值 //类型不同多个变量, 全局变量, 局部变量不能使用这种方式 var ( vname1 int vname2 string ) 如果你想要交换两个变量的值，则可以简单地使用 a, b = b, a。\n空白标识符 _ 也被用于抛弃值，如值 5 在：_, b = 5, 7 中被抛弃。\n常量 常量是一个简单值的标识符，在程序运行时，不会被修改的量。常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型。\n常量的定义格式：\nconst identifier [type] = value 你可以省略类型说明符 [type]，因为编译器可以根据变量的值来推断其类型。\n常量还可以用作枚举：\nconst ( Unknown = 0 Female = 1 Male = 2 ) 常量可以用len(), cap(), unsafe.Sizeof()常量计算表达式的值。常量表达式中，函数必须是内置函数，否则编译不通过：\npackage main import \u0026#34;unsafe\u0026#34; const ( a = \u0026#34;abc\u0026#34; b = len(a) c = unsafe.Sizeof(a) ) func main(){ println(a, b, c) } 以上实例运行结果为：\nabc 3 16 iota iota，特殊常量，可以认为是一个可以被编译器修改的常量。\n在每一个const关键字出现时，被重置为0，然后再下一个const出现之前，每出现一次iota，其所代表的数字会自动增加1。\niota 可以被用作枚举值：\nconst ( a = iota b = iota c = iota ) 第一个 iota 等于 0，每当 iota 在新的一行被使用时，它的值都会自动加 1；所以 a=0, b=1, c=2 可以简写为如下形式：\nconst ( a = iota b c ) package main import \u0026#34;fmt\u0026#34; func main() { const ( a = iota //0 b //1 c //2 d = \u0026#34;ha\u0026#34; //独立值，iota += 1 e //\u0026#34;ha\u0026#34; iota += 1 f = 100 //iota +=1 g //100 iota +=1 h = iota //7,恢复计数 i //8 ) fmt.Println(a,b,c,d,e,f,g,h,i) } 以上实例运行结果为：\n0 1 2 ha ha 100 100 7 8 运算符 几乎和java一样。\n算术运算符 下表列出了所有Go语言的算术运算符。假定 A 值为 10，B 值为 20。\n运算符 描述 实例 + 相加 A + B 输出结果 30 - 相减 A - B 输出结果 -10 * 相乘 A * B 输出结果 200 / 相除 B / A 输出结果 2 % 求余 B % A 输出结果 0 ++ 自增 A++ 输出结果 11 \u0026ndash; 自减 A\u0026ndash; 输出结果 9 关系运算符 下表列出了所有Go语言的关系运算符。假定 A 值为 10，B 值为 20。\n运算符 描述 实例 == 检查两个值是否相等，如果相等返回 True 否则返回 False。 (A == B) 为 False != 检查两个值是否不相等，如果不相等返回 True 否则返回 False。 (A != B) 为 True \u0026gt; 检查左边值是否大于右边值，如果是返回 True 否则返回 False。 (A \u0026gt; B) 为 False \u0026lt; 检查左边值是否小于右边值，如果是返回 True 否则返回 False。 (A \u0026lt; B) 为 True \u0026gt;= 检查左边值是否大于等于右边值，如果是返回 True 否则返回 False。 (A \u0026gt;= B) 为 False \u0026lt;= 检查左边值是否小于等于右边值，如果是返回 True 否则返回 False。 (A \u0026lt;= B) 为 True 逻辑运算符 下表列出了所有Go语言的逻辑运算符。假定 A 值为 True，B 值为 False。\n运算符 描述 实例 \u0026amp;\u0026amp; 逻辑 AND 运算符。 如果两边的操作数都是 True，则条件 True，否则为 False。 (A \u0026amp;\u0026amp; B) 为 False || 逻辑 OR 运算符。 如果两边的操作数有一个 True，则条件 True，否则为 False。 (A || B) 为 True ! 逻辑 NOT 运算符。 如果条件为 True，则逻辑 NOT 条件 False，否则为 True。 !(A \u0026amp;\u0026amp; B) 为 True 在其他语言中（比如C语言，java语言，JavaScript语言等），条件语句会使用一个小括号将其包围起来，在go语言中不需要使用这样的小括号（类似于python），但是如果使用这样的小括号也可以正常通过运行（但这是不符合go语言风格的，某些IDE会提示冗余括号）。为了整体代码风格更偏向于go语言，本手册代码不采用小括号包围条件语句。\n位运算符 Go 语言支持的位运算符如下表所示。假定 A 为60，B 为13：\n运算符 描述 实例 \u0026amp; 按位与运算符\u0026quot;\u0026amp;\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相与。 (A \u0026amp; B) 结果为 12, 二进制为 0000 1100 | 按位或运算符\u0026rdquo;|\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相或 (A | B) 结果为 61, 二进制为 0011 1101 ^ 按位异或运算符\u0026rdquo;^\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相异或，当两对应的二进位相异时，结果为1。 (A ^ B) 结果为 49, 二进制为 0011 0001 \u0026laquo; 左移运算符\u0026rdquo;\u0026laquo;\u0026ldquo;是双目运算符。左移n位就是乘以2的n次方。 其功能把\u0026rdquo;\u0026laquo;\u0026ldquo;左边的运算数的各二进位全部左移若干位，由\u0026rdquo;\u0026laquo;\u0026ldquo;右边的数指定移动的位数，高位丢弃，低位补0。 A \u0026laquo; 2 结果为 240 ，二进制为 1111 0000 \u0026raquo; 右移运算符\u0026rdquo;\u0026raquo;\u0026ldquo;是双目运算符。右移n位就是除以2的n次方。 其功能是把\u0026rdquo;\u0026raquo;\u0026ldquo;左边的运算数的各二进位全部右移若干位，\u0026quot;\u0026raquo;\u0026ldquo;右边的数指定移动的位数。 A \u0026raquo; 2 结果为 15 ，二进制为 0000 1111 赋值运算符 下表列出了所有Go语言的赋值运算符。\n运算符 描述 实例 = 简单的赋值运算符，将一个表达式的值赋给一个左值 C = A + B 将 A + B 表达式结果赋值给 C += 相加后再赋值 C += A 等于 C = C + A -= 相减后再赋值 C -= A 等于 C = C - A *= 相乘后再赋值 C *= A 等于 C = C * A /= 相除后再赋值 C /= A 等于 C = C / A %= 求余后再赋值 C %= A 等于 C = C % A \u0026laquo;= 左移后赋值 C \u0026laquo;= 2 等于 C = C \u0026laquo; 2 \u0026raquo;= 右移后赋值 C \u0026raquo;= 2 等于 C = C \u0026raquo; 2 \u0026amp;= 按位与后赋值 C \u0026amp;= 2 等于 C = C \u0026amp; 2 ^= 按位异或后赋值 C ^= 2 等于 C = C ^ 2 |= 按位或后赋值 其他运算符 运算符 描述 实例 \u0026amp; 返回变量存储地址 \u0026amp;a; 将给出变量的实际地址。 * 指针变量。 *a; 是一个指针变量 条件语句 if a := 10 if a == 10 { fmt.Println(\u0026#34;OK\u0026#34;) } else if a \u0026lt; 10 { fmt.Println(\u0026#34;Error\u0026#34;) } else { fmt.Println(\u0026#34;UNOWN\u0026#34;) } switch package main import \u0026#34;fmt\u0026#34; func main() { /* 定义局部变量 */ var grade string = \u0026#34;B\u0026#34; var marks int = 90 switch marks { case 90: grade = \u0026#34;A\u0026#34; case 80: grade = \u0026#34;B\u0026#34; case 50,60,70 : grade = \u0026#34;C\u0026#34; default: grade = \u0026#34;D\u0026#34; } switch { case grade == \u0026#34;A\u0026#34; : fmt.Printf(\u0026#34;优秀!\\n\u0026#34; ) case grade == \u0026#34;B\u0026#34;, grade == \u0026#34;C\u0026#34; : fmt.Printf(\u0026#34;良好\\n\u0026#34; ) case grade == \u0026#34;D\u0026#34; : fmt.Printf(\u0026#34;及格\\n\u0026#34; ) case grade == \u0026#34;F\u0026#34;: fmt.Printf(\u0026#34;不及格\\n\u0026#34; ) default: fmt.Printf(\u0026#34;差\\n\u0026#34; ) } fmt.Printf(\u0026#34;你的等级是 %s\\n\u0026#34;, grade ) } switch 语句还可以被用于 type-switch 来判断某个 interface 变量中实际存储的变量类型:\npackage main import \u0026#34;fmt\u0026#34; func main() { var x interface{} switch i := x.(type) { case nil:\tfmt.Printf(\u0026#34; x 的类型 :%T\u0026#34;,i) case int:\tfmt.Printf(\u0026#34;x 是 int 型\u0026#34;) case float64: fmt.Printf(\u0026#34;x 是 float64 型\u0026#34;) case func(int) float64: fmt.Printf(\u0026#34;x 是 func(int) 型\u0026#34;) case bool, string: fmt.Printf(\u0026#34;x 是 bool 或 string 型\u0026#34; ) default: fmt.Printf(\u0026#34;未知型\u0026#34;) } } select select是Go中的一个控制结构，类似于用于通信的switch语句。每个case必须是一个通信操作，要么是发送要么是接收。\nselect随机执行一个可运行的case。如果没有case可运行，它将阻塞，直到有case可运行。一个默认的子句应该总是可运行的。\n这里的通信，可以简单的理解为IO（输入输出），例如如下代码\nselect { case \u0026lt;-ch1: // 如果从 ch1 信道成功接收数据，则执行该分支代码 case ch2 \u0026lt;- 1: // 如果成功向 ch2 信道成功发送数据，则执行该分支代码 default: // 如果上面都没有成功，则进入 default 分支处理流程 } ","date":"1年1月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/1/01/","series":[],"smallImg":"","tags":[],"timestamp":-62135596800,"title":""},{"authors":[],"categories":[{"title":"中间件","url":"/myblog/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"content":"依赖解析 Gradle项目声明的每个依赖项都适用于特定范围。例如，一些依赖项应该用于编译源代码，而其他依赖项只需要在运行时可用。Gradle在Configuration的帮助下表示依赖项的范围。每个Configuration都可以用唯一的名称标识。\n下面是java 插件的一个示例：\nConfiguration 配置可以扩展其他配置以形成继承层次结构。子配置拥有父配置声明的整个依赖项集。配置继承被Gradle核心插件（如Java插件）大量使用。例如，testImplementation配置扩展了 implementation 配置。\n假设你想写一套烟雾测试。每个烟雾测试都会发出一个HTTP调用来验证web服务端点。作为底层测试框架，项目已经使用了JUnit。您可以定义一个名为smokeTest的新配置，该配置从testImplementation配置扩展，以重用现有的测试框架依赖项。\nconfigurations { smokeTest.extendsFrom testImplementation } dependencies { testImplementation \u0026#39;junit:junit:4.13\u0026#39; smokeTest \u0026#39;org.apache.httpcomponents:httpclient:4.5.5\u0026#39; } 配置是Gradle中依赖关系解决的基本部分。在依赖解析的上下文中，区分消费者和生产者是很有用的。按照这些原则，配置至少具有3种不同的角色：\n声明依赖项 作为消费者，解析文件的一组依赖关系 作为一个生产者，暴露工件及其依赖关系，供其他项目使用 例如，为了表示app应用程序依赖于lib库，至少需要一种配置：\nconfigurations { // declare a \u0026#34;configuration\u0026#34; named \u0026#34;someConfiguration\u0026#34; someConfiguration } dependencies { // add a project dependency to the \u0026#34;someConfiguration\u0026#34; configuration someConfiguration project(\u0026#34;:lib\u0026#34;) } 配置可以通过从其他配置扩展来继承依赖关系。现在，请注意，上面的代码没有告诉我们任何有关此配置的预期消费者的信息。特别是，它没有告诉我们如何使用配置。假设lib是一个Java库：它可能会暴露不同的东西，例如它的API、实现或测试装置。根据我们正在执行的任务（根据lib的API编译、执行应用程序、编译测试等），可能需要更改我们如何解析app的依赖关系。为了解决这个问题，您通常会发现伴随配置，它们旨在明确地声明用法：\nconfigurations { // declare a configuration that is going to resolve the compile classpath of the application compileClasspath.extendsFrom(someConfiguration) // declare a configuration that is going to resolve the runtime classpath of the application runtimeClasspath.extendsFrom(someConfiguration) } 此时，我们有3种不同的配置，具有不同的角色：\nsomeConfiguration声明应用程序的依赖关系。它只是一个可以保存依赖项列表的桶。 compileClasspath和runtimeClasspath是要解析的配置：解析后，它们应该分别包含编译类路径和应用程序的运行时类路径。 这种区别由配置类型中的canBeResolved标志表示。可以解析的配置是我们可以计算依赖关系图的配置，因为它包含解析所需的所有信息. 也就是说，我们将计算一个依赖关系图，解析图中的组件，最终得到工件。canBeResolved设置为false的配置不会被解析。这样的配置只用于声明依赖项。原因是，根据用法（编译类路径、运行时类路径），它可以解析为不同的图。尝试解析canBeResolved设置为false的配置是错误的。在某种程度上，这类似于不应该实例化的抽象类（canBeResolved=false）和扩展抽象类的具体类（canBeResolved=true）。可解析配置将扩展至少一个不可解析配置（并且可以扩展多个）。\n另一方面，在库项目端（生产者），我们也使用配置来表示可以使用的内容。例如，库可以公开API或运行时，我们可以将工件附加到其中一个、另一个或两者。通常，要针对lib进行编译，我们需要lib的API，但不需要它的运行时依赖项。因此，lib项目将公开一个apiElements配置，该配置面向寻找其API的用户。这种配置是可消费的，但并不意味着可解析。这通过配置的canBeConsumed标志表示：\nconfigurations { // A configuration meant for consumers that need the API of this component exposedApi { // This configuration is an \u0026#34;outgoing\u0026#34; configuration, it\u0026#39;s not meant to be resolved canBeResolved = false // As an outgoing configuration, explain that consumers may want to consume it canBeConsumed = true } // A configuration meant for consumers that need the implementation of this component exposedRuntime { canBeResolved = false canBeConsumed = true } } 简而言之，配置的角色由canBeResolved和canBeConsumed标志组合决定：\nConfiguration role can be resolved can be consumed Bucket of dependencies false false Resolve for certain usage true false Exposed to consumers false true Legacy, don’t use true true 为了向后兼容，这两个标志的默认值都为true，但作为插件作者，您应该始终为这些标志确定正确的值，否则可能会意外引入解析错误。\n项目有时不依赖二进制存储库产品，例如JFrog Artifactory或Sonatype Nexus来托管和解决外部依赖关系。通常的做法是将这些依赖项托管在共享驱动器上，或者将它们与项目源代码一起检入版本控制。这些依赖关系称为文件依赖关系，原因是它们表示的文件没有附加任何元数据（如有关传递依赖关系、来源或作者的信息）。\nconfigurations { antContrib externalLibs deploymentTools } dependencies { runtimeOnly files(\u0026#39;libs/a.jar\u0026#39;, \u0026#39;libs/b.jar\u0026#39;) runtimeOnly fileTree(\u0026#39;libs\u0026#39;) { include \u0026#39;*.jar\u0026#39; } antContrib files(\u0026#39;ant/antcontrib.jar\u0026#39;) externalLibs files(\u0026#39;libs/commons-lang.jar\u0026#39;, \u0026#39;libs/log4j.jar\u0026#39;) deploymentTools(fileTree(\u0026#39;tools\u0026#39;) { include \u0026#39;*.exe\u0026#39; }) } 正如您在代码示例中看到的，每个依赖项都必须定义其在文件系统中的确切位置。创建文件引用的最主要方法是Project.files（java.lang.Object…), ProjectLayout.files（java.lang.Object…) 和Project.fileTree（java.lang.Object）或者，也可以以平面目录存储库的形式定义一个或多个文件依赖项的源目录。\nFileTree中文件的顺序不稳定，即使在一台计算机上也是如此。这意味着以这种构造为种子的依赖配置可能会产生具有不同顺序的解析结果，可能会影响使用结果作为输入的任务的可缓存性。建议尽可能使用更简单的文件。\n软件项目通常将软件组件分解为模块，以提高可维护性并防止强耦合。模块可以定义彼此之间的依赖关系，以便在同一项目中重用代码。\nGradle可以建模模块之间的依赖关系。这些依赖关系称为项目依赖关系，因为每个模块都由Gradle项目表示。\ndependencies { implementation project(\u0026#39;:shared\u0026#39;) } 在运行时，构建会自动确保以正确的顺序构建项目依赖项，并将其添加到类路径中进行编译。\n自Gradle 7以来，Gradle为项目依赖项提供了一个实验性的类型安全API。与上述相同的示例现在可以改写为：\ndependencies { implementation projects.utils implementation projects.api } 项目访问器是从项目路径映射的。例如，如果项目路径是：commons:utils:some:lib，那么项目访问器将是projects.commons.utils.some.lib（这是projects.getCommons().getUtils().getSome().get-lib（）的缩写）。 带有kebab case（someLib）或snake case（some_lib）的项目名称将在accessors中转换为camel-case：projects.someLib。\n流程 Gradle需要依赖关系图中包含的模块的元数据。需要这些信息：\n当声明的版本是动态的时，确定模块的现有版本。 确定给定版本的模块依赖关系。 面对动态版本，Gradle需要确定具体的匹配版本：\n每个存储库都会被检查，Gradle不会在第一个返回一些元数据时停止。定义多个时，将按添加顺序检查它们。 对于Maven存储库，Gradle将使用maven-metadata.xml（提供有关可用版本的信息）。 对于Ivy存储库，Gradle将使用目录列表。 此过程生成一个候选版本列表，然后将其与所表达的动态版本相匹配。注意Gradle缓存了版本信息，更多信息可以在控制动态版本缓存一节中找到。\n给定一个所需的依赖项和一个版本，Gradle试图通过搜索依赖项指向的模块来解决依赖项。\n按顺序检查每个存储库。 根据存储库的类型，Gradle查找描述模块的元数据文件（.module、.pom或ivy.xml文件）或直接查找工件文件。 具有模块元数据文件（.module、.pom或ivy.xml文件）的模块优于仅具有工件文件的模块。 一旦存储库返回元数据结果，将忽略后面存储库。 如果找到依赖项的元数据，将检索并分析该元数据 如果模块元数据是声明了父POM的POM文件，Gradle将递归地尝试解析POM的每个父模块。 然后从上述过程中选择的同一存储库中请求模块的所有工件。 然后，所有这些数据（包括存储库源和潜在未命中）都存储在依赖缓存中。 当Gradle无法从存储库中检索信息时，它将在构建期间禁用它，并使所有依赖项解析失败。最后一点对于再现性很重要。如果允许继续构建，而忽略错误的存储库，那么一旦存储库恢复联机，后续的构建可能会产生不同的结果。\nGradle将多次尝试连接到给定的存储库，然后将其禁用。如果连接失败，Gradle将对某些可能是暂时性的错误进行重试，从而增加每次重试之间等待的时间。\n当由于永久错误或已达到最大重试次数而无法联系存储库时，就会出现黑名单。\n依赖缓存 Gradle包含一个高度复杂的依赖缓存机制，该机制旨在最大限度地减少依赖解析中发出的远程请求数量，同时努力确保依赖解析的结果正确且可重复。\nGradle依存关系缓存由位于Gradle_USER_HOME/caches下的两种存储类型组成：\n基于文件的下载工件存储，包括二进制文件（如jar）以及原始下载元数据（如POM文件和Ivy文件）。下载的工件的存储路径包括SHA1校验和，这意味着可以轻松缓存具有相同名称但不同内容的两个工件。 已解析模块元数据的二进制存储，包括解析动态版本、模块描述符和工件的结果。 Gradle 会跟踪访问依赖项缓存中的工件。 定期（最多每 24 小时）扫描缓存以查找超过 30 天未使用的项目。 然后删除过时的项目，以确保缓存不会无限增长。\n版本声明 声明依赖版本 声明具体的版本号，例如：1.3, 1.3.0-beta3, 1.0-20150201.131010-1\nmaven 风格的版本号范围。例如[1.0,), [1.1, 2.0), (1.2, 1.5] 。\n[]表示包含边界， （）表示不包含。默认都是取范围内的最大版本。 符号]可以代替（表示排他下限，[代替）表示排他上限。例如]1.0、2.0[ 上限排除充当前缀排除。这意味着[1.0，2.0]也将排除所有以2.0开头且小于2.0的版本。例如，2.0-dev1或2.0-SNAPSHOT等版本不再包含在范围内。 前缀范围： 1.+, 1.3.+ ，下载当前前缀下的最大可用版本\nlatest-status： 例如 latest.integration, latest.release\n基本的版本声明：\ndependencies { implementation(\u0026#39;org.slf4j:slf4j-api:1.7.15\u0026#39;) } 然后，该版本被认为是必需的版本，这意味着它应该最低为1.7.15，但可以由引擎进行升级（乐观升级）。然而，有一种严格版本的速记符号，使用!!符号：\ndependencies { // short-hand notation with !! implementation(\u0026#39;org.slf4j:slf4j-api:1.7.15!!\u0026#39;) // is equivalent to implementation(\u0026#34;org.slf4j:slf4j-api\u0026#34;) { version { strictly \u0026#39;1.7.15\u0026#39; } } // or... implementation(\u0026#39;org.slf4j:slf4j-api:[1.7, 1.8[!!1.7.25\u0026#39;) // is equivalent to implementation(\u0026#39;org.slf4j:slf4j-api\u0026#39;) { version { strictly \u0026#39;[1.7, 1.8[\u0026#39; prefer \u0026#39;1.7.25\u0026#39; } } } 一个严格的版本不能被升级并覆盖任何源于此依赖关系的可传递依赖关系。建议对严格版本使用范围。\n对于较大的项目，推荐的做法是声明没有版本的依赖项，并在版本声明中使用依赖项约束。其优点是依赖项约束允许您在一个地方管理所有依赖项的版本，包括可传递的依赖项。例如：\ndependencies { implementation \u0026#39;org.springframework:spring-web\u0026#39; } dependencies { constraints { implementation \u0026#39;org.springframework:spring-web:5.0.2.RELEASE\u0026#39; } } 版本策略 声明版本的时候，可以指定以下策略：\nstrictly：任何与此版本符号不匹配的版本都将被排除在外。这是最强的版本声明。在声明的依赖项上，strictly可以降级版本。在传递依赖项上时，如果无法选择此子句可接受的版本，则会导致依赖项解析失败。有关详细信息，请参阅重写依赖项版本。此术语支持动态版本。 require：意味着所选版本不能低于所需接受的版本，但通过冲突解决可以更高，即使更高版本具有独占上限。这就是直接依赖关系的含义。这个术语支持动态版本。 prefer：这是一个非常软的版本声明。只有在对模块的版本没有更强烈的非动态意见时，它才适用。此术语不支持动态版本。 reject：声明模块不接受特定版本。如果唯一可选择的版本也被拒绝，这将导致依赖性解析失败。此术语支持动态版本。 ependencies { implementation(\u0026#39;org.slf4j:slf4j-api\u0026#39;) { version { strictly \u0026#39;[1.7, 1.8[\u0026#39; prefer \u0026#39;1.7.25\u0026#39; } } constraints { implementation(\u0026#39;org.springframework:spring-core\u0026#39;) { version { require \u0026#39;4.2.9.RELEASE\u0026#39; reject \u0026#39;4.3.16.RELEASE\u0026#39; } } } } Gradle 通过在依赖关系图中找到的最新版本来解决冲突,但有的时候我们需要旧的版本，该怎么办呢？\nimplementation \u0026#39;org.apache.httpcomponents:httpclient:4.5.4\u0026#39; implementation(\u0026#39;commons-codec:commons-codec:1.9\u0026#39;) 根据gradle的依赖解析规则，commons-codec的版本会是1.10，并不是我们想要的1.9。可以下面的设置更改\nimplementation \u0026#39;org.apache.httpcomponents:httpclient:4.5.4\u0026#39; implementation(\u0026#39;commons-codec:commons-codec\u0026#39;) { version { strictly \u0026#39;1.9\u0026#39; } } 这种方式是有风险的，因为强制的指定了版本，依赖此库的app无法覆盖传递依赖，造成无法提升版本的问题。\n在许多情况下，您需要使用特定模块依赖项的最新版本，或一系列版本中的最新。这可能是开发过程中的一项要求，或者您正在开发一个旨在与一系列依赖关系版本一起使用的库。通过使用动态版本，您可以轻松地依赖这些不断变化的依赖关系。动态版本可以是版本范围（例如2.+），也可以是最新版本的占位符，例如latest.integration。\n或者，您请求的模块可以随时间变化，即使是同一版本，也就是所谓的变化版本。这种类型的更改模块的一个例子是Maven SNAPSHOT模块，它总是指向最新发布的工件。换句话说，标准Maven快照是一个不断发展的模块，它是一个“不断变化的模块”。\n使用动态版本和更改模块可能导致无法生产的构建。随着特定模块的新版本发布，其API可能会与源代码不兼容。小心使用此功能！\n项目可能会采用更积极的方法来消费对模块的依赖。例如，您可能希望始终集成最新版本的依赖项，以便在任何给定时间使用尖端功能。动态版本允许解析给定模块的版本范围的最新版本或最新版本。\nplugins { id \u0026#39;java-library\u0026#39; } repositories { mavenCentral() } dependencies { implementation \u0026#39;org.springframework:spring-web:5.+\u0026#39; } 构建扫描可以有效地可视化动态依赖关系版本及其各自的选定版本。\n默认情况下，Gradle缓存依赖项的动态版本24小时。在此时间框架内，Gradle不会尝试从声明的存储库中解析较新的版本。可以根据需要配置阈值，例如，如果您希望更早地解析新版本。\n团队可能会决定在发布应用程序或库的新版本之前实现一系列功能。一种常见的策略是允许消费者尽早集成他们的工件的未完成版本，通常是发布一个具有所谓更改版本的模块。不断变化的版本表明该功能集仍在积极开发中，尚未发布稳定的版本以供全面使用。\n在Maven存储库中，更改的版本通常称为快照版本。快照版本包含后缀-Snapshot。以下示例演示如何在Spring依赖项上声明快照版本。\nplugins { id \u0026#39;java-library\u0026#39; } repositories { mavenCentral() maven { url \u0026#39;https://repo.spring.io/snapshot/\u0026#39; } } dependencies { implementation \u0026#39;org.springframework:spring-web:5.0.3.BUILD-SNAPSHOT\u0026#39; } 默认情况下，Gradle会在24小时内缓存依赖项的更改版本。在此时间框架内，Gradle不会尝试从声明的存储库中解析较新的版本。可以根据需要配置阈值，例如，如果要更早地解析新的快照版本。\nGradle足够灵活，可以将任何版本视为正在更改的版本，例如，如果您想为Ivy模块建模快照行为。您只需设置属性ExternalModuleDependency.setChanging（布尔值）设置为true。\n可以使用命令行选项覆盖默认缓存模式。您还可以使用解析策略以编程方式更改构建中的缓存过期时间。\nconfigurations.all { resolutionStrategy.cacheDynamicVersionsFor 10, \u0026#39;minutes\u0026#39; resolutionStrategy.cacheChangingModulesFor 4, \u0026#39;hours\u0026#39; } \u0026ndash;offline命令行开关告诉Gradle始终使用缓存中的依赖模块，无论它们是否需要再次检查。在脱机运行时，Gradle不会尝试访问网络以执行依赖关系解析。如果依赖缓存中不存在所需的模块，则build执行将失败。\n要刷新依赖项缓存中的所有依赖项，请在命令行上使用\u0026ndash;refresh-dependencies选项。Gradle忽略已解析模块和工件的所有缓存条目。将对所有配置的存储库执行新的解析，重新计算动态版本、刷新模块并下载工件。然而，如果可能，Gradle将在再次下载之前检查先前下载的工件是否有效。这是通过将存储库中发布的SHA1值与现有下载工件的SHA1数值进行比较来完成的。\n当多个版本与版本选择器匹配时，组件选择规则可能会影响应选择哪个组件实例。规则针对每个可用版本应用，并允许规则明确拒绝该版本。这允许Gradle忽略任何不满足规则设置的条件的组件实例。示例包括：\n对于像1.+这样的动态版本，某些版本可能会被明确拒绝选择。 对于像1.4这样的静态版本，可能会基于额外的组件元数据（如Ivy分支属性）拒绝实例，从而允许使用后续存储库中的实例。 通过ComponentSelectionRules对象配置规则。将使用ComponentSelection对象作为参数调用配置的每个规则，该对象包含有关正在考虑的候选版本的信息。调用ComponentSelection.reject（java.lang.String）会导致给定的候选版本被显式拒绝，在这种情况下，选择器不会考虑候选版本。\n以下示例显示了一个规则，该规则不允许模块的特定版本，但允许动态版本选择下一个最佳候选:\nconfigurations { rejectConfig { resolutionStrategy { componentSelection { // Accept the highest version matching the requested version that isn\u0026#39;t \u0026#39;1.5\u0026#39; all { ComponentSelection selection -\u0026gt; if (selection.candidate.group == \u0026#39;org.sample\u0026#39; \u0026amp;\u0026amp; selection.candidate.module == \u0026#39;api\u0026#39; \u0026amp;\u0026amp; selection.candidate.version == \u0026#39;1.5\u0026#39;) { selection.reject(\u0026#34;version 1.5 is broken for \u0026#39;org.sample:api\u0026#39;\u0026#34;) } } } } } } dependencies { rejectConfig \u0026#34;org.sample:api:1.+\u0026#34; } 请注意，版本选择首先从最高版本开始应用。所选版本将是所有组件选择规则接受的第一个版本。如果没有规则明确拒绝某个版本，则认为该版本被接受。\n类似地，规则可以针对特定模块。必须以group:module的形式指定模块。\nconfigurations { targetConfig { resolutionStrategy { componentSelection { withModule(\u0026#34;org.sample:api\u0026#34;) { ComponentSelection selection -\u0026gt; if (selection.candidate.version == \u0026#34;1.5\u0026#34;) { selection.reject(\u0026#34;version 1.5 is broken for \u0026#39;org.sample:api\u0026#39;\u0026#34;) } } } } } } 组件选择规则还可以在选择版本时考虑组件元数据。可以考虑的其他元数据包括ComponentMetadata和IvyModuleDescriptor。请注意，这些额外信息可能并不总是可用的，因此应检查空值。\nconfigurations { metadataRulesConfig { resolutionStrategy { componentSelection { // Reject any versions with a status of \u0026#39;experimental\u0026#39; all { ComponentSelection selection -\u0026gt; if (selection.candidate.group == \u0026#39;org.sample\u0026#39; \u0026amp;\u0026amp; selection.metadata?.status == \u0026#39;experimental\u0026#39;) { selection.reject(\u0026#34;don\u0026#39;t use experimental candidates from \u0026#39;org.sample\u0026#39;\u0026#34;) } } // Accept the highest version with either a \u0026#34;release\u0026#34; branch or a status of \u0026#39;milestone\u0026#39; withModule(\u0026#39;org.sample:api\u0026#39;) { ComponentSelection selection -\u0026gt; if (selection.getDescriptor(IvyModuleDescriptor)?.branch != \u0026#34;release\u0026#34; \u0026amp;\u0026amp; selection.metadata?.status != \u0026#39;milestone\u0026#39;) { selection.reject(\u0026#34;\u0026#39;org.sample:api\u0026#39; must be a release branch or have milestone status\u0026#34;) } } } } } } 升级传递依赖的版本 组件可能有两种不同的依赖关系：\n直接依赖关系。直接依赖性也称为第一级依赖性。例如，如果您的项目源代码需要Guava，则应将Guava声明为直接依赖项。 传递依赖是您的组件需要的依赖，但这只是因为另一个依赖需要它们。 依赖关系管理的问题是关于可传递的依赖关系，这是很常见的。开发人员通常通过添加直接依赖项来错误地解决可传递依赖项问题。为了避免这种情况，Gradle提供了依赖约束的概念。\n依赖关系约束允许您定义生成脚本中声明的依赖关系和可传递依赖关系的版本或版本范围。它是表示应 应用于配置的所有依赖项的约束的首选方法。\n当Gradle试图解析模块版本的依赖关系时，将考虑该模块的所有版本依赖关系声明、所有可传递依赖关系和所有依赖约束。选择符合所有条件的最高版本。如果找不到这样的版本，Gradle将失败，并显示一个错误，显示冲突的声明。\n如果发生这种情况，您可以调整依赖关系或依赖约束声明，或者根据需要对传递依赖关系进行其他调整。与依赖关系声明类似，依赖关系约束声明由配置确定范围，因此可以为构建的部分选择性地定义。\ndependencies { implementation \u0026#39;org.apache.httpcomponents:httpclient\u0026#39; constraints { implementation(\u0026#39;org.apache.httpcomponents:httpclient:4.5.3\u0026#39;) { because \u0026#39;previous versions have a bug impacting this application\u0026#39; } implementation(\u0026#39;commons-codec:commons-codec:1.11\u0026#39;) { because \u0026#39;version 1.9 pulled from httpclient has bugs affecting this application\u0026#39; } } } 在本例中，依赖关系声明中省略了所有版本。而是在约束块中定义版本。commons-codec:1.11 仅在作为传递依赖项引入时考虑，因为其在项目中未定义为依赖项。否则，约束无效。依赖性约束也可以定义富版本约束，并支持严格版本来强制执行版本，即使它与传递依赖性定义的版本相冲突（例如，如果版本需要降级）。\nGradle通过选择依赖关系图中找到的最新版本来解决任何依赖关系版本冲突。某些项目可能需要偏离默认行为，并强制实施早期版本的依赖关系。\n假设一个项目使用HttpClient库来执行HTTP调用。HttpClient将Commons Codec1.10版本作为可传递依赖项引入。然而，项目的生产源代码需要Commons Codec1.9中的API，而1.10版本中不再提供该API。依赖版本可以通过在构建脚本中将其声明为严格版本来强制执行：\ndependencies { implementation \u0026#39;org.apache.httpcomponents:httpclient:4.5.4\u0026#39; implementation(\u0026#39;commons-codec:commons-codec\u0026#39;) { version { strictly \u0026#39;1.9\u0026#39; } } } 然而，对于消费者来说，在图形解析过程中，严格的版本仍然是全局考虑的，如果消费者不同意，可能会触发错误。 例如，假设您的项目B严格依赖于C:1.0。现在，消费者A同时依赖于B和C:1.1。然后，这将触发解析错误，因为A表示它需要C:1.1，而B在其子图中严格需要1.0。这意味着，如果您在严格约束中选择了一个版本，则该版本将无法再升级，除非用户也对同一模块设置了严格的版本约束。\n在上面的例子中，A必须说它严格依赖于1.1。\n因此，一个好的做法是，如果您使用严格的版本，则应使用范围和在此范围内的首选版本来表示它们。例如，B可能会说，它严格依赖于[1.0，2.0]范围，而不是严格依赖于1.0。然后，如果消费者选择1.1（或范围内的任何其他版本），则构建将不再失败（约束已解决）。\n如果出于某种原因，您不能使用严格的版本，则可以强制依赖项执行以下操作：\ndependencies { implementation \u0026#39;org.apache.httpcomponents:httpclient:4.5.4\u0026#39; implementation(\u0026#39;commons-codec:commons-codec:1.9\u0026#39;) { force = true } } 如果项目需要特定版本的配置级别依赖项，则可以通过调用ResolutionStrategy.force（java.lang.Object[]）方法来实现。\nconfigurations { compileClasspath { resolutionStrategy.force \u0026#39;commons-codec:commons-codec:1.9\u0026#39; } } dependencies { implementation \u0026#39;org.apache.httpcomponents:httpclient:4.5.4\u0026#39; } 文件操作 复制文件 通过创建Gradle的内置Copy任务的实例，可以复制文件。此示例模拟将生成的报告复制到打包目录中：\ntasks.register(\u0026#39;copyReport\u0026#39;, Copy) { from layout.buildDirectory.file(\u0026#34;reports/my-report.pdf\u0026#34;) into layout.buildDirectory.dir(\u0026#34;toArchive\u0026#34;) } Project.file（java.lang.Object）方法用于创建与当前项目相关的文件或目录路径。您甚至可以直接使用路径而不使用file（）方法：\ntasks.register(\u0026#39;copyReport2\u0026#39;, Copy) { from \u0026#34;$buildDir/reports/my-report.pdf\u0026#34; into \u0026#34;$buildDir/toArchive\u0026#34; } 通过为from（）提供多个参数，可以很容易地将前面的示例扩展到多个文件：\ntasks.register(\u0026#39;copyReportsForArchiving\u0026#39;, Copy) { from layout.buildDirectory.file(\u0026#34;reports/my-report.pdf\u0026#34;), layout.projectDirectory.file(\u0026#34;src/docs/manual.pdf\u0026#34;) into layout.buildDirectory.dir(\u0026#34;toArchive\u0026#34;) } 复制指定模式的文件：\ntasks.register(\u0026#39;copyPdfReportsForArchiving\u0026#39;, Copy) { from layout.buildDirectory.dir(\u0026#34;reports\u0026#34;) include \u0026#34;*.pdf\u0026#34; into layout.buildDirectory.dir(\u0026#34;toArchive\u0026#34;) } 您可以使用Ant样式的glob模式（**/*）将文件包含在子目录中，如下示例所示：\ntasks.register(\u0026#39;copyAllPdfReportsForArchiving\u0026#39;, Copy) { from layout.buildDirectory.dir(\u0026#34;reports\u0026#34;) include \u0026#34;**/*.pdf\u0026#34; into layout.buildDirectory.dir(\u0026#34;toArchive\u0026#34;) } 需要记住的一点是，像这样的深度过滤器会产生复制reports目录结构的副作用。如果只想复制没有目录结构的文件，则需要使用fileTree(dir) { includes }.files表达式。\n创建归档文件 tasks.register(\u0026#39;packageDistribution\u0026#39;, Zip) { archiveFileName = \u0026#34;my-distribution.zip\u0026#34; destinationDirectory = layout.buildDirectory.dir(\u0026#39;dist\u0026#39;) from layout.buildDirectory.dir(\u0026#34;toArchive\u0026#34;) } 每种类型的存档都有自己的任务类型，最常见的是Zip、Tar和Jar。它们都共享Copy的大部分配置选项，包括过滤和重命名。\n更改文件内容 文件内容过滤允许您在复制文件时转换文件的内容。这可能涉及使用token替换的基本模板、删除文本行，或者使用成熟的模板引擎进行更复杂的过滤。\n以下示例演示了几种形式的过滤，包括使用CopySpec.exexpand（java.util.Map）方法进行token替换，以及使用CopySpec.filter（java.lang.Class）和Ant过滤器进行token替换：\nimport org.apache.tools.ant.filters.FixCrLfFilter import org.apache.tools.ant.filters.ReplaceTokens tasks.register(\u0026#39;filter\u0026#39;, Copy) { from \u0026#39;src/main/webapp\u0026#39; into layout.buildDirectory.dir(\u0026#39;explodedWar\u0026#39;) // Substitute property tokens in files expand(copyright: \u0026#39;2009\u0026#39;, version: \u0026#39;2.3.1\u0026#39;) expand(project.properties) // Use some of the filters provided by Ant filter(FixCrLfFilter) filter(ReplaceTokens, tokens: [copyright: \u0026#39;2009\u0026#39;, version: \u0026#39;2.3.1\u0026#39;]) // Use a closure to filter each line filter { String line -\u0026gt; \u0026#34;[$line]\u0026#34; } // Use a closure to remove lines filter { String line -\u0026gt; line.startsWith(\u0026#39;-\u0026#39;) ? null : line } filteringCharset = \u0026#39;UTF-8\u0026#39; } filter（）方法有两个变体，其行为不同：\n一个采用FilterReader，设计用于Ant过滤器，如ReplaceTokens 一个是闭包或Transformer，它为源文件的每一行定义转换 当您将ReplaceTokens类与filter（）一起使用时，结果是一个模板引擎，它将@tokenName@（Ant样式的token）形式的token替换为您定义的值。\nexpand（）方法将源文件视为Groovy模板，用于计算和扩展${expression}形式的表达式。您可以传入属性名称和值，然后在源文件中展开。expand（）允许的不仅仅是基本的令牌替换，因为嵌入的表达式是完整的Groovy表达式。\n","date":"1年1月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/1/01/gradle-%E4%BE%9D%E8%B5%96%E8%A7%A3%E6%9E%90/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"},{"title":"gradle","url":"/myblog/tags/gradle/"}],"timestamp":-62135596800,"title":"Gradle 依赖解析"},{"authors":[],"categories":[{"title":"中间件","url":"/myblog/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"content":"插件的生命周期 Base插件提供了大多数构建通用的一些任务和约定，并为构建添加了一个结构，以提高它们运行方式的一致性。它最重要的贡献是一组生命周期任务，充当其他插件和具体任务的保护伞。\n主要任务和声明周期:\nclean — Delete: 删除build目录及其子目录下的所有内容，即Project.getBuildDir（）项目属性指定的路径。 check — lifecycle task：插件和构建作者应使用check.dependsOn(*task*)将验证任务（例如运行测试的任务）附加到此生命周期任务。 assemble — lifecycle task：插件和构建作者应该将生成发行版和其他可消费工件的任务附加到此生命周期任务。例如，jar为Java库生成可消费的工件。使用assemble.dependsOn(*task*)将任务附加到此生命周期任务 build — lifecycle task：依赖check, assemble。旨在构建一切，包括运行所有测试、生成生产工件和生成文档。您可能很少直接将具体任务附加到构建中，因为assemble和check通常更合适。 buildConfiguration — task rule： 组装附加到命名配置的那些工件。例如，buildArchives将执行任务，将所有工件绑定到archives 配置。 cleanTask — task rule： 删除任务的输出，例如cleanJar将删除Java插件的JAR任务生成的JAR文件。 base插件没有为依赖项添加配置，但它添加了以下配置：\ndefault: 消费者项目使用的回退配置。假设您的项目B依赖于项目A。Gradle使用一些内部逻辑来确定项目A的哪些工件和依赖项添加到项目B的指定配置中。如果没有其他因素适用-您不必担心这些因素是什么-那么Gradle会回到使用项目A的默认配置中的所有内容。新版本和插件不应使用默认配置！由于向后兼容的原因，它仍然存在。 archives: 项目生产工件的标准配置。 base插件将base扩展添加到项目中。这允许在专用DSL块内配置以下属性:\nbase { archivesName = \u0026#34;gradle\u0026#34; distsDirectory = layout.buildDirectory.dir(\u0026#39;custom-dist\u0026#39;) libsDirectory = layout.buildDirectory.dir(\u0026#39;custom-libs\u0026#39;) } archivesName : 默认**$project.name** distsDirectory：默认**$buildDir/distributions** ：创建分发存档（即非JAR）的目录的默认名称。 libsDirectory： 默认**$buildDir/libs**： 创建库存档（即JAR）的目录的默认名称。 该插件还为任何扩展AbstractArchiveTask的任务提供以下属性的默认值：\ndestinationDirectory：对于非JAR归档文件，默认为distsDirectory；对于JAR及其派生文件，例如WAR，默认为libsDirectory。 archiveVersion： 默认为$project.version或unspecified（如果项目没有版本）。 archiveBaseName： 默认值为$archivesBaseName。 构建java项目 Gradle使用约定优于配置的方法来构建基于JVM的项目，该方法借鉴了Apache Maven的一些约定。特别是，它对源文件和资源使用相同的默认目录结构，并与Maven兼容的存储库一起工作。\n入门项目 Java项目最简单的构建脚本 先从应用Java Library 插件开始，设置项目版本并选择要使用的Java工具链：\nbuild.gradle:\nplugins { id \u0026#39;java-library\u0026#39; } java { toolchain { languageVersion = JavaLanguageVersion.of(11) } } version = \u0026#39;1.2.1\u0026#39; 通过应用Java Library插件，您可以获得一整套功能：\ncompileJava任务，编译src/main/java下的所有Java源文件 compileTestJava任务，编译src/test/java下的所有Java源文件 test 任务， 运行src/test/java下的测试用例 一个jar任务，将主要编译类（src/main/java下的类）和src/main/resources中的资源打包到一个名为-.jar的jar中 为主要类生成javadoc的javadoc任务 尽管示例中的属性是可选的，但我们建议您在项目中指定它们。工具链选项可防止使用不同Java版本构建的项目出现问题。版本字符串对于跟踪项目进度非常重要。默认情况下，项目版本也用于存档名称中。\nJava Library插件还将上述任务集成到标准Base插件生命周期任务中：\njar 绑定到 assemble 生命周期 test 绑定到 check 生命周期 定义sourceSet 源代码集主要思想是源文件和资源按类型进行逻辑分组，例如应用程序代码、单元测试和集成测试。每个逻辑组通常都有自己的文件依赖项集、类路径等。值得注意的是，形成源集的文件不必位于同一目录中！\n源集是一个强大的概念，它将编译的几个方面联系在一起：\n源文件及其位置 编译类路径，包括任何必需的依赖项（通过Gradle配置） 编译的类文件所在的位置 您可以在这个图表中看到它们是如何相互关联的：\n着色框表示源集本身的属性。除此之外，Java Library 插件会自动为您或插件定义的每个源集和几个依赖项配置创建一个编译任务（名为compileSourceSetJava）。\nJava项目通常包括源文件以外的资源，例如属性文件，这些资源可能需要处理（例如，通过替换文件中的标记），并在最终JAR中打包。Java Library 插件通过为每个定义的源集自动创建一个专用任务来处理此问题，该任务称为processSourceSetResources（或main源集的processResources）。下图显示了源集如何适应此任务：\n如前所述，阴影框表示源集的属性，在本例中，源集包括资源文件的位置及其复制到的位置。\n除了主源代码集之外，Java Library插件还定义了一个表示项目测试的测试源代码集。此源集由运行测试的测试任务使用。您可以在Java测试一章中了解有关此任务和相关主题的更多信息。\n项目通常将此源集用于单元测试，但如果您愿意，也可以将其用于集成、验收和其他类型的测试。另一种方法是为每个其他测试类型定义一个新的源集，这通常是出于以下一个或两个原因：\n为了美观性和可管理性，您希望将测试彼此分开 不同的测试类型需要不同的编译或运行时类路径或设置中的一些其他差异 自定义sourceSet的位置 假设您有一个遗留项目，它为生产代码使用src目录，为测试代码使用test。传统的目录结构不起作用，因此您需要告诉Gradle在哪里可以找到源文件。您可以通过源代码集配置来实现。\nsourceSets { main { java { srcDirs = [\u0026#39;src\u0026#39;] } } test { java { srcDirs = [\u0026#39;test\u0026#39;] } } } 现在Gradle只会直接在src中搜索并测试相应的源代码。如果您不想重写约定，而只是想添加一个额外的源目录，也许其中包含一些您希望保持独立的第三方源代码，该怎么办？语法类似：\nsourceSets { main { java { srcDir \u0026#39;thirdParty/src/main/java\u0026#39; } } } 重要的是，我们在这里使用srcDir（）方法来附加目录路径，而设置srcDirs属性将替换任何现有值。这是Gradle中的一个常见约定：设置属性替换值，而相应的方法附加值。\n更改编译配置 大多数编译器选项都可以通过相应的任务访问，例如compileJava和compileTestJava。这些任务属于JavaCompile类型，因此请阅读任务参考以获取最新和全面的选项列表。\n例如，如果您希望为编译器使用单独的JVM进程，并防止编译失败导致生成失败，则可以使用以下配置：\ncompileJava { options.incremental = true options.fork = true options.failOnError = false } 更改java的版本 默认情况下，Gradle会将Java代码编译到运行Gradle的JVM的语言级别。通过使用Java工具链，您可以通过确保构建定义的给定Java版本用于编译、执行和文档来打破这一联系。然而，可以在任务级别重写一些编译器和执行选项。\n从版本9开始，Java编译器可以被配置为为较旧的Java版本生成字节码，同时确保代码不使用任何较新版本的API。Gradle现在直接在CompileOptions上支持此release标志，用于Java编译:\ncompileJava { options.release = 7 } 此选项优先于下面描述的属性。\nJava编译器的历史选项仍然可用：\nsourceCompatibility: 定义源文件应被视为哪种语言版本的Java。 targetCompatibility: 定义代码应该运行的最小JVM版本，即它决定编译器生成的字节代码的版本。 这些选项可以为每个JavaCompile任务设置，也可以在所有编译任务的java｛｝扩展上设置，使用具有相同名称的属性。\n然而，这些选项并不能防止使用在以后的Java版本中引入的API。\n处理资源文件 许多Java项目使用源文件以外的资源，如图像、配置文件和本地化数据。有时，这些文件打包时不变，有时需要作为模板文件或以其他方式处理。无论哪种方式，Java库插件都会为每个源集添加一个特定的复制任务，以处理其相关资源的处理。\n任务的名称遵循processSourceSetResources（或主源集的processResources）的约定，它将自动将src/[sourceSet]/resources中的任何文件复制到将包含在生产JAR中的目录中。该目标目录也将包含在测试的运行时类路径中。\n您可以通过WriteProperties任务轻松创建Java属性文件。每次都会生成一个唯一的文件，即使使用相同的属性和值，因为它在注释中包含时间戳。Gradle的WriteProperties任务在所有属性都未更改的情况下生成完全相同的输出字节。这是通过对属性文件的生成方式进行一些调整来实现的：\n没有时间戳注释添加到输出 行分隔符与系统无关，但可以显式配置（默认为“\\n”） 属性按字母顺序排序 构建JVM组件 所有特定的JVM插件都构建在Java插件之上。上面的示例仅说明了这个基本插件提供的概念，并与所有JVM插件共享。 继续阅读以了解哪些插件适合哪个项目类型，因为建议选择特定的插件，而不是直接应用Java插件。\n构建java库 库项目的独特之处在于它们被其他Java项目使用。这意味着与JAR文件一起发布的依赖元数据（通常以Maven POM的形式）至关重要。特别是，库的使用者应该能够区分两种不同类型的依赖关系：仅编译库所需的依赖关系和编译被消费者所需的依存关系。\nGradle通过Java Library插件管理这一区别，该插件除了本章介绍的实现之外，还引入了api配置。如果依赖项的类型出现在库的公共类的公共字段或方法中，则依赖项通过库的公共API公开，因此应添加到API配置中。否则，依赖项是一个内部实现细节，应该添加到implementation。\n构建java应用 打包为JAR的Java应用程序不适合从命令行或桌面环境轻松启动。application插件通过创建一个包含生产JAR、其依赖项和类似Unix和Windows系统的启动脚本来启动应用。\n构建java web应用 Java web应用程序可以以多种方式打包和部署，具体取决于您使用的技术。例如，您可以将Spring Boot与一个胖JAR或一个运行在Netty上的基于Reactive的系统一起使用。无论您使用什么技术，Gradle及其庞大的插件社区都将满足您的需求。然而，CoreGradle仅直接支持部署为WAR文件的传统基于Servlet的web应用程序。\n该支持通过War插件提供，该插件自动应用Java插件并添加额外的打包步骤，该步骤执行以下操作：\n将src/main/webapp中的静态资源复制到WAR的根目录中 将编译的生产类复制到WAR的WEB-INF/classes子目录中 将库依赖项复制到WAR的WEB-INF/lib子目录中 这是由war任务完成的，它有效地替换了jar任务（尽管该任务仍然存在），并附加到assemble生命周期任务。\n构建JAVA Platforms Java平台表示一组依赖性声明和约束，这些声明和约束形成了一个用于消费项目的内聚单元。该平台没有自己的来源和人工制品。它在Maven世界中映射到BOM。\n该支持通过Java平台插件提供，该插件设置了不同的配置和发布组件。\n","date":"1年1月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/1/01/gradle-java/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"},{"title":"gradle","url":"/myblog/tags/gradle/"}],"timestamp":-62135596800,"title":"Gradle-Java"},{"authors":[],"categories":[{"title":"技术","url":"/myblog/categories/%E6%8A%80%E6%9C%AF/"}],"content":"学习新技术，要抓住以下要点：\n技术出现的背景和要解决的问题 （2.5%）\n优势和劣势 ,对比已有实现 （5%）\n使用的场景，分业务场景和技术场景 （2.5%）\n组成部分和关键点 （80%）\n底层原理和关键实现 （10%）\njava 日志打印之前要检查日志级别 如下面的代码（不正确的）：\nLOGGER.info(\u0026#34;the DTO info: {}\u0026#34;, JSON.toJSONString(DTO)); DTO可能是一个大对象，JSON序列化要消耗服务器资源。此时，生产日志级别为warn，也就是说这行代码不会打印，但是却执行了json序列化。解决方案如下：\nif(LOGGER.isInfoEnabled()) { LOGGER.info(\u0026#34;the DTO info: {}\u0026#34;, JSON.toJSONString(DTO)); } 不必对所有的logger使用前都要判定日志级别，只对那些可能会损耗性能的开启即可。\nmysql IP地址的存储方式 通常，在保存IPv4地址时，一个IPv4最小需要7个字符，最大需要15个字符，所以，使用VARCHAR(15)即可。MySQL在保存变长的字符串时，还需要额外的一个字节来保存此字符串的长度。而如果使用无符号整数来存储，只需要4个字节即可。\nmysql\u0026gt; select inet_aton(\u0026#39;192.168.0.1\u0026#39;); +--------------------------+ | inet_aton(\u0026#39;192.168.0.1\u0026#39;) | +--------------------------+ | 3232235521 | +--------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select inet_ntoa(3232235521); +-----------------------+ | inet_ntoa(3232235521) | +-----------------------+ | 192.168.0.1 | +-----------------------+ 1 row in set (0.00 sec) public class IpLongUtils { /** * 把字符串IP转换成long * * @param ipStr 字符串IP * @return IP对应的long值 */ public static long ip2Long(String ipStr) { String[] ip = ipStr.split(\u0026#34;\\\\.\u0026#34;); return (Long.valueOf(ip[0]) \u0026lt;\u0026lt; 24) + (Long.valueOf(ip[1]) \u0026lt;\u0026lt; 16) + (Long.valueOf(ip[2]) \u0026lt;\u0026lt; 8) + Long.valueOf(ip[3]); } /** * 把IP的long值转换成字符串 * */ public static String long2Ip(long ipLong) { StringBuilder ip = new StringBuilder(); ip.append(ipLong \u0026gt;\u0026gt;\u0026gt; 24).append(\u0026#34;.\u0026#34;); ip.append((ipLong \u0026gt;\u0026gt;\u0026gt; 16) \u0026amp; 0xFF).append(\u0026#34;.\u0026#34;); ip.append((ipLong \u0026gt;\u0026gt;\u0026gt; 8) \u0026amp; 0xFF).append(\u0026#34;.\u0026#34;); ip.append(ipLong \u0026amp; 0xFF); return ip.toString(); } public static void main(String[] args) { System.out.println(ip2Long(\u0026#34;192.168.0.1\u0026#34;)); System.out.println(long2Ip(3232235521L)); System.out.println(ip2Long(\u0026#34;10.0.0.1\u0026#34;)); } } ","date":"1年1月1日","img":"","lang":"zh-hans","langName":"简体中文","largeImg":"","permalink":"/myblog/blog/1/01/%E7%9F%A5%E8%AF%86%E7%89%87%E6%AE%B5/","series":[],"smallImg":"","tags":[{"title":"java","url":"/myblog/tags/java/"}],"timestamp":-62135596800,"title":"知识片段"}]
