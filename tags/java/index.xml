<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>java on</title><link>https://banrenshan.github.io/tags/java/</link><description>Recent content in java on</description><generator>Hugo -- gohugo.io</generator><language>zh-hans</language><copyright/><lastBuildDate>Sat, 10 Dec 2022 13:56:12 +0000</lastBuildDate><atom:link href="https://banrenshan.github.io/tags/java/index.xml" rel="self" type="application/rss+xml"/><item><title>grafana</title><link>https://banrenshan.github.io/blog/2022/12/grafana/</link><pubDate>Sat, 10 Dec 2022 13:56:12 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/grafana/</guid><description><![CDATA[exemplars exemplar表示在给定时间间隔内的metrics对应的trace。虽然metrics擅长为您提供系统的聚合视图，但trace可以为您提供单个请求的细粒度视图；exemplar是将两者联系起来的一种方式。
假设您的公司网站正在经历流量激增。虽然超过80%的用户能够在两秒内访问网站，但一些用户的响应时间比正常时间长，导致用户体验不佳。要确定导致延迟的因素，必须将快速响应的trace与慢速响应的trace进行比较。考虑到典型生产环境中的大量数据，这将是一项极其费力和耗时的工作。
使用exemplars，查询在一段时间间隔内表现出高延迟的trace，帮助诊断数据分布中的问题。一旦将延迟问题定位为几个exemplars trace，就可以将其与其他基于系统的信息或位置属性相结合，以更快地执行根本原因分析，从而快速解决性能问题。
对exemplars的支持仅适用于Prometheus数据源。启用该功能后，默认情况下exemplars数据可用。具体配置参考 configuring exemplars in Prometheus data source
Grafana在Explore视图和仪表板中显示了exemplars以及metrics。每个exemplars为突出显示的星形。您可以将光标悬停在exemplars上查看更多，它是键值对的组合。要进一步调查，请单击traceID属性旁边的蓝色按钮。
配置 Grafana具有默认和自定义配置文件。您可以通过修改自定义配置文件或使用环境变量来自定义Grafana实例。Grafana实例的默认设置存储在$WORKING_DIR/conf/defaults.ini 文件。不要更改此文件。你可以使用 &ndash;config 参数指定自定义文件。
Grafana使用分号（；）注释.ini文件中的行。
变量替换 不要使用环境变量添加新的配置。相反，使用环境变量替代现有选项。
GF_&lt;SectionName&gt;_&lt;KeyName&gt; SectionName 和 KeyName要全大写 . 和 - 要替换成 _ # default section instance_name = ${HOSTNAME} [security] admin_user = admin [auth.google] client_secret = 0ldS3cretKey [plugin.grafana-image-renderer] rendering_ignore_https_errors = true [feature_toggles] enable = newNavigation export GF_DEFAULT_INSTANCE_NAME=my-instance export GF_SECURITY_ADMIN_USER=owner export GF_AUTH_GOOGLE_CLIENT_SECRET=newS3cretKey export GF_PLUGIN_GRAFANA_IMAGE_RENDERER_RENDERING_IGNORE_HTTPS_ERRORS=true export GF_FEATURE_TOGGLES_ENABLE=newNavigation 变量扩展 如果配置包含表达式$__&lt;provider&gt;{&lt;argument&gt;}或${&lt;environmentvariable&gt;}，则它们将由Grafana的变量扩展器处理。有三个提供程序：env、file和vault。
Env provider env提供程序可用于扩展环境变量。如果将选项设置为$__env｛PORT｝，则将在其位置使用PORT环境变量。对于环境变量，您还可以使用速记语法${PORT}。
[paths] logs = $__env{LOGDIR}/grafana File provider file从文件系统读取文件。它删除文件开头和结尾的空白。以下示例中的数据库密码将替换为/etc/secrets/gf_sql_password文件的内容：]]></description></item><item><title>gradle-basic</title><link>https://banrenshan.github.io/blog/2022/12/gradle-basic/</link><pubDate>Fri, 02 Dec 2022 16:43:59 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/gradle-basic/</guid><description>核心概念 1. Gradle 是一个通用的构建工具 Gradle 可以用于构建（build）任何软件，因为它对你要构建的东西或构建方式几乎不做任何假设。不过当前它最大的限制是，只支持兼容 Maven 和 lvy 的仓库和文件系统。
这并不意味着你需要为构建做许多工作。Gradle 可以通过插件（plugins）添加一层约定（convention）以及预构建功能（prebuild functionality）来让常见的项目类型，例如 Java 库，更容易被构建。你甚至能将自己的约定和构建功能封装成插件来发布。
2. 核心模型基于 task task 是 Gradle 的工作单元。Gradle 的构建模型就是一个 task 的定向无环图（Directed Acyclic Graphs, DAGs）。也就是说，构建本质上是在配置一个由 task 组成的定向无环图。task 之间根据它们的依赖关系相连。一旦 task 图被创建，Gradle 就能确定该以何种顺序执行 task。
这张图显示了两个 task 图的例子，一个是抽象的，一个是具体的，task 之间的依赖关系用箭头表示：
几乎所有的构建过程都可以通过这种方式建模为一个 task 图，这也是 Gradle 灵活的原因之一。而且这个 task 图可以由插件和你的构建脚本来定义，并通过 task 依赖机制将 task 连接起来。
一个 task 包括：
动作（Actions）——执行某些工作。例如复制文件或者编译源码。 输入（Inputs）——给动作使用或操作的值、文件和目录 输出（Outputs）——由动作修改或生成的文件和目录 以上内容都是可选的，使用与否取决于实际需要。一些 task，比如标准生命周期 task（standard lifecycle tasks），甚至没有任何动作。它们只是将多个任务聚合在一起，以方便使用。
你可以选择你需要的 task 来运行。为了节约时间，请选择刚好能满足需要的 task。如果想运行单元测试，就选择执行单元测试的 task——通常是 test。如果想打包一个应用，大多数构建都提供一个 assemble task 以供使用。</description></item><item><title>zero-copy</title><link>https://banrenshan.github.io/blog/2022/12/zero-copy/</link><pubDate>Fri, 02 Dec 2022 13:06:18 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/zero-copy/</guid><description>零拷贝 概述 零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。实现零拷贝用到的最主要技术是 DMA 数据传输技术和内存区域映射技术。
零拷贝机制可以减少数据在内核缓冲区和用户进程缓冲区之间反复的 I/O 拷贝操作。
零拷贝机制可以减少用户进程地址空间和内核地址空间之间因为上下文切换而带来的 CPU 开销。
物理内存和虚拟内存 进程之间是共享 CPU 和内存资源的，因此需要一套内存管理机制防止进程之间内存泄漏的问题。为了更加有效地管理内存并减少出错，现代操作系统提供了一种对主存的抽象概念，即是虚拟内存（Virtual Memory）。虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。
物理内存：物理内存（Physical memory）是相对于虚拟内存（Virtual Memory）而言的。物理内存指通过物理内存条而获得的内存空间，而虚拟内存则是指将硬盘的一块区域划分来作为内存。内存主要作用是在计算机运行时为操作系统和各种程序提供临时储存。
虚拟内存：是计算机系统内存管理的一种技术。 它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间）。而实际上，虚拟内存通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换，加载到物理内存中来。 目前，大多数操作系统都使用了虚拟内存，如 Windows 系统的虚拟内存、Linux 系统的交换空间等等。
虚拟内存地址和用户进程紧密相关，一般来说不同进程里的同一个虚拟地址指向的物理地址是不一样的，所以离开进程谈虚拟内存没有任何意义。每个进程所能使用的虚拟地址大小和 CPU 位数有关。在 32 位的系统上，虚拟地址空间大小是 2 ^ 32 = 4G，在 64位系统上，虚拟地址空间大小是 2 ^ 64 = 2 ^ 34G，而实际的物理内存可能远远小于虚拟内存的大小。每个用户进程维护了一个单独的页表（Page Table），虚拟内存和物理内存就是通过这个页表实现地址空间的映射的。下面给出两个进程 A、B 各自的虚拟内存空间以及对应的物理内存之间的地址映射示意图：
当进程执行一个程序时，需要先从内存中读取该进程的指令然后执行，获取指令时用到的就是虚拟地址。这个虚拟地址是程序链接时确定的（内核加载并初始化进程时会调整动态库的地址范围）。为了获取到实际的数据，CPU 需要将虚拟地址转换成物理地址，CPU 转换地址时需要用到进程的页表（Page Table），而页表（Page Table）里面的数据由操作系统维护。
其中页表（Page Table）可以简单的理解为单个内存映射（Memory Mapping）的链表（当然实际结构很复杂），里面的每个内存映射（Memory Mapping）都将一块虚拟地址映射到一个特定的地址空间（物理内存或者磁盘存储空间）。每个进程拥有自己的页表（Page Table），和其它进程的页表（Page Table）没有关系。
通过上面的介绍，我们可以简单的将用户进程申请并访问物理内存（或磁盘存储空间）的过程总结如下：
用户进程向操作系统发出内存申请请求
系统会检查进程的虚拟地址空间是否被用完，如果有剩余，给进程分配虚拟地址
系统为这块虚拟地址创建的内存映射（Memory Mapping），并将它放进该进程的页表（Page Table）</description></item><item><title>java-lock</title><link>https://banrenshan.github.io/blog/2022/12/java-lock/</link><pubDate>Fri, 02 Dec 2022 13:03:48 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/java-lock/</guid><description>Java锁 对象头 Java对象保存在内存中时，由以下三部分组成：对象头、实例数据、对齐填充字节。
java的对象头由以下三部分组成：Mark Word、指向类的指针、数组长度（只有数组对象才有）
Mark Word在不同的锁状态下存储的内容不同，在32位JVM中是这么存的：
Syschronized底层的原理 Monitor Monitor被翻译为监视器或管程
每个Java对象都可以关联一个Monitor对象,如果使用synchronized给对象上锁(重量级)之后【之前可能要先经过轻量级锁或者偏向锁】，该对象头的Mark Word中就被设置指向Monitor对象的指针。
Monitor的结果如下：
刚开始Monitor中Owner为null
当Thread-2执行synchronized(obj)就会将Monitor的所有者Owner置为Thread-2, Monitor中只能有一一个Owner
在Thread-2持有锁的过程中，如果Thread-3, Thread-4， Thread-5 也来执行synchronized(obj)， 就会进入EntryList BLOCKED
Thread-2执行完同步代码块的内容，然后唤醒EntryL ist中等待的线程来竞争锁，竞争的时是非公平的
图中WaitSet中的Thread-0，Thread-1 是之前获得过锁，但条件不满足进入WAITING状态的线程，后面讲wait-notify时会分析
注意:
synchronized必须是进入同一个对象的monitor才有上述的效果
不加synchronized的对象不会关联监视器， 不遵从以上规则
字节码层面的上理解 static final Object lock = new Object();
static int counter = 0;
public static void main(String[] args) {
synchronized (lock) {
​ counter++;
}
}
Code:
​ stack=2, locals=3, args_size=1
​ 0: getstatic #2 // 获取静态变量
​ 3: dup // 压入操作数栈顶</description></item><item><title>java-log</title><link>https://banrenshan.github.io/blog/2022/12/java-log/</link><pubDate>Fri, 02 Dec 2022 13:02:32 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/java-log/</guid><description><![CDATA[JAVA日志体系 日志门面 SLF4J(Simple Logging Facade for Java)是一套日志门面，或者说规范。其他的日志组件都是基于这个门面进行实际实现，比如 java.util.logging, logback 和 reload4j.
用户只需要在代码中使用SLF4J的API，而不需要关系具体的实现，是不是与JDBC很像。
快速入门 在类路径添加依赖：slf4j-api-xx.jar 编写下面示例代码： import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class HelloWorld { public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(&#34;Hello World&#34;); } } 运行此代码，控制台会打印以下警告信息：
SLF4J: Failed to load class &#34;org.slf4j.impl.StaticLoggerBinder&#34;. SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. 打印此警告是因为在类路径上找不到 slf4j 绑定实现。此时我们将 slf4j-simple-xxx.jar 添加到类路径，就会打印出下面的正常日志信息：
0 [main] INFO HelloWorld - Hello World 典型的使用方式 占位符]]></description></item><item><title>flyway</title><link>https://banrenshan.github.io/blog/2022/12/flyway/</link><pubDate>Fri, 02 Dec 2022 13:01:55 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/flyway/</guid><description><![CDATA[Flyway 工作原理 项目启动，应用程序完成数据库连接池的建立后，Flyway自动运行。 初次使用时，Flyway会创建一个flyway_schema_history表，用于记录sql执行记录。 Flyway会扫描项目指定路径下(默认是classpath:db/migration)的所有sql脚本，与flyway_schema_history表脚本记录进行比对。根据脚本的名称提取版本号来比对 如果脚本没有执行过，则执行脚本。如果脚本执行过，则比对文件是否发生变更，如果发生了变更，则抛出异常，终止迁移 在spring boot中使用 初始化一个SpringBoot项目，引入MySQL数据库驱动依赖等，并且需要引入Flyway依赖： &lt;dependency&gt; &lt;groupId&gt;org.flywaydb&lt;/groupId&gt; &lt;artifactId&gt;flyway-core&lt;/artifactId&gt; &lt;version&gt;6.1.0&lt;/version&gt; &lt;/dependency&gt; 添加Flyway配置： spring: # 数据库连接配置 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm-demo?characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8 username: xxx password: xxx flyway: # 是否启用flyway enabled: true # 编码格式，默认UTF-8 encoding: UTF-8 # 迁移sql脚本文件存放路径，默认db/migration locations: classpath:db/migration # 迁移sql脚本文件名称的前缀，默认V sql-migration-prefix: V # 迁移sql脚本文件名称的分隔符，默认2个下划线__.前面的用作版本号，后面的用作描述信息 sql-migration-separator: __ # 迁移sql脚本文件名称的后缀 sql-migration-suffixes: .sql # 迁移时是否进行校验，默认true validate-on-migrate: true # 当迁移发现数据库非空且存在没有元数据的表时，自动执行基准迁移，新建schema_version表 baseline-on-migrate: 根据在配置文件的脚本存放路径的配置，在resource目录下建立文件夹db/migration。 添加需要运行的sql脚本。sql脚本的命名规范为：V+版本号(版本号的数字间以”.“或”_“分隔开)+双下划线(用来分隔版本号和描述)+文件描述+后缀名，例如：V20201100__create_user.sql。如图所示： 启动项目。启动成功后，在数据库中可以看到已按照定义好的脚本，完成数据库变更，并在flyway_schema_history表插入了sql执行记录： 主要配置项 flyway.baseline-on-migrate： 当迁移时发现目标schema非空，而且带有没有元数据的表时，是否自动执行基准迁移（创建元数据表，然后执行sql脚本），默认false.
flyway.baseline-version开始执行基准迁移时对现有的schema的版本打标签，默认值为1.
flyway.validate-on-migrate迁移时是否校验，默认为true. 校验机制检查本地迁移是否仍与数据库中已执行的迁移具有相同的校验和。主要防止已迁移的本地文件发生了变动，数据库却没有更新这种变化。这是一种预警机制。
flyway.clean-on-validation-error当发现校验错误时是否自动调用clean，这是开发环境中的方便机制。默认false. 警告！ 不要在生产中启用！]]></description></item><item><title>spring-boot-deploy</title><link>https://banrenshan.github.io/blog/2022/12/spring-boot-deploy/</link><pubDate>Fri, 02 Dec 2022 13:00:20 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-boot-deploy/</guid><description><![CDATA[Spring Boot应用部署 传统服务器部署 除了使用 java -jar 命令运行程序之外，你还可以将jar包制作成可执行的，这样你只需要使用 ./xx.jar 的方式就可以启动程序。
完全可执行的 jar 文件通过在文件前面嵌入一个额外的脚本来工作。 包含 jar 的目录用作应用程序的工作目录。
可以通过构建工具制作完全可执行jar：
maven方式：
&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;executable&gt;true&lt;/executable&gt; &lt;/configuration&gt; &lt;/plugin&gt; gradle方式：
tasks.named(&#39;bootJar&#39;) { launchScript() } 安装成Systemd服务 我们可以将可执行jar与系统服务结合使用，例如systemd。
假设您在/var/myapp中安装了 Spring Boot 应用程序，要将 Spring Boot 应用程序安装为systemd服务，请创建一个名为myapp.service的脚本并将其放置在/etc/systemd/system目录中：
[Unit] Description=myapp After=syslog.target [Service] User=myapp ExecStart=/var/myapp/myapp.jar SuccessExitStatus=143 [Install] WantedBy=multi-user.target 请注意，与作为init.d服务运行时不同，运行应用程序的用户、PID 文件和控制台日志文件由systemd自身管理，因此必须使用“service”脚本中的适当字段进行配置。
自定启动脚本 有两种方式可以更改启动脚本，一种是在写入之前，另一种是在启动之前。
写入之前 所谓写入之前，即在脚本写入到jar包的时候。你可以使用maven插件的embeddedLaunchScriptProperties或 gradle的launchScript更改脚本的内容。
默认脚本支持以下属性替换：
参数 描述 Gradle default Maven default mode 脚本的模式 auto auto initInfoProvides 服务的名称 ${task.baseName} ${project.artifactId} initInfoRequiredStart 服务启动前依赖的其他服务 $remote_fs $syslog $network $remote_fs $syslog $network initInfoRequiredStop 服务关闭前的，需要关闭的其他的服务 $remote_fs $syslog $network $remote_fs $syslog $network initInfoDefaultStart 服务的启动级别 2 3 4 5 2 3 4 5 initInfoDefaultStop 服务的关闭级别 0 1 6 0 1 6 initInfoShortDescription 服务的简短描述 Single-line version of ${project.]]></description></item><item><title>spring-boot-starter-actuator</title><link>https://banrenshan.github.io/blog/2022/12/spring-boot-starter-actuator/</link><pubDate>Fri, 02 Dec 2022 12:59:36 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-boot-starter-actuator/</guid><description>Spring Boot性能监控 Spring Boot 包含许多附加功能，可帮助您在将应用程序推送到生产环境时对其进行监控和管理。 您可以选择使用 HTTP 端点或 JMX 来管理和监视您的应用程序。 审计、健康和指标收集也可以自动应用于您的应用程序。
这些功能是通过 spring-boot-actuator 模块实现的，你只需要在类路径添加spring-boot-starter-actuator 依赖即可。
dependencies { implementation &amp;#39;org.springframework.boot:spring-boot-starter-actuator&amp;#39; } 端点 执行器端点使您可以监视应用程序并与之交互。Spring Boot 包含许多内置端点，并允许您添加自己的端点。例如，health端点提供基本的应用程序健康信息。
您可以启用或禁用每个单独的端点并通过 HTTP 或 JMX 公开它们（使它们可以远程访问）。当端点被启用和公开时，它被认为是可用的。内置端点仅在可用时才会自动配置。大多数应用程序选择通过 HTTP 公开，其中端点的 ID 和前缀/actuator映射到 URL。例如，默认情况下，health端点映射到/actuator/health.
以下与技术无关的端点：
ID 描述 auditevents 公开当前应用程序的审计事件信息。需要一个AuditEventRepository bean。 beans 显示应用程序中所有 Spring bean 的完整列表。 caches 公开可用的缓存。 conditions 显示在配置和自动配置类上评估的条件以及它们匹配或不匹配的原因。 configprops 显示所有@ConfigurationProperties. env 公开 Spring 的ConfigurableEnvironment. flyway 显示已应用的任何 Flyway 数据库迁移。需要一个或多个Flyway bean。 health 显示应用程序运行状况信息。 httptrace 显示 HTTP 跟踪信息（默认情况下，最近 100 个 HTTP 请求-响应交换）。需要一个HttpTraceRepository bean。 info 显示任意应用程序信息。 integrationgraph 显示 Spring 集成图。需要依赖spring-integration-core.</description></item><item><title>spring-mvc</title><link>https://banrenshan.github.io/blog/2022/12/spring-mvc/</link><pubDate>Fri, 02 Dec 2022 12:56:09 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-mvc/</guid><description><![CDATA[spring mvc官方文档 DispatcherServlet 与其他许多Web框架一样，Spring MVC围绕前端控制器模式进行设计，在该模式下，中央Servlet DispatcherServlet提供了用于请求处理的共享算法，而实际工作是由可配置的委托组件执行的。 该模型非常灵活，并支持多种工作流程。
与任何Servlet一样，都需要使用Java配置或在web.xml中根据Servlet规范声明和映射DispatcherServlet。 反过来，DispatcherServlet使用Spring配置发现请求映射，视图解析，异常处理等所需的委托组件。
以下Java配置示例注册并初始化DispatcherServlet，该容器由Servlet容器自动检测到（请参阅Servlet Config）：
public class MyWebApplicationInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext servletContext) { // 加载 Spring web application configuration AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); context.register(AppConfig.class); // 创建并注册DispatcherServlet DispatcherServlet servlet = new DispatcherServlet(context); ServletRegistration.Dynamic registration = servletContext.addServlet(&#34;app&#34;, servlet); registration.setLoadOnStartup(1); registration.addMapping(&#34;/app/*&#34;); } } 除了使用 ServletContext API，你也可以继承AbstractAnnotationConfigDispatcherServletInitializer，覆盖指定的方法来配置DispatcherServlet,参考Conetxt层级关系中的例子
Context的层级关系 DispatcherServlet需要配置WebApplicationContext（纯ApplicationContext的扩展）为自身属性。 WebApplicationContext具有指向ServletContext和与其关联的Servlet的链接。它还绑定到ServletContext，以便应用程序可以在RequestContextUtils上使用静态方法来查找WebApplicationContext（如果需要访问它们）。
对于许多应用程序来说，拥有一个WebApplicationContext很简单并且足够。也可能具有上下文层次结构，其中一个根WebApplicationContext在多个DispatcherServlet（或其他Servlet）实例之间共享，每个实例都有其自己的子WebApplicationContext配置。有关上下文层次结构功能的更多信息，请参见ApplicationContext的其他功能。
根WebApplicationContext通常包含基础结构bean，例如需要在多个Servlet实例之间共享的数据存储库和业务服务。这些Bean是有效继承的，并且可以在Servlet特定的子WebApplicationContext中重写（即重新声明），该子WebApplicationContext通常包含给定Servlet本地的Bean。下图显示了这种关系：
下面的例子配置WebApplicationContext
public class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class&lt;?]]></description></item><item><title>Resilience4j</title><link>https://banrenshan.github.io/blog/2022/12/resilience4j/</link><pubDate>Fri, 02 Dec 2022 12:54:32 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/resilience4j/</guid><description><![CDATA[简介 Resilience4j一个轻量级（只依赖Vavr第三方库）的，易于使用的容错框架，灵感来源于Netflix Hystrix，依托于java8的函数式编程。
Resilience4j提供了断路器、限速、重试、Bulkhead等功能。你可以任意选择和搭配这些功能。
Bulkhead(隔板模式)是一种容错的应用程序设计。 在隔板架构中，应用程序的元素被隔离到池中，因此，如果其中一个失败，则其他元素将继续运行。 它是根据船体的分段隔板（凸头）来命名的。 如果船体受损，则只有损坏的部分会充满水，从而防止船下沉。
以下示例显示了如何使用CircuitBreaker和Retry装饰lambda表达式，以便在发生异常时最多重试3次。
// 创建默认的断路器 CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults(&#34;backendService&#34;); // 创建默认的重试器，重拾3次，间隔为500ms Retry retry = Retry.ofDefaults(&#34;backendService&#34;); // 创建默认的隔离器 Bulkhead bulkhead = Bulkhead.ofDefaults(&#34;backendService&#34;); //具体的业务调用 Supplier&lt;String&gt; supplier = () -&gt; backendService.doSomething(param1, param2) // 使用装扮器装扮函数 Supplier&lt;String&gt; decoratedSupplier = Decorators.ofSupplier(supplier) .withCircuitBreaker(circuitBreaker) .withBulkhead(bulkhead) .withRetry(retry) .decorate(); // 执行函数，并设置后退函数 String result = Try.ofSupplier(decoratedSupplier) .recover(throwable -&gt; &#34;Hello from Recovery&#34;).get(); // 不使用装扮器，直接使用断路器调用函数 String result = circuitBreaker .executeSupplier(backendService::doSomething); // 使用ThreadPoolBulkhead在另外的线程中异步运行 ThreadPoolBulkhead threadPoolBulkhead = ThreadPoolBulkhead.ofDefaults(&#34;backendService&#34;); // 设定超时机制，超时需要Scheduler来调度 ScheduledExecutorService scheduledExecutorService = Executors.]]></description></item><item><title>spring-cloud-Circuit-breaker</title><link>https://banrenshan.github.io/blog/2022/12/spring-cloud-circuit-breaker/</link><pubDate>Fri, 02 Dec 2022 12:54:03 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-cloud-circuit-breaker/</guid><description><![CDATA[Spring Cloud Circuit breaker 提供了跨不同断路器实现的抽象。 它提供了在您的应用程序中使用的一致 API，让您（开发人员）可以选择最适合您的应用程序需求的断路器实现。
可用的实现如下：
Resilience4J Sentinel Spring Retry 快速入门 在API中使用CircuitBreakerFactory 类创建CircuitBreaker断路器。当你添加实现了断路器的依赖时，会自动创建CircuitBreakerFactory bean，下面代码是使用例子：
@Service public static class DemoControllerService { private RestTemplate rest; private CircuitBreakerFactory cbFactory; public DemoControllerService(RestTemplate rest, CircuitBreakerFactory cbFactory) { this.rest = rest; this.cbFactory = cbFactory; } public String slow() { return cbFactory.create(&#34;slow&#34;).run( //断路器的名称 () -&gt; rest.getForObject(&#34;/slow&#34;, String.class), //业务方法 throwable -&gt; &#34;fallback&#34; //后备方法 ); } } 如果reactor在你的classpath下，你可以使用ReactiveCircuitBreakerFactory 来处理响应式代码：
@Service public static class DemoControllerService { private ReactiveCircuitBreakerFactory cbFactory; private WebClient webClient; public DemoControllerService(WebClient webClient, ReactiveCircuitBreakerFactory cbFactory) { this.]]></description></item><item><title>spring-cloud-loadBalancer</title><link>https://banrenshan.github.io/blog/2022/12/spring-cloud-loadbalancer/</link><pubDate>Fri, 02 Dec 2022 12:53:28 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-cloud-loadbalancer/</guid><description>Spring Cloud 提供了自己的客户端负载均衡器抽象和实现。 对于负载均衡机制，添加了 ReactiveLoadBalancer 接口，从响应式的ServiceInstanceListSupplier 中选择实例，并为其提供了基于 Round 和 Random 的实现。 目前，我们支持基于服务发现的ServiceInstanceListSupplier，该实现使用类路径中可用的发现发现客户端检索可用实例。
如何切换负载均衡算法 默认使用的 ReactiveLoadBalancer 实现是 RoundRobinLoadBalancer。 要为选定的服务或所有服务切换到不同的实现，您可以使用自定义 LoadBalancer 配置机制。
例如，可以通过@LoadBalancerClient的configuration 属性配置RandomLoadBalancer：
public class CustomLoadBalancerConfiguration { //注意不要添加 @Configuration @Bean ReactorLoadBalancer&amp;lt;ServiceInstance&amp;gt; randomLoadBalancer(Environment environment, LoadBalancerClientFactory loadBalancerClientFactory) { String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME); return new RandomLoadBalancer(loadBalancerClientFactory .getLazyProvider(name, ServiceInstanceListSupplier.class), name); } } 如何集成负载均衡客户端 为了方便使用 Spring Cloud LoadBalancer，我们提供了可与 WebClient 一起使用的 ReactorLoadBalancerExchangeFilterFunction 和与 RestTemplate 一起使用的 BlockingLoadBalancerClient。 您可以在以下部分中查看更多信息和用法示例：
RestTemplate @Configuration public class MyConfiguration { @LoadBalanced @Bean RestTemplate restTemplate() { return new RestTemplate(); } } public class MyClass { @Autowired private RestTemplate restTemplate; public String doOtherStuff() { String results = restTemplate.</description></item><item><title>spring-cloud-discovery</title><link>https://banrenshan.github.io/blog/2022/12/spring-cloud-discovery/</link><pubDate>Fri, 02 Dec 2022 12:53:04 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-cloud-discovery/</guid><description>@EnableDiscoveryClient Spring Cloud Commons 提供了 @EnableDiscoveryClient 注解。 这会在META-INF/spring.factories（org.springframework.cloud.client.discovery.EnableDiscoveryClient是key，value是具体的实现） 文件中搜索 DiscoveryClient 和 ReactiveDiscoveryClient 接口的实现。 DiscoveryClient 实现的示例包括 Spring Cloud Netflix Eureka、Spring Cloud Consul Discovery 和 Spring Cloud Zookeeper Discovery。
默认情况下，Spring Cloud 将提供阻塞和反应式服务发现客户端。 您可以通过设置 spring.cloud.discovery.blocking.enabled=false 或 spring.cloud.discovery.reactive.enabled=false 轻松禁用阻塞和/或反应客户端。 要完全禁用服务发现，您只需设置 spring.cloud.discovery.enabled=false。
默认情况下， DiscoveryClient 的实现会自动向远程发现服务器注册本地 Spring Boot 应用。 可以通过在 @EnableDiscoveryClient 中设置 autoRegister=false 来禁用此行为。
@EnableDiscoveryClient不需要显示声明。 只需要在类路径上放置一个 DiscoveryClient 实现。
健康检查 spring.cloud.discovery.client.health-indicator.enabled=false.禁用健康检查 要禁用描述字段，请设置 spring.cloud.discovery.client.health-indicator.include-description=false。 否则，它可能会冒泡作为汇总的 HealthIndicator 的描述。 要禁用服务检索，请设置 spring.cloud.discovery.client.health-indicator.use-services-query=false。 默认情况下，指标调用客户端的 getServices 方法。 在具有许多注册服务的部署中，在每次检查期间检索所有服务的成本可能太高。 这将跳过服务检索，而是使用客户端的探测方法。 DiscoveryCompositeHealthContributor复合健康指标基于所有已注册的 DiscoveryHealthIndicator bean。 要禁用，请设置 spring.</description></item><item><title>nginx</title><link>https://banrenshan.github.io/blog/2022/12/nginx/</link><pubDate>Fri, 02 Dec 2022 12:51:30 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/nginx/</guid><description>访问日志解码请求参数 打印post请求的请求体信息 默认的日志打印不包含请求体的内容,如果要打印改值,只需要在log_format中添加$request_body 即可,更多日志打印变量参考官方文档
另外,即使打印出来请求体,内容不支持中文,都是经过url编码后的字符串.
添加或启动新模块 nginx不支持动态安装、加载模块的，所以当你安装第三方模块或者启动nginx本身的新模块功能的时候，都是覆盖nginx的；所以，一定要注意：首先查看你已经安装的nginx模块！然后安装新东西的时候，要把已安装的，再次配置。
1.查看ngnix已经安装的模块./nginx -V
2.执行configure和make
./configure --prefix=/usr/local/nginx \ --with-http_stub_status_module \ --with-http_ssl_module --with-http_realip_module \ --with-http_image_filter_module \ --add-module=../ngx_pagespeed-master make 3.替换nginx二进制文件
cp /root/nginx-1.8.1/objs/nginx /usr/local/nginx/sbin/nginx X-Forwarded-For 和 X-Real-IP X-Forwarded-For:被代理服务器使用,用来记录经过的代理服务信息. X-Real-IP:被代理服务器使用,用来记录客户端的真实IP地址.
举例: 现在有ngnix代理服务器A和B,请求先请过A[10.187.144.41],然后B[10.187.112.151],最后到达服务器[10.176.175.149]处理该请求.
A的ngnix配置
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; B的ngnix配置
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 服务器的响应
x-forwarded-for:114.141.166.125, 10.187.144.41 host:10.176.175.149:8080 connection:close x-real-ip:114.141.166.125 getRemoteAddr:10.187.112.151 getRemoteHost:10.187.112.151 getServerName:10.176.175.149 变动1:如果B的配置也加上proxy_set_header X-Real-IP $remote_addr呢,服务器收到的请求头信息会是神马呢?
x-real-ip:10.187.144.41 x-forwarded-for:114.141.166.125, 10.187.144.41 host:10.176.175.149:8080 getRemoteAddr:10.187.112.151 getRemoteHost:10.187.112.151 getServerName:10.176.175.149 需要注意的是x-forwarded-for并没有把最后一个代理添加上去
我们看到x-real-ip的地址发生改变,不再是真实的客户端ip,而是代理A的ip,说明此时的$remote_addr的值是代理A的IP,如何修改这个值为真实的IP呢? 可以使用ngx_http_realip_module模块
ngx_http_realip_module模块 安装请参考模块安装,A配置不变,B配置如下:
set_real_ip_from 10.187.144.41 real_ip_header X-Real-IP ; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Real-IP $remote_addr; set_real_ip_from:指定真实IP的地址是在哪个代理机器上 real_ip_header:真实IP所在的请求头字段</description></item><item><title>spring-security</title><link>https://banrenshan.github.io/blog/2022/12/spring-security/</link><pubDate>Fri, 02 Dec 2022 12:50:01 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-security/</guid><description><![CDATA[快速入门 第一步：依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; 第二步：编写测试controller @RestController @RequestMapping(&#34;/hello&#34;) public class HelloController { @GetMapping public String hello() { return &#34;hello&#34;; } } 第三步启动并测试 浏览器中输入： http://localhost:8080/hello 浏览器会呈现登录页，如下： 用户名是 user ，密码在启动的控制台中打印。
至此，一个安全的web应用就产生了。接下来，我们来看一下spring默认的配置。
spring boot 自动配置 启用 Spring Security 的默认配置，它创建一个 servlet 过滤器（名为 springSecurityFilterChain 的 bean）。 此 bean 负责应用程序中的所有安全性（保护应用程序 URL、验证提交的用户名和密码、重定向到登录表单等）。 使用用户名 user 和随机生成的密码创建一个 UserDetailsService bean，该密码登录到控制台。 使用名为 springSecurityFilterChain 的 bean 向 Servlet 容器注册过滤器。 Spring Boot 配置的并不多，但是却做了很多。 功能摘要如下：
需要经过身份验证的用户才能与应用程序进行任何交互
为您生成默认登录表单
让用户名 user 和登录到控制台的密码的用户使用基于表单的身份验证进行身份验证]]></description></item><item><title>CompletableFuture</title><link>https://banrenshan.github.io/blog/2022/12/completablefuture/</link><pubDate>Fri, 02 Dec 2022 12:48:41 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/completablefuture/</guid><description></description></item><item><title>Guava</title><link>https://banrenshan.github.io/blog/2022/12/guava/</link><pubDate>Fri, 02 Dec 2022 12:48:14 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/guava/</guid><description><![CDATA[集合 List操作 // 创建ArrayList ArrayList&lt;String&gt; arrayList1 = Lists.newArrayList(); ArrayList&lt;String&gt; arrayList2 = Lists.newArrayList(&#34;1&#34;, &#34;2&#34;, &#34;3&#34;); ArrayList&lt;String&gt; arrayList3 = Lists.newArrayList(arrayList1); ArrayList&lt;String&gt; arrayList4 = Lists.newArrayListWithCapacity(10); //创建LinkedList LinkedList&lt;Object&gt; linkedList1 = Lists.newLinkedList(); LinkedList&lt;String&gt; linkedList2 = Lists.newLinkedList(arrayList1); //创建CopyOnWriteArrayList CopyOnWriteArrayList&lt;Object&gt; copyOnWriteArrayList1 = Lists.newCopyOnWriteArrayList(); CopyOnWriteArrayList&lt;String&gt; copyOnWriteArrayList2 = Lists.newCopyOnWriteArrayList(arrayList1); //反转list List&lt;String&gt; reverse = Lists.reverse(arrayList2); System.err.println(reverse); //[3, 2, 1] //切分list List&lt;List&lt;String&gt;&gt; partition = Lists.partition(arrayList2, 2); System.err.println(partition); //[[1, 2], [3]] //笛卡尔集 List&lt;List&lt;String&gt;&gt; lists = Lists.cartesianProduct(Lists.newArrayList(&#34;A&#34;, &#34;B&#34;), arrayList2); System.err.println(lists);//[[A, 1], [A, 2], [A, 3], [B, 1], [B, 2], [B, 3]] //转化集合元素 List&lt;String&gt; transform = Lists.]]></description></item><item><title>reactor</title><link>https://banrenshan.github.io/blog/2022/12/reactor/</link><pubDate>Fri, 02 Dec 2022 12:47:03 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/reactor/</guid><description><![CDATA[响应式编程是观察者设计模式的扩展 对比迭代器模式，一个重要区别是，迭代器基于拉模式，reactive streams基于推模式 使用迭代器是一种命令式编程，即必须通过Iterable访问值，这就需要开发者手动next()访问值。reactive streams采用的是Publisher-Subscriber：发布者在新的可用值到来时通知订阅者，这种基于推的模式是响应式编程的核心。此外，应用于推送值的操作是以声明的方式而不是命令的方式表达的，程序员表达计算的逻辑而不是描述其确切的控制流程。
发布者可以向其订阅者推送新值（通过调用 onNext），但也可以发出错误（通过调用 onError）或完成（通过调用 onComplete信号。 错误和完成信号都会终止序列。 这可以总结如下：
onNext x 0..N [onError | onComplete] reactor实现了两种Publisher：
Flux: 0..N个item的响应式序列 Mono: 0..1个item的响应式序列 这两种类型更多的是语义上的区别。例如，一个http请求仅产生一个响应，这时候使用Mono比 Flux更好，毕竟前者表示了0或1的意思。两者之间也可以相互转化，例如count操作符，Flux执行count返回 Mono
下面是Flux的基本弹珠图：
所有的事件，甚至终止事件，都是可选的：
没有onNext事件，只有OnComplete事件，表示一个空序列。 没有任何事件，表示一个空的无限序列。 同样，无限序列不一定为空。 例如，Flux.interval（Duration）产生Flux ，它是无限的并从时钟发出规则的滴答声。 Mono是一个特殊的Publisher，它通过onNext信号最多发出一项，然后以onComplete信号（成功的Mono）终止，或仅发出一个onError信号（失败的Mono）。
订阅 subscribe(); //订阅并触发序列 subscribe(Consumer&lt;? super T&gt; consumer); //对每个产生的价值做一些事情。 subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer); //处理值的同时也要对错误做出反应。 subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer, Runnable completeConsumer); //处理值和错误，但也会在序列成功完成时运行一些代码。 subscribe(Consumer&lt;? super T&gt; consumer, Consumer&lt;? super Throwable&gt; errorConsumer, Runnable completeConsumer, Consumer&lt;?]]></description></item><item><title>oauth2</title><link>https://banrenshan.github.io/blog/2022/12/oauth2/</link><pubDate>Fri, 02 Dec 2022 12:45:48 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/oauth2/</guid><description><![CDATA[为了理解OAuth的适用场合，让我举一个假设的例子。
有一个&quot;云冲印&quot;的网站，可以将用户储存在Google的照片，冲印出来。用户为了使用该服务，必须让&quot;云冲印&quot;读取自己储存在Google上的照片。
问题是只有得到用户的授权，Google才会同意&quot;云冲印&quot;读取这些照片。那么，&ldquo;云冲印&quot;怎样获得用户的授权呢？
传统方法是，用户将自己的Google用户名和密码，告诉&quot;云冲印&rdquo;，后者就可以读取用户的照片了。这样的做法有以下几个严重的缺点:
&ldquo;云冲印&quot;为了后续的服务，会保存用户的密码，这样很不安全。 &ldquo;云冲印&quot;拥有了获取用户储存在Google所有资料的权力，用户没法限制&quot;云冲印&quot;获得授权的范围和有效期。 用户只有修改密码，才能收回赋予&quot;云冲印&quot;的权力。但是这样做，会使得其他所有获得用户授权的第三方应用程序全部失效。 只要有一个第三方应用程序被破解，就会导致用户密码泄漏，以及所有被密码保护的数据泄漏。 OAuth就是为了解决上面这些问题而诞生的。
名词定义 在详细讲解OAuth 2.0之前，需要了解几个专用名词。
Third-party application：第三方应用程序，本文中又称&quot;客户端&rdquo;（client），即上门面的&quot;云冲印&rdquo;。 HTTP service：HTTP服务提供商（Provider），本文中简称&quot;服务提供商&quot;，即上一节例子中的Google。 Resource Owner：资源所有者，本文中又称&quot;用户&quot;（user）。 User Agent：用户代理，本文中就是指浏览器。 Authorization server：认证服务器，即服务提供商专门用来处理认证的服务器。 Resource server：资源服务器，即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。 OAuth的作用就是让&quot;客户端&quot;安全可控地获取&quot;用户&quot;的授权，与&quot;服务商提供商&quot;进行互动。
OAuth在&quot;客户端&quot;与&quot;服务提供商&quot;之间，设置了一个授权层（authorization layer）。&ldquo;客户端&quot;不能直接登录&quot;服务提供商&rdquo;，只能登录授权层，以此将用户与客户端区分开来。&ldquo;客户端&quot;登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。
&ldquo;客户端&quot;登录授权层以后，&ldquo;服务提供商&quot;根据令牌的权限范围和有效期，向&quot;客户端&quot;开放用户储存的资料。
运行流程 OAuth 2.0的运行流程如下图，摘自RFC 6749。
（A）用户打开客户端以后，客户端要求用户给予授权。
（B）用户同意给予客户端授权。
（C）客户端使用上一步获得的授权，向认证服务器申请令牌。
（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。
（E）客户端使用令牌，向资源服务器申请获取资源。
（F）资源服务器确认令牌无误，同意向客户端开放资源。
不难看出来，上面六个步骤之中，B是关键，即用户怎样才能给于客户端授权。有了这个授权以后，客户端就可以获取令牌，进而凭令牌获取资源。下面一一讲解客户端获取授权的四种模式。
授权模式 客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0定义了四种授权方式。
授权码模式（authorization code） 简化模式（implicit） 密码模式（resource owner password credentials） 客户端模式（client credentials） 授权码模式 授权码模式（authorization code）是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与&quot;服务提供商&quot;的认证服务器进行互动。
（A）用户访问客户端，后者将用户重定向认证服务器。
（B）用户选择是否给予客户端授权。
（C）假设用户给予授权，认证服务器将用户导向客户端事先指定的&quot;重定向URI&rdquo;（redirection URI），同时附上一个授权码。
（D）客户端收到授权码，附上早先的&quot;重定向URI&rdquo;，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。
（E）认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和刷新令牌（refresh token）。
A步骤中，客户端申请认证的URI，包含以下参数：
response_type：表示授权类型，必选项，此处的值固定为&quot;code&rdquo; client_id：表示客户端的ID，必选项 redirect_uri：表示重定向URI，可选项 scope：表示申请的权限范围，可选项 state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。 GET /authorize?]]></description></item><item><title>json-web-token</title><link>https://banrenshan.github.io/blog/2022/12/json-web-token/</link><pubDate>Fri, 02 Dec 2022 12:45:09 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/json-web-token/</guid><description><![CDATA[跨域认证的问题 互联网服务离不开用户认证。一般流程是下面这样:
1、用户向服务器发送用户名和密码。
2、服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。
3、服务器向用户返回一个 session_id，写入用户的 Cookie。
4、用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。
5、服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。
JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样:
{ &#34;姓名&#34;: &#34;张三&#34;, &#34;角色&#34;: &#34;管理员&#34;, &#34;到期时间&#34;: &#34;2018年7月1日0点0分&#34; } 以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名（详见后文）。服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。
客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。
此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面( Authorization: Bearer &lt;token&gt; )。
JWT特点：
（1）JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。
（2）JWT 不加密的情况下，不能将隐秘数据写入 JWT。
（3）JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。
（4）JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。
（5）JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。
（6）为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。]]></description></item><item><title>spring-security-oauth2</title><link>https://banrenshan.github.io/blog/2022/12/spring-security-oauth2/</link><pubDate>Fri, 02 Dec 2022 12:43:31 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-security-oauth2/</guid><description>OAuth2的配置属性 Spring Boot 2.x ClientRegistration spring.security.oauth2.client.registration.[registrationId] registrationId spring.security.oauth2.client.registration.[registrationId].client-id clientId spring.security.oauth2.client.registration.[registrationId].client-secret clientSecret spring.security.oauth2.client.registration.[registrationId].client-authentication-method clientAuthenticationMethod spring.security.oauth2.client.registration.[registrationId].authorization-grant-type authorizationGrantType spring.security.oauth2.client.registration.[registrationId].redirect-uri redirectUri spring.security.oauth2.client.registration.[registrationId].scope scopes spring.security.oauth2.client.registration.[registrationId].client-name clientName spring.security.oauth2.client.provider.[providerId].authorization-uri providerDetails.authorizationUri spring.security.oauth2.client.provider.[providerId].token-uri providerDetails.tokenUri spring.security.oauth2.client.provider.[providerId].jwk-set-uri providerDetails.jwkSetUri spring.security.oauth2.client.provider.[providerId].issuer-uri providerDetails.issuerUri spring.security.oauth2.client.provider.[providerId].user-info-uri providerDetails.userInfoEndpoint.uri spring.security.oauth2.client.provider.[providerId].user-info-authentication-method providerDetails.userInfoEndpoint.authenticationMethod spring.security.oauth2.client.provider.[providerId].user-name-attribute providerDetails.userInfoEndpoint.userNameAttributeName 配置举例：
spring: security: oauth2: client: registration: okta: client-id: okta-client-id client-secret: okta-client-secret provider: okta: authorization-uri: https://your-subdomain.oktapreview.com/oauth2/v1/authorize token-uri: https://your-subdomain.oktapreview.com/oauth2/v1/token user-info-uri: https://your-subdomain.oktapreview.com/oauth2/v1/userinfo user-name-attribute: sub jwk-set-uri: https://your-subdomain.oktapreview.com/oauth2/v1/keys OAuth2ClientAutoConfiguration 类主要做了下面的工作：
注册 ClientRegistrationRepository@Bean，该Bean由配置的OAuth客户端属性中的ClientRegistry组成。 注册 SecurityFilterChain@Bean，并通过httpSecurity.oauth2Login()启用OAuth 2.0登录。 如果你想覆盖自动配置可以通过下面的方式：
注册 ClientRegistrationRepository bean 注册 SecurityFilterChain bean 完全覆盖自动注册类 注册 ClientRegistrationRepository bean @Configuration public class OAuth2LoginConfig { @Bean public ClientRegistrationRepository clientRegistrationRepository() { return new InMemoryClientRegistrationRepository(this.</description></item><item><title>spring-boot-how-to</title><link>https://banrenshan.github.io/blog/2022/12/spring-boot-how-to/</link><pubDate>Fri, 02 Dec 2022 12:42:53 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-boot-how-to/</guid><description><![CDATA[构建时替换属性 您可以使用构建工具中设定的属性来替换应用属性，而不是对项目的生成配置中指定的某些属性进行硬编码。这在Maven和Gradle都是可能的。
maven 您可以通过使用资源过滤从Maven项目自动展开属性。如果使用spring-boot-starter-parent，则可以使用@..@占位符引用Maven的“project properties，如下例所示：
app.encoding=@project.build.sourceEncoding@ app.java.version=@java.version@ 如果启用addResources标志，springboot:run目标可以将src/main/resources直接添加到类路径（用于热重新加载）。这样做可以避免资源筛选和此功能。相反，您可以使用exec:java目标或自定义插件的配置。有关详细信息，请参见插件使用页面。????
如果不使用starter父级，则需要在pom.xml的＜build/＞元素中包含以下元素：
&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; 您还需要在＜plugins/＞中包含以下元素：
&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;delimiter&gt;@&lt;/delimiter&gt; &lt;/delimiters&gt; &lt;useDefaultDelimiters&gt;false&lt;/useDefaultDelimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; Gradle 您可以通过配置Java插件的processResources任务来自动扩展Gradle项目中的属性，如下例所示：
tasks.named(&#39;processResources&#39;) { expand(project.properties) } 然后，可以使用占位符引用Gradle项目的属性，如以下示例所示：
app.name=${name} app.description=${description} Gradle的expand方法使用Groovy的SimpleTemplateEngine，它转换${..}标记。${..}样式与Spring自己的属性占位符机制冲突。要将Spring属性占位符与自动扩展一起使用，请按如下方式转义Spring属性占位符：${..}。
生成build信息 Maven插件和Gradle插件都允许生成包含项目坐标、名称和版本的构建信息。插件还可以通过配置文件添加附加属性。当存在这样的文件时，Spring Boot会自动配置BuildProperties bean。
要使用Maven生成构建信息，请为执行添加build-info 目标，如下例所示：
&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.7.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;build-info&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 以下示例对Gradle执行相同操作：
springBoot { buildInfo() } 生成git信息 Maven和Gradle都允许生成git.properties文件，其中包含有关项目生成时git源代码存储库状态的信息。
对于Maven用户，spring-boot-starter-parent POM包括一个预配置的插件，用于生成 git.properties 文件。要使用它，请将以下声明添加到POM中：]]></description></item><item><title>spring-boot-core</title><link>https://banrenshan.github.io/blog/2022/12/spring-boot-core/</link><pubDate>Fri, 02 Dec 2022 12:42:06 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-boot-core/</guid><description><![CDATA[SpringApplication SpringApplication类提供了一种从main方法启动的Spring应用程序方法。在许多情况下，您可以委托给静态的SpringApplication.run方法，如下例所示：
@SpringBootApplication public class MyApplication { public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } 当应用程序启动时，您应该会看到类似于以下输出的内容：
. ____ _ __ _ _ /\\ / ___&#39;_ __ _ _(_)_ __ __ _ \ \ \ \ ( ( )\___ | &#39;_ | &#39;_| | &#39;_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#39; |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.]]></description></item><item><title>jackson</title><link>https://banrenshan.github.io/blog/2022/12/jackson/</link><pubDate>Fri, 02 Dec 2022 12:41:07 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/jackson/</guid><description><![CDATA[ObjectMapper 基本使用 public class Car { private String color; private String type; // standard getters setters } 序列化:
ObjectMapper objectMapper = new ObjectMapper(); Car car = new Car(&#34;yellow&#34;, &#34;renault&#34;); objectMapper.writeValue(new File(&#34;target/car.json&#34;), car); {&#34;color&#34;:&#34;yellow&#34;,&#34;type&#34;:&#34;renault&#34;} ObjectMapper类的writeValueAsString和writeValueAsBytes方法从Java对象生成JSON，并将生成的JSON作为字符串或字节数组返回：
String carAsString = objectMapper.writeValueAsString(car); 反序列化：
String json = &#34;{ \&#34;color\&#34; : \&#34;Black\&#34;, \&#34;type\&#34; : \&#34;BMW\&#34; }&#34;; Car car = objectMapper.readValue(json, Car.class);	readValue函数还接受其他形式的输入，例如包含JSON字符串的文件：
Car car = objectMapper.readValue(new File(&#34;src/test/resources/json_car.json&#34;), Car.class); 或者从URL中：
Car car = objectMapper.readValue(new URL(&#34;file:src/test/resources/json_car.json&#34;), Car.class); JsonNode：json的表示对象 或者，可以将JSON解析为JsonNode对象，并用于从特定节点检索数据：]]></description></item><item><title>spring容器</title><link>https://banrenshan.github.io/blog/2022/12/spring%E5%AE%B9%E5%99%A8/</link><pubDate>Fri, 02 Dec 2022 12:02:30 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring%E5%AE%B9%E5%99%A8/</guid><description>1.容器和 Bean 介绍 控制反转也叫依赖注入(DI)，这是一个过程。对象通过下面的方式，知道自己的依赖项：
构造函数参数 工厂方法创建对象时的参数 对象的setter方法参数 然后容器在创建bean时，注入这些依赖。在这个过程中，bean控制着自身的创建，通过类上的构造函数等机制搜索所需的依赖，因此称为控制反转。
org.springframework.beans 和 org.springframework.context 包是 Spring Framework 的 IoC 容器的基础。 BeanFactory 接口管理容器中的bean。 ApplicationContext 是 BeanFactory 的扩展子接口，扩展项如下：
更容易与 Spring 的 AOP 特性集成 消息资源处理（用于国际化） 事件发布 应用层特定上下文，例如用于 Web 应用程序的 WebApplicationContext。 简而言之，BeanFactory 提供了配置框架和基本功能，ApplicationContext 增加了更多企业特定的功能。
在 Spring 中，构成应用程序主干并由 Spring IoC 容器管理的对象称为 bean。 bean 是由 Spring IoC 容器实例化、组装和管理的对象。
2.容器概览 org.springframework.context.ApplicationContext接口表示Spring IoC容器，并负责实例化，配置和组装Bean。 容器通过读取配置元数据获取有关要实例化，配置和组装哪些对象的指令。 配置元数据以XML，Java批注或Java代码表示。 它使您能够表达组成应用程序的对象以及这些对象之间的丰富相互依赖关系。
Spring提供了ApplicationContext接口的几种实现。 在独立应用程序中，通常创建ClassPathXmlApplicationContext或FileSystemXmlApplicationContext的实例。 尽管XML是定义配置元数据的传统格式，但是您可以通过提供少量XML配置来声明性地启用对这些其他元数据格式的支持，从而指示容器将Java注释或代码用作元数据格式。
在大多数应用场景中，不需要显式用户代码即可实例化一个Spring IoC容器的一个或多个实例。 例如，在Web应用程序场景中，应用程序的web.xml文件中配置简单八行样板XML就足够了（请参阅Web应用程序的便捷ApplicationContext实例化）。
下图显示了Spring的工作原理的高级视图。 您的应用程序类与配置元数据结合在一起，以便在创建和初始化ApplicationContext之后，您将拥有一个完全配置且可执行的系统或应用程序。
配置元数据 如上图所示，Spring IoC容器使用一种形式的配置元数据。 此配置元数据表示您作为应用程序开发人员如何告诉Spring容器实例化，配置和组装应用程序中的对象。
传统上，配置元数据以简单直观的XML格式提供，这是本章大部分内容用来传达Spring IoC容器的关键概念和功能的内容。
有关在Spring容器中使用其他形式的元数据的信息，请参见：</description></item><item><title>spring-batch</title><link>https://banrenshan.github.io/blog/2022/12/spring-batch/</link><pubDate>Fri, 02 Dec 2022 11:51:23 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/12/spring-batch/</guid><description>spring batch 核心概念 一个作业有一到多个步骤，每个步骤正好有一个ItemReader、一个ItemProcessor和一个ItemWriter。需要使用JobLauncher启动作业，JobRepository存储关于当前运行作业的元数据。
作业（Job） 作业是封装整个批处理过程的实体。是整个层次结构的顶部，如下图所示：
在SpringBatch中，作业只是步骤实例的容器。它将逻辑上属于一个流的多个步骤组合在一起，并允许配置所有步骤的全局属性，例如可重启性。作业配置包含：
名称 步骤的顺序 作业是否需要重启 对于那些使用Java配置的人，SpringBatch以SimpleJob类的形式提供了作业接口的默认实现，它在作业之上创建了一些标准功能。使用基于java的配置时，可以使用构建器集合来实例化作业，如下例所示：
@Bean public Job footballJob() { return this.jobBuilderFactory.get(&amp;#34;footballJob&amp;#34;) .start(playerLoad()) .next(gameLoad()) .next(playerSummarization()) .build(); } JobInstance JobInstance是job运行时的概念，这样说可能有些抽象。假如我们有个作业A，在每天快要结束的时候运行。那么一月一日运行该job就会创建一个JobInstance,一月二日则会创建一个新的JobInstance。
但是，会有这样的情况，一月一日的JobInstance运行失败了，在一月二日会继续运行这个失败的JobInstance,同时一月二日的JobInstance照旧执行。
因此，JobInstacen可能会多次执行（这是后面的JobExecution概念）。并且在给定时刻只能运行一个对应于特定作业和JobParameters的JobInstance。
JobInstance的定义与要加载的数据完全没有关系。如何加载数据完全取决于ItemReader实现。使用新的JobInstance意味着“从头开始”，而使用现有实例通常意味着“从您停止的地方开始”。
JobParameters 如何区分不同的JobInstance呢？答案：JobParameters。JobParameters对象包含一组用于启动批处理作业的参数。它们可用于识别，甚至在运行期间用作参考数据，如下图所示：
并非所有作业参数都需要用于标识作业实例。默认情况下，它们会这样做。但是，该框架还允许提交带有不影响JobInstance标识的参数的作业。
JobExecution JobExecution是指一次尝试运行作业的技术概念。执行可能以失败或成功结束，但对应的JobInstance不会被视为已完成，除非执行成功完成。假如任务A第一次执行失败，此时JobInstance会被标记会失败，当下次继续执行这个失败的JobInstance时，如果成功了，就会变更JobInstance为成功。
Job定义了什么是作业以及如何执行作业，而JobInstance是一个纯粹的组织对象，用于将执行分组在一起，主要是为了实现正确的重启语义。然而，JobExecution是运行期间实际发生的事情的主要存储机制，它包含许多必须控制和持久化的属性，如下表所示：
属性 定义 Status 指示执行状态的BatchStatus对象。运行时，状态为BatchStatus#STARTED。如果失败，则为BatchStatus#FAILED。如果成功完成，则为BatchStatus#COMPLETED startTime java.util.Date ,表示开始执行的时间，没有执行则为空 endTime java.util.Date,执行结束的时间 exitStatus 执行的结果，空代表还没有结束 createTime java.util.Date,创建的时间 lastUpdated java.util.Date executionContext 属性包，包含在执行之间需要的用户数据。 failureExceptions 作业执行期间遇到的异常列表 这些属性很重要，因为它们是持久化的，可用于完全确定执行状态。例如，如果01-01的EndOfDay作业在晚上9:00执行，但在9:30失败，则在批处理元数据表中创建以下条目：
为了清晰和格式，列名可能已被缩写或删除。
表：BATCH_JOB_INSTANCE
JOB_INST_ID JOB_NAME 1 EndOfDayJob 表：BATCH_JOB_EXECUTION_PARAMS
JOB_EXECUTION_ID TYPE_CD KEY_NAME DATE_VAL IDENTIFYING 1 DATE schedule.Date 2017-01-01 TRUE 表：BATCH_JOB_EXECUTION</description></item><item><title>jdk新特性</title><link>https://banrenshan.github.io/blog/2022/11/jdk%E6%96%B0%E7%89%B9%E6%80%A7/</link><pubDate>Sun, 27 Nov 2022 19:18:43 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/11/jdk%E6%96%B0%E7%89%B9%E6%80%A7/</guid><description><![CDATA[java9 模块化 接口里可以添加私有接口 JAVA 8 对接口增加了默认方法的支持，在 JAVA 9 中对该功能又来了一次升级，现在可以在接口里定义私有方法，然后在默认方法里调用接口的私有方法。
public interface TestInterface { default void wrapMethod(){ innerMethod(); } private void innerMethod(){ System.out.println(&#34;&#34;); } } 匿名内部类也支持钻石（diamond）运算符 JAVA 5 就引入了泛型（generic），到了 JAVA 7 开始支持钻石（diamond）运算符：&lt;&gt;，可以自动推断泛型的类型：
List&lt;Integer&gt; numbers = new ArrayList&lt;&gt;(); 但是这个自动推断类型的钻石运算符可不支持匿名内部类，在 JAVA 9 中也对匿名内部类做了支持：
Comparable&lt;Integer&gt; numbers = new Comparable&lt;&gt;() { // 9之前必须指定泛型 ... } 增强的 try-with-resources JAVA 7 中增加了try-with-resources的支持，可以自动关闭资源：
try (BufferedReader bufferReader = new BufferedReader(...)) { return bufferReader.readLine(); } 但需要声明多个资源变量时，代码看着就有点恶心了，需要在 try 中写多个变量的创建过程：
try (BufferedReader bufferReader0 = new BufferedReader(.]]></description></item><item><title>graphql-spring</title><link>https://banrenshan.github.io/blog/2022/11/graphql-spring/</link><pubDate>Sun, 27 Nov 2022 19:02:13 +0000</pubDate><guid>https://banrenshan.github.io/blog/2022/11/graphql-spring/</guid><description><![CDATA[注解驱动 Spring for GraphQL提供了一个基于注释的编程模型，其中@Controller组件使用注释来声明具有灵活方法签名的处理程序方法，以获取特定GraphQL字段的数据。例如：
@Controller public class GreetingController { @QueryMapping public String hello() { return &#34;Hello, world!&#34;; } } 将此方法绑定到查询，即查询类型下的字段。 如果未在注释上声明，则根据方法名确定查询。 Spring使用RuntimeWiring.Builder将上述处理程序方法注册为名为“hello”的查询graphql.schema.DataFetcher。
AnnotatedControllerConfigurer 检测 @Controller bean 并通过 RuntimeWiring.Builder 将标注的方法注册为 DataFetchers。 它是 RuntimeWiringConfigurer 的一个实现，可以添加到 GraphQlSource.Builder。 Spring Boot 自动将 AnnotatedControllerConfigurer 声明为 bean，并将所有 RuntimeWiringConfigurer bean 添加到 GraphQlSource.Builder 并启用对带注释的 DataFetchers 的支持。
@SchemaMapping @SchemaMapping 注解将方法映射到 GraphQL schema中的字段，并将其声明为该字段的 DataFetcher。 注解可以指定类型名称，以及字段名称：
@Controller public class BookController { @SchemaMapping(typeName=&#34;Book&#34;, field=&#34;author&#34;) public Author getAuthor(Book book) { // ... } } @SchemaMapping 注解也可以省略这些属性，在这种情况下，字段名称默认为方法名称，而类型名称默认为方法参数的简单类名称。 例如，下面默认键入Book和字段author：]]></description></item><item><title>gradle 依赖解析</title><link>https://banrenshan.github.io/blog/1/01/gradle-%E4%BE%9D%E8%B5%96%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://banrenshan.github.io/blog/1/01/gradle-%E4%BE%9D%E8%B5%96%E8%A7%A3%E6%9E%90/</guid><description><![CDATA[依赖解析 Gradle项目声明的每个依赖项都适用于特定范围。例如，一些依赖项应该用于编译源代码，而其他依赖项只需要在运行时可用。Gradle在Configuration的帮助下表示依赖项的范围。每个Configuration都可以用唯一的名称标识。
下面是java 插件的一个示例：
Configuration 配置可以扩展其他配置以形成继承层次结构。子配置拥有父配置声明的整个依赖项集。配置继承被Gradle核心插件（如Java插件）大量使用。例如，testImplementation配置扩展了 implementation 配置。
假设你想写一套烟雾测试。每个烟雾测试都会发出一个HTTP调用来验证web服务端点。作为底层测试框架，项目已经使用了JUnit。您可以定义一个名为smokeTest的新配置，该配置从testImplementation配置扩展，以重用现有的测试框架依赖项。
configurations { smokeTest.extendsFrom testImplementation } dependencies { testImplementation &#39;junit:junit:4.13&#39; smokeTest &#39;org.apache.httpcomponents:httpclient:4.5.5&#39; } 配置是Gradle中依赖关系解决的基本部分。在依赖解析的上下文中，区分消费者和生产者是很有用的。按照这些原则，配置至少具有3种不同的角色：
声明依赖项 作为消费者，解析文件的一组依赖关系 作为一个生产者，暴露工件及其依赖关系，供其他项目使用 例如，为了表示app应用程序依赖于lib库，至少需要一种配置：
configurations { // declare a &#34;configuration&#34; named &#34;someConfiguration&#34; someConfiguration } dependencies { // add a project dependency to the &#34;someConfiguration&#34; configuration someConfiguration project(&#34;:lib&#34;) } 配置可以通过从其他配置扩展来继承依赖关系。现在，请注意，上面的代码没有告诉我们任何有关此配置的预期消费者的信息。特别是，它没有告诉我们如何使用配置。假设lib是一个Java库：它可能会暴露不同的东西，例如它的API、实现或测试装置。根据我们正在执行的任务（根据lib的API编译、执行应用程序、编译测试等），可能需要更改我们如何解析app的依赖关系。为了解决这个问题，您通常会发现伴随配置，它们旨在明确地声明用法：
configurations { // declare a configuration that is going to resolve the compile classpath of the application compileClasspath.extendsFrom(someConfiguration) // declare a configuration that is going to resolve the runtime classpath of the application runtimeClasspath.]]></description></item><item><title>gradle-java</title><link>https://banrenshan.github.io/blog/1/01/gradle-java/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://banrenshan.github.io/blog/1/01/gradle-java/</guid><description><![CDATA[插件的生命周期 Base插件提供了大多数构建通用的一些任务和约定，并为构建添加了一个结构，以提高它们运行方式的一致性。它最重要的贡献是一组生命周期任务，充当其他插件和具体任务的保护伞。
主要任务和声明周期:
clean — Delete: 删除build目录及其子目录下的所有内容，即Project.getBuildDir（）项目属性指定的路径。 check — lifecycle task：插件和构建作者应使用check.dependsOn(*task*)将验证任务（例如运行测试的任务）附加到此生命周期任务。 assemble — lifecycle task：插件和构建作者应该将生成发行版和其他可消费工件的任务附加到此生命周期任务。例如，jar为Java库生成可消费的工件。使用assemble.dependsOn(*task*)将任务附加到此生命周期任务 build — lifecycle task：依赖check, assemble。旨在构建一切，包括运行所有测试、生成生产工件和生成文档。您可能很少直接将具体任务附加到构建中，因为assemble和check通常更合适。 buildConfiguration — task rule： 组装附加到命名配置的那些工件。例如，buildArchives将执行任务，将所有工件绑定到archives 配置。 cleanTask — task rule： 删除任务的输出，例如cleanJar将删除Java插件的JAR任务生成的JAR文件。 base插件没有为依赖项添加配置，但它添加了以下配置：
default: 消费者项目使用的回退配置。假设您的项目B依赖于项目A。Gradle使用一些内部逻辑来确定项目A的哪些工件和依赖项添加到项目B的指定配置中。如果没有其他因素适用-您不必担心这些因素是什么-那么Gradle会回到使用项目A的默认配置中的所有内容。新版本和插件不应使用默认配置！由于向后兼容的原因，它仍然存在。 archives: 项目生产工件的标准配置。 base插件将base扩展添加到项目中。这允许在专用DSL块内配置以下属性:
base { archivesName = &#34;gradle&#34; distsDirectory = layout.buildDirectory.dir(&#39;custom-dist&#39;) libsDirectory = layout.buildDirectory.dir(&#39;custom-libs&#39;) } archivesName : 默认**$project.name** distsDirectory：默认**$buildDir/distributions** ：创建分发存档（即非JAR）的目录的默认名称。 libsDirectory： 默认**$buildDir/libs**： 创建库存档（即JAR）的目录的默认名称。 该插件还为任何扩展AbstractArchiveTask的任务提供以下属性的默认值：
destinationDirectory：对于非JAR归档文件，默认为distsDirectory；对于JAR及其派生文件，例如WAR，默认为libsDirectory。 archiveVersion： 默认为$project.version或unspecified（如果项目没有版本）。 archiveBaseName： 默认值为$archivesBaseName。 构建java项目 Gradle使用约定优于配置的方法来构建基于JVM的项目，该方法借鉴了Apache Maven的一些约定。特别是，它对源文件和资源使用相同的默认目录结构，并与Maven兼容的存储库一起工作。
入门项目 Java项目最简单的构建脚本 先从应用Java Library 插件开始，设置项目版本并选择要使用的Java工具链：]]></description></item><item><title>知识片段</title><link>https://banrenshan.github.io/blog/1/01/%E7%9F%A5%E8%AF%86%E7%89%87%E6%AE%B5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://banrenshan.github.io/blog/1/01/%E7%9F%A5%E8%AF%86%E7%89%87%E6%AE%B5/</guid><description><![CDATA[学习新技术，要抓住以下要点：
技术出现的背景和要解决的问题 （2.5%）
优势和劣势 ,对比已有实现 （5%）
使用的场景，分业务场景和技术场景 （2.5%）
组成部分和关键点 （80%）
底层原理和关键实现 （10%）
java 日志打印之前要检查日志级别 如下面的代码（不正确的）：
LOGGER.info(&#34;the DTO info: {}&#34;, JSON.toJSONString(DTO)); DTO可能是一个大对象，JSON序列化要消耗服务器资源。此时，生产日志级别为warn，也就是说这行代码不会打印，但是却执行了json序列化。解决方案如下：
if(LOGGER.isInfoEnabled()) { LOGGER.info(&#34;the DTO info: {}&#34;, JSON.toJSONString(DTO)); } 不必对所有的logger使用前都要判定日志级别，只对那些可能会损耗性能的开启即可。
mysql IP地址的存储方式 通常，在保存IPv4地址时，一个IPv4最小需要7个字符，最大需要15个字符，所以，使用VARCHAR(15)即可。MySQL在保存变长的字符串时，还需要额外的一个字节来保存此字符串的长度。而如果使用无符号整数来存储，只需要4个字节即可。
mysql&gt; select inet_aton(&#39;192.168.0.1&#39;); +--------------------------+ | inet_aton(&#39;192.168.0.1&#39;) | +--------------------------+ | 3232235521 | +--------------------------+ 1 row in set (0.00 sec) mysql&gt; select inet_ntoa(3232235521); +-----------------------+ | inet_ntoa(3232235521) | +-----------------------+ | 192.168.0.1 | +-----------------------+ 1 row in set (0.00 sec) public class IpLongUtils { /** * 把字符串IP转换成long * * @param ipStr 字符串IP * @return IP对应的long值 */ public static long ip2Long(String ipStr) { String[] ip = ipStr.]]></description></item></channel></rss>